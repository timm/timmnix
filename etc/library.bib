Automatically generated by Mendeley Desktop 1.13.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@inproceedings{petke14,
abstract = {Genetic Improvement (GI) is a form of Genetic$\backslash$nProgramming that improves an existing program. We use$\backslash$nGI to evolve a faster version of a C++ program, a$\backslash$nBoolean satisfiability (SAT) solver called MiniSAT,$\backslash$nspecialising it for a particular problem class, namely$\backslash$nCombinatorial Interaction Testing (CIT), using$\backslash$nautomated code transplantation. Our GI-evolved solver$\backslash$nachieves overall 17percent improvement, making it$\backslash$ncomparable with average expert human performance.$\backslash$nAdditionally, this automatically evolved solver is$\backslash$nfaster than any of the human-improved solvers for the$\backslash$nCIT problem.},
author = {Petke, Justyna and Harman, Mark and Langdon, William B and Weimer, Westley},
booktitle = {Proceedings of the 17th European Conference on Genetic Programming, EuroGP 2014},
keywords = { SBSE, code specialisation, code transplants, evolutionary programming, genetic improvement, genetic programming, software enngineering,SBSE,code specialisation,code transplants,evolutionary programming,genetic algorithms,genetic improvement,genetic programming,software enngineering},
title = {{Using Genetic Improvement \& Code Transplants to Specialise a \{C\}++ Program to a Problem Class}},
url = {http://www0.cs.ucl.ac.uk/staff/J.Petke/papers/Petke\_2014\_EuroGP.pdf},
year = {2014}
}
@book{kol93,
author = {Kolodner, J},
publisher = {Morgan Kaufmann},
title = {{Case-Based Reasoning}},
year = {1993}
}
@incollection{mich93,
author = {Michalski, R S},
booktitle = {Readings in Knowledge Acquisition and Learning: Automatic Construction and Improvement of Expert System},
editor = {Buchanan, B G and Wilkin, D C},
publisher = {Morgan Kaufmann Publishers},
title = {{Toward a Unified Theory of Learning: Multistrategy Task-adaptive Learning}},
year = {1993}
}
@inproceedings{druzdel94,
author = {Druzdzel, M J},
booktitle = {Proceedings of the Tenth Annual Conference on Uncertainty in Artificial Intelligence (UAI-94)},
pages = {187--194},
title = {{Some properties of joint probability distributions}},
year = {1994}
}
@inproceedings{me96l,
author = {Ramakrishnan, S and Menzies, T and Hasslinger, M and Bok, P and Mccarthy, H and Devakadadcham, B and Moulder, D},
booktitle = {Proceedings of Tools-Pacific, Melbourne},
publisher = {Prentice-Hall},
title = {{On Building an Effective Measurement System for OO Software Process}},
year = {1996}
}
@article{Liu2004a,
author = {Liu, H and Motoda, H and Yu, L},
doi = {10.1016/j.artint.2004.05.009},
file = {:Users/timm/svns/doc/Liu04.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {ac,asu,corresponding author,dimensionality reduction,e-mail addresses,edu,feature selection and ranking,h,hliu,jp,learning,leiyu,liu,motoda,osaka-u,sampling,sanken},
month = nov,
number = {1-2},
pages = {49--74},
title = {{A selective sampling approach to active feature selection}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370204000980},
volume = {159},
year = {2004}
}
@article{Demsar2007,
abstract = {Visualization can largely improve biomedical data analysis. It plays a crucial role in explorative data analysis and may support various data mining tasks. The paper presents FreeViz, an optimization method that finds linear projection and associated scatterplot that best separates instances of different class. In a single graph, the resulting FreeViz visualization can provide a global view of the classification problem being studied, reveal interesting relations between classes and features, uncover feature interactions, and provide information about intra-class similarities. The paper gives mathematical foundations of FreeViz, and presents its utility on various biomedical data sets. Â© 2007 Elsevier Inc. All rights reserved.},
author = {Dem\v{s}ar, Janez and Leban, Gregor and Zupan, Bla\v{z}},
doi = {10.1016/j.jbi.2007.03.010},
file = {:Users/timm/svns/doc/2007-Demsar.pdf:pdf},
isbn = {1532-0480 (Electronic)$\backslash$n1532-0464 (Linking)},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Explorative data analysis,Intelligent visualisation,Multivariate visualization,Projection search for supervised data},
number = {6},
pages = {661--671},
pmid = {17531544},
title = {{FreeViz-An intelligent multivariate visualization approach to explorative analysis of biomedical data}},
volume = {40},
year = {2007}
}
@misc{fowl02,
author = {Fowler, Martin},
title = {{The New Methodology}},
year = {2002}
}
@article{Kononenko97,
annote = {Available from $\backslash$url\{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.4740\}},
author = {Kononenko, Igor and Simec, Edvard and Sikonja, Marko Robnik-},
journal = {Applied Intelligence},
pages = {39--55},
title = {{Overcoming the myopia of inductive learning algorithms with RELIEFF}},
volume = {7},
year = {1997}
}
@article{mi90,
author = {Mi, P and Scacchi, W},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = sep,
pages = {283--294},
title = {{A Knowledge-Based Environment for Modeling and Simulation Software Engineering Processes}},
year = {1990}
}
@book{camp70,
author = {Campbell, D T and Stanley, J C},
publisher = {Rand McNally \& Company},
title = {{Experimental and Quasi-Experimental Designs for Research}},
year = {1970}
}
@inproceedings{iwasaki88,
author = {Iwasaki, Y},
booktitle = {Proceedings of AAAI '88},
pages = {313--318},
title = {{Causal Ordering in a Mixed Structure}},
year = {1988}
}
@inproceedings{gerth95,
author = {Gerth, R and Peled, D and Vardi, M and Wolper, P},
booktitle = {Proc. PSTV 1995 Conference, Warsaw, Poland},
title = {{Simple on-the-fly automatic verification of linear temporal logic}},
year = {1995}
}
@inproceedings{me07f,
address = {New York, NY, USA},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07casease-v0.pdf\}},
author = {Menzies, T and Elrawas, O and Hihn, J and Feathear, M and Boehm, B and Madachy, R},
booktitle = {ASE '07: Proceedings of the twenty-second IEEE/ACM international conference on Automated software engineering},
doi = {http://doi.acm.org/10.1145/1321631.1321676},
isbn = {978-1-59593-882-4},
pages = {303--312},
publisher = {ACM},
title = {{The Business Case for Automated Software Engineerng}},
year = {2007}
}
@incollection{sch92,
author = {Schreiber, A T and Wielinga, B J and Akkermans, J M},
booktitle = {Formal Methods for Knowledge Modeling in the CommonKADS Methodology: A Compilation (KADS-EE/T1.2/TR/ECN/014/1.0)},
editor = {Balder, J and Akkermans, H},
pages = {53--90},
publisher = {Netherlands Energy Research Foundation},
title = {{Using \{KADS\} to \{A\}nalyse \{P\}roblem \{S\}olving \{M\}ethods}},
year = {1992}
}
@article{tidhar98,
author = {Tidhar, G and Heinze, C and Selvestrel, M},
journal = {Applied Intelligence},
number = {3},
pages = {195--218},
title = {{Flying together: Modelling air mission teams}},
volume = {8},
year = {1998}
}
@article{Jagannathana,
author = {Jagannathan, Geetha and Wright, Rebecca N},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Jagannathan, Wright - Unknown - Privacy-Preserving Distributed -Means Clustering over Arbitrarily Partitioned Data.pdf:pdf},
journal = {Technology},
title = {{Privacy-Preserving Distributed -Means Clustering over Arbitrarily Partitioned Data}}
}
@article{sen12,
author = {Sen, Arun and Ramamurthy, K (Ram) and Sinha, Atish P},
journal = {IEEE Transactions on Software Engineering},
number = {2},
pages = {336--353},
title = {{A Model of Data Warehousing Process Maturity}},
volume = {38},
year = {2012}
}
@inproceedings{dabney06,
annote = {Available from $\backslash$url\{http://promisedata.org/pdf/phil2006DabneyBarberOhi.pdf\}},
author = {Dabney, J B and Barber, G and Ohi, D},
booktitle = {Proceedings of the PROMISE workshop, 2006},
title = {{Predicting Software Defect Function Point Ratios Using a Bayesian Belief Network}},
year = {2006}
}
@article{Hann2004,
abstract = {Lipinski and others, through concepts such as drug-likeness, re-focussed drug discovery back to the principles of medicinal chemistry in the high-throughput era as key to reducing attrition. More recently, the need to go further in defining what makes a good lead has been recognised with the concept of leadlikeness. Leadlikeness implies cut-off values in the physico-chemical profile of chemical libraries such that they have reduced complexity (e.g. MW below <400) and other more restricted properties. We examine these concepts in the context of Virtual (theoretically possible), Tangible (chemically feasible) and Real (physically available) worlds of molecules. In a thought experiment, we take the HTS concept to the extreme: screening an estimated 60 million 'Global Collection' on 5000 targets and realising that perhaps millions of drug candidates might be found that could not possibly be handled in reality. Sampling of the Virtual and Tangible worlds is therefore a necessity. We show that the world of Reals is significantly under-sampled as the MW of compounds increases. This supports the design and screening of 'reduced complexity' (leadlike) compound libraries, preferably with synthetic handles available for rapid chemical iteration and detected as interesting by careful screening or biophysical assays.},
author = {Hann, Mike M. and Oprea, Tudor I.},
doi = {10.1016/j.cbpa.2004.04.003},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Hann\_Oprea\_Leadlike\_COCHBI2004.pdf:pdf},
isbn = {1367-5931 (Print)},
issn = {13675931},
journal = {Current Opinion in Chemical Biology},
keywords = {ACD,Available Chemicals Directory,HAC,HAM,HDO,HTS,MDDR,MDL Drug Data Report,RNG,RO5,RTB,VTR,high-activity molecule,high-throughput screening,hydrogen bond acceptors,hydrogen bond donors,number of rings,rotatable bonds,rule of fives},
number = {3},
pages = {255--263},
pmid = {15183323},
title = {{Pursuing the leadlikeness concept in pharmaceutical research}},
volume = {8},
year = {2004}
}
@article{brady10a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/10w0.pdf\}},
author = {Brady, Adam and Menzies, Tim and El-Rawas, Oussama and Kocaguneli, Ekrem and Keung, Jacky},
journal = {Journal of Software Engineering and Applications},
title = {{Case-Based Reasoning for Reducing Software Development Effort}},
volume = {3},
year = {2010}
}
@inproceedings{coarfa00,
annote = {Availabe from $\backslash$url\{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.3662\}},
author = {Coarfa, Cristian and Demopoulos, Demetrios D and San, Alfonso and Aguirre, Miguel and Subramanian, Devika and Vardi, Moshe Y},
booktitle = {In Principles and Practice of Constraint Programming},
pages = {143--159},
title = {{Random 3-SAT: The plot thickens}},
year = {2000}
}
@inproceedings{hori98,
author = {Hori, M and Yoshida, T},
booktitle = {Submitted to the Banff KA workshop, 1998.},
title = {{Measuring the evolution of a knowledge library: Assessment study}},
year = {1998}
}
@inproceedings{Basili01cebase,
author = {Basili, Victor and Tesoriero, Roseanne and Costa, Patricia and Lindvall, Mikael and Rus, Ioana and Shull, Forrest and Zelkowitz, Marvin},
booktitle = {in Profes (Product Focused Software Process Improvement},
pages = {110--125},
title = {{Building an Experience Base for Software Engineering: A report on the first CeBASE eWorkshop}},
year = {2001}
}
@inproceedings{me91a,
author = {Compton, P and Edwards, G and Kang, B and Lazarus, L and Malor, R and Menzies, T and Preston, P and Srinivasan, A and Sammut, C},
booktitle = {6th Banff AAAI Knowledge Acquisition for Knowledge Based Systems},
title = {{Ripple down rules: possibilities and limitations}},
year = {1991}
}
@inproceedings{APS93,
author = {Agesen, O and Palsberg, J and Schwartzbach, M},
booktitle = {ECOOP'93, Seventh European Conference on Object-Oriented Programming},
pages = {329--349},
publisher = {Springer-Verlag},
title = {{Analysis of Objects with Dynamic and Multiple Inheritance}},
year = {1993}
}
@inproceedings{level89,
author = {Levesque, H},
booktitle = {\{IJCAI\} '89},
pages = {1061--1067},
title = {{A \{K\}nowledge-\{L\}evel \{A\}ccount of \{A\}bduction (\{P\}reliminary \{V\}ersion)}},
volume = {2},
year = {1989}
}
@article{mukho92,
author = {Mukhopadhyay, T and Vicinanza, S S and Prietula, M J},
journal = {MIS Quarterly},
month = jun,
pages = {155--171},
title = {{Examining the Feasibility of a Case-based Reasoning Tool for Software Effort Estimation}},
year = {1992}
}
@book{glass02,
author = {Glass, Robert},
isbn = {0321117425},
publisher = {Addison-Wesley},
title = {{Facts and Falllacies of Software Engineering}},
year = {2002}
}
@article{Verhein2008,
author = {Verhein, Florian},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/FPGrowth.pdf:pdf},
journal = {Read},
title = {{Frequent Pattern Growth ( FP-Growth ) Algorithm An Introduction Outline Introduction FP-Tree data structure Step 1 : FP-Tree Construction Step 2 : Frequent Itemset Generation Discussion Introduction uses a generate-and-test approach generates candidate it}},
year = {2008}
}
@inproceedings{jensen83,
author = {Jensen, R},
booktitle = {5th ISPA Conference},
month = apr,
pages = {88--92},
title = {{An Improved Macrolevel Software Development Resource Estimation Model}},
year = {1983}
}
@misc{me97s,
author = {Menzies, T J},
title = {{Evaluation Issues for Problem Visual Programming Languages}},
year = {1998}
}
@article{turhan12,
author = {Turhan, Burak},
journal = {Empirical Software Engineering},
number = {1},
pages = {62--74},
publisher = {Springer Netherlands},
title = {{On the dataset shift problem in software engineering prediction models}},
volume = {17},
year = {2012}
}
@article{dijkstra68,
annote = {letter to the Editor},
author = {Dijkstra, Edsger W},
journal = {Comm. ACM},
number = {3},
pages = {147--148},
title = {{Go \{T\}o statement considered harmful}},
volume = {11},
year = {1968}
}
@article{cohen98,
author = {Cohen, Paul and Schrag, Robert and Jones, Eric and Pease, Adam and Lin, Albert and Starr, Barbara and Gunning, David and Burke, Murray},
journal = {AI Magazine},
number = {4},
pages = {25--49},
title = {{The DARPA High-Performance Knowledge Bases Project}},
volume = {19},
year = {1998}
}
@article{Song2010a,
author = {Song, Qinbao and Jia, Zihan and Shepperd, Martin and Ying, Shi and Liu, Jin},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework.pdf:pdf},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {machine learning,scheme evaluation,software defect prediction,software defect-proneness prediction},
number = {X},
pages = {1--16},
publisher = {Published by the IEEE Computer Society},
title = {{A General Software Defect-Proneness Prediction Framework}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/TSE.2010.90},
volume = {X},
year = {2010}
}
@article{Garcia-Nieto2012,
author = {Garcia-Nieto, Jos\'{e} and Alba, Enrique},
doi = {10.1145/2330163.2330168},
file = {:Users/timm/svns/doc/pso/12pso6.pdf:pdf},
isbn = {9781450311779},
journal = {\ldots of the Fourteenth International Conference on \ldots},
keywords = {distance correlation,fitness-,fitness-fitness cloud,fully informed pso,particle swarm optimization},
pages = {25},
title = {{Why six informants is optimal in PSO}},
url = {http://dl.acm.org/citation.cfm?doid=2330163.2330168$\backslash$nhttp://dl.acm.org/citation.cfm?id=2330168},
year = {2012}
}
@book{neilson93,
author = {Nielson, J},
publisher = {Academic Press},
title = {{Usability Engineering}},
year = {1993}
}
@article{okeefe93,
author = {O'Keefe, R M and O'Leary, D E},
journal = {Artificial Intelligence Review},
pages = {3--42},
title = {{Expert system verification and validation: a survey and tutorial}},
volume = {7},
year = {1993}
}
@article{Peyton2007a,
author = {Peyton, Liam and Hu, Jun and Doshi, Chintan and Seguin, Pierre},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Peyton et al. - 2007 - Addressing Privacy in a Federated Identity Management Network for E- Health.pdf:pdf},
journal = {Management},
number = {WCMeB},
title = {{Addressing Privacy in a Federated Identity Management Network for E- Health}},
year = {2007}
}
@inproceedings{me09n,
abstract = {The mantra of the PROMISE series is "repeatable, improvable, maybe refutable" software engineering experiments. This community has successfully created a library of reusable software engineering data sets. The next challenge in the PROMISE community will be to not only share data, but to share experiments. Our experience with existing data mining environments is that these tools are not suitable for publishing or sharing repeatable experiments. OURMINE is an environment for the development of data mining experiments. OURMINE offers a succinct notation for describing experiments. Adding new tools to OURMINE, in a variety of languages, is a rapid and simple process. This makes it a useful research tool. Complicated graphical interfaces have been eschewed for simple command-line prompts. This simplifies the learning curve for data mining novices. The simplicity also encourages large scale modification and experimentation with the code. In this paper, we show the OURMINE code required to reproduce a recent experiment checking how defect predictors learned from one site apply to another. This is an important result for the PROMISE community since it shows that our shared repository is not just a useful academic resource. Rather, it is a valuable resource industry: companies that lack the local data required to build those predictors can use PROMISE data to build defect predictors.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09ourmine.pdf\}},
author = {Gay, Gregory and Menzies, Tim and Cukic, Bojan and Turhan, Burak},
booktitle = {Proceedings of the 5th International Conference on Predictor Models in Software Engineering - PROMISE '09},
doi = {10.1145/1540438.1540460},
isbn = {9781605586342},
keywords = {algorithms,development of data mining,envi-,experimentation,measurement,of powerful open-source development,platforms also came the,with the recent rise},
pages = {1},
title = {{How to build repeatable experiments}},
url = {http://portal.acm.org/citation.cfm?doid=1540438.1540460},
year = {2009}
}
@article{pearson1901,
author = {Pearson, K},
journal = {Philosophical Magazine},
pages = {559--572},
title = {{On lines and planes of closest fit to systems of points in space}},
volume = {2},
year = {1901}
}
@inproceedings{bandekar89,
author = {Bandekar, V R},
booktitle = {Artifical Intelligence in Engineering},
number = {2},
title = {{Causal Models for Diagnostic Reasoning}},
volume = {4},
year = {1989}
}
@article{Kok2010,
author = {Kok, Stanley and Domingos, Pedro},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Kok, Domingos - 2010 - Learning Markov Logic Networks Using Structural Motifs.pdf:pdf},
journal = {Learning},
title = {{Learning Markov Logic Networks Using Structural Motifs}},
year = {2010}
}
@article{Basha2010,
abstract = {Reliable effort estimation remains an ongoing challenge to software engineers. Accurate effort estimation is the state of art of software engineering, effort estimation of software is the preliminary phase between the client and the business enterprise. The relationship between the client and the business enterprise begins with the estimation of the software. The credibility of the client to the business enterprise increases with the accurate estimation. Effort estimation often requires generalizing from a small number of historical projects. Generalization from such limited experience is an inherently under constrained problem. Accurate estimation is a complex process because it can be visualized as software effort prediction, as the term indicates prediction never becomes an actual. This work follows the basics of the empirical software effort estimation models. The goal of this paper is to study the empirical software effort estimation. The primary conclusion is that no single technique is best for all situations, and that a careful comparison of the results of several approaches is most likely to produce realistic estimates.},
archivePrefix = {arXiv},
arxivId = {1004.1239},
author = {Basha, Saleem and Ponnurangam, Dhavachelvan},
eprint = {1004.1239},
file = {:Users/timm/svns/doc/cost/10Saleem.pdf:pdf},
keywords = {-software estimation,wilcoxon signed-rank test},
number = {3},
title = {{Analysis of Empirical Software Effort Estimation Models}},
url = {http://arxiv.org/abs/1004.1239},
volume = {7},
year = {2010}
}
@inproceedings{myers81,
author = {Myers, E},
booktitle = {Conference Record of the Eighth Annual Symposium on Principles of Programming Languages},
month = jan,
title = {{A precise inter-procedural data flow algorithm}},
year = {1981}
}
@inproceedings{craven98,
author = {Craven, M and DiPasquo, D and Freitag, D and McCallum, A and Mitchell, T and Nigam, K and Slattery, S},
booktitle = {AAAI-98},
title = {{Learning to Extract Symbolic Knowledge from the World Wide Web}},
year = {1998}
}
@inproceedings{fea02a,
abstract = {Planning for the optimal attainment of requirements is an important early lifecycle activity. However, such planning is difficult when dealing with competing requirements, limited resources, and the incompleteness of information available at requirements time. A novel approach to requirements optimization is described. A requirements interaction model is executed to randomly sample the space of options. This produces a large amount of data, which is then condensed by a summarization tool. The result is a small list of critical decisions (i.e., those most influential in leading towards the desired optimum). This focuses human experts' attention on a relatively few decisions and makes them aware of major alternatives. This approach is iterative. Each iteration allows experts to select from among the major alternatives. In successive iterations the execution and summarization modules are run again, but each time further constrained by the decisions made in previous iteration. In the case study shown here, out of 99 yes/no decisions (approximately 10<sup>30</sup> possibilities), five iterations were sufficient to find and make the 30 key ones.},
author = {Feather, M.S. and Menzies, T.},
booktitle = {Proceedings IEEE Joint International Conference on Requirements Engineering},
doi = {10.1109/ICRE.2002.1048537},
isbn = {0-7695-1465-0},
issn = {1090-705X},
title = {{Converging on the optimal attainment of requirements}},
year = {2002}
}
@article{buntine98,
author = {Buntime, W},
journal = {IEEE Intelligent Systems},
pages = {9--15},
title = {{Will Domain-Specific Code Syhthsis Become a Silver Bullet?}},
year = {1998}
}
@inproceedings{sayyad13a,
author = {Sayyad, Abdel Salam and Menzies, Tim and Ammar, Hany},
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
file = {:Users/timm/svns/doc/13ibea.pdf:pdf},
pages = {492--501},
series = {ICSE '13},
title = {{On the Value of User Preferences in Search-based Software Engineering: A Case Study in Software Product Lines}},
year = {2013}
}
@article{Japkowicz2000,
author = {Japkowicz, N},
file = {:Users/timm/svns/doc/09imbalanced.pdf:pdf},
journal = {Papers from AAAI Workshop},
number = {9},
pages = {10--15},
title = {{Learning from Imbalanced Data Sets.}},
url = {http://www.aaai.org/Papers/Workshops/2000/WS-00-05/WS00-05-003.pdf},
volume = {21},
year = {2000}
}
@inproceedings{huan06,
author = {Cleland-Huang, J and Settimi, R and Zou, X and Solc, P},
booktitle = {RE 2006},
pages = {36--45},
title = {{The Detection and Classification of Non-Functional Requirements with Application to Early Aspects}},
year = {2006}
}
@article{shepperd01,
author = {Shepperd, M and Kadoda, Gada F},
journal = {IEEE Trans. Software Eng},
number = {11},
pages = {1014--1022},
title = {{Comparing Software Prediction Techniques Using Simulation}},
volume = {27},
year = {2001}
}
@article{evanco03,
author = {Evanco, William M},
journal = {IEEE Transactions on Software Engineering},
month = jul,
pages = {670--672},
title = {{Comments on 'The Confounding Effect of Class Size on the Validity of Object-Oriented Metrics$\backslash$'}},
year = {2003}
}
@article{Musen2013,
abstract = {Intense interest in knowledge-acquisition research began 25 years ago, stimulated by the excitement about knowledge-based systems that emerged in the 1970s followed by the realities of the AI Winter that arrived in the 1980s. The knowledge-acquisition workshops that responded to this interest led to the formation of a vibrant research community that has achieved remarkable consensus on a number of issues. These viewpoints include (1) the rejection of the notion of knowledge as a commodity to be transferred from one locus to another, (2) an acceptance of the situated nature of human expertise, (3) emphasis on knowledge acquisition as the modeling of problem solving, and (4) the pursuit of reusable patterns in problem solving and in domain descriptions that can facilitate both modeling and system implementation. The Semantic Web community will benefit greatly by incorporating these perspectives in its work. ?? 2012 Elsevier Ltd.},
author = {Musen, Mark a.},
doi = {10.1016/j.ijhcs.2012.10.011},
file = {:Users/timm/svns/doc/25YearsofKaw.pdf:pdf},
issn = {10715819},
journal = {International Journal of Human Computer Studies},
keywords = {Knowledge acquisition,Knowledge-based systems,Semantic web,Workshops and conferences},
number = {2},
pages = {195--199},
publisher = {Elsevier},
title = {{The knowledge acquisition workshops: A remarkable convergence of ideas}},
url = {http://dx.doi.org/10.1016/j.ijhcs.2012.10.011},
volume = {71},
year = {2013}
}
@misc{seer-sem,
annote = {$\backslash$url\{http://www1.jsc.nasa.gov/bu2/PCEHHTML/pceh225.htm\}},
author = {of USA, DoD},
title = {{Parametric Cost Estimating Handbook, second Edition}},
year = {1999}
}
@article{campbell82,
author = {Campbell, A N and Hollister, V F and Duda, R O and Hart, P E},
journal = {Science},
pages = {927--929},
title = {{Recognition of a \{H\}idden \{M\}aterial \{D\}eposit by and \{A\}rtificially \{I\}ntelligent \{P\}rogram}},
volume = {217},
year = {1982}
}
@inproceedings{marcus10,
author = {Marcus, A and Menzies, Tim},
booktitle = {FoSER 2010},
month = nov,
title = {{Software is Data Too}},
year = {2010}
}
@misc{rush88,
annote = {SRI-CSL-88-7R, SRI Project 4616},
author = {Rushby, J},
title = {{Quality Measures and Assurance for AI Software}},
year = {1988}
}
@inproceedings{fenton07a,
annote = {Available from $\backslash$url\{http://promisedata.org/pdf/mpls2007FentonNeilMarshHeartyRadlinskiKrause.pdf\}},
author = {Fenton, Norman and Neil, Martin and Marsh, William and Hearty, Peter and Radlinski, Lukasz and Krause, Paul},
booktitle = {PROMISE'09},
title = {{Project Data Incorporating Qualitative Factors for Improved Software Defect Prediction}},
year = {2007}
}
@book{tansley93,
author = {Tansley, D S W and Hayball, C C},
pages = {528},
publisher = {Prentice-Hall},
title = {{Knowledge-Based Systems Analysis and Design}},
year = {1993}
}
@article{smith96,
author = {Smith, B and Dyer, M},
journal = {Artificial Intelligence},
number = {1-2},
pages = {155--181},
title = {{Locating the Phase Transition in Binary Constraint Satisfaction Problems}},
volume = {81},
year = {1996}
}
@misc{parkes99lifted,
author = {Parkes, A},
title = {{Lifted Search Engines for Satisfiability}},
url = {citeseer.nj.nec.com/parkes99lifted.html},
year = {1999}
}
@inproceedings{Mac06,
author = {Machanavajjhala, Ashwin and Gehrke, Johannes and Kifer, Daniel and Venkitasubramaniam, Muthuramakrishnan},
booktitle = {ICDE},
pages = {24},
title = {{l-Diversity: Privacy Beyond k-Anonymity}},
year = {2006}
}
@article{Cooper1992,
author = {Cooper, Gregory F and Herskovits, Edward},
doi = {10.1023/A:1022649401552},
file = {:Users/timm/svns/doc/02k2.pdf:pdf},
isbn = {0885-6125},
issn = {0885-6125},
journal = {Mach. Learn.},
keywords = {Bayesian belief networks,induction,machine learning,probabilistic networks},
number = {4},
pages = {309--347},
title = {{A Bayesian Method for the Induction of Probabilistic Networks from Data}},
url = {http://dx.doi.org/10.1023/A:1022649401552},
volume = {9},
year = {1992}
}
@phdthesis{clark05,
author = {Clark, R},
title = {{Faster Treatment Learning, \{C\}omputer \{S\}cience, \{P\}ortland \{S\}tate \{U\}niversity}},
year = {2005}
}
@book{kuhn62,
author = {Kuhn, T},
publisher = {Cambridge Press},
title = {{The Structure of Scientific Revolutions}},
year = {1962}
}
@inproceedings{zdrahal94,
author = {Zdrahal, Z and Motta, E},
booktitle = {Proceedings of the Third Japanese Knowledge Acquisition for Knowledge-Based Systems Workshop: \{JKAW\} '94},
editor = {Mizoguchi, R and Motoda, H and Boose, J and Gaines, B and Compton, P},
organization = {Japanese \{AI\} Society},
title = {{An \{I\}n-\{D\}epth \{A\}nalysis of \{P\}ropose \& \{R\}evise \{P\}roblem \{S\}olving \{M\}ethods}},
year = {1994}
}
@book{sch99,
editor = {Schreiber, Guus},
isbn = {0262193000},
publisher = {MIT Press},
title = {{Knowledge Engineering and Management : The CommonKADS Methodology}},
year = {1999}
}
@inproceedings{Siskind1993,
abstract = {nondeterministic lisp as a substrate for constraint logic programming},
author = {Siskind, JM},
booktitle = {PROCEEDINGS OF THE NATIONAL},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Siskind - 1993 - nondeterministic lisp as a substrate for constraint logic programming.pdf:pdf},
keywords = {nondeterministic lisp as a substrate for constrain},
mendeley-tags = {nondeterministic lisp as a substrate for constrain},
title = {nondeterministic lisp as a substrate for constraint logic programming},
url = {http://www.aaai.org/Library/AAAI/1993/aaai93-021.php},
year = {1993}
}
@inproceedings{kerth95,
author = {Kerth, N},
booktitle = {Pattern Languages of Program Design},
editor = {Coplien, J and Schmidt, D},
publisher = {Addison-Wesley},
title = {{Caterpillar's Fate: A Pattern Language for Transformation from Analysis to Design}},
year = {1995}
}
@inproceedings{Rushby:Tutorial,
address = {Bad Herrenalb, Germany},
author = {{S. Owre} and {J.M. Rushby} and {N. Shankar} and {M.K. Srivas}},
booktitle = {Proc. 2nd International Conference on Theorem Provers in Circuit Design (TPCD94)},
editor = {{T. Kropf} and {R. Kumar}},
pages = {258--279},
publisher = {Springer-Verlag},
title = {{A Tutorial on Using \{PVS\} for Hardware Verification}},
url = {citeseer.nj.nec.com/owre95tutorial.html},
volume = {901},
year = {1994}
}
@inproceedings{holmes10,
author = {Holmes, Reid and Robillard, Martin P and Walker, Robert J and Zimmermann, Thomas},
booktitle = {Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 2},
pages = {455--456},
publisher = {ACM},
series = {ICSE '10},
title = {{RSSE 2010: Second International Workshop on Recommendation Systems for Software Engineering}},
year = {2010}
}
@misc{me02j,
author = {T.Menzies},
institution = {Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{V and V of adaptive systems}},
year = {2002}
}
@inproceedings{jurjens06,
address = {New York, NY, USA},
author = {Jerjens, Jan and Fox, Jorge},
booktitle = {ICSE '06: Proceeding of the 28th international conference on Software engineering},
doi = {http://doi.acm.org.proxy.lib.muohio.edu/10.1145/1134285.1134423},
isbn = {1-59593-375-1},
pages = {819--822},
publisher = {ACM Press},
title = {{Tools for model-based security engineering}},
year = {2006}
}
@incollection{hameco95,
author = {Haynes, P and Menzies, T and Cohen, R F},
chapter = {Visualisat},
publisher = {World-Scientific},
title = {{Software Visualization}},
year = {1997}
}
@book{hof81,
author = {Hofstader, D R and Dennett, D C},
title = {{The Mind's I}},
year = {1981}
}
@article{Zabiht1987a,
author = {Zabiht, Ramin and Mcallester, David and Chapman, David},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zabiht, Mcallester, Chapman - 1987 - Non-Deterministic Lisp with Backtracking.pdf:pdf},
journal = {In Practice},
pages = {59--64},
title = {{Non-Deterministic Lisp with Backtracking}},
year = {1987}
}
@article{Menzies2013,
author = {Menzies, Tim and Butcher, Andrew and Cok, David},
doi = {http://dx.doi.org/10.1109/TSE.2012.83},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/gense-v13.pdf:pdf},
journal = {Software Engineering, IEEE Transactions on},
number = {6},
pages = {822 -- 834},
title = {{Local versus Global Lessons for Defect Prediction and Effort Estimation}},
volume = {39},
year = {2013}
}
@inproceedings{Zweben1992,
author = {Zweben, S},
booktitle = {Experimental Software Engineering Issues, International Workshop, Rombach and Basili and Selby (Eds.), LNCS 706, Springer-Verlag},
pages = {247--251},
title = {{Effective Use of Measurement and Experimentation in Computing Curricula}},
year = {1992}
}
@inproceedings{owen02a,
author = {Owen, D and Menzies, T and Cukic, B},
booktitle = {IEEE Conference on Automated Software Engineering (ASE '02)},
title = {{What Makes Finite-State Models more (or less) Testable?}},
year = {2002}
}
@misc{orourke90,
annote = {September 27, 1990},
author = {O'Rourke, P},
institution = {University of California, Irvine, CA.},
number = {90-32},
title = {{Working Notes of the 1990 Spring Symposium on Automated Abduction}},
year = {1990}
}
@inproceedings{don99,
author = {Dondossola, G},
booktitle = {Validation and Verication of Knowledge Based Systems: Theory, Tools and Practice},
editor = {Vermesan, A and Coenen, F},
isbn = {0-7923-8645-0},
pages = {113--130},
publisher = {Kluwer Academic Publishing, Utrecht, Netherlands},
title = {{Formal Method for Engineering and Certification of Safety-Critical Knowledge Based Systems}},
year = {1999}
}
@article{boda85,
author = {Boehm-Davis, D A and Fregly, A M},
journal = {Human Factors},
pages = {423--432},
title = {{Documentation of Concurrent Programs}},
volume = {27},
year = {1985}
}
@article{Kralj2009,
abstract = {This paper gives a survey of contrast set mining (CSM), emerging pattern mining (EPM), and subgroup
discovery (SD) in a unifying framework named supervised descriptive rule discovery. While
all these research areas aim at discovering patterns in the form of rules induced from labeled data,
they use different terminology and task definitions, claim to have different goals, claim to use different
rule learning heuristics, and use different means for selecting subsets of induced patterns.
This paper contributes a novel understanding of these subareas of data mining by presenting a unified
terminology, by explaining the apparent differences between the learning tasks as variants of
a unique supervised descriptive rule discovery task and by exploring the apparent differences between
the approaches. It also shows that various rule learning heuristics used in CSM, EPMand SD
algorithms all aim at optimizing a trade off between rule coverage and precision. The commonalities
(and differences) between the approaches are showcased on a selection of best known variants
of CSM, EPM and SD algorithms. The paper also provides a critical survey of existing supervised
descriptive rule discovery visualization methods.},
author = {Kralj, Petra and Lavrac, Nada and Webb, Geoff},
doi = {10.1145/1577069.1577083},
file = {:Users/timm/svns/doc/kralj-novak09a.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
keywords = {Theory \& Algorithms},
pages = {377--403},
title = {{Supervised Descriptive Rule Discovery: A Unifying Survey of Contrast Set, Emerging Pattern and Subgroup Mining}},
url = {http://eprints.pascal-network.org/archive/00005127/},
volume = {10},
year = {2009}
}
@article{KULTUR2009,
address = {Amsterdam, The Netherlands, The Netherlands},
author = {Kultur, Yigit and Turhan, Burak and Bener, Ayse},
doi = {http://dx.doi.org/10.1016/j.knosys.2009.05.001},
issn = {0950-7051},
journal = {Know.-Based Syst.},
number = {6},
pages = {395--402},
publisher = {Elsevier Science Publishers B. V.},
title = {{Ensemble of neural networks with associative memory (ENNA) for estimating software development costs}},
volume = {22},
year = {2009}
}
@article{jorgensen07,
author = {J\o rgensen, M and Shepperd, M},
file = {:Users/timm/svns/doc/cost/07Jorgensen.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
month = jan,
pages = {33--53},
title = {{A Systematic Review of Software Development Cost Estimation Studies}},
year = {2007}
}
@misc{She02,
author = {Shepperd, M J},
institution = {Bournemouth University, UK},
number = {TR02-08},
title = {{Case-based Reasoning and Software Engineering}},
year = {2002}
}
@article{Hippocratic2007a,
author = {Hippocratic, Leveraging and Technology, Database},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Hippocratic, Technology - 2007 - Privacy in eHealth Why Should I Worry About Privacy Compliance with Data Protection Laws.pdf:pdf},
journal = {Information Security},
title = {{Privacy in eHealth : Why Should I Worry About Privacy ? Compliance with Data Protection Laws}},
year = {2007}
}
@article{SM91,
author = {Sugiyama, K and Misue, K},
journal = {IEEE Transactions on Systems, Man and Cybernetics},
number = {4},
pages = {876--892},
title = {{Visualization of structural information: Automatic drawing of compound digraphs}},
volume = {21},
year = {1991}
}
@article{kampenes07,
author = {Kampenes, Vigdis By and Dyb\aa, Tore and Hannay, Jo Erskine and Sj\o berg, Dag I K},
file = {:Users/timm/svns/doc/erin/references/ClusterQuality/EffectSizeKampenes07.pdf:pdf},
journal = {Information \{\&\} Software Technology},
number = {11-12},
pages = {1073--1086},
title = {{A systematic review of effect size in software engineering experiments}},
volume = {49},
year = {2007}
}
@article{Han2000,
abstract = {Mining frequent patterns in transaction databases? time? series databases? and man y other kinds of databases has been studied popularly in data mining researc h? Most of the previous studies adopt an Ap rio ri ?lik e candidate set generation?and?test approac h? Ho ev w er? candidate set generation is still costly ? especially when there exist proli?c patterns and?or long patterns? In this study ?w e propose a no el frequent pattern v tree ?FP?tree ? structure? whic h is an extended pre?x? tree structure for storing compressed? crucial information about frequen t patterns? and dev elop an e?cien t FP?tree? based mining method? FP?gro wth? for mining the c omplete set of fr quent p e atterns b y pattern fragmen t gro wth? E?ciency of mining is ac hiev ed with three tec hniques? ??? a large database is compressed in to a highly condensed? m h smaller data structure? whic uc ha oids costly v ? repeated database scans? ??? our FP?tree ?based mining adopts a pattern fragmen t gro wth method to a oid the costly v generation of a large n um ber of candidate sets? and ??? a partitioning?based? divide?and?conquer method is used to decompose the mining task in to a set of smaller tasks for mining con?ned patterns in conditional databases? whic h dramatically reduces the searc h space? Our performance study sho ws that the FP?gro wth method is e?cien t and scalable for mining both long and short frequen t patterns? and is about an order of magnitude faster than the Ap rio ri algorithm and also faster than some recen tly reported new frequen t pattern mining methods?},
author = {Han, Jiawei and Pei, Jian and Yin, Yiwen},
doi = {10.1145/335191.335372},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/han04.pdf:pdf},
isbn = {1581132182},
issn = {01635808},
journal = {ACM SIGMOD Record},
keywords = {algorithm,and it was supported,association mining,at simon fraser university,canada,data structure,frequent pattern mining,in part by the,natural sciences,performance improvements,the work was done},
number = {2},
pages = {1--12},
pmid = {24075448},
title = {{Mining frequent patterns without candidate generation}},
volume = {29},
year = {2000}
}
@article{buch78,
author = {Buchanan, B G and Feigenbaum, E A},
journal = {Artificial Intelligence},
pages = {5--24},
title = {{DENDRAL and META-DENDRAL: their applications dimensions}},
volume = {11},
year = {1978}
}
@inproceedings{me04g,
author = {Menzies, T and DiStefano, J and Orrego, A and Chapman, R},
booktitle = {Proceedings, workshop on Predictive Software Models, Chicago},
title = {{Assessing Predictors of Software Defects}},
year = {2004}
}
@article{easter91,
author = {Easterbrook, S},
journal = {Knowledge Acquisition},
pages = {255--289},
title = {{Handling conflicts between domain descriptions with computer-supported negotiation}},
volume = {3},
year = {1991}
}
@misc{ratrose,
annote = {$\backslash$url\{http://www.rational.com\}},
author = {Corporation, Rational Software},
title = {{Rational-Rose}},
year = {1997}
}
@book{Tate2010,
author = {Tate, Bruce},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - What Readers Are Saying About Seven Languages in Seven Weeks.pdf:pdf},
publisher = {Pragmatic Programmaers, LLC},
title = {{Seven Languages in Seven Weeks}},
year = {2010}
}
@article{swig89,
author = {Swigger, K M and Brazile, R P},
journal = {International Journal of Man-Machine Studies},
pages = {47--60},
title = {{Experimental Comparisons of Design/Documentation Formats for Expert Systems}},
volume = {31},
year = {1989}
}
@article{ramey94,
annote = {Available from $\backslash$url\{http://tiswww.case.edu/php/chet/bash/rose94.pdf\}},
author = {Ramey, Chet},
title = {{BASH, the Bourne-again Shell}},
year = {1994}
}
@article{Giannella,
archivePrefix = {arXiv},
arxivId = {arXiv:0911.2942v1},
author = {Giannella, Chris R and Liu, Kun and Kargupta, Hillol and Member, Senior},
eprint = {arXiv:0911.2942v1},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Giannella et al. - Unknown - On the Privacy of Euclidean Distance Preserving Data Perturbation.pdf:pdf},
journal = {Science},
pages = {1--46},
title = {{On the Privacy of Euclidean Distance Preserving Data Perturbation}}
}
@article{paulk99,
author = {Paulk, M},
month = jun,
number = {3},
pages = {19--29},
title = {{ASQ Software Quality Professional}},
volume = {1},
year = {1999}
}
@article{noy97,
author = {Noy, N F and Hafner, C D},
journal = {AI Magazines},
pages = {53--74},
title = {{The State of the Art in Ontology Design: A Survey and Comparative Review}},
year = {1997}
}
@article{vandebrug86,
author = {de Brug, A Van and Bachant, J and McDermott, J},
journal = {IEEE Expert},
pages = {33--39},
title = {{The \{T\}aming of \{R1\}}},
year = {1986}
}
@article{Vaidya2003,
author = {Vaidya, Jaideep and Lafayette, West and Clifton, Chris},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Vaidya, Lafayette, Clifton - 2003 - Privacy-Preserving K -Means Clustering over Vertically Partitioned Data.pdf:pdf},
journal = {Security},
title = {{Privacy-Preserving K -Means Clustering over Vertically Partitioned Data}},
year = {2003}
}
@article{ragland95,
author = {Ragland, B},
journal = {Crosstalk},
number = {3},
title = {{Measure, Metric or Indicator: What's the Difference?}},
volume = {8},
year = {1995}
}
@inproceedings{RANA2008,
address = {New York, NY, USA},
author = {Rana, Zeeshan Ali and Shamail, Shafay and Awais, Mian Muhammad},
booktitle = {WoSQ '08: Proceedings of the 6th international workshop on Software quality},
doi = {http://doi.acm.org/10.1145/1370099.1370108},
isbn = {978-1-60558-023-4},
pages = {35--40},
publisher = {ACM},
title = {{Towards a generic model for software quality prediction}},
year = {2008}
}
@article{Technology2010,
author = {Technology, Software and Analysis, Cost},
file = {:Users/timm/svns/doc/cost/10Stsgcahandbook.pdf:pdf},
number = {October},
title = {{Software Development Cost Estimating Guidebook Software Technology Support Center Cost Analysis Group}},
year = {2010}
}
@article{dowl84,
author = {Dowling, W F and Gallier, J H},
journal = {Journal of Logic Programming},
pages = {267--284},
title = {{Linear-time Algorithms for Testing the Satisfiability of Propositional Horn Formulae}},
volume = {3},
year = {1984}
}
@article{ginsberg88,
author = {Ginsberg, A and Weiss, S and Politakis, P},
journal = {Artificial Intelligence},
pages = {197--226},
title = {{Automatic knowledge base refinement for classification systems}},
volume = {35},
year = {1988}
}
@book{moran96,
author = {Moran, T P and Carroll, J M},
publisher = {Lawerence Erlbaum Associates},
title = {{Design Rationale: Concepts, Techniques, and Use}},
year = {1996}
}
@book{white09,
author = {White, Tom},
publisher = {O'Reilly Media},
title = {{Hadoop: The Definitive Guide}},
year = {2009}
}
@article{Bird2009b,
annote = {Social metrics stuff.},
author = {Bird, Christian and Nagappan, Nachiappan and Gall, Harald and Murphy, Brendan and Devanbu, Premkumar},
doi = {10.1109/ISSRE.2009.17},
file = {:Users/timm/svns/doc/bird09.pdf:pdf},
isbn = {978-1-4244-5375-7},
journal = {2009 20th International Symposium on Software Reliability Engineering},
month = nov,
pages = {109--119},
publisher = {Ieee},
title = {{Putting It All Together: Using Socio-technical Networks to Predict Failures}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5362091},
year = {2009}
}
@phdthesis{rela04,
author = {Rela, L},
school = {Department of Information Technology},
title = {{Evolutionary computing in search-based software engineering}},
year = {2004}
}
@book{salton83introduction,
author = {Salton, G and McGill, M J},
publisher = {McGraw Hill},
title = {{Introduction to Modern Information Retrieval}},
year = {1983}
}
@article{Catal2009,
author = {Catal, Cagatay and Diri, Banu},
journal = {Expert Systems with Applications},
month = may,
number = {4},
pages = {7346--7354},
publisher = {Elsevier Ltd},
title = {{A systematic review of software fault prediction studies}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0957417408007215},
volume = {36},
year = {2009}
}
@article{apswall79,
author = {Apswall, B and Plass, M and Tarjan, R},
journal = {Information Processing Letters},
pages = {121--123},
title = {{A linear-time algorithm for testing the truth of certain quantified Boolean formulas}},
volume = {8},
year = {1979}
}
@inproceedings{ginsberg90,
author = {Ginsberg, A},
booktitle = {AAAI '90},
pages = {777--782},
title = {{Theory Reduction, Theory Revision, and Retranslation}},
year = {1990}
}
@inproceedings{valerdi04,
author = {{Valerdi R.}, Miller C Thomas G},
booktitle = {17th International Conference on Systems Engineering},
month = sep,
title = {{Systems Engineering Cost Estimation by Consensus}},
year = {2004}
}
@inproceedings{quinlan82,
author = {Quinlan, J R},
booktitle = {Machine Learning},
title = {{Learning Efficient Classification Procedures and Thier Application to Chess End-Games}},
year = {1982}
}
@misc{compton95,
author = {Compton, P and Preston, P and Kang, B},
booktitle = {Proceedings of the Banff KA workshop on Knowledge Acquisition for Knowledge-Based Systems},
title = {{The Use of Simulated Experts in Evaluating Knowledge Acquisition}},
year = {1995}
}
@article{Wettschereck1997,
author = {Wettschereck, D. and Aha, D.W. and Mohri, T.},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Wettschereck, Aha, Mohri - 1997 - A review and empirical evaluation of feature weightng methods for a class of lazy learning algorithms.pdf:pdf},
issn = {0269-2821},
journal = {Artificial Intelligence Review},
keywords = {cbr,feature selection,instance,weighting},
number = {1},
pages = {273--314},
publisher = {Springer},
title = {{A review and empirical evaluation of feature weightng methods for a class of lazy learning algorithms}},
url = {http://www.springerlink.com/index/R1323574686528KT.pdf},
volume = {11},
year = {1997}
}
@misc{ford1,
author = {Ford, G},
institution = {Software Engineering Institute Carnegie Mellon University},
number = {SEI-94-TR-011},
title = {{A \{P\}rogress \{R\}eport on \{U\}ndergraduate \{S\}oftware \{E\}ngineering \{E\}ducation}},
year = {1994}
}
@inproceedings{Daran96,
author = {Daran, M and Thevenod-Fosse, P},
booktitle = {Proc. ISSTA 96},
keywords = {Error propagation,mutation,testing},
pages = {158--171},
title = {{Software Error Analysis: \{A\} Real Case Study Involving Real Faults and Mutations}},
year = {1996}
}
@inproceedings{brouck03,
author = {Bouckaert, Remco},
booktitle = {ICML'03},
title = {{Choosing between two learning algorithms based on calibrated tests}},
year = {2003}
}
@inproceedings{burk04,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/04lean.pdf\}},
author = {Burkleaux, T and Menzies, T and Owen, D},
booktitle = {Proceedings of WITSE 2005},
title = {{LEAN = (LURCH+TAR3) = Reusable Modeling Tools}},
year = {2004}
}
@inproceedings{born89,
author = {Borning, A and Maher, M and Martindale, A and Wilson, W},
booktitle = {Proceedings of Sixth International Logic Programming Conference Lisbon, Portugal},
pages = {149--164},
title = {{Constraint Hierachies and Logic Programming}},
year = {1989}
}
@inproceedings{marcus03,
author = {Marcus, A and Maletic, J},
booktitle = {Proceedings of the Twenty-Fifth International Conference on Software Engineering},
title = {{Recovering Documentation-to-Source Code Traceability Links using Latent Semantic Indexing}},
year = {2003}
}
@article{clancey83,
author = {Clancey, W},
journal = {Artificial Intelligence},
pages = {289--350},
title = {{The Epistomology of Rule-Based Systems: a Framework for Explanation.}},
volume = {27},
year = {1983}
}
@inproceedings{me11b,
author = {Kocaguneli, E and Menzies, T and {J. Keung}},
title = {{How to Find Relevant Data for Effort Estimation?}},
year = {2011}
}
@article{compton92,
author = {Compton, P and Edwards, G and Srinivasan, A and Malor, P and Preston, P and Kang, B and Lazarus, L},
journal = {Artificial Intelligence in Medicine},
pages = {47--59},
title = {{Ripple-down-rules: Turning Knowledge Acquisition into Knowledge Maintenance}},
volume = {4},
year = {1992}
}
@article{Moreno-MontesdeOca2014,
abstract = {Context: Business process modeling is an essential part of understanding and redesigning the activities that a typical enterprise uses to achieve its business goals. The quality of a business process model has a significant impact on the development of any enterprise and IT support for that process. Objective: Since the insights on what constitutes modeling quality are constantly evolving, it is unclear whether research on business process modeling quality already covers all major aspects of modeling quality. Therefore, the objective of this research is to determine the state of the art on business process modeling quality: What aspects of process modeling quality have been addressed until now and which gaps remain to be covered? Method: We performed a systematic literature review of peer reviewed articles as published between 2000 and August 2013 on business process modeling quality. To analyze the contributions of the papers we use the Formal Concept Analysis technique. Results: We found 72 studies addressing quality aspects of business process models. These studies were classified into different dimensions: addressed model quality type, research goal, research method, and type of research result. Our findings suggest that there is no generally accepted framework of model quality types. Most research focuses on empirical and pragmatic quality aspects, specifically with respect to improving the understandability or readability of models. Among the various research methods, experimentation is the most popular one. The results from published research most often take the form of intangible knowledge. Conclusion: We believe there is a lack of an encompassing and generally accepted definition of business process modeling quality. This evidences the need for the development of a broader quality framework capable of dealing with the different aspects of business process modeling quality. Different dimensions of business process quality and of the process of modeling still require further research. Â© 2014 Elsevier B.V. All rights reserved.},
author = {{Moreno-Montes de Oca}, Isel and Snoeck, Monique and Reijers, Hajo a. and Rodr\'{\i}guez-Morffi, Abel},
doi = {10.1016/j.infsof.2014.07.011},
file = {:Users/timm/svns/doc/sbse/15businessModels.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Business process modeling,Modeling quality,Systematic literature review},
pages = {187--205},
publisher = {Elsevier B.V.},
title = {{A systematic literature review of studies on business process modeling quality}},
url = {http://dx.doi.org/10.1016/j.infsof.2014.07.011},
volume = {58},
year = {2014}
}
@book{Dil84,
author = {Dillon, W and Goldstein, M},
pages = {247--251},
publisher = {Wiley-Interscience},
title = {{Multivariate Analysis: Methods and Applications}},
year = {1984}
}
@article{Gong2010,
author = {Gong, Wenyin and Cai, Zhihua and Ling, Charles X.},
doi = {10.1007/s00500-010-0591-1},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Gong, Cai, Ling - 2010 - DEBBO a hybrid differential evolution with biogeography-based optimization for global numerical optimization.pdf:pdf},
issn = {1432-7643},
journal = {Soft Computing},
month = mar,
pages = {1--15},
title = {{DE/BBO: a hybrid differential evolution with biogeography-based optimization for global numerical optimization}},
url = {http://www.springerlink.com/index/10.1007/s00500-010-0591-1},
year = {2010}
}
@inproceedings{me08c,
abstract = {Most process models calibrate their internal settings using historical data. Collecting this data is expensive, tedious, and often an incomplete process. Is it possible to make accurate software process estimates without historical data? Suppose much of uncertainty in a model comes from a small subset of the model variables. If so, then after (a) ranking variables by their ability to constrain the output; and (b) applying a small number of the top-ranked variables; then it should be possible to (c) make stable predictions in the constrained space. To test that hypothesis, we combined a simulated annealer (to generate random solutions) with a variable ranker. The results where quite dramatic: in one of the studies in this paper, we found process options that reduced the median and variance of the effort estimates by a factor of 20. In ten case studies, we show that the estimates generated in this manner are usually similar to those produced by standard local calibration. Our conclusion is that while it is always preferable to tune models to local data, it is possible to learn process control options without that data. Â© 2008 Springer-Verlag Berlin Heidelberg.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08icsp.pdf\}},
author = {Menzies, Tim and Elrawas, Oussama and Boehm, Barry and Madachy, Raymond and Hihn, Jairus and Baker, Daniel and Lum, Karen},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-540-79588-9\_19},
isbn = {3540795871},
issn = {03029743},
pages = {210--221},
title = {{Accurate estimates without calibration?}},
volume = {5007 LNCS},
year = {2008}
}
@incollection{ruhe03,
author = {Ruhe, Guenther},
booktitle = {Advances in Learning Software Organizations},
editor = {Henninger, Scott and Maurer, Frank},
pages = {104--113},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Software Engineering Decision Support â A New Paradigm for Learning Software Organizations}},
year = {2003}
}
@misc{compton94,
annote = {regarding the status of the PIERS system},
author = {Compton, P},
title = {{Personal communication}},
year = {1994}
}
@inproceedings{darden90,
author = {Darden, L},
booktitle = {Computational Models of Scientific Discovery and Theory Formation},
editor = {Sharager, J and Langley, P},
publisher = {Morgan Kaufmann Publishers Inc.},
title = {{Diagnosing and Fixing Faults in Theories}},
year = {1990}
}
@book{bratko90,
author = {Bratko, I},
publisher = {Addison-Wesley},
title = {{Prolog Programming for Artificial Intelligence. (second edition)}},
year = {1990}
}
@article{Watson2007a,
author = {Watson, Hugh J and Wixom, Barbara H},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Watson, Wixom - Unknown - Intelligence.pdf:pdf;:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Watson, Wixom - 2007 - The Current State of Business Intelligence.pdf:pdf},
journal = {IEEE Computer},
pages = {96--99},
title = {{The Current State of Business Intelligence}},
year = {2007}
}
@article{Guan2009,
abstract = {Traditional clustering models based on distance similarity are not always effective in capturing correlation among data objects, while pattern-based clustering can do well in identifying correlation hidden among data objects. However, the state-of-the-art pattern-based clustering methods are inefficient and provide no metric to measure the clustering quality. This paper presents a new pattern-based subspace clustering method, which can tackle the problems mentioned above. Observing the analogy between mining frequent itemsets and discovering subspace clusters, we apply pattern tree - a structure used in frequent itemsets mining to determining the target subspaces by scanning the database once, which can be done efficiently in large datasets. Furthermore, we introduce a general clustering quality evaluation model to guide the identifying of meaningful clusters. The proposed new method enables the users to set flexibly proper quality-control parameters to meet different needs. Experimental results on synthetic and real datasets show that our method outperforms the existing methods in both efficiency and effectiveness. ?? 2009 Elsevier B.V. All rights reserved.},
author = {Guan, Jihong and Gan, Yanglan and Wang, Hao},
doi = {10.1016/j.knosys.2009.02.011},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/Guan09.pdf:pdf},
isbn = {0950-7051},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Clustering analysis,Pattern similarity,Pattern tree,Subspace clustering},
number = {8},
pages = {569--579},
title = {{Discovering pattern-based subspace clusters by pattern tree}},
volume = {22},
year = {2009}
}
@phdthesis{me95,
author = {Menzies, T J},
school = {University of New South Wales},
title = {{Principles for Generalised Testing of Knowledge Bases}},
year = {1995}
}
@inproceedings{owen03a,
author = {Owen, D and Menzies, T},
booktitle = {SEKE '03},
title = {{Lurch: a Lightweight Alternative to Model Checking}},
year = {2003}
}
@book{booch94,
author = {Booch, G},
publisher = {Benjamin/ Cummings},
title = {{\{O\}bject-\{O\}riented \{D\}esign with \{A\}pplications (second edition)}},
year = {1994}
}
@article{song06,
address = {Piscataway, NJ, USA},
author = {Song, Qinbao and Shepperd, Martin and Cartwright, Michelle and Mair, Carolyn},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {2},
pages = {69--82},
publisher = {IEEE Press},
title = {{Software Defect Association Mining and Defect Correction Effort Prediction}},
volume = {32},
year = {2006}
}
@inproceedings{agrawal92,
author = {R.Agrawal and T.Imeilinski and A.Swami},
booktitle = {Proceedings of the 1993 ACM SIGMOD Conference, Washington DC, USA},
title = {{Mining Association Rules between Sets of Items in Large Databases}},
year = {1993}
}
@inproceedings{allahyari:user-oriented,
author = {Allahyari, Hiva and Lavesson, Niklas},
booktitle = {SCAI'11},
pages = {11--19},
title = {{User-oriented Assessment of Classification Model Understandability}},
year = {2011}
}
@article{donzelli01,
author = {Donzelli, P and Iazeolla, G},
journal = {Journal of Systems and Software},
month = dec,
number = {3},
title = {{Hybrid Simulation Modelling of the Software Process}},
volume = {59},
year = {2001}
}
@article{vard88,
author = {Vardi, M Y},
journal = {IEEE Software},
month = mar,
pages = {80--85},
title = {{The Universal-Relation Rata Model for Logical Independence}},
year = {1988}
}
@misc{wiel97,
annote = {Draft},
author = {Wielinga, B J and Akkermans, J M and Schreiber, A.Th.},
title = {{A Comptence Theory Approach to Problem Solving Method Construction}},
year = {1997}
}
@inproceedings{menz91,
author = {Menzies, T J},
booktitle = {Tools Pacific 4},
editor = {Meyer, B},
title = {{\{ISA\} \{O\}bject \{PARTOF\} \{K\}nowledge \{R\}epresentation (Part Two)?}},
year = {1991}
}
@book{edgeworth1881,
author = {Edgeworth, Francis},
publisher = {P. Keagan, London, England},
title = {{Mathematical Psychics}},
year = {1881}
}
@book{beck99,
author = {Beck, K},
isbn = {0201616416},
publisher = {Addison-Wesley},
title = {{Extreme Programming Xplained}},
year = {1999}
}
@inproceedings{me03n,
author = {Menzies, T and Kiper, J and Feather, M},
booktitle = {SEDECS'2003: the 2nd International Workshop on Software Engineering Decision Support (part of SEKE2003)},
month = jun,
title = {{Improved software engineering decision support through automatic argument reduction tools}},
year = {2003}
}
@article{martens11,
author = {Martens, David and Vanthienen, Jan and Verbeke, Wouter and Baesens, Bart},
doi = {http://dx.doi.org/10.1016/j.dss.2011.01.013},
issn = {0167-9236},
journal = {Decision Support Systems},
number = {4},
pages = {782--793},
title = {{Performance of classification models from a user perspective}},
url = {http://www.sciencedirect.com/science/article/pii/S016792361100042X},
volume = {51},
year = {2011}
}
@misc{me09h,
author = {Menzies, Tim},
booktitle = {Journal of Software Engineering and Applications},
doi = {10.4236/jsea.2009.24030},
issn = {1945-3116},
month = nov,
number = {04},
pages = {221--236},
title = {{Explanation vs Performance in Data Mining: A Case Study with Predicting Runaway Projects}},
volume = {02},
year = {2009}
}
@article{Barski,
author = {Barski, Conrad},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Barski - 2010 - The Land of Lisp.pdf:pdf},
title = {{Conrad Barski, M.D.}}
}
@article{AZZEH2010,
address = {Hingham, MA, USA},
author = {Azzeh, Mohammad and Neagu, Daniel and Cowling, Peter I},
doi = {http://dx.doi.org/10.1007/s10664-009-9113-0},
issn = {1382-3256},
journal = {Empirical Softw. Engg.},
number = {1},
pages = {60--90},
publisher = {Kluwer Academic Publishers},
title = {{Fuzzy grey relational analysis for software effort estimation}},
volume = {15},
year = {2010}
}
@inproceedings{ceruti00,
author = {Ceruti, M and Anken, C and Lin, A and Rubin, S},
booktitle = {Proceedings of IEEE Systems Man and Cybernetics},
title = {{Applications of High-Performance Knowledge-Based Technology}},
year = {2000}
}
@article{kuipers86,
author = {Kuipers, B},
journal = {Artificial Intelligence},
pages = {229--338},
title = {{Qualitative Simulation}},
volume = {29},
year = {1986}
}
@inproceedings{bradley98refining,
author = {Bradley, Paul S and Fayyad, Usama M},
booktitle = {Proc. 15th International Conf. on Machine Learning},
pages = {91--99},
publisher = {Morgan Kaufmann, San Francisco, CA},
title = {{Refining initial points for \{K\}-\{M\}eans clustering}},
year = {1998}
}
@inproceedings{mah94,
author = {Mahihadia, A and Sammut, C and Compton, P},
booktitle = {Artificial Intelligence: Sowing the Seeds for the Future; Proceedings of AI'94},
publisher = {World Scientific},
title = {{Applying Inductive Logic Programming to Causal Qualitative Models in Neuroendocrinology}},
year = {1994}
}
@article{Fung10,
author = {Fung, Benjamin C M and Chen, R and Yu, P S},
issn = {03600300},
journal = {Computing},
number = {4},
pages = {1--53},
title = {{Privacy-Preserving Data Publishing: A Survey on Recent Developments}},
volume = {V},
year = {2010}
}
@article{pearl87,
author = {Pearl, J and Korf, R E},
journal = {Ann. Rev. Comput. Sci. 1987},
pages = {451--467},
title = {{Search Techniques}},
volume = {2},
year = {1987}
}
@article{Bhatti2006,
author = {Bhatti, Rafae},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Bhatti - 2006 - Policy-Based Security Management for Federated Healthcare Databases ( or RHIOs ).pdf:pdf},
journal = {Policy},
keywords = {federated healthcare architecture,privacy and disclosure policy,role based access control},
pages = {41--48},
title = {{Policy-Based Security Management for Federated Healthcare Databases ( or RHIOs )}},
year = {2006}
}
@article{levenson96,
author = {Heimdahl, M P E and Leveson, N},
journal = {IEEE Transactions on Software Engineering},
month = may,
title = {{Completeness and Consistency Analysis of State-Based Requirements}},
year = {1996}
}
@article{jackson96a,
author = {Jackson, D and Wing, J},
journal = {Computer},
number = {4},
pages = {21--22},
title = {{Formal Methods Light: Lightweight Formal Methods}},
volume = {29},
year = {1996}
}
@misc{david00,
annote = {$\backslash$url\{http://www.space.com/businesstechnology/business/spear\_report\_000313.html\}},
author = {David, Leonard},
month = mar,
title = {{\{NASA\} report: Too Many Failures with Faster, Better, Cheaper}},
year = {2000}
}
@article{me89za,
author = {Menzies, Tim},
journal = {AI Magazine},
title = {{An \{I\}nvestigation of the \{AI\} and \{E\}xpert \{S\}ystems \{L\}iterature 1980-1984}},
year = {1989}
}
@misc{jones08,
annote = {Available from $\backslash$url\{http://www.di.univaq.it/ase2008/docs/ASE-08-slides.pdf\}},
author = {Jones, C B},
title = {{Reflections on, and predictions for, support systems for the development of programs, \{K\}eynote address, \{IEEE\} \{ASE\}}},
year = {2008}
}
@book{pup93,
author = {Puppe, F},
publisher = {Springer-Verlag},
title = {{Systematic Introduction to Expert Systems: Knowledge Representation and Problem-Solving Methods}},
year = {1993}
}
@misc{me09h,
author = {Menzies, T and Mizuno, O and Takagi, Y and Kikuno, Y},
booktitle = {Journal of Software Engineering and Applications},
month = nov,
pages = {221--236},
title = {{Explanation vs Performance in Data Mining: A Case Study with Predicting Runaway Projects}},
year = {2009}
}
@misc{polyspace,
title = {{Polyspace Verifier\^{}\{$\backslash$mbox $\backslash$textregistered\}}},
url = {$\backslash$url\{http://www.di.ens.fr/~cousot/projects/DAEDALUS/synthetic\_summary/POLYSPACE/polyspace-daedalus.htm\}},
year = {2005}
}
@inproceedings{kakas01,
author = {Kakas, Antonis C and Nuffelen, Bert Van and Denecker, Marc},
booktitle = {IJCAI},
pages = {591--596},
title = {{A-System: Problem Solving through Abduction.}},
year = {2001}
}
@incollection{benavides05,
author = {Benavides, David and Trinidad, Pablo and Ruiz-Cort\'{e}s, Antonio},
booktitle = {Advanced Information Systems Engineering},
doi = {10.1007/11431855\_34},
editor = {Pastor, Oscar and e Cunha, Jo\~{a}o},
isbn = {978-3-540-26095-0},
pages = {491--503},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Automated Reasoning on Feature Models}},
url = {http://dx.doi.org/10.1007/11431855\_34},
volume = {3520},
year = {2005}
}
@article{Lee2009a,
abstract = {Landmark multidimensional scaling (LMDS) uses a subset of data (landmark points) to solve classical multidimensional scaling (MDS), where the scalability is increased but the approximation is noise-sensitive. In this paper we present an LMDS ensemble where we use a portion of the input in a piecewise manner to solve classical MDS, combining individual LMDS solutions which operate on different partitions of the input. Ground control points (GCPs) that are shared by partitions considered in the ensemble, allow us to align individual LMDS solutions in a common coordinate system through affine transformations. We incorporate priors into combining multiple LMDS solutions such that the weighted averaging by priors improves the noise-robustness of our method. Our LMDS ensemble is much less noise-sensitive while maintaining the scalability and the speed of LMDS. Experiments on synthetic data (noisy grid) and real-world data (similar image retrieval) confirm the high performance of the proposed LMDS ensemble. ?? 2009 Elsevier Ltd. All rights reserved.},
author = {Lee, Seunghak and Choi, Seungjin},
doi = {10.1016/j.patcog.2008.11.039},
file = {:Users/timm/svns/doc/09landmark\_MBS\_ensembles.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Dimensionality reduction,Embedding,Multidimensional scaling (MDS),Unsupervised learning},
number = {9},
pages = {2045--2053},
title = {{Landmark MDS ensemble}},
volume = {42},
year = {2009}
}
@article{clancey91,
author = {Clancey, W},
journal = {Artificial Intelligence},
pages = {241--284},
title = {{Book Review of Israel Rosenfield, The Invention of Memory: A New View of the Brain}},
volume = {50},
year = {1991}
}
@book{davis02,
author = {Davis, J and Fensel:q, D and {van Harmelen (eds.)}, F},
publisher = {John Wiley},
title = {{Towards the Semantic Web: Ontology-Driven Knowledge Management}},
year = {2002}
}
@misc{gent97,
author = {Gent, I P and Grant, S A and MacIntyre, E and Prosser, P and P.Shar and Smith, B M and Walsh, T},
institution = {University of Leeds, School of Computer Studies},
number = {97.27},
title = {{How not to do it}},
year = {1997}
}
@inproceedings{briand98,
author = {Briand, Lionel C and Emam, Khaled El and Bomarius, Frank},
booktitle = {ICSE},
pages = {390--399},
title = {{COBRA: A Hybrid Method for Software Cost Estimation, Benchmarking, and Risk Assessment}},
year = {1998}
}
@misc{compton96a,
annote = {Regarding time interval literal connections.},
author = {Compton, P},
title = {{Personal communication}},
year = {1996}
}
@misc{carver03,
author = {Carver, J and Shull, F and Basili, V R},
booktitle = {University of Maryland, Tech Report Number: CS-TR-4441},
month = mar,
title = {{Invstigating the effect of Process Experience on Inspection Effectiveness}},
year = {2003}
}
@misc{briand06,
author = {Briand, Lionel},
title = {{Keynote address, PROMISE'06}},
year = {2006}
}
@article{rissanen78,
author = {Rissanen, J},
journal = {Automatica},
pages = {465--471},
title = {{Modeling by shortest data description}},
volume = {14},
year = {1978}
}
@inproceedings{zhang10,
author = {Zhang, Hongyu and Nelson, Adam and Menzies, Tim},
title = {{Proceedings of PROMISE'10}},
year = {2010}
}
@article{jarv88,
author = {Jarvenpaa, S L and Dickson, G W},
journal = {Communications of the ACM},
number = {6},
pages = {764--774},
title = {{Graphics and Managerial Decision Making: Research Based Guidelines}},
volume = {31}
}
@article{Quickstart2011b,
author = {Quickstart, A Beamer},
doi = {10.1002/ajmg.a.33889},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Quickstart - 2010 - Table of contents, volume 77, december 2010.pdf:pdf},
issn = {1552-4833},
journal = {American journal of medical genetics. Part A},
month = jan,
number = {1},
pages = {fmi--fmiv},
pmid = {21344620},
title = {{Table of contents, volume 155, number 1, january 2011.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21344620},
volume = {155},
year = {2011}
}
@book{Subramaniam,
author = {Subramaniam, Venkat},
booktitle = {October},
file = {:Users/timm/svns/doc/Seven Languages in Seven Weeks A Pragmatic Guide to Learning Programming Languages.pdf:pdf},
isbn = {9781934356593},
title = {{What Readers Are Saying About Seven Languages in Seven Weeks}}
}
@inproceedings{me00w,
author = {Menzies, T J},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{Knowledge Elicitation: the State of the Art}},
year = {2002}
}
@inproceedings{dekhtyar04,
author = {Dekhtyar, A and Hayes, J Huffman and Menzies, T},
booktitle = {International Workshop on Mining Software Repositories (submitted)},
title = {{Text is Software Too}},
year = {2004}
}
@inproceedings{slezak92,
author = {Slezak, P},
booktitle = {AAAI Spring Symposium on Reasoning with Diagrammatic Representations},
editor = {Narayanan, N H},
pages = {12--17},
title = {{The "Philosphical" Case Against Visual Images: a "Crucial" Experiment}},
year = {1992}
}
@article{shull08,
author = {Shull, F and Seaman, C},
number = {7},
pages = {88--90},
title = {{Inspecting the History of Inspections: An Example of Evidence-Based Technology Diffusion}},
volume = {24},
year = {2008}
}
@book{Webb2002,
abstract = {Statistical pattern recognition is a very active area of study and research, which has seen many advances in recent years. New and emerging applications - such as data mining, web searching, multimedia data retrieval, face recognition, and cursive handwriting recognition - require robust and efficient pattern recognition techniques. Statistical decision making and estimation are regarded as fundamental to the study of pattern recognition.Statistical Pattern Recognition, Second Edition has been fully updated with new methods, applications and references. It provides a comprehensive introduction to this vibrant area - with material drawn from engineering, statistics, computer science and the social sciences - and covers many application areas, such as database design, artificial neural networks, and decision support systems.* Provides a self-contained introduction to statistical pattern recognition.* Each technique described is illustrated by real examples.* Covers Bayesian methods, neural networks, support vector machines, and unsupervised classification.* Each section concludes with a description of the applications that have been addressed and with further developments of the theory.* Includes background material on dissimilarity, parameter estimation, data, linear algebra and probability.* Features a variety of exercises, from 'open-book' questions to more lengthy projects.The book is aimed primarily at senior undergraduate and graduate students studying statistical pattern recognition, pattern processing, neural networks, and data mining, in both statistics and engineering departments. It is also an excellent source of reference for technical professionals working in advanced information development environments.For further information on the techniques and applications discussed in this book please visit www.statistical-pattern-recognition.net},
author = {Webb, a and Webb, a},
booktitle = {Books.Google.Com},
doi = {10.1002/0470854774},
file = {:Users/timm/svns/doc/02webb.pdf:pdf},
isbn = {0-470-84513-9},
pages = {470},
title = {{Statistical pattern recognition}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=vS0w2XhU0j8C\&amp;oi=fnd\&amp;pg=PR15\&amp;dq=Statistical+pattern+recognition\&amp;ots=QWvlOS7tmB\&amp;sig=ndnP7\_ygbrK8X3Wpg-V5V8P-vss},
volume = {9},
year = {2002}
}
@inproceedings{eshghi93,
author = {Eshghi, K},
booktitle = {\{IJCAI\} '93},
pages = {3--8},
title = {{A \{T\}ractable \{C\}lass of \{A\}bductive \{P\}roblems}},
volume = {1},
year = {1993}
}
@article{me99c,
author = {Menzies, T},
journal = {Submitted to AAAI-99},
title = {{Simpler, Faster Abductive Validation}},
year = {1999}
}
@incollection{bar83,
author = {Barstow, D R and Aiello, N and Duda, R O and Erman, L D and Forgy, C L and Gorlin, D and Greiner, R D and Lenat, D B and London, P E and McDermott, J and Nii, H Penny and Politakis, P and Reboh, R and Rosenchein, S and Scott, A C and van Melle, W and Weiss, S M},
booktitle = {Building Expert Systems},
chapter = {9},
editor = {Hayes-Roth, F and Waterman, D A and Lenat, D B},
pages = {283--345},
publisher = {Addison-Wesley},
title = {{Languages and Tools for Knowledge Engineering}},
year = {1983}
}
@article{Lin2005,
author = {Lin, Xiaodong and Clifton, Chris and Zhu, Michael},
doi = {10.1007/s10115-004-0148-7},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Lin, Clifton, Zhu - 2004 - Privacy-preserving clustering with distributed EM mixture modeling.pdf:pdf},
issn = {0219-1377},
journal = {Knowledge and Information Systems},
keywords = {clustering,privacy,security},
month = dec,
number = {1},
pages = {68--81},
title = {{Privacy-preserving clustering with distributed EM mixture modeling}},
url = {http://www.springerlink.com/index/10.1007/s10115-004-0148-7},
volume = {8},
year = {2004}
}
@inproceedings{me97b,
author = {Menzies, T J and Mahidadia, a},
booktitle = {Workshop on Problem-Solving Methods for Knowledge-based Systems, IJCAI '97, August 23.},
title = {{Ripple-Down Rationality: A Framework for Maintaining PSMs}},
year = {1997}
}
@misc{Boetticher:Menzies:Ostrand:2007,
author = {Menzies, T and Caglayan, B and Kocaguneli, E and Krall, J and Peters, F and Turhan, B},
booktitle = {Available: promisedata. googlecode. com},
institution = {West Virginia University, Department of Computer Science},
title = {{The promise repository of empirical software engineering data}},
url = {http://promisedata.org/repository},
year = {2012}
}
@article{Guo11az,
address = {New York, NY, USA},
author = {Guo, Jianmei and White, Jules and Wang, Guangxin and Li, Jian and Wang, Yinglin},
doi = {10.1016/j.jss.2011.06.026},
issn = {0164-1212},
journal = {J. Syst. Softw.},
keywords = {Configuration,Feature models,Genetic algorithm,Optimization,Product derivation,Software product lines},
month = dec,
number = {12},
pages = {2208--2221},
publisher = {Elsevier Science Inc.},
title = {{A Genetic Algorithm for Optimized Feature Selection with Resource Constraints in Software Product Lines}},
url = {http://dx.doi.org/10.1016/j.jss.2011.06.026},
volume = {84},
year = {2011}
}
@article{Harper2004,
abstract = {In this paper we introduce a quantitative model that relates chemical structural similarity to biological activity, and in particular to the activity of lead series of compounds in high-throughput assays. From this model we derive the optimal screening collection make up for a given fixed size of screening collection, and identify the conditions under which a diverse collection of compounds or a collection focusing on particular regions of chemical space are appropriate strategies. We derive from the model a diversity function that may be used to assess compounds for acquisition or libraries for combinatorial synthesis by their ability to complement an existing screening collection. The diversity function is linked directly through the model to the goal of more frequent discovery of lead series from high-throughput screening. We show how the model may also be used to derive relationships between collection size and probabilities of lead discovery in high-throughput screening, and to guide the judicious application of structural filters.},
author = {Harper, G and Pickett, S D and Green, D V S},
doi = {10.2174/138620704772884832},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/HarperPickett04.pdf:pdf},
isbn = {1386-2073},
issn = {13862073},
journal = {Combinatorial chemistry \& high throughput screening},
keywords = {design of experiments,high throughput screening,library design,mathematical,optimization,statistical design},
number = {1},
pages = {63--70},
pmid = {14965262},
title = {{Design of a compound screening collection for use in high throughput screening.}},
volume = {7},
year = {2004}
}
@article{konoligue92,
author = {Konoligue, K},
journal = {Artificial Intelligence},
pages = {255--272},
title = {{Abduction versus \{C\}losure in \{C\}ausal \{T\}heories}},
volume = {53},
year = {1992}
}
@article{me99p,
abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article. ACM has opted to expose the complete List rather than only correct and linked references.},
author = {Menzies, Tim},
doi = {10.1145/318964.318969},
isbn = {1523-8822},
issn = {15238822},
journal = {Intelligence},
number = {3},
pages = {26--32},
title = {{Cost benefits of ontologies}},
volume = {10},
year = {1999}
}
@book{simon96,
author = {Simon, H},
publisher = {MIT Press},
title = {{The Science of the Artificial (third edition)}},
year = {1996}
}
@article{lees96,
author = {Lee, S and O'Keefe, R M},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = feb,
number = {1},
pages = {173--178},
title = {{The Effect of Knowledge Representation Schemes on Maintainability of Knowledge-Based Systems}},
volume = {8},
year = {1996}
}
@article{Fischer2003a,
author = {Fischer, Bernd and Schumann, Johann},
doi = {10.1017/S0956796802004562},
file = {:Users/timm/svns/doc/FISCHER03.pdf:pdf},
issn = {09567968},
journal = {Journal of Functional Programming},
month = may,
number = {3},
pages = {483--508},
title = {{AutoBayes: a system for generating data analysis programs from statistical models}},
url = {http://www.journals.cambridge.org/abstract\_S0956796802004562},
volume = {13},
year = {2003}
}
@article{sand89,
author = {Sanderson, P M and Verhapge, A G and Fuld, R B},
journal = {Ergonomics},
number = {11},
pages = {1343--1372},
title = {{State-space and Verbal Protocol Methods for Studying the Human Operator in Process Control}},
volume = {32},
year = {1989}
}
@inproceedings{owen2b,
author = {Owen, D and Cukic, B and Menzies, T},
booktitle = {7th IEEE International Symposium on High Assurance Systems Engineering},
pages = {119},
title = {{An Alternative to Model Checking: Verification by Random Search of AND-OR Graphs Representing Finite-State Models}},
volume = {1},
year = {2002}
}
@article{widmer96learning,
annote = {Availabel from $\backslash$url\{http://citeseer.ist.psu.edu/widmer96learning.html\}},
author = {Widmer, Gerhard and Kubat, Miroslav},
journal = {Machine Learning},
number = {1},
pages = {69--101},
title = {{Learning in the Presence of Concept Drift and Hidden Contexts}},
volume = {23},
year = {1996}
}
@inproceedings{me99k,
abstract = {Knowledge-based engineering and computational intelligence are
expected to become core technologies in the design and manufacturing for
the next generation of space exploration missions. Yet, if one is
concerned with the reliability of knowledge based systems, studies
indicate significant disagreement regarding the amount of testing needed
for system assessment. The sizes of standard black-box test suites are
impracticably large since the black-box approach neglects the internal
structure of knowledge-based systems. On the contrary, practical results
repeatedly indicate that only a few tests are needed to sample the range
of behaviors of a knowledge-based program. In this paper, we model
testing as a search process over the internal state space of the
knowledge-based system. When comparing different test suites, the test
suite that examines larger portion of the state space is considered more
complete. Our goal is to investigate the trade-off between the
completeness criterion and the size of test suites. The results of
testing experiment on tens of thousands of mutants of real-world
knowledge based systems indicate that a very limited gain in
completeness can be achieved through prolonged testing. The use of
simple (or random) search strategies for testing appears to be as
powerful as testing by more thorough search algorithms},
author = {Menzies, T. and Cukic, B.},
booktitle = {Proceedings 11th International Conference on Tools with Artificial Intelligence},
doi = {10.1109/TAI.1999.809838},
isbn = {0-7695-0456-6},
issn = {1082-3409},
title = {{On the sufficiency of limited testing for knowledge based systems}},
year = {1999}
}
@inproceedings{catlett91,
author = {Catlett, J},
booktitle = {Australian Workshop on Knowledge Acqusition for Knowledge-Based Systems, Pokolbin},
pages = {53--67},
title = {{Inductive learning from subsets or Disposal of excess training data considered harmful.}},
year = {1991}
}
@inproceedings{owen06a,
author = {{D. Owen}, D Desovski and Cukic, B},
booktitle = {ISSRE 06},
title = {{Effectively Combining Software Verification Strategies: Understanding Different Assumptions}},
year = {2006}
}
@article{Peyton2007,
author = {Peyton, Liam and Hu, Jun and Doshi, Chintan and Seguin, Pierre and Se, Pierre},
doi = {10.1109/WCMEB.2007.34},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Peyton et al. - 2007 - Addressing Privacy in a Federated Identity Management Network for E- Health.pdf:pdf},
isbn = {0-7695-2820-1},
journal = {Eighth World Congress on the Management of eBusiness (WCMeB 2007)},
month = jul,
number = {WCMeB},
pages = {12--12},
publisher = {Ieee},
title = {{Addressing Privacy in a Federated Identity Management Network for EHealth}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4285311},
year = {2007}
}
@inproceedings{mull02,
author = {M\"{u}ller, Matthias M and Padberg, Frank},
booktitle = {Proceedings of the Fourth International Workshop on Economics-Driven Software Engineering Research (EDSER)},
title = {{Extreme Programming from an Engineering Economics Viewpoint}},
year = {2002}
}
@phdthesis{edwards96,
author = {Edwards, G},
school = {Computer Science \& Engineering, University of NSW},
title = {{Reflective Expert Systems in Pathology}},
year = {1996}
}
@misc{me01b,
author = {Menzies, T},
booktitle = {ASERC workshop on Quantiative Software Engineering},
title = {{Applictions of Computational Intelligence to Quantitative Software Engineering}},
year = {2001}
}
@inproceedings{meedng92,
author = {Menzies, T J and Edwards, J and Ng, K},
booktitle = {Tools Pacific 1992},
pages = {421--428},
publisher = {Prentice Hall},
title = {{The \{M\}ysterious \{C\}ase of the \{M\}issing \{R\}e-usable \{C\}lass \{L\}ibraries}},
year = {1992}
}
@article{brown94,
author = {Brown, T B and Kimura, T D},
journal = {Software- Concepts and Tools},
pages = {34--48},
title = {{Completeness of a Visual Computation Model}},
year = {1994}
}
@inproceedings{landi91,
author = {Landi, W and Ryder, B G},
booktitle = {Conference Record of the 18th ACM Symposium on Principles of Programming Languages},
month = jan,
pages = {93--103},
title = {{Pointer-induced aliasing: a problem classification}},
year = {1991}
}
@misc{TheMendeleySupportTeam2010,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2010}
}
@article{goldin98,
author = {{D. Goldin S. Venneri}, A Noor},
journal = {Mechanical Engineering},
month = feb,
pages = {62--69},
title = {{A New Frontier in Engineering}},
year = {1998}
}
@misc{Bavota2012b,
abstract = {During software evolution changes are inevitable. These changes may lead to design erosion and the introduction of inadequate design solutions, such as design antipatterns. Several empirical studies provide evidence that the presence of antipatterns is generally associated with lower productivity, greater rework, and more significant design efforts for developers. In order to improve the quality and remove antipatterns, refactoring operations are needed. In this demo, we present the Extract class features of ARIES (Automated Refactoring In EclipSe), an Eclipse plug-in that supports the software engineer in removing the \#x201C;Blob \#x201D; antipattern.},
annote = {Laura. Fixed on 10/17/2012},
author = {{Bavota Gabriele}, De Lucia Andrea Marcus Andrian Oliveto Rocco and Palomba, F},
keywords = {bad\_smells refactoring SEVERE software},
month = jun,
pages = {1419--1422},
title = {{Supporting Extract Class Refactoring in Eclipse: The ARIES Project}}
}
@book{felt97,
author = {Feltovich, P J and Ford, K M and (eds), R R Hoffman},
publisher = {MIT PRess},
title = {{Expertise in Context}},
year = {1997}
}
@inproceedings{me01e,
author = {Menzies, T and Kiper, J D},
booktitle = {ASE-2001},
title = {{Better reasoning about software engineering activities}},
year = {2001}
}
@incollection{me10b,
author = {Menzies, Tim and Shull, Forrest},
booktitle = {Making Software: What really works, and why we believe it},
editor = {Oram, A and G.Wilson},
pages = {3--11},
publisher = {O'Reilly Books},
title = {{The Quest for Convincing Evidence}},
year = {2010}
}
@article{Attarzadeh2011,
author = {Attarzadeh, Iman and Ow, Sh},
doi = {10.1007/978-3-642-18129-0\_4},
file = {:Users/timm/svns/doc/cost/11Iman.pdf:pdf},
journal = {Intelligent Computing and Information Science},
keywords = {artificial neural networks,cocomo model,cost estimation models,soft computing techniques,software,software engineering,software project management},
pages = {18--26},
title = {{Software development cost and time forecasting using a high performance artificial neural network model}},
year = {2011}
}
@phdthesis{huang06a,
annote = {Available from $\backslash$url\{http://csse.usc.edu/csse/TECHRPTS/PhD\_Dissertations/files/Huang\_Dissertation.pdf\}},
author = {Huang, L},
school = {Department of Computer Science, University of Southern California},
title = {{Software Quality Analysis: A Value-Based Approach}},
year = {2006}
}
@article{ZheWeb00Lazy,
author = {Zheng, Zijian and Webb, Geoffrey I},
doi = {http://dx.doi.org/10.1023/A:1007613203719},
issn = {0885-6125},
journal = {Mach. Learn.},
number = {1},
pages = {53--84},
publisher = {Kluwer Academic Publishers},
title = {{Lazy Learning of Bayesian Rules}},
volume = {41},
year = {2000}
}
@article{Kirsopp2003,
author = {Kirsopp, C and Shepperd, M and Premraj, R},
journal = {Proc. 22nd SGAI Intï¿½l Conf. Knowledge-Based Systems and Applied Artificial Intelligence},
pages = {61},
publisher = {Springer-Verlag New York Inc},
title = {{Case and feature subset selection in case-based software project effort prediction}},
year = {2003}
}
@inproceedings{jiang08,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08compare.pdf\}},
author = {Jiang, Y and Cukic, B and Menzies, T and Bartlow, N},
booktitle = { 4th International Workshop on Predictor Models in Software Engineering, PROMISE 2008},
isbn = {978-1-60558-036-4},
keywords = {Software Quality Measurement},
pages = {11--18},
title = {{Comparing Design and Code Metrics for Software Quality Prediction}},
year = {2008}
}
@article{jones96a,
author = {Jones, B and Sthamer, H.-H. and Eyres, D},
journal = {ï¿½Software Engineering Journalï¿½},
pages = {299--306},
title = {{Automatic structural tsting using genetic algorithms}},
volume = {11},
year = {1996}
}
@inproceedings{andrews06,
author = {Andrews, James H and Haldar, Susmita and Lei, Yong and Li, Felix Chun Hang},
title = {{Tool support for randomized unit testing}}
}
@article{me07e,
annote = {$\backslash$url\{http://menzies.us/pdf/07precision.pdf\}},
author = {Menzies, Tim and Menzies, Tim and Dekhtyar, Alex and Dekhtyar, Alex and Distefano, Justin and Distefano, Justin and Greenwald, Jeremy},
journal = {Engineering},
month = sep,
number = {1},
pages = {11--14},
title = {{Problems with Precision}},
volume = {6},
year = {2007}
}
@article{Yang2005,
author = {Yang, Zhiqiang and Zhong, Sheng and Wright, Rebecca N},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Yang, Zhong, Wright - 2005 - Privacy-Preserving Classification of Customer Data without Loss of Accuracy â.pdf:pdf},
journal = {Science},
pages = {1--11},
title = {{Privacy-Preserving Classification of Customer Data without Loss of Accuracy â}},
year = {2005}
}
@article{lang83,
author = {Langlotx, C P and Shortliffe, E H},
journal = {International Journal of Man-Machine Studies},
number = {5},
pages = {479--496},
title = {{Adapating a consultatation system to critique user plans}},
volume = {19}
}
@book{olle91,
author = {Olle, T W and Hagelstein, J and MacDonald, I G and Rolland, C and Sol, H K and Assche, F J M Van and Verrijn-Stuart, A A},
publisher = {Addison-Wesley},
title = {{Information Systems Methodologies: A Framework for Understanding}},
year = {1991}
}
@inproceedings{bentley90,
author = {Bentley, J L},
booktitle = {Proceedings Proceedings of the 6th Annual Symposium on Computational Geometry, Berkley, California, United States},
pages = {187--197},
title = {{K-d Trees for Semidynamic Point Sets}},
year = {1990}
}
@book{miller02,
author = {Miller, A},
isbn = {1-58488-171-2},
publisher = {Chapman \& Hall},
title = {{Subset Selection in Regression (second edition)}},
year = {2002}
}
@article{Houle2005,
author = {Houle, M.E.},
doi = {10.1109/ICDE.2005.66},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Houle - 2005 - Fast Approximate Similarity Search in Extremely High-Dimensional Data Sets.pdf:pdf},
isbn = {0-7695-2285-8},
journal = {21st International Conference on Data Engineering (ICDE'05)},
number = {Icde},
pages = {619--630},
publisher = {Ieee},
title = {{Fast Approximate Similarity Search in Extremely High-Dimensional Data Sets}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1410179},
year = {2005}
}
@article{Grassberger1983,
abstract = {We study the correlation exponent v introduced recently as a characteristic measure of strange attractors which allows one to distinguish between deterministic chaos and random noise. The exponent v is closely related to the fractal dimension and the information dimension, but its computation is considerably easier. Its usefulness in characterizing experimental data which stem from very high dimensional systems is stressed. Algorithms for extracting v from the time series of a single variable are proposed. The relations between the various measures of strange attractors and between them and the Lyapunov exponents are discussed. It is shown that the conjecture of Kaplan and Yorke for the dimension gives an upper bound for v. Various examples of finite and infinite dimensional systems are treated, both numerically and analytically.},
author = {Grassberger, Peter and Procaccia, Itamar},
doi = {10.1016/0167-2789(83)90298-1},
file = {:Users/timm/svns/doc/83intrinsicDimension.pdf:pdf},
isbn = {978-981-02-2310-6},
issn = {01672789},
journal = {Physica D: Nonlinear Phenomena},
number = {1-2},
pages = {189--208},
title = {{Measuring the strangeness of strange attractors}},
volume = {9},
year = {1983}
}
@article{wilcoxon45,
author = {Wilcoxon, F},
journal = {Biometrics},
pages = {80--83},
title = {{Individual comparisons by ranking methods}},
volume = {1},
year = {1945}
}
@inproceedings{weimer13,
author = {Weimer, W and Fry, Z P and Forrest, S},
title = {{No Title}}
}
@book{jones96,
author = {Jones, C},
publisher = {McGraw Hill},
title = {{Applied Software Measurement (second edition)}},
year = {1991}
}
@article{avri96,
author = {Avritzer, A and Ros, J P and Weyuker, E J},
journal = {IEEE Software},
month = sep,
pages = {76--82},
title = {{Reliability of Rule-Based Systems}},
year = {1996}
}
@inproceedings{kamvar03,
author = {Kamvar, Sepandar and Klein, Dan and Manning, Christopher},
booktitle = {IJCAI'03},
file = {:Users/timm/svns/doc/03spectral.pdf:pdf},
pages = {561--566},
title = {{Spectral learning}},
year = {2003}
}
@phdthesis{odberg95,
annote = {408 pages},
author = {Odberg, Erik},
month = feb,
school = {Division of Computer Systems and Telematics, Norwegian Institute of Technology},
title = {{MultiPerspectives: Object Evolution and Schema Modification Management for Object-Oriented Databases}},
year = {1995}
}
@article{chang74,
author = {Chang, C L},
journal = {IEEE Trans. on Computers},
pages = {1179--1185},
title = {{Finding Prototypes for Nearest Neighbor Classifiers}},
year = {1974}
}
@article{Song2010,
author = {Song, Qinbao and Jia, Zihan and Shepperd, Martin and Ying, Shi and Liu, Jin},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework.pdf:pdf;:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework(2).pdf:pdf},
keywords = {machine learning,scheme evaluation,software defect prediction,software defect-proneness prediction},
number = {X},
pages = {1--16},
title = {{A General Software Defect-Proneness Prediction Framework}},
volume = {X},
year = {2010}
}
@article{kol91,
author = {Kolodner, J L},
journal = {AI Magazine},
pages = {68},
title = {{Improving \{H\}uman \{D\}ecision \{M\}aking \{T\}hrough \{C\}ase-\{B\}ased \{D\}ecision \{A\}iding}},
year = {1991}
}
@inproceedings{Litt95,
author = {Littlewood, B and Wright, D},
booktitle = {Proceedings of the 25th Conference on Fault Tolerant Computing (FTCS 25), Pasadena, CA, July},
title = {{Stopping Rules for the Operational Testing of Safety Critical Software}},
year = {1995}
}
@inproceedings{albrecht79,
author = {Albrecht, A J},
booktitle = {Proceedings of the Joint SHARE, GUIDE, and IBM Application Development Symposium, Monterey, California, October 14-17, IBM Corporation},
pages = {83--92},
title = {{Measuring Application Development Productivity}},
year = {1979}
}
@article{dennett82,
annote = {8 June 24},
author = {Dennett, D C},
journal = {The New York Review of Books},
pages = {56--57},
title = {{Letter to the Editor}},
year = {1982}
}
@misc{web98a,
author = {at UCSD, Hypertext Webster Gateway},
title = {{Definition of ontology}},
year = {1998}
}
@article{Lopez-Herrejon2015,
author = {Lopez-Herrejon, Roberto E. and Linsbauer, Lukas and Egyed, Alexander},
doi = {10.1016/j.infsof.2015.01.008},
file = {:Users/timm/svns/doc/sbse/15sbseMappingStudy.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {search based software engineering,software product line,systematic mapping study},
pages = {33--51},
publisher = {Elsevier B.V.},
title = {{A systematic mapping study of search-based software engineering for software product lines}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950584915000166},
volume = {61},
year = {2015}
}
@misc{prevue,
author = {$\backslash$urlhttp://www.pacorp.com, Performance Awareness Corporation},
title = {{preVue-C/S}},
year = {1998}
}
@article{Madhusudan2004,
annote = {unread},
author = {Madhusudan, Therani and Zhao, J.Leon and Marshall, Byron},
doi = {10.1016/j.datak.2004.01.005},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Madhusudan, Zhao, Marshall - 2004 - A case-based reasoning framework for workflow model management.pdf:pdf},
issn = {0169023X},
journal = {Data \& Knowledge Engineering},
keywords = {ad hoc workflows,case-based reasoning,case-oriented workflow modeling,model reuse},
month = jul,
number = {1},
pages = {87--115},
title = {{A case-based reasoning framework for workflow model management}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0169023X04000060},
volume = {50},
year = {2004}
}
@book{simon82,
author = {Simon, H A},
publisher = {MIT Press},
title = {{Models of bounded rationality}},
volume = {2},
year = {1982}
}
@article{martin00,
author = {Martin, R H and Raffo, D M},
journal = {International Journal of Software Process Improvement and Practice},
title = {{A Model of the Software Development Process Using Both Continuous and Discrete Models}},
year = {2000}
}
@article{Harper2006,
abstract = {Data mining is a fast-growing field that is finding application across a wide range of industries. HTS is a crucial part of the drug discovery process at most large pharmaceutical companies. Accurate analysis of HTS data is, therefore, vital to drug discovery. Given the large quantity of data generated during an HTS, and the importance of analyzing those data effectively, it is unsurprising that data-mining techniques are now increasingly applied to HTS data analysis. Taking a broad view of both the HTS process and the data-mining process, we review recent literature that describes the application of data-mining techniques to HTS data. ?? 2006 Elsevier Ltd. All rights reserved.},
author = {Harper, Gavin and Pickett, Stephen D.},
doi = {10.1016/j.drudis.2006.06.006},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/HarperPickett06.pdf:pdf},
isbn = {1359-6446 (Print)},
issn = {13596446},
journal = {Drug Discovery Today},
number = {15-16},
pages = {694--699},
pmid = {16846796},
title = {{Methods for mining HTS data}},
volume = {11},
year = {2006}
}
@inproceedings{gurp99,
author = {van Gurp, Jilles and Bosch, Jan},
booktitle = {ICT Architectures '99 , Amsterdam},
month = nov,
title = {{Using Bayesian Belief Networks in Assessing Software Designs}},
year = {1999}
}
@article{reed74,
author = {Reed, S and Ernst, G and Banerji, R},
journal = {Cognitive Psychology},
number = {3},
pages = {436--450},
title = {{The Role of Analogy in Transfer Between Similar Problem States}},
volume = {6},
year = {1974}
}
@article{nii86a,
author = {Nii, H P},
journal = {\{AI\} Magazine},
pages = {38--53},
title = {{Blackboard Systems: The Blackboard Model for Problem Solving And the Evolution of Blackboard Architectures}},
year = {1986}
}
@inproceedings{ester96,
author = {Ester, Martin and Kriegel, Hans-peter and S, J\"{o}rg and Xu, Xiaowei},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Ester et al. - 1996 - A density-based algorithm for discovering clusters in large spatial databases with noise.pdf:pdf},
pages = {226--231},
publisher = {AAAI Press},
title = {{A density-based algorithm for discovering clusters in large spatial databases with noise}},
year = {1996}
}
@misc{IEEE90,
publisher = {\{IEEE\}, New York},
title = {{\{IEEE\} Glossary of Software Engineering Terminology, \{ANSI/IEEE\} Standard 610.12}},
year = {1990}
}
@article{Koyuturk2004,
abstract = { Biclustering is an important problem that arises in diverse applications, including analysis of gene expression and drug interaction data. The problem can be formalized in various ways through different interpretation of data and associated optimization functions. We focus on the problem of finding unusually dense patterns in binary (0-1) matrices. This formulation is appropriate for analyzing experimental datasets that come from not only binary quantization of gene expression data, but also more comprehensive datasets such as gene-feature matrices that include functions of coded proteins and motifs in the coding sequence. We formalize the notion of an "unusually" dense submatrix to evaluate the interestingness of a pattern in terms of statistical significance based on the assumption of a uniform memoryless source. We then simplify it to assess statistical significance of discovered patterns. Using statistical significance as an objective function, we formulate the problem as one of finding significant dense submatrices of a large sparse matrix. Adopting a simple iterative heuristic along with randomized initialization techniques, we derive fast algorithms for discovering binary biclusters. We conduct experiments on a binary gene-feature matrix and a quantized breast tumor gene expression matrix. Our experimental results show that the proposed method quickly discovers all interesting patterns in these datasets.},
author = {Koyuturk, M. and Szpankowski, W. and Grama, a.},
doi = {10.1109/CSB.2004.1332467},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/Koyurturk04.pdf:pdf},
isbn = {0-7695-2194-0},
journal = {Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference, 2004. CSB 2004.},
title = {{Biclustering gene-feature matrices for statistically significant dense patterns}},
year = {2004}
}
@misc{schw02,
author = {Schwaber, Ken},
title = {{No Title}},
year = {2002}
}
@inproceedings{JALALI2007,
address = {Washington, DC, USA},
author = {Jalali, Omid and Menzies, Tim and Baker, Dan and Hihn, Jairus},
booktitle = {PROMISE '07: Proceedings of the Third International Workshop on Predictor Models in Software Engineering},
doi = {http://dx.doi.org/10.1109/PROMISE.2007.3},
isbn = {0-7695-2954-2},
pages = {7},
publisher = {IEEE Computer Society},
title = {{Column Pruning Beats Stratification in Effort Estimation}},
year = {2007}
}
@article{hayes06,
author = {Hayes, Jane Huffman and Dekhtyar, Alex and Sundaram, Senthil Karthikeyan},
journal = {IEEE Trans. Software Eng},
number = {1},
pages = {4--19},
title = {{Advancing Candidate Link Generation for Requirements Tracing: The Study of Methods}},
url = {http://doi.ieeecomputersociety.org/10.1109/TSE.2006.3},
volume = {32},
year = {2006}
}
@article{avri95,
author = {Avritzer, A and Weyuker, E J},
journal = {IEEE Trans. on Software Engineering},
month = sep,
number = {9},
pages = {705--716},
title = {{The Automatic Generation of Load Test Suites and the Assessment of the Resulting Software}},
volume = {21},
year = {1995}
}
@article{zave97,
author = {Zave, Pamela and Jackson, Michael},
issn = {1049-331X},
journal = {ACM Trans. Softw. Eng. Methodol.},
number = {1},
pages = {1--30},
title = {{Four dark corners of requirements engineering}},
volume = {6},
year = {1997}
}
@inproceedings{zlatareva93,
author = {Zlatareva, N},
booktitle = {IJCAI '93 workshop on Validation, Verification and Test of KBs Chambery, France},
pages = {67--77},
title = {{Distributed Verification and Automated Generation of Test Cases}},
year = {1993}
}
@article{Watsona,
author = {Watson, Hugh J and Wixom, Barbara H},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Watson, Wixom - Unknown - Intelligence.pdf:pdf},
journal = {Idea},
title = {{Intelligence}}
}
@misc{warren83,
author = {Warren, D H D},
institution = {SRI},
month = oct,
number = {Tec. Note 309},
title = {{An Abstract Prolog Instruction Set}},
year = {1983}
}
@article{Batal2009,
author = {Batal, Iyad},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/iyadAR.pdf:pdf},
title = {{Association Rule Mining Overview}},
year = {2009}
}
@book{ull:88a,
author = {Ullman, J D},
publisher = {Computer Science Press},
title = {{Principles of Database and Knowledge-base Systems}},
year = {1988}
}
@book{basset97,
author = {Bassett, P G},
publisher = {Yourdon Press},
title = {{Framing Software Reuse}},
year = {1997}
}
@inproceedings{me09j,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09pom2.pdf\}},
author = {Lemon, B and Riesbeck, A and Menzies, T and Price, J and D'Alessandro, J and Carlsson, R and Prifiti, T and Peters, F and Lu, H and Port, D},
booktitle = {IEEE ASE'09},
title = {{Applications of Simulation and AI Search: Assessing the Relative Merits of Agile vs Traditional Software Development}},
year = {2009}
}
@inproceedings{aranda07,
address = {Washington, DC, USA},
author = {Aranda, Jorge and Ernst, Neil and Horkoff, Jennifer and Easterbrook, Steve},
booktitle = {Proceedings of the International Workshop on Modeling in Software Engineering},
doi = {10.1109/MISE.2007.2},
file = {:Users/timm/svns/doc/xplain/07aranda.pdf:pdf},
isbn = {0-7695-2953-4},
pages = {7----},
publisher = {IEEE Computer Society},
series = {MISE '07},
title = {{A Framework for Empirical Evaluation of Model Comprehensibility}},
url = {http://dx.doi.org/10.1109/MISE.2007.2},
year = {2007}
}
@article{aha91,
author = {Aha, David W and Kibler, Dennis and Albert, Marc K},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Aha, Kibler, Albert - 1991 - Instance-based learning algorithms.pdf:pdf},
journal = {Mach. Learn.},
month = jan,
number = {1},
pages = {37--66},
title = {{Instance-Based Learning Algorithms}},
volume = {6},
year = {1991}
}
@inproceedings{hihn00,
author = {Hihn, J and Habib-agahi, H},
booktitle = {Proceedings of the 22nd Annual Conference of the International Society of Parametric Analysts (ISPA), Noordwijk, Netherlands},
title = {{Identification and Measurement of the Sources of Flight Software Cost Growth}},
year = {2000}
}
@inproceedings{HAYES2005,
address = {New York, NY, USA},
author = {Hayes, Jane Huffman and Dekhtyar, Alex and Sundaram, Senthil},
booktitle = {MSR '05: Proceedings of the 2005 international workshop on Mining software repositories},
doi = {http://doi.acm.org/10.1145/1083142.1083153},
isbn = {1-59593-123-6},
pages = {1--5},
publisher = {ACM},
title = {{Text mining for software engineering: how analyst feedback impacts final results}},
year = {2005}
}
@article{clan89a,
author = {Clancey, W},
journal = {Machine Learning},
number = {3/4},
pages = {285--293},
title = {{The knowledge level reinterpreted: Modeling how systems interact}},
volume = {4},
year = {1989}
}
@article{darwiche02,
annote = {Available from $\backslash$url\{ww.jair.org/media/989/live-989-2063-jair.pdf\}},
author = {Darwiche, A and Marquis, P},
journal = {Journal of Artifical Intelligence Research},
pages = {229--264},
title = {{A Knowledge Compulation Map}},
volume = {17},
year = {2002}
}
@misc{me01d,
author = {Menzies, T and Kiper, J D},
title = {{Machine Learning for Requirements Engineering}},
year = {2001}
}
@inproceedings{davies94,
author = {Davies, P},
booktitle = {ECAI '94},
title = {{Planning and Expert Systems}},
year = {1994}
}
@misc{smith93,
author = {Smith, B},
month = dec,
title = {{The Phase Transition in Constraint Satisfaction Problems: A Closer Look at the Mushy Region}},
year = {1993}
}
@inproceedings{me03p,
author = {Liu, Yan and Gururajan, Srikanth and Cukic, Bojan and Menzies, Tim and Napolitano, Marcello},
booktitle = {IEEE Tools with AI},
title = {{Validating an Online Adaptive System Using SVDD}},
year = {2003}
}
@inproceedings{Chaslot2006,
author = {Chaslot, Guillaume and Bakkes, Sander and Szita, Istvan and Spronck, Pieter},
booktitle = {Artificial Intelligence},
file = {:Users/timm/svns/doc/sander08.pdf:pdf},
keywords = {gaming},
mendeley-tags = {gaming},
title = {{Monte-Carlo Tree Search : A New Framework for Game AI Monte-Carlo Tree Search Application to Video Games}},
year = {2006}
}
@article{Kocaguneli2012,
abstract = {Background: There are too many design options for software effort estimators. How can we best explore them all? Aim: We seek aspects on general principles of effort estimation that can guide the design of effort estimators. Method: We identified the essential assumption of analogy-based effort estimation, i.e., the immediate neighbors of a project offer stable conclusions about that project. We test that assumption by generating a binary tree of clusters of effort data and comparing the variance of supertrees versus smaller subtrees. Results: For 10 data sets (from Coc81, Nasa93, Desharnais, Albrecht, ISBSG, and data from Turkish companies), we found: 1) The estimation variance of cluster subtrees is usually larger than that of cluster supertrees; 2) if analogy is restricted to the cluster trees with lower variance, then effort estimates have a significantly lower error (measured using MRE, AR, and Pred(25) with a Wilcoxon test, 95 percent confidence, compared to nearest neighbor methods that use neighborhoods of a fixed size). Conclusion: Estimation by analogy can be significantly improved by a dynamic selection of nearest neighbors, using only the project data from regions with small variance.},
author = {Kocaguneli, Ekrem and Menzies, Tim and Bener, Ayse Basar and Keung, Jacky W.},
doi = {10.1109/TSE.2011.27},
file = {:Users/timm/svns/doc/cost/11teak.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Software cost estimation,analogy,k-NN},
number = {2},
pages = {425--438},
title = {{Exploiting the essential assumptions of analogy-based effort estimation}},
volume = {38},
year = {2012}
}
@article{Harel87:statecharts,
author = {Harel, D},
journal = {Science of Computer Programming},
month = jun,
number = {3},
pages = {231--274},
title = {{Statecharts: A Visual Formalism for Complex Systems}},
volume = {8},
year = {1987}
}
@article{dekleer86c,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {197--224},
title = {{Problem Solving with the ATMS}},
volume = {28},
year = {1986}
}
@inproceedings{rich97za,
author = {Richards, D and Menzies, T J},
booktitle = {Third Australian Knowledge Acquisition Workshop, Perth},
editor = {Menzies, T J and Richards, D and Compton, P},
title = {{Extending Knowledge Engineering to Requirements Engineering from Multiple Perspectives}},
year = {1997}
}
@article{zhang07:TEC,
author = {Zhang, Qingfu and Li, Hui},
doi = {10.1109/TEVC.2007.892759},
issn = {1089-778X},
journal = {Evolutionary Computation, IEEE Transactions on},
keywords = {computational complexity;genetic algorithms;comput},
month = dec,
number = {6},
pages = {712--731},
title = {{MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition}},
volume = {11},
year = {2007}
}
@inproceedings{zannier06,
author = {Zannier, C and Melnik, G and Maurer, F},
booktitle = {ICSE'06},
title = {{On the Success of Empirical Studies in the International Conference on Software Engineering}},
year = {2006}
}
@article{iwasaki86a,
author = {Iwasaki, Y and Simon, H},
journal = {Artificial Intelligence},
pages = {63--72},
title = {{Theories of Causal Ordering: Reply to deKleer and Brown}},
volume = {29},
year = {1986}
}
@inproceedings{deb98c,
author = {Debenham, J},
booktitle = {Proceedings Seventh International Conference on Intelligent Systems ICIS'98, Paris, France, July},
title = {{An Integrated Conceptual Model of Knowledge-Based Systems Simplifies Mainteance}},
year = {1998}
}
@article{jiang08b,
author = {Jiang, Y and Cukic, B and Ma, Y},
journal = {Empirical Software Engineering},
month = oct,
pages = {561--595},
title = {{Techniques for evaluating fault prediction models}},
year = {2008}
}
@article{Fung2010,
author = {Fung, Benjamin C. M. and Wang, Ke and Chen, Rui and Yu, Philip S.},
doi = {10.1145/1749603.1749605},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Fung et al. - 2010 - Privacy-preserving data publishing.pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
month = jun,
number = {4},
pages = {1--53},
title = {{Privacy-preserving data publishing}},
url = {http://portal.acm.org/citation.cfm?doid=1749603.1749605},
volume = {42},
year = {2010}
}
@inproceedings{bhat!icse12,
address = {Piscataway, NJ, USA},
author = {Bhattacharya, Pamela and Iliofotou, Marios and Neamtiu, Iulian and Faloutsos, Michalis},
booktitle = {Proceedings of the 34th International Conference on Software Engineering},
isbn = {978-1-4673-1067-3},
pages = {419--429},
publisher = {IEEE Press},
series = {ICSE '12},
title = {{Graph-based Analysis and Prediction for Software Evolution}},
url = {http://dl.acm.org/citation.cfm?id=2337223.2337273},
year = {2012}
}
@article{davis93,
author = {Davis, R and Shrobe, H and Szolovits, P},
journal = {\{AI\} Magazine},
pages = {17--33},
title = {{What is a \{K\}nowledge \{R\}epresentation?}},
year = {1993}
}
@inproceedings{ng90,
author = {Ng, H T and Mooney, R J},
booktitle = {Working \{N\}otes of the 1990 \{S\}pring \{S\}ymposium on \{A\}utomated \{A\}bduction},
organization = {UC Irvine},
pages = {13--17},
title = {{The \{R\}ole of \{C\}oherence in \{C\}onstructing and \{E\}valuating \{A\}bductive \{E\}xplanations}},
volume = {TR 90-32},
year = {1990}
}
@inproceedings{cordero97,
author = {Cordero, R and Costamagna, M and Paschetta, E},
booktitle = {12th COCOMO Forum},
title = {{A Genetic Algorithm Approach for the Calibration of COCOMO-like Models}},
year = {1997}
}
@inproceedings{molo03,
author = {Molokken, K and Jorgensen, M},
booktitle = {ISESE'03},
title = {{A Review of Surveys on Software Effort Estimation}},
year = {2003}
}
@book{gleick87,
author = {Gleick, J},
pages = {352},
publisher = {Cardinal},
title = {{Chaos}},
year = {1987}
}
@inproceedings{hirata94,
annote = {Also in \{$\backslash$em Machine Intelligence\} 14},
author = {Hirata, K},
booktitle = {Proceedings of the Fourteenth International Machine Learning Workshop, ML-14},
pages = {16},
title = {{A \{C\}lassification of \{A\}bduction: \{A\}bduction for \{L\}ogic \{P\}rogramming}},
year = {1994}
}
@inproceedings{me03g,
author = {{Tim Menzies J. Smith}, D Raffo},
title = {{When is Pair Programming Better?}},
year = {2003}
}
@article{me97j,
author = {Menzies, Tim},
doi = {10.1002/(SICI)1097-024X(199712)27:12<1457::AID-SPE140>3.3.CO;2-0},
issn = {00380644},
journal = {Software: Practice and Experience},
keywords = {knowledge-level modelling,oo patterns expert systems},
month = dec,
number = {12},
pages = {1457--1478},
title = {{Objectâoriented patterns: lessons from expert systems}},
url = {http://doi.wiley.com/10.1002/(SICI)1097-024X(199712)27:12<1457::AID-SPE140>3.3.CO;2-0},
volume = {27},
year = {1997}
}
@article{vicente95,
author = {Vicente, K J and Christoffersen, K and Pereklita, A},
journal = {IEEE Transactions of Systems, Man, and Cybernetics},
month = apr,
number = {4529-545},
title = {{Supporting Operator Problem Solving Through Ecological Interface Design}},
volume = {25},
year = {1995}
}
@article{Song2010,
author = {Song, Qinbao and Jia, Zihan and Shepperd, Martin and Ying, Shi and Liu, Jin},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework.pdf:pdf;:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework(2).pdf:pdf},
keywords = {machine learning,scheme evaluation,software defect prediction,software defect-proneness prediction},
number = {X},
pages = {1--16},
title = {{A General Software Defect-Proneness Prediction Framework}},
volume = {X},
year = {2010}
}
@article{hall03,
author = {Hall, M A and Holmes, G},
file = {:Users/timm/svns/doc/03hall.pdf:pdf},
journal = {IEEE Transactions On Knowledge And Data Engineering},
number = {6},
pages = {1437--1447},
title = {{Benchmarking Attribute Selection Techniques for Discrete Class Data Mining}},
volume = {15},
year = {2003}
}
@article{aguilar01,
author = {Aguilar-Ruiz, J and Ramos, I and Riquelme, J C and Toro, M},
journal = {Information and Software Technology},
month = dec,
number = {14},
pages = {875--882},
title = {{An evolutionary approach to estimating software development projects}},
volume = {43},
year = {2001}
}
@inproceedings{me92l,
author = {Menzies, T and Mahidadia, A and Compton, P},
booktitle = {Proceedings of the 7th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge-Based Systems Workshop},
title = {{Using Causality as a Generic Knowledge Representation, or Why and How Centralised Knowledge Servers Can Use Causality}},
year = {1992}
}
@inproceedings{FERNANDES2010,
address = {New York, NY, USA},
author = {Fernandes, Paulo and Lopes, Lucelene and Ruiz, Duncan D A},
booktitle = {SAC '10: Proceedings of the 2010 ACM Symposium on Applied Computing},
doi = {http://doi.acm.org/10.1145/1774088.1774300},
isbn = {978-1-60558-639-7},
pages = {1002--1009},
publisher = {ACM},
title = {{The impact of random samples in ensemble classifiers}},
year = {2010}
}
@book{coplein92,
author = {Coplein, J},
publisher = {Addison-Wesley},
title = {{Advanced C++ Programming Styles and Idioms}},
year = {1992}
}
@article{Ben-Hur2003,
abstract = {Clustering, principal component analysis, clustering stability, gene expression Clustering is one of the most commonly used tools in the analysis of gene expression data. The usage in grouping genes is based on the premise that co-expression is a result of co-regulation. It is thus a preliminary step in extracting gene networks and inference of gene function. Clustering is a form of unsupervised learning, i.e. no information on the class variable is assumed, and the objective is to find the "natural" groups in the data. However, most clustering algorithms generate a clustering even if the data has no inherent cluster structure, so external validation tools are required. The emergence of cluster structure depends on several choices: data representation and normalization, the choice of a similarity measure and clustering algorithm. In this chapter we extend the stability-based validation of cluster structure, and propose stability as a figure of merit that is useful for comparing clustering solutions, thus helping in making these choices. We use this framework to demonstrate the ability of principal component analysis (PCA) to extract features relavant to the cluster structure. We use stability as a tool for simultaneously choosing the number of principal components and the number of clusters.},
author = {Ben-Hur, Asa and Guyon, Isabelle},
doi = {10.1385/1-59259-364-X:159},
file = {:Users/timm/svns/doc/03BenHurPcaClustering.pdf:pdf},
issn = {1064-3745},
journal = {Methods in molecular biology (Clifton, N.J.)},
number = {1},
pages = {159--182},
pmid = {12710673},
title = {{Detecting stable clusters using principal component analysis.}},
volume = {224},
year = {2003}
}
@article{Breiman1996,
author = {Breiman, Leo},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Langer - 1969 - No Title Avail.pdf:pdf},
number = {1},
title = {{No Title}},
year = {1996}
}
@incollection{hameco95,
abstract = {The field of software visualization (SV) investigates approaches and techniques for static and dynamic graphical representations of algorithms, programs (code), and processed data. SV is concerned primarily with the analysis of programs and their development. The goal is to improve our understanding of inherently invisible and intangible software, particularly when dealing with large information spaces that characterize domains like software maintenance, reverse engineering, and collaborative development. The main challenge is to find effective mappings from different software aspects to graphical representations using visual metaphors. This paper provides an overview of the SV research, describes current research directions, and includes an extensive list of recommended readings.},
author = {Gra\v{c}anin, Denis and Matkovi\'{c}, Kre\v{s}imir and Eltoweissy, Mohamed},
booktitle = {Innov. Syst. Softw. Eng.},
chapter = {Visualisat},
doi = {10.1007/s11334-005-0019-8},
issn = {1614-5046},
keywords = {Software Visualization},
number = {2},
pages = {221--230},
publisher = {World-Scientific},
title = {{Software Visualization}},
url = {http://www.springerlink.com/content/q4r0t56w726620u4/},
volume = {1},
year = {2005}
}
@article{kirkpatrick83,
author = {Kirkpatrick, S and Gelatt, C D and Vecchi, M P},
journal = {Science, Number 4598, 13 May 1983},
pages = {671--680},
title = {{Optimization by Simulated Annealing}},
url = {citeseer.nj.nec.com/kirkpatrick83optimization.html},
volume = {220, 4598},
year = {1983}
}
@article{Indyk2008,
annote = {A little high church, but discusses fast hashing algorith,s},
author = {Indyk, Piotr},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Indyk - 2008 - Near-Optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions.pdf:pdf},
journal = {Communications of the ACM},
number = {1},
pages = {117--122},
title = {{Near-Optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions}},
volume = {51},
year = {2008}
}
@inproceedings{me00m,
author = {Menzies, T J and Debenham, J},
booktitle = {Encyclopedia of Computer Science and Technology},
editor = {Kent, A and Williams, J G},
number = {27},
pages = {35--54},
publisher = {Marcell Dekker Inc.},
title = {{Expert Systems Maintenance}},
volume = {47},
year = {2000}
}
@inproceedings{me00t,
author = {Menzies, Tim and Singh, Harhsinder},
booktitle = {2nd International Workshop on Soft Computing applied to Software Engineering (Netherlands), February},
pages = {1--24},
title = {{Many Maybes Mean ( Mostly ) the Same Thing}},
year = {2001}
}
@inproceedings{peters12,
annote = {$\backslash$url\{http://menzies.us/pdf/12privacy.pdf\}},
author = {Peters, Fayola and Menzies, Tim},
booktitle = {ICSE'12},
title = {{Privacy and Utility for Defect Prediction: Experiments with MORPH}},
year = {2012}
}
@book{brooks75,
author = {Brooks, F P},
publisher = {Addison-Wesley},
title = {{The Mythical Man-Month, Anniversary edition}},
year = {1975}
}
@book{forr69,
author = {Forrester, J W},
publisher = {Pegasus Communications},
title = {{Urban Dynamics}},
year = {1969}
}
@article{me07b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06learnPredict.pdf\}},
author = {{Menzies T, Greenwald J}, FrankA},
journal = {IEEE Software},
month = jan,
title = {{Datamining static code attributes to learn defect predictors}},
year = {2007}
}
@inproceedings{malin07,
author = {Malin, J T and Throop, D R},
booktitle = {IEEE Aerospace Conference},
month = mar,
title = {{Basic Concepts and Distinctions for an Aerospace Ontology of Functions, Entities and Problems}},
year = {2007}
}
@inproceedings{fawcett01,
annote = {Available from $\backslash$url\{http://home.comcast.net/\~{}tom.fawcett/public\_html/papers/ICDM-final.pdf\}},
author = {Fawcett, Tom},
booktitle = {2001 IEEE International Conference on Data Mining (ICDM-01)},
title = {{Using Rule Sets to Maximize ROC Performance}},
year = {2001}
}
@article{franco83,
author = {Franco, J and Paull, M},
journal = {Discrete Applied Math},
pages = {77--87},
title = {{Probabilistic Analysis of the Davis Putnam Procedure for Solving the Satisfiability Problem}},
volume = {5},
year = {1983}
}
@inproceedings{me91a,
abstract = {A major problem with building expert systems is that experts always communicate knowledge in a specific context. A knowledge acquisition methodology has been developed which restricts the use of knowledge to the context in which it was provided. This method, "ripple down rules" allows for extremely rapid and simple knowledge acquisition without the help of a knowledge engineer. An expert system based on this approach and built by experts is now in routine use. This paper reviews what has been achieved using the approach, its problems and potential.},
author = {Compton, Pea and Edwards, G and Kang, B and Lazarus, L and Malor, R and Menzies, T and Preston, P and Srinivasan, a and Sammut, C},
booktitle = {Proceedings of the Sixth AAAI Knowledge Acquisition for Knowledge-Based Systems Workshop, Calgary, Canada, University of Calgary},
pages = {1--6},
title = {{Ripple down rules: possibilities and limitations}},
year = {1991}
}
@misc{musc00,
author = {{N. Muscettola}, NASA Ames Research Center},
title = {{Personal communication}},
year = {2000}
}
@inproceedings{cold94,
author = {Coldwell, J M and Wrightson, G},
booktitle = {Artificial Intelligence: Sowing the Seeds for the Future; Proceedings of AI '94},
editor = {Zhang, C and Debenham, J and Lukose, D},
pages = {275--282},
publisher = {World Scientific},
title = {{Lemmas and Links in Analystic Tableau}},
year = {1994}
}
@inproceedings{Aha1996,
author = {Aha, D. and Chang, L.W.},
booktitle = {Navy Center for},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Aha, Chang - 1996 - Cooperative Bayesian and Case-Based Reasoning for Solving Multiagent Planning Tasks.pdf:pdf},
keywords = {case-based reasoning},
publisher = {Citeseer},
title = {{Cooperative Bayesian and Case-Based Reasoning for Solving Multiagent Planning Tasks}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.20.7752},
year = {1996}
}
@inproceedings{Gupta2004,
author = {Gupta, Chetan and Grossman, R.},
booktitle = {2004 SIAM International Conference on Data Mining},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Gupta, Grossman - 2004 - Genic A single pass generalized incremental algorithm for clustering.pdf:pdf},
title = {{Genic: A single pass generalized incremental algorithm for clustering}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=gcJVK9a9RR0C\&amp;oi=fnd\&amp;pg=PA147\&amp;dq=Genic:+A+single+pass+generalized+incremental+algorithm+for+clustering\&amp;ots=mNwb3Yxl4p\&amp;sig=NWU1GO2ppHXMJumbow96pTo0Y5E},
year = {2004}
}
@article{shum94,
author = {Shum, S Buckingham and Hammond, N},
journal = {International Journal of Human-Computer Studies},
number = {4},
pages = {603--652},
title = {{Argumentation-Based Design Rationale: What Use at What Cost?}},
volume = {40},
year = {1994}
}
@article{Kim2010,
author = {Kim, Sangkyum and Kim, Hyungsul and Weninger, Tim and Han, Jiawei},
doi = {10.1145/1816112.1816121},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/kim10.pdf:pdf},
isbn = {9781450302166},
journal = {SIGKDD UP Workshop},
keywords = {authorship classification,closed pattern,discriminative pattern,pattern,text categorization,text mining},
pages = {65--73},
title = {{Authorship classification - A syntatic tree mining approach}},
url = {http://dl.acm.org/citation.cfm?id=1816112.1816121},
year = {2010}
}
@article{lapu91,
author = {Lalonde, W and Pugh, J},
journal = {Journal of Object-Oriented Programming},
month = jan,
pages = {57--62},
title = {{Subclassing $\backslash$neq subtyping $\backslash$neq Is-a}},
year = {1991}
}
@inproceedings{me03m,
author = {Menzies, T and Ammar, K and Nikora, A and Stefano, Justin Di},
booktitle = {Tech report, Computer Science, Portland State University},
title = {{How Simple is Software Defect Detection?}},
year = {2004}
}
@techreport{kang90a,
author = {Kang, Kyo C and Cohen, Sholom G and Hess, James A and Novak, William E and Peterson, A Spencer},
institution = {Carnegie-Mellon University, Software Engineering Institute},
title = {{Feature-oriented domain analysis (FODA) feasibility study}},
year = {1990}
}
@inproceedings{antoniol05,
author = {Antoniol, G and Gueheneuc, Yann-Gael},
booktitle = {ICSM 2005},
pages = {357--366},
title = {{Feature Identification: A Novel Approach and a Case Study}},
year = {2005}
}
@article{Rossum2003,
abstract = {"Python is a simple, yet powerful programming language that bridges the gap between C and shell programming, and is thus ideally suited for `throw-away programming' and rapid prototyping. Its syntax is put together from constructs borrowed from a variety of other languages; most prominent are influences from ABC, C, Modula-3 and Icon. The Python interpreter is easily extended with new functions and data types implemented in C. Python is also suitable as an extension language for highly customizable C applications such as editors or window managers. Python is available for various operating systems, amongst which several flavors of UNIX, Amoeba, the Apple Macintosh O.S., and MS-DOS. This tutorial introduces the reader informally to the basic concepts and features of the Python language and system. It helps to have a Python interpreter handy for hands-on experience, but as the examples are self-contained, the tutorial can be read off-line as well. For a description of standard objects and modules, see the Python Library Reference manual. The Python Reference Manual gives a more formal definition of the language."},
author = {Rossum, Guido Van and Drake, Fred L},
file = {:Users/timm/svns/doc/pythonVanRossum.pdf:pdf},
journal = {Python},
number = {10},
pages = {1600--1600},
title = {{Python Tutorial}},
volume = {206},
year = {2003}
}
@article{vaab96,
author = {van Harmelen, F and Aben, M},
journal = {International Journal of Human-Computer Studies},
pages = {187--212},
title = {{Structure-Preserving Specification Languages for Knowledge-Based Systems}},
volume = {44},
year = {1996}
}
@inproceedings{boutif06,
author = {Bouktif, S and Sahraoui, H and Antoniol, G},
booktitle = {GECCO '06: Proceedings of the 8th annual conference on Genetic and evolutionary computation},
pages = {1893--1900},
title = {{Simulated annealing for improving software quality prediction}},
year = {2006}
}
@inproceedings{clarke89a,
author = {Clark, E M and Long, D E},
booktitle = {Fourth Annual Symposium on Logic in Computer Science},
title = {{Compositional Model Checking}},
year = {1989}
}
@inproceedings{me92m,
author = {Mahidadia, A J and Compton, P and Menzies, T J and Sammut, C and Smythe, G A},
booktitle = {AI '92, Horbart, Australia},
publisher = {World-Scientific},
title = {{Inventing Causal Qualitative Models: A Tool for Experimental Research}},
year = {1992}
}
@inproceedings{sellev90,
author = {Selman, B and Levesque, H J},
booktitle = {\{AAAI\} '90},
pages = {343--348},
title = {{Abductive and \{D\}efault \{R\}easoning: a \{C\}omputational \{C\}ore}},
year = {1990}
}
@inproceedings{me95c,
author = {Menzies, T J},
booktitle = {Proceedings of AI '95, Australia},
publisher = {World-Scientific},
title = {{\{L\}imits to \{K\}nowledge \{L\}evel-\{B\} \{M\}odeling (and \{KADS\})}},
year = {1995}
}
@misc{lum03handbook,
author = {Lum, Karen and Bramble, Michael and Hihn, Jairus and Hackney, John and Khorrami, Mori and Monson, Erik},
title = {{Handbook for Software Cost Estimation}},
url = {http://ceh.nasa.gov/downloadfiles/Web Links/cost\_hb\_public-6-5.pdf},
year = {2003}
}
@article{lanubile97,
author = {Lanubile, F and Visaggio, G},
journal = {The Journal of Software and Systems},
pages = {225--234},
title = {{Evaluating Predictive Quality Models Derived from Software Measures: Lessons Learned}},
volume = {38},
year = {1997}
}
@misc{bailey02,
author = {Bailey, John},
title = {{Using Monte Carlo and COCOMO-2 to Model a Large IT System Development}},
url = {http://sunset.usc.edu/events/2002/cocomo17/John Bailey--COCOMO and Monte Carlo 10-24.pdf},
year = {2002}
}
@inproceedings{jiang07,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07issre.pdf\}},
author = {Jiang, Y and Cukic, B and Menzies, T},
booktitle = {ISSRE'07},
title = {{Fault Prediction using Early Lifecycle Data}},
year = {2007}
}
@article{mcderm93,
author = {McDermott, J},
journal = {Artificial Intelligence},
pages = {241--247},
title = {{R1 ("XCON") at age 12: lessons from an elementary school achiever}},
volume = {59},
year = {1993}
}
@inproceedings{krall14aaai,
author = {Krall, Joseph and Menzies, Tim and Davies, Misty},
booktitle = {2014 AAAI Spring Symposium Series},
title = {{Learning the Task Management Space of an Aircraft Approach Model}},
year = {2014}
}
@article{Ignjatovic2009,
author = {Ignjatovic, Aleksandar and Lee, Chung Tong and Kutay, Cat and Guo, Hui and Compton, Paul},
file = {:Users/timm/svns/doc/Ignjatovic\_2009.pdf:pdf},
journal = {International \ldots},
pages = {1--7},
title = {{Computing marks from multiple assessors using adaptive averaging}},
url = {http://cgi.cse.unsw.edu.au/~ignjat/Computing Marks.pdf},
year = {2009}
}
@inproceedings{me00m,
author = {Menzies, T J and Debenham, J},
booktitle = {Encyclopedia of Computer Science and Technology},
editor = {Kent, A and Williams, J G},
number = {27},
pages = {35--54},
publisher = {Marcell Dekker Inc.},
title = {{Expert Systems Maintenance}},
volume = {47},
year = {2000}
}
@misc{visser05a,
author = {Visser, W},
title = {{Personel communication: Comments on different tools}},
year = {2005}
}
@inproceedings{dieng93,
author = {Dieng, R and Corby, O and Lapalut, S},
booktitle = {EKAW '93: Knowledge Acquisition for Knowledge-Based Systems: 7th European Workshop},
editor = {Aussenac, N and Boy, G and Gaines, B and {M. Linster}, T.-G. Ganascia and Kodratoff, Y},
pages = {407--426},
title = {{Acquisition of Gradual Knowledge}},
year = {1993}
}
@book{saltelli00,
author = {Saltelli, A and Chan, K and Scott, E M},
publisher = {Wiley},
title = {{Sensitivity Analysis}},
year = {2000}
}
@article{Verma2012,
abstract = {Recent theory work has found that a special type of spatial partition tree - called a random projection tree - is adaptive to the intrinsic dimension of the data from which it is built. Here we examine this same question, with a combination of theory and experiments, for a broader class of trees that includes k-d trees, dyadic trees, and PCA trees. Our motivation is to get a feel for (i) the kind of intrinsic low dimensional structure that can be empirically verified, (ii) the extent to which a spatial partition can exploit such structure, and (iii) the implications for standard statistical tasks such as regression, vector quantization, and nearest neighbor search.},
archivePrefix = {arXiv},
arxivId = {1205.2609},
author = {Verma, Nakul and Kpotufe, Samory and Dasgupta, Sanjoy},
eprint = {1205.2609},
file = {:Users/timm/svns/doc/09rptrees.pdf:pdf},
isbn = {978-0-9749039-5-8},
title = {{Which Spatial Partition Trees are Adaptive to Intrinsic Dimension?}},
url = {http://arxiv.org/abs/1205.2609},
year = {2012}
}
@misc{ctc86,
annote = {Vol. 2, No. 3},
howpublished = {Control Theory and Advanced Technology},
month = sep,
title = {{Special Issue on Expert Systems}},
year = {1986}
}
@inproceedings{motta01,
author = {Motta, E},
booktitle = {Handbook of Software and Knowledge Engineering (volume 1)},
editor = {Chung, S K},
title = {{The Knowledge Modelling Paradigm in Knowledge Engineering}},
year = {2001}
}
@inproceedings{chung95,
author = {Chung, L and Nixon, B A},
booktitle = {Proceedings of ICSE '95: the International Conference on Software Engineering},
pages = {25--36},
title = {{Dealing with Non-Functional Requirements: Three Experimental Studies of a Process-Oriented Approach}},
year = {1995}
}
@article{Kohavi1995e,
author = {Kohavi, R.},
file = {:Users/timm/svns/doc/kohavi95a.pdf:pdf},
journal = {Machine Learning: ECML-95},
pages = {174--189},
publisher = {Springer},
title = {{The power of decision tables}},
url = {http://www.springerlink.com/index/P5N736U105315054.pdf},
year = {1995}
}
@article{Quinlan1986,
abstract = {Recent literature has demonstrated the applicability of genetic programming to induction of decision trees for modelling toxicity endpoints. Compared with other decision tree induction techniques that are based upon recursive partitioning employing greedy searches to choose the best splitting attribute and value at each node that will necessarily miss regions of the search space, the genetic programming based approach can overcome the problem. However, the method still requires the discretization of the often continuous-valued toxicity endpoints prior to the tree induction. A novel extension of this method, YAdapt, is introduced in this work which models the original continuous endpoint by adaptively finding suitable ranges to describe the endpoints during the tree induction process, removing the need for discretization prior to tree induction and allowing the ordinal nature of the endpoint to be taken into account in the models built.},
author = {Quinlan, J. R.},
doi = {10.1007/BF00116251},
file = {:Users/timm/svns/doc/86LearningTreesquinlan.pdf:pdf},
isbn = {9783540283485},
issn = {08856125},
journal = {Machine Learning},
keywords = {classification,decision trees,expert systems,induction,information theory,knowledge acquisition},
number = {1},
pages = {81--106},
pmid = {17050186},
title = {{Induction of decision trees}},
volume = {1},
year = {1986}
}
@inproceedings{abe06,
author = {Abe, S and O.Mizuno and Kikuno, T and Kikuchi, N and Hirayama, M},
booktitle = {ICSE 2006},
pages = {600--603},
title = {{Estimation of project success using Bayesian classifier}},
year = {2006}
}
@article{graves00,
annote = {Available on-line at $\backslash$url\{www.niss.org/technicalreports/tr80.pdf\}},
author = {Graves, Todd L and Karr, Alan F and Marron, J S and Siy, Harvey P},
journal = {IEEE Trans. Software Eng.},
number = {7},
pages = {653--661},
title = {{Predicting Fault Incidence Using Software Change History}},
volume = {26},
year = {2000}
}
@article{beausoleil06,
author = {Beausoleil, Ricardo P},
issn = {0377-2217},
journal = {European Journal of Operational Research},
keywords = {Metaheuristics,Multiple objectives,Nonlinear optimization,Scatter search,Tabu search},
number = {2},
pages = {426--449},
title = {{\{MOSS\}: multiobjective scatter search applied to non-linear multiple criteria optimization}},
volume = {169},
year = {2006}
}
@article{brac83,
author = {Brachman, R},
journal = {The \{AI\} Magazine},
month = oct,
pages = {66--73},
title = {{What IS-A Is and Isn't: An Analysis of Taxonomic Links in Semantic Networks}},
year = {1983}
}
@phdthesis{hall99,
author = {Hall, Mark A},
school = {Department of Computer Science, University of Waikato},
title = {{Correlation-based Feature Selection for Machine Learning}},
year = {1999}
}
@inproceedings{Dum98,
author = {Dumais, S and Platt, J and Heckerman, D and Sahami, M},
booktitle = {The International Conference on Information and Knowledge Management},
pages = {pp. 148--155},
title = {{Inductive learning algorithms and representations for text categorization}},
year = {1998}
}
@inproceedings{hihn91,
author = {Hihn, J M and Habib-agahi, H},
booktitle = {Proceedings of the Thirteenth IEEE International Conference of Software Engineering},
month = may,
title = {{Cost Estimation of Software Intensive Projects: A Survey of Current Practices}},
year = {1991}
}
@article{Thomas2013,
abstract = {Bug localization is the task of determining which source code$\backslash$nentities are relevant to a bug report. Manual bug localization is labor$\backslash$nintensive since developers must consider thousands of source code$\backslash$nentities. Current research builds bug localization classifiers, based on$\backslash$ninformation retrieval models, to locate entities that are textually$\backslash$nsimilar to the bug report. Current research, however, does not consider$\backslash$nthe effect of classifier configuration, i.e., all the parameter values$\backslash$nthat specify the behavior of a classifier. As such, the effect of each$\backslash$nparameter or which parameter values lead to the best performance is$\backslash$nunknown. In this paper, we empirically investigate the effectiveness of$\backslash$na large space of classifier configurations, 3,172 in total. Further, we$\backslash$nintroduce a framework for combining the results of multiple classifier$\backslash$nconfigurations since classifier combination has shown promise in other$\backslash$ndomains. Through a detailed case study on over 8,000 bug reports from$\backslash$nthree large-scale projects, we make two main contributions. First, we$\backslash$nshow that the parameters of a classifier have a significant impact on$\backslash$nits performance. Second, we show that combining multiple$\backslash$nclassifiers--whether those classifiers are hand-picked or randomly$\backslash$nchosen relative to intelligently defined subspaces of$\backslash$nclassifiers--improves the performance of even the best individual$\backslash$nclassifiers.},
author = {Thomas, Stephen W. and Nagappan, Meiyappan and Blostein, Dorothea and Hassan, Ahmed E.},
doi = {10.1109/TSE.2013.27},
file = {:Users/timm/svns/doc/Thomas\_2013\_TSE.pdf:pdf},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {LDA,LSI,Software maintenance,VSM,bug localization,classifier combination,information retrieval},
number = {10},
pages = {1427--1443},
title = {{The impact of classifier configuration and classifier combination on bug localization}},
volume = {39},
year = {2013}
}
@article{preece96,
author = {Preece, A D and Grossner, C and Radhakrishnan, T},
journal = {Int. J. Human-Computer Studies},
pages = {145--169},
title = {{Validating Dynamic Properties of Rule Based Systems}},
volume = {44},
year = {1996}
}
@article{bahill95,
author = {Bahill, A T and Bharathan, K and Curlee, R F},
journal = {IEEE Transactions on Systems, Man, and Cybernetics},
month = dec,
number = {12},
pages = {1535--1542},
title = {{How the Testing Techniques for a Decision Support Systems Changed Over Nine Years}},
volume = {25},
year = {1995}
}
@inproceedings{me00b,
author = {Menzies, Tim and Cukic, Bojan and Singh, Harhsinder and Powell, John},
booktitle = {ISSRE 2000},
title = {{Testing Nondeterminate Systems}},
year = {2000}
}
@article{wille92,
author = {Wille, R},
journal = {Computers Math. Applic.},
number = {6-9},
pages = {493--515},
title = {{Concept Lattices and Conceptual Knowledge Systems}},
volume = {23},
year = {1992}
}
@book{Hesterberg2005,
abstract = {16.1 The Bootstrap Idea 16.2 First Steps in Using the Bootstrap 16.3 How Accurate Is a Bootstrap Distribution? 16.4 Bootstrap Confidence Intervals 16.5 Significance Testing Using Permutation Tests},
author = {Hesterberg, Tim and Moore, David S Ds and Monaghan, Shaun and Clipson, Ashley and Epstein, Rachel},
booktitle = {Introduction to the Practice of Statistics},
doi = {10.1002/wics.182},
file = {:Users/timm/svns/doc/03bootstrap.pdf:pdf},
isbn = {2002108463},
issn = {19395108},
pages = {1--70},
title = {{Bootstrap Methods and Permutation Tests}},
url = {http://seongjoon.com/drupal/files/Bootstrap methods and permutation tests\_PBS18.pdf},
volume = {5},
year = {2005}
}
@article{shn83,
author = {Shneiderman, B},
journal = {Computer},
month = aug,
pages = {57--69},
title = {{Direct Manipulation: A Step Beyond Programming Languages}},
year = {1983}
}
@article{iwasaki93,
author = {Iwasaki, Y and Simon, H A},
journal = {Artificial Intelligence},
pages = {141--146},
title = {{Reprospecitve on "Causality in Device Behavior"}},
volume = {59},
year = {1993}
}
@article{Yoshida1995,
annote = {Great article on graph mining to learn what folks will do next.},
author = {Yoshida, Kenichi and Motoda, Hiroshi},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Yoshida, Motoda - 1995 - CLIP Concept learning from inference patterns.pdf:pdf},
issn = {0004-3702},
journal = {Artificial Intelligence},
number = {1},
pages = {63--92},
publisher = {Elsevier},
title = {{CLIP: Concept learning from inference patterns}},
url = {http://linkinghub.elsevier.com/retrieve/pii/000437029400066A},
volume = {75},
year = {1995}
}
@article{warrenDS92,
author = {Warren, D S},
journal = {Communications of the ACM},
month = mar,
pages = {93--101},
title = {{Memoing for Logic Programs}},
volume = {35},
year = {1992}
}
@article{Vinterbo2004a,
author = {Vinterbo, S.a.},
doi = {10.1109/TKDE.2004.31},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Vinterbo - 2004 - Privacy a machine learning view.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {approx-,combinatorial optimization,complexity,disclosure control,imation properties,machine learning,privacy},
month = aug,
number = {8},
pages = {939--948},
title = {{Privacy: a machine learning view}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1318579},
volume = {16},
year = {2004}
}
@article{Dasgupta2008,
address = {New York, New York, USA},
author = {Dasgupta, Sanjoy and Hsu, Daniel},
journal = {Proceedings of the 25th international conference on Machine learning - ICML '08},
pages = {208--215},
publisher = {ACM Press},
title = {{Hierarchical sampling for active learning}},
year = {2008}
}
@article{dwyer97,
author = {Dwyer, M B and Avrunin, G S and Corbett, J C},
journal = {$\backslash$url\{http://www.cis.ksu.edu/santos/spec-patterns/\}},
title = {{A System Specification of Patterns}},
year = {1997}
}
@article{bagnall01,
author = {Bagnall, A and {V. Rayward-Smith} and Whittley, I},
journal = {Information and Software Technology},
month = dec,
number = {14},
title = {{The next release problem}},
volume = {43},
year = {2001}
}
@inproceedings{CHEN2005,
address = {New York, NY, USA},
author = {Chen, Zhihao and Menzies, Tim and Port, Dan and Boehm, Barry},
booktitle = {PROMISE '05: Proceedings of the 2005 workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1083165.1083171},
isbn = {-159593-125-2},
pages = {1--6},
publisher = {ACM},
title = {{Feature subset selection can improve software cost estimation accuracy}},
year = {2005}
}
@inproceedings{lokan09,
author = {Lokan, C and Mendes, E},
booktitle = {Empirical Software Engineering and Measurement, 2009. ESEM 2009. 3rd International Symposium on},
file = {:Users/timm/svns/doc/transfer/09lokan.pdf:pdf},
pages = {111--122},
title = {{Applying moving windows to software effort estimation}},
year = {2009}
}
@inproceedings{michael97,
author = {Michael, C C},
booktitle = {Proceedings of the 12th Annual Confererence on Computer Assurance (COMPASS '97) Gaithersburg, MD},
title = {{On the Uniformity of Error Propagation in Software}},
year = {1997}
}
@article{Liu2005a,
abstract = {This paper introduces concepts and algorithms of feature selection, surveys existing feature selection algorithms for classification and clustering, groups and compares different algorithms with a categorizing framework based on search strategies, evaluation criteria, and data mining tasks, reveals unattempted combinations, and provides guidelines in selecting feature selection algorithms. With the categorizing framework, we continue our efforts toward building an integrated system for intelligent feature selection. A unifying platform is proposed as an intermediate step. An illustrative example is presented to show how existing feature selection algorithms can be integrated into a meta algorithm that can take advantage of individual algorithms. An added advantage of doing so is to help a user employ a suitable algorithm without knowing details of each algorithm. Some real-world applications are included to demonstrate the use of feature selection in data mining. We conclude this work by identifying trends and challenges of feature selection research and development.},
author = {Liu, Huan and Member, Senior and Yu, Lei and Member, Student},
doi = {10.1109/TKDE.2005.66},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/Liu05.pdf:pdf},
issn = {10414347},
journal = {Knowledge Creation Diffusion Utilization},
number = {4},
pages = {491--502},
title = {{Algorithms for Classification and Clustering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1401889},
volume = {17},
year = {2005}
}
@article{devedzic99,
author = {Devedzic, V},
journal = {Intelligence (formerly, SIGART)},
pages = {14--24},
title = {{Ontologies: Borrowing from Software Patterns}},
year = {1999}
}
@inproceedings{BOETTICHER08,
address = {New York, NY, USA},
author = {Boetticher, Gary D and Lokhandwala, Nazim},
booktitle = {PROMISE '08: Proceedings of the 4th international workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1370788.1370797},
isbn = {978-1-60558-036-4},
pages = {33--38},
publisher = {ACM},
title = {{Using correlation and accuracy for identifying good estimators}},
year = {2008}
}
@article{dennett95,
author = {Dennett, D C},
journal = {The New York Review of Books},
month = dec,
pages = {83},
title = {{'The Mystery of Consciousness': An Exchange}},
year = {1995}
}
@misc{reaction03,
annote = {Available from $\backslash$url\{http://www.rrs.org/Projects/Launches/Space\_Shot/space\_shot.html\}},
author = {Research, Reaction},
title = {{Reaction Research Society Space Shot}},
year = {2003}
}
@misc{me97s,
author = {Menzies, T J},
title = {{Evaluation Issues for Problem Visual Programming Languages}},
year = {1998}
}
@inproceedings{lum02,
author = {Lum, K and Powell, J and Hihn, J},
booktitle = {ISPA Conference Proceedings, Software Modeling Track},
month = may,
title = {{Validation of Spacecraft Software Cost Estimation Models for Flight and Ground Systems}},
year = {2002}
}
@article{Garson2008a,
address = {New York, New York, USA},
author = {Garson, Kathryn and Adams, Carlisle},
doi = {10.1145/1373290.1373306},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Garson, Kn, Adams - 2008 - Security and Privacy System Architecture for an e-Hospital Environment.pdf:pdf},
isbn = {9781605580661},
journal = {Proceedings of the 7th symposium on Identity and trust on the Internet - IDtrust '08},
keywords = {authentication,health care,policy-based encryption,privacy},
pages = {122},
publisher = {ACM Press},
title = {{Security and privacy system architecture for an e-hospital environment}},
url = {http://portal.acm.org/citation.cfm?doid=1373290.1373306},
year = {2008}
}
@article{Manolescu2008,
author = {Manolescu, I. and Shasha, D. and Afanasiev, L. and Arion, A. and Dittrich, J. and Manegold, S. and Polyzotis, N. and Schnaitter, K. and Senellart, P. and Zoupanos, S.},
doi = {10.1145/1374780.1374791},
file = {:Users/timm/svns/doc/manolescu08.pdf:pdf},
issn = {01635808},
journal = {ACM SIGMOD Record},
keywords = {repeatability},
month = mar,
number = {1},
pages = {39},
title = {{The repeatability experiment of SIGMOD 2008}},
url = {http://portal.acm.org/citation.cfm?doid=1374780.1374791},
volume = {37},
year = {2008}
}
@inproceedings{budgen09,
author = {{D. Budgen P. Brereton}, B Kitchenham},
booktitle = {33rd Annual IEEE Software Engineering Workshop 2009 (SEW-33), Skï¿½vde, Sweden},
title = {{Is Evidence Based Software Engineering mature enough for Practice \& Policy?}},
year = {2009}
}
@inproceedings{me04b,
author = {Menzies, T and Di\~{}Stefano, Justin S and Cunanan, Chris and Chapman, Robert (Mike)},
booktitle = {IEEE Transactions Software Engineering (in preperation)},
title = {{The Business Case for Defect Logging}},
year = {2004}
}
@inproceedings{feig77,
author = {Feigenbaum, E A},
booktitle = {IJCAI '77},
title = {{The Art of Artificial Intelligence: Themes and Case Studies of Knowledge Engineering.}},
year = {1977}
}
@inproceedings{me00v,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/00vp.pdf\}},
author = {Menzies, T J},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{Evaluation Issues for Problem Visual Programming Languages}},
year = {1998}
}
@article{zimmermann10a,
author = {Zimmermann, Thomas and Premraj, Rahul and Bettenburg, Nicolas and Just, Sascha and Schr\"{o}ter, Adrian and Weiss, Cathrin},
journal = {IEEE Transactions on Software Engineering},
month = sep,
number = {5},
pages = {618--643},
title = {{What Makes a Good Bug Report?}},
volume = {36},
year = {2010}
}
@misc{chapman02,
author = {Chapman, Mike and Solomon, Dan},
title = {{The Relationship of Cyclomatic Complexity, Essential Complexity and Error Rates}},
year = {2002}
}
@inproceedings{BOETTICHER2009,
address = {New York, NY, USA},
author = {Boetticher, Gary D},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540458},
isbn = {978-1-60558-634-2},
pages = {1--5},
publisher = {ACM},
title = {{From software engineer to day trader in 3 easy steps: a comparison of software engineering (SE) data mining with financial data mining}},
year = {2009}
}
@book{norvig92,
author = {Norvig, P},
pages = {946},
publisher = {Morgan Kaufmann},
title = {{Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp}},
year = {1992}
}
@book{press92,
author = {Press, H and Flannery, B P and Teukolsky, S A and Vetterling, W T},
isbn = {0521437202},
publisher = {Cambridge University Press, second edition},
title = {{Numerical Recipes in C Example Book : The Art of Scientific Computing (The Art of Scientific Computing)}},
year = {1992}
}
@article{ack67,
author = {Ackoff, R L},
journal = {Management Science},
month = dec,
pages = {319--331},
title = {{Management \{M\}isinformation \{S\}ystems}},
year = {1967}
}
@article{Saclay,
author = {Saclay, Inria and Sud, U Paris and Orsay, F- and Schoenauer, Marc and Sebag, Mich\`{e}le},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Saclay et al. - Unknown - A Mono Surrogate for Multiobjective Optimization.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {multiobjective optimization,pareto,support vec-,surrogate models},
mendeley-tags = {pareto},
pages = {471--478},
title = {{A Mono Surrogate for Multiobjective Optimization}}
}
@book{law00,
author = {Law, A and Kelton, B},
publisher = {McGraw Hill},
title = {{Simulation Modeling and Analysis}},
year = {2000}
}
@article{hammill09,
author = {Hamill, M and Goseva-Popstojanova, K},
journal = {Software Engineering, IEEE Transactions on},
number = {4},
pages = {484--496},
title = {{Common Trends in Software Fault and Failure Data}},
volume = {35},
year = {2009}
}
@misc{price-s,
author = {NJ, PRICE Systems L L C Mt. Laurel},
title = {{Your Guide to PRICE-S: Estimating Cost and Schedule of Software Development and Support}},
year = {1998}
}
@inproceedings{mittle07,
author = {Mittelmann, H D},
booktitle = {22nd Euorpean Conference on Operational Research},
title = {{Recent Benchmarks of Optimization Software}},
year = {2007}
}
@article{keung2008b,
address = {Piscataway, NJ, USA},
author = {Keung, Jacky Wai and Kitchenham, Barbara A and Jeffery, David Ross},
doi = {http://dx.doi.org/10.1109/TSE.2008.34},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {4},
pages = {471--484},
publisher = {IEEE Press},
title = {{Analogy-X: Providing Statistical Inference to Analogy-Based Software Cost Estimation}},
volume = {34},
year = {2008}
}
@article{Vaidyaa,
author = {Vaidya, Jaideep and Clifton, Chris},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Vaidya, Clifton - Unknown - Privacy-Preserving Decision Trees over Vertically Partitioned Data.pdf:pdf},
journal = {Constraints},
number = {0312357},
title = {{Privacy-Preserving Decision Trees over Vertically Partitioned Data}}
}
@inproceedings{Kohavi1995a,
author = {Kohavi, R.},
booktitle = {International joint Conference on artificial intelligence},
file = {:Users/timm/svns/doc/kohavi95.pdf:pdf},
issn = {1045-0823},
publisher = {Citeseer},
title = {{A study of cross-validation and bootstrap for accuracy estimation and model selection}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.48.529\&amp;rep=rep1\&amp;type=pdf},
volume = {14},
year = {1995}
}
@article{SINGH2009,
address = {New York, NY, USA},
author = {Singh, Yogesh and Kaur, Arvinder and Malhotra, Ruchika},
doi = {http://doi.acm.org/10.1145/1457516.1457529},
issn = {0163-5948},
journal = {SIGSOFT Softw. Eng. Notes},
number = {1},
pages = {1--6},
publisher = {ACM},
title = {{Application of support vector machine to predict fault prone classes}},
volume = {34},
year = {2009}
}
@article{Journal2010,
author = {Journal, C I S},
file = {:Users/timm/svns/doc/cost/11Vahid.pdf:pdf},
keywords = {- cost estimation,accuracy,cocomo,project fail},
number = {1},
pages = {21--29},
title = {{Software Cost Estimation Methods : A Review}},
volume = {2},
year = {2010}
}
@inproceedings{me96f,
author = {Menzies, T J and Goss, S},
booktitle = {Proceedings PKAW '96: Pacific Knowledge Acquisition Workshop and Monash University Department of Software Development Technical Report TR96-15},
title = {{Vague Models and Their Implications for the KBS Design Cycle}},
year = {1996}
}
@article{smythe82,
author = {Smythe, G A and Duncam, M W and Bradshaw, J E and Cai, M Y and Symons, R G},
journal = {Endocrinology},
pages = {376--383},
title = {{Control of Growth Hormone Secretion: Hypothalmic Dopamine, Norepinephrine and Serotonin Levels and Metabolism in Three Hyposomatrophic Rat Models and in Normal Rats}},
volume = {110},
year = {1982}
}
@book{kosko92,
author = {Kosko, B},
publisher = {Prentice-Hall},
title = {{Neural Networks and Fuzzy Systems A Dynamic Systems Approach}},
year = {1992}
}
@inproceedings{palma12,
author = {Palma, Francis and Farzin, Hadi and Gueheneuc, Yann-Gael},
booktitle = {Third International Workshop on Recommendation Systems for Software Engineering},
title = {{Recommendation System for Design Patterns in Software Development: An DPR Overview}},
year = {2012}
}
@article{Li2008,
author = {Li, Jingzhou and Ruhe, Guenther},
doi = {10.1007/s10664-007-9054-4},
journal = {Empirical Softw. Engg.},
month = feb,
number = {1},
pages = {63--96},
title = {{Analysis of attribute weighting heuristics for analogy-based software effort estimation method AQUA+}},
volume = {13},
year = {2008}
}
@article{Ruiz2005,
author = {Ruiz, C},
file = {:Users/timm/svns/doc/k2.pdf:pdf},
journal = {Department of Computer Science},
pages = {1--7},
title = {{Illustration of the K2 algorithm for learning Bayes net structures}},
url = {http://web.cs.wpi.edu/~cs539/s07/Projects/k2\_algorithm.pdf},
year = {2005}
}
@book{medawar79,
author = {Medawar, P B},
publisher = {Pan Books},
title = {{Advice to a Young Scientist}},
year = {1979}
}
@article{stefik87,
author = {Stefix, M J and Bobrow, D G},
journal = {Artificial Intelligence},
pages = {220--226},
title = {{Review of Winograd \& Flores, Understanding Computers and Cognition: A New Foundation for Design}},
volume = {31},
year = {1987}
}
@inproceedings{me05b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05sawtooth.pdf\}},
author = {Menzies, Tim},
number = {August},
pages = {1--6},
title = {{Incremental Discretization and Bayes Classifiers Handles Concept Drift and Scales Very Well}},
volume = {X},
year = {2005}
}
@article{born86,
author = {Borning, A H},
journal = {Human-Computer Interaction},
number = {4},
pages = {269--295},
title = {{Graphically Defining New Building Blocks in ThingLab}},
volume = {2},
year = {1986}
}
@inproceedings{benj94y,
author = {Benjamins, R},
booktitle = {Proceedings of the European Knowledge Acquisition Workshop, 1994},
title = {{On a Role of Probem Solving Methods in Knowledge Acquisition- Experiments with Diagnostic Strategies}},
year = {1994}
}
@book{sed88,
author = {Sedgewick, R},
publisher = {Addison-Wesley},
title = {{Algorithms}},
year = {1988}
}
@inproceedings{me03r,
abstract = { Model-based software has become quite popular in recent years, making its way into a broad range of areas, including the aerospace industry. The models provide an easy graphical interface to develop systems, which can generate the sometimes tedious code that follows. While there are many tools available to assess standard procedural code, there are limits to the testing of model-based systems. A major problem with the models are that their internals often contain gray areas of unknown system behavior. These possible behaviors form what is known as a data cloud, which is an overwhelming range of possibilities of a system that can overload analysts (Menzies et al., 2003). With large data clouds, it is hard to demonstrate which particular decision leads to a particular outcome. Even if definite decisions can't be made, it is possible to reduce the variance of and condense the clouds (Menzies et al., 2003). This paper presents two case studies; one with a simple illustrative model and another with a more complex application. The TAR3 treatment learning tool summarizes the particular attribute ranges that selects for particular behaviors of interest, reducing the data clouds.},
author = {Geletko, D. and Menzies, T.},
booktitle = {28th Annual NASA Goddard Software Engineering Workshop, 2003. Proceedings.},
doi = {10.1109/SEW.2003.1270729},
isbn = {0-7695-2064-2},
month = dec,
title = {{Model-based software testing via incremental treatment learning}},
year = {2003}
}
@article{bastani93,
author = {Bastani, F and Chen, I},
journal = {International Journal of Software Engineering and Knowledge Engineering},
number = {1},
pages = {99--114},
title = {{Assessment of the Reliability of AI Programs}},
volume = {3},
year = {1993}
}
@book{Witten2011,
author = {Witten, I.H. and Frank, E.},
edition = {3rd},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Witten, Frank - 2011 - Data Mining, practical machine learning tools and techniques.pdf:pdf},
isbn = {0120884070},
publisher = {Morgan Kaufmann Pub},
title = {{Data Mining, practical machine learning tools and techniques}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=QTnOcZJzlUoC\&amp;oi=fnd\&amp;pg=PA3\&amp;dq=Data+Mining,+practical+machine+learning+tools+and+techniques\&amp;ots=3ggzbtYjL9\&amp;sig=X-Uh43uLUwt3ahx5CqzoRGWw9OU},
year = {2011}
}
@article{brat05,
author = {Brat, G and Drusinsky, D and Giannakopoulou, D and Goldberg, A and Havelund, K and Lowry, M and Pasareanu, C and Venet, A and Washington, R and Visser, W},
journal = {Formal Methods in Systems Design Journal},
month = sep,
title = {{Experimental Evaluation of Verification and Validation Tools on Martian Rover Software}},
year = {2005}
}
@inproceedings{whittle00,
author = {Whittle, J and Schumann, J},
booktitle = {Proceedings of the 22nd International Conference on Software Engineering (ICSE). Limerick, Ireland},
month = jun,
title = {{Generating Statechart Designs From Scenarios}},
year = {2000}
}
@article{smith1988,
author = {Smith, Leonard A},
journal = {Physics Letters A},
number = {6},
pages = {283--288},
publisher = {Elsevier},
title = {{Intrinsic limits on dimension calculations}},
volume = {133},
year = {1988}
}
@article{lopez90,
author = {{B. Lopez P. Meseguer}, E Plaza},
journal = {AI Communications},
number = {3},
pages = {119--135},
title = {{Knowledge Based Systems Validation: A State of the Art.}},
volume = {5},
year = {1990}
}
@article{Cha2002,
author = {Cha, S},
doi = {10.1016/S0031-3203(01)00118-2},
file = {:Users/timm/svns/doc/distanceBetweenHistograms.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {distance measure,histogram,modulo,nominal,ordinal},
month = jun,
number = {6},
pages = {1355--1370},
title = {{On measuring the distance between histograms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320301001182},
volume = {35},
year = {2002}
}
@inproceedings{deb95b,
author = {Debenham, J},
booktitle = {Proceedings Seventh International Conference on Software Engineering and Knowledge Engineering SEKE'95, Washington, June},
title = {{A Unified Approach to Requirements Specification and Systems Analysis in the Design of Knowledge-Based Systems}},
year = {1995}
}
@article{lutz03,
author = {Lutz, R and Mikulski, Carmen},
journal = {Journal of Systems and Software},
title = {{Operational Anomalies as a Cause of Safety-Critical Requirements Evolution}},
year = {2003}
}
@phdthesis{me95,
author = {Menzies, T J},
school = {University of New South Wales},
title = {{Principles for Generalised Testing of Knowledge Bases}},
year = {1995}
}
@article{ilin10,
author = {Ulin, A and T.Raiko},
journal = {Journal of Machine Learning Research},
pages = {1957--2000},
title = {{Practical Approaches to Principal Component Analysis in the Presence of Missing Values}},
volume = {11},
year = {2010}
}
@misc{Coiera99,
annote = {Technical Report, 1999, to appear},
author = {Coiera, E},
institution = {Hewlett-Packard Laboratories},
title = {{Communication under scarcity of resources}},
year = {1999}
}
@inproceedings{gautier93,
author = {Gautier, Patrice O and Gruber, Thomas R},
booktitle = {AAAI-93},
pages = {264--270},
title = {{Generating Explanations of Device Behavior Using Compositional Modeling and Causal Ordering}},
year = {1993}
}
@article{aamodt94,
author = {Aamodt, A and Plaza, E},
journal = {AI Communications},
month = mar,
number = {1},
pages = {39--59},
title = {{Case-based reasoning; Foundational issues, methodological variations, and system approaches}},
volume = {7},
year = {1994}
}
@article{Iliuk2011,
abstract = {With over 2,000 publications, including about 250 reviews, resulting from a SciFinder search in just a two year period (2009-2010), the field of aptamer research has continuously generated lots of interest in the scientific community. Aptamers, first reported by three groups independently in 1990, are the artificial single-stranded DNA or RNA sequences (more recently, peptides) that fold into secondary and tertiary structures making them bind to certain targets with extremely high specificity. Owing to the high specific affinity of an aptamer to its target molecule (small molecules, proteins and even entire cells), it is thought to resemble chemical antibodies, with the dissociation constants ranging from nanomolar to picomolar level. Aptamers have a number of unique features which make them a more effective choice than antibodies. First, aptamers can be screened via in vitro process against a synthetic library, making it possible to target any molecules (from small inorganic ions to intact cells), overcoming the limit of having to use cell lines or animals, as is necessary for antibodies. Second, aptamers, once selected, can undergo subsequent amplification through polymerase chain reaction to produce a large quantity with high purity. Third, the simple chemical structure of aptamer makes it easily amendable to further modifications with functional groups according to different purposes. Finally, aptamers are much more stable than antibodies, making them suitable in applications requiring harsh conditions (e.g., high temperature or extreme pH).The applications of aptamers remain very dynamic, with increasing explorations in the fields of biosensing, diagnostics and therapeutics. There have been a numbers of excellent reviews in recent years with different emphases.4-8 Herein, as the first review of aptamers on Analytical Chemistry, we attempt to cover major progresses in bioanalytical applications of aptamers in the past 2 years.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Iliuk, Anton B. and Hu, Lianghai and Tao, W. Andy},
doi = {10.1021/ac201057w},
eprint = {NIHMS150003},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Iliuk11.pdf:pdf},
isbn = {0003-2700$\backslash$n1520-6882},
issn = {00032700},
journal = {Analytical Chemistry},
number = {12},
pages = {4440--4452},
pmid = {21524128},
title = {{Aptamer in bioanalytical applications}},
volume = {83},
year = {2011}
}
@incollection{emmerich98,
annote = {Available $\backslash$url\{eprints.ucl.ac.uk/937/1/10.6\_chapter2v2.pdf\}},
author = {Emmerich, W and Finkelstein, A and Fuggetta, A and Montangero, C and Derniame, J},
booktitle = {J.C. Derniame and B.A. Kaba and D. Wastell},
editor = {{Software Process: Principles Methodology}, Technology Lecture Notes in Computer Science},
pages = {15--25},
publisher = {Springer Verlag},
title = {{Software process: standards, assessments and improvements}},
volume = {1500},
year = {1998}
}
@inproceedings{lang99,
author = {Langley, P and Sage, S},
booktitle = {Proceedings of the Sixteenth International Conference on Machine Learning, Bled, Slovenia},
pages = {220--228},
title = {{Tractable average-case analysis of naive Bayesian classifiers}},
year = {1999}
}
@misc{key03,
annote = {$\backslash$url\{http://www.space-travel.com/reports/Columbia\_\_The\_Legacy\_Of\_Better\_\_Faster\_\_Cheaper.html\}},
author = {Key, Sugarloaf},
month = jul,
title = {{Columbia, The Legacy Of "Better, Faster, Cheaper"?}},
year = {2003}
}
@inproceedings{Quinlan1993a,
author = {Quinlan, J.R.},
booktitle = {Proceedings of the Tenth International Conference on Machine Learning},
file = {:Users/timm/svns/doc/quinlan93.pdf:pdf},
pages = {236--243},
publisher = {Citeseer},
title = {{Combining instance-based and model-based learning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.34.6358\&amp;rep=rep1\&amp;type=pdf},
year = {1993}
}
@inproceedings{pavl03,
author = {Pavlovic, D and Smith, D R},
booktitle = {UNU/IIST 10th Anniversary Colloquium, Formal Methods at the Crossroads: From Panaea to Foundational Support},
publisher = {Springer-Verlag},
title = {{Software Development by Refinement}},
year = {2003}
}
@article{easter96,
author = {Easterbrook, S and Nuseibeh, B},
journal = {BCS/IEE Software Engineering Journal},
month = jan,
pages = {31--43},
title = {{Using Viewpoints for Inconsistency Management}},
year = {1996}
}
@inproceedings{me97n,
author = {Menzies, T J},
booktitle = {Banff Knowledge Acquisition workshop, 1998},
title = {{Evaluation Issues for Problem Solving Methods}},
year = {1998}
}
@article{dietterich97,
author = {Dietterich, T G},
journal = {AI Magazine},
number = {4},
pages = {97--136},
title = {{Machine Learning Research: Four Current Directions}},
volume = {18},
year = {1997}
}
@article{dunsmore88,
author = {Dunsmore, H E},
journal = {IEEE Software},
month = may,
pages = {96--99},
title = {{Evidence Supports some Truisms, Belies Others. (Some Empirical Results concerning Software Development)}},
year = {1988}
}
@misc{john96,
annote = {(personal communication)},
author = {Johnson, R},
title = {{No Title}}
}
@book{hamid91,
author = {Abdel-Hamid, T and Madnick, S},
isbn = {0-13-822040-9},
publisher = {Prentice-Hall Software Series},
title = {{Software Project Dynamics: An Integrated Approach}},
year = {1991}
}
@inproceedings{lum06,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06ispa.pdf\}},
author = {Lum, Karen and Menzies, Tim and Hihn, Jairus},
booktitle = {ISPA Conference Proceedings},
title = {{Studies in Software Cost Model Behavior: Do We Really Understand Cost Model Performance?}},
url = {http://trs-new.jpl.nasa.gov/dspace/handle/2014/41450},
year = {2006}
}
@inproceedings{Blockeel2001,
author = {Blockeel, H. and Struyf, J.},
booktitle = {INTERNATIONAL WORKSHOP on machine learning},
file = {:Users/timm/svns/doc/blockeel01.pdf:pdf},
pages = {11--18},
title = {{Effecient Algorithms for Decision Tree Cross-Validation}},
year = {2001}
}
@inproceedings{clancy97,
author = {Clancy, D J and Kuipers, B K},
booktitle = {AAAI-97},
title = {{Model Decomposition and Simulation: A component based qualitative simulation algorithm}},
year = {1997}
}
@inproceedings{stokely09,
author = {Stokely, Murray and Winget, Jim and Keyes, Ed and Grimes, Carrie and Yolken, Benjamin},
booktitle = {Proceedings for the International Parallel and Distributed Processing Symposium 2009},
pages = {1--8},
title = {{Using a Market Economy to Provision Compute Resources Across Planet-wide Clusters}},
url = {http://www.stokely.org/papers/google-cluster-auctions.pdf},
year = {2009}
}
@inproceedings{me99n,
author = {Menzies, T},
booktitle = {KAW'99: the 12th Workshop on Knowledge Acquisition, Modeling and Management, Voyager Inn, Banff, Alberta, Canada Oct 16-22, 1999},
title = {{h\{Q\}kb- The High Quality Knowledge Base Initiative (Sisyphus V: Learning Design Assessment Knowledge)}},
year = {1999}
}
@phdthesis{WEILAI93,
address = {Callaghan, New South Wales, Australia, 2308},
author = {Lai, W},
month = jun,
school = {Department of Computer Science, University of Newcatle},
title = {{Building Interactive Diagram Applications}},
year = {1993}
}
@incollection{brac89,
author = {Brachman, R J and Gilbert, V P and Levesque, H J},
booktitle = {Readings in Artificial Intelligence and Databases},
editor = {Mylopoulos, J and Brodie, M L},
pages = {293--300},
publisher = {Morgan Kaufmann},
title = {{An \{E\}ssential \{H\}ybrid \{R\}easoning \{S\}ystem: \{K\}nowledge and \{S\}ymbol \{L\}evel \{A\}ccounts of \{K\}rypton}},
year = {1989}
}
@article{chill92,
author = {Chillarege, R and Bhandari, I S and Chaar, J K and Halliday, M J and Moebus, D S and Ray, B K and Wong, M.-Y.},
journal = {IEEE Transactions on Software Engineering},
month = nov,
number = {11},
pages = {943--956},
title = {{Orthogonal Defect Classification--A Concept for In-Process Measurements}},
volume = {18},
year = {1992}
}
@inproceedings{boose92,
author = {Boose, J H and Bradshaw, J M and Koszareck, J L and Shema, D B},
booktitle = {Proceedings of the 7th Knowledge Acquisition for Knowledge-Based Systems Workshop},
editor = {Gaines, B R and Musen, M A and Boose, J R},
pages = {2.1----2.22},
title = {{Knowledge \{A\}cquisition \{T\}echniques for \{G\}roup \{D\}ecision \{S\}upport}},
year = {1992}
}
@inproceedings{me01g,
author = {Menzies, Tim and Hu, Ying},
booktitle = {First International Workshop on Model-based Requirements Engineering},
title = {{Constraining Discussions in Requirements Engineering via Models}},
year = {2001}
}
@article{gama00,
author = {Gama, J},
journal = {Intelligent Data Analysis},
pages = {475--488},
title = {{Iterative Bayes}},
year = {2000}
}
@article{step05,
author = {Stepney, S and Braunstein, S L and Clark, J A and Tyrrell, A and Adamatzky, A and Smith, R E and Addis, T and Johnson, C and Timmis, J and Welch, P and Others},
journal = {International Journal of Parallel, Emergent and Distributed Systems},
number = {1},
pages = {5--19},
publisher = {Taylor \& Francis},
title = {{Journeys in non-classical computation I: A grand challenge for computing research}},
volume = {20},
year = {2005}
}
@book{clocksin87,
author = {Clocksin, W F and Mellish, C S},
publisher = {Springer-Verlag},
title = {{Programming in Prolog (third edition)}},
year = {1987}
}
@article{morisio02,
author = {Morisio, M and {M. Ezran} and Tully, C},
journal = {IEEE Transactions on Software Engineering},
number = {4},
pages = {340--357},
title = {{Success and failure factors in software reuse}},
volume = {28},
year = {2002}
}
@inproceedings{Zabiht1987,
author = {Zabiht, Ramin and Mcallester, David and Chapman, David},
booktitle = {AAAI'87},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zabiht, Mcallester, Chapman - 1987 - Non-Deterministic Lisp with Backtracking.pdf:pdf},
pages = {59--64},
title = {{Non-Deterministic Lisp with Backtracking}},
year = {1987}
}
@article{newell93,
author = {Newell, A},
journal = {Artificial Intelligence},
pages = {31--38},
title = {{Reflections on the \{K\}nowledge \{L\}evel}},
volume = {59},
year = {1993}
}
@article{Dejaeger2012,
abstract = {A predictive model is required to be accurate and comprehensible in order to inspire confidence in a business setting. Both aspects have been assessed in a software effort estimation setting by previous studies. However, no univocal conclusion as to which technique is the most suited has been reached. This study addresses this issue by reporting on the results of a large scale benchmarking study. Different types of techniques are under consideration, including techniques inducing tree/rule based models like M5 and CART, linear models such as various types of linear regression, nonlinear models (MARS, multilayered perceptron neural networks, radial basis function networks, and least squares support vector machines), and estimation techniques that do not explicitly induce a model (e.g., a case-based reasoning approach). Furthermore, the aspect of feature subset selection by using a generic backward input selection wrapper is investigated. The results are subjected to rigorous statistical testing and indicate that ordinary least squares regression in combination with a logarithmic transformation performs best. Another key finding is that by selecting a subset of highly predictive attributes such as project size, development, and environment related attributes, typically a significant increase in estimation accuracy can be obtained.},
author = {Dejaeger, Karel and Verbeke, Wouter and Martens, David and Baesens, Bart},
file = {:Users/timm/svns/doc/cost/12Dejaeger.pdf:pdf},
keywords = {HF Commerce,QA76 Computer software},
number = {2},
pages = {375--397},
title = {{Data mining techniques for software effort estimation: a comparative study}},
url = {http://eprints.soton.ac.uk/336472/},
volume = {38},
year = {2012}
}
@inproceedings{deb96a,
author = {Debenham, J},
booktitle = {Proceedings 9th International Sympoisum on Methodologies for Intelligent Systems ISMIS '96, Zakopane, Poland, June},
pages = {314--705},
title = {{Knowledge Simplificiation}},
year = {1996}
}
@inproceedings{me04b,
author = {Menzies, T and Di\~{}Stefano, Justin S and Cunanan, Chris and Chapman, Robert (Mike)},
booktitle = {IEEE Transactions Software Engineering (in preperation)},
title = {{The Business Case for Defect Logging}},
year = {2004}
}
@book{love93,
author = {Love, T},
publisher = {SIG Books Incorporated},
title = {{Object Lessons}},
year = {1993}
}
@article{ostr05,
author = {Ostrouchov, George and Samatova, Nagiza F},
issn = {0162-8828},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
month = aug,
number = {8},
pages = {1340--1343},
title = {{On FastMap and the Convex Hull of Multivariate Data: Toward Fast and Robust Dimension Reduction}},
volume = {27},
year = {2005}
}
@book{kalman02,
author = {Kalman, John A},
publisher = {Rinton Press},
title = {{Automated Reasoning with OTTER}},
year = {2002}
}
@article{Wama2008,
author = {Wama, Takenori and Nakatsu, Ryohei},
doi = {10.1109/UMEDIA.2008.4570929},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Wama, Nakatsu - 2008 - Analysis and generation of Japanese folktales based on Vladimir Proppâs methodology.pdf:pdf},
isbn = {978-1-4244-1865-7},
journal = {2008 First IEEE International Conference on Ubi-Media Computing},
keywords = {folktale},
mendeley-tags = {folktale},
month = jul,
pages = {426--430},
publisher = {Ieee},
title = {{Analysis and generation of Japanese folktales based on Vladimir Proppâs methodology}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4570929},
year = {2008}
}
@phdthesis{reggia81,
author = {Reggia, J A},
school = {University of Maryland},
title = {{Knowledge-Based Decision Support Systems: Development Through KMS}},
year = {1981}
}
@article{demillo95,
author = {DeMillo, R A and Mathur, A P and Wong, W E},
journal = {IEEE Transactions on Software Engineering},
month = oct,
number = {10},
pages = {854--861},
title = {{Some Critical Remarks on a Hierarchy of Fault-Detecting Abilities of Test Methods}},
volume = {21},
year = {1995}
}
@inproceedings{me97e,
author = {M.Posterma and Wu, X and Menzies, T J},
booktitle = {First Pacific Asia Conference on Knowledge Discovery and Data Mining (PAKDD97)},
title = {{A Tuning Aid for Discretization in Rule Induction}},
year = {1997}
}
@inproceedings{schn97,
author = {Schneidewind, N F},
booktitle = {Proceedings of the 8th International Symposium on Software Reliability Engineering, Albuquerque, New Mexico},
month = nov,
pages = {402--415},
title = {{Software Metrics Model for Integrating Quality Control and Prediction}},
year = {1997}
}
@incollection{preece98,
author = {Preece, A},
booktitle = {Proceedings of the Banff KA workshop, 1998},
title = {{Building the Right System Right: Evaluating V\&V Methods in Knowledge Engineering}},
year = {1998}
}
@book{endres03,
author = {Endres, A and Rombach, H D},
publisher = {Addison Wesley},
title = {{A Handbook of Software and Systems Engineering: Empirical Observations, Laws and Theories}},
year = {2003}
}
@article{Settles2010,
author = {Settles, Burr},
doi = {10.1.1.167.4245},
file = {:Users/timm/svns/doc/10bsettlesActiveLearning.pdf:pdf},
issn = {00483931},
journal = {Active Learning, University of Wisconsin Madison},
title = {{Active Learning Literature Survey}},
year = {2010}
}
@article{fenton07,
author = {Fenton, Norman E and Neil, Martin and Caballero, Jose Galan},
journal = {IEEE Trans. on Knowl. and Data Eng.},
number = {10},
pages = {1420--1432},
title = {{Using Ranked Nodes to Model Qualitative Judgments in Bayesian Networks}},
volume = {19},
year = {2007}
}
@inproceedings{lee95,
author = {Lee, M and Compton, P},
booktitle = {Proceedings of the 8th Australian Joint Conference on Aritificial Intelligence (AI'95)},
pages = {83--90},
title = {{From Heuristic Knowledge to Causal Explanations}},
year = {1995}
}
@misc{fenton07b,
author = {Fenton, N},
title = {{Keynote address, PROMISE'07}},
year = {2007}
}
@article{Spears1990,
author = {Spears, W.M. and {De Jong}, K.a.},
file = {:Users/timm/svns/doc/92ga\_rules.pdf:pdf},
pages = {335--341},
title = {{Using genetic algorithms for supervised concept learning}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=130359},
year = {1990}
}
@inproceedings{elkan93,
address = {Menlo Park, California},
author = {Elkan, Charles},
booktitle = {Proceedings of the Eleventh National Conference on Artificial Intelligence},
editor = {Fikes, Richard and Lehnert, Wendy},
pages = {698--703},
publisher = {AAAI Press},
title = {{The Paradoxical Success of Fuzzy Logic}},
year = {1993}
}
@misc{wilke96,
author = {Wilke, W and Vollrath, I and Altho, K and Bergmann, R},
booktitle = {Adaptation in Case Based Reasoning: A Workshop at ECAI 1996 in Budapes},
title = {{A Framework for Learning Adaptation Knowledge Based on Knowledge Light Approaches}},
year = {1996}
}
@incollection{newell91,
author = {Newell, A and Yost, G R and Laird, J E and Rosenbloom, P S and Altmann, E},
booktitle = {The Soar Papers},
editor = {Rosenbloom, P S and Laird, J E and Newell, A},
pages = {1321--1359},
publisher = {MIT Press},
title = {{Formulating the \{P\}roblem \{S\}pace \{C\}omputational \{M\}odel}},
volume = {2},
year = {1991}
}
@article{He,
archivePrefix = {arXiv},
arxivId = {arXiv:1411.4228v1},
author = {He, Peng and Li, Bing},
eprint = {arXiv:1411.4228v1},
file = {:Users/timm/svns/doc/transfer/ 14CPDPifs.pdf:pdf},
keywords = {-cross-project defect prediction,learning technique,software metric,software quality},
title = {{Towards Cross-Project Defect Prediction with Imbalanced Feature Sets}}
}
@article{me06e,
annote = {Available on-line at $\backslash$url\{http://menzies.us/pdf/06costs.pdf\}},
author = {Menzies, T and Hihn, J},
journal = {IEEE Software},
title = {{Evidence-Based Cost Estimation for Better Quality Software}},
year = {2006}
}
@book{jones94,
author = {Jones, C},
publisher = {Yourdon Press},
title = {{Assessment and Control of Software Risks}},
year = {1994}
}
@inproceedings{buse12,
author = {Buse, Raymond P L and Zimmermann, Thomas},
booktitle = {ICSE'12, Industry Track},
title = {{Information Needs for Software Development Analytics}},
year = {2012}
}
@article{Liu2005,
abstract = {This paper introduces concepts and algorithms of feature selection, surveys existing feature selection algorithms for classification and clustering, groups and compares different algorithms with a categorizing framework based on search strategies, evaluation criteria, and data mining tasks, reveals unattempted combinations, and provides guidelines in selecting feature selection algorithms. With the categorizing framework, we continue our efforts toward building an integrated system for intelligent feature selection. A unifying platform is proposed as an intermediate step. An illustrative example is presented to show how existing feature selection algorithms can be integrated into a meta algorithm that can take advantage of individual algorithms. An added advantage of doing so is to help a user employ a suitable algorithm without knowing details of each algorithm. Some real-world applications are included to demonstrate the use of feature selection in data mining. We conclude this work by identifying trends and challenges of feature selection research and development.},
author = {Liu, Huan and Member, Senior and Yu, Lei and Member, Student},
doi = {10.1109/TKDE.2005.66},
file = {:Users/timm/svns/doc/04clusteringReview.pdf:pdf},
issn = {10414347},
journal = {Knowledge Creation Diffusion Utilization},
number = {4},
pages = {491--502},
title = {{Algorithms for Classification and Clustering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1401889},
volume = {17},
year = {2005}
}
@incollection{getner83,
author = {Getner, D and Getner, D R},
chapter = {Flowing Wa},
publisher = {Hillsdale N.J. Erlbarum},
title = {{Mental Models}},
year = {1983}
}
@article{MALHOTRA2010,
address = {New York, NY, USA},
author = {Malhotra, Ruchika and Kaur, Arvinder and Singh, Guru Gobind},
doi = {http://doi.acm.org/10.1145/1764810.1764825},
issn = {0163-5948},
journal = {SIGSOFT Softw. Eng. Notes},
number = {3},
pages = {1--6},
publisher = {ACM},
title = {{Application of machine learning methods for software effort prediction}},
volume = {35},
year = {2010}
}
@misc{pisces,
author = {Technlogies, Reliable Sotware},
title = {{PiSCES Automatic Test Case Generator $\backslash$url\{http://www.rstcorp.com/tools.html\#pisces\}}},
year = {1997}
}
@article{kitc01,
author = {Kitchenham, B A and Pickard, L M and MacDonell, S G and Shepperd, M J},
journal = {Software, IEE Proceedings},
number = {3},
pages = {81--85},
title = {{What accuracy statistics really measure}},
volume = {148},
year = {2001}
}
@article{JingGao2010,
abstract = {Ensemble methods have emerged as a powerful method for improving the robustness as well as the accuracy of both supervised and unsupervised solutions. Moreover, as enormous amounts of data are continuously generated from different views, it is important to consolidate different concepts for intelligent decision making. In the past decade, there have been numerous studies on the problem of combining competing models into a committee, and the success of ensemble techniques has been observed in multiple disciplines, including recommendation systems, anomaly detection, stream mining, and web applications. The ensemble techniques have been mostly studied in supervised and unsupervised learning communities separately. However, they share the same basic principles, i.e., combination of diversified base models strengthens weak models. Also, when both supervised and unsupervised models are available for a single task, merging all of the results leads to better performances. Therefore, there is a need of a systematic introduction and comparison of the ensemble techniques, combining the views of both supervised and unsupervised learning ensembles. In this tutorial, we will present an organized picture on ensemble methods with a focus on the mechanism to merge the results. We start with the description and applications of ensemble methods. Through reviews of well-known and state-of-the-art ensemble methods, we show that supervised learning ensembles usually learn" this mechanism based on the available labels in the training data, whereas unsupervised ensembles simply combine multiple clustering solutions based on consensus". We end the tutorial with a systematic approach to combine both supervised and unsupervised models, and several applications of ensemble methods.},
author = {{Jing Gao}, Wei Fan And Jiawei Han},
publisher = {Tutorial on SIAM Data Mining Conference (SDM)},
title = {{On the Power of Ensemble: Supervised and Unsupervised Methods Reconciled}},
year = {2010}
}
@inproceedings{corbet94,
author = {Corbett, J},
booktitle = {Proceedings of the 1994 International Symposium on Software Testing and Analysis (ISSTA)},
title = {{An Empirical Evaluation of Three Methods for Deadlock Analysis of \{ADA\} Tasking Programs}},
year = {1994}
}
@inproceedings{swig91,
author = {Swigger, K M and Brazile, R P},
booktitle = {Empirical Studies of Programmers: Fourth Workshop},
editor = {Koenemann-Belliveau, J and Moher, T and Robertson, S},
publisher = {Ablex Publishing Corp},
title = {{An Empirical Study of the Effects of Design/Documentation Formats on Expert System Modifiability}},
year = {1991}
}
@book{BERGE89,
author = {Berge, Claude},
publisher = {North-Holland},
title = {{Hypergraphs}},
year = {1989}
}
@book{witten99,
author = {Witten, I H and Frank, E},
isbn = {1-55860-552-5},
publisher = {Morgan Kaufmann},
title = {{Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations}},
year = {1999}
}
@inproceedings{me96n,
author = {Menzies, T},
booktitle = {Proceedings of the ECAI '96 workshop on Validation, Verification, and Refinement of KBS},
title = {{Generalised Test = Generalised Inference}},
year = {1996}
}
@article{car,
annote = {Available on-line at $\backslash$url\{http://spectrum.ieee.org/green-tech/advanced-cars/this-car-runs-on-code\}},
author = {Charette, R N},
journal = {IEEE Spectrum},
title = {{This Car Runs on Code}},
year = {2009}
}
@article{Song2010b,
author = {Song, Qinbao and Jia, Zihan and Shepperd, Martin and Ying, Shi and Liu, Jin},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework(2).pdf:pdf},
keywords = {machine learning,scheme evaluation,software defect prediction,software defect-proneness prediction},
number = {X},
pages = {1--16},
title = {{A General Software Defect-Proneness Prediction Framework}},
volume = {X},
year = {2010}
}
@article{Meng2011,
abstract = {For applications of data mining techniques in geosciences, through mining spatial databases which are constructed with geophysical and geochemical data measured in fields, critical knowledge, such as the spatial distribution of geological targets, the geophysical and geochemical characteristics of geological targets, the differentiation among the geological targets, and the relationship among geophysical and geochemical data, can be discovered. Due to the complexity of geophysical and geochemical data, traditional mining methods of cluster analysis and association analysis have limitations in processing complex data. In this paper, a clustering algorithm based on density and adaptive density-reachable is presented which has the ability to handle clusters of arbitrary shapes, sizes, and densities. For association analysis, mining the continuous attributes may reveal useful and interesting insights about the data objects in geoscientific applications. An approach for distance-based quantitative association analysis is presented in this paper. Experiments and applications indicate that the algorithm and approach are effective in real-world applications. },
author = {Meng, Hai-Dong and Song, Yu-Chen and Song, Fei-Yan and Shen, Hai-Tao},
doi = {10.1007/s10596-010-9199-x},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/meng11.pdf:pdf},
isbn = {1420-0597},
issn = {1420-0597},
journal = {Computational Geosciences},
keywords = {association analysis,cluster analysis,geo-spatial database,geochemical data},
number = {1},
pages = {87--98},
title = {{Research and application of cluster and association analysis in geochemical data processing}},
volume = {15},
year = {2011}
}
@inproceedings{suthers95,
author = {Suthers, D and Weiner, A},
booktitle = {CSCL '95, Computer Supported Cooperative Learning; Bloomington, Indiana, October 17-20},
title = {{Groupware for developing critical discussion skills}},
year = {1995}
}
@inproceedings{owen03c,
author = {Owen, David and Menzies, Tim and Heimdahl, Mats and Gao, Jimin},
booktitle = {IEEE NASE SEW 2003},
title = {{On the Advantages of Approximate vs. Complete Verification: Bigger Models, Faster, Less Memory, Usually Accurate}},
year = {2003}
}
@inproceedings{runkel94,
author = {Runkel, J T and Birmingham, W P},
booktitle = {Proceedings of the 8th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge-Based Systems Workshop},
editor = {Gaines, B R and Musen, M},
pages = {42.1--42.28},
title = {{Solving VT by Reuse}},
year = {1994}
}
@article{nii86b,
author = {Nii, H P},
journal = {\{AI\} Magazine},
month = aug,
pages = {82--106},
title = {{Blackboard Systems: Blackboard Application Systems, Blackboard Systems from a Knowledge Engineering Perspective}},
year = {1986}
}
@inproceedings{sculley10,
author = {Sculley, D},
booktitle = {Proceedings of the 19th international conference on World wide web},
file = {:Users/timm/svns/doc/10fastkmeans.pdf:pdf},
pages = {1177--1178},
series = {WWW '10},
title = {{Web-scale k-means clustering}},
year = {2010}
}
@inproceedings{orrego09,
abstract = {Using process simulation and AI search methods, we compare software reuse against other possible changes to a project. such as reducing functionality or improving the skills of the programmer population. In one case, two generations of reuse were as good or better than any other project change (but a third and fourth generation of reuse was not useful). In another case, applying reuse to a project was demonstrable worse than several other possible changes to a project. Our conclusion is that the general claims regarding the benefits of software reuse do not hold for specific projects. We argue that the merits of software reuse need to be evaluated in a project by project basis. AI search over process models is useful for such an assessment, particularly when there is not sufficient data for precisely tuning a simulation model.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09reuse.pdf\}},
author = {{Andres Orrego, Tim Menzies}, Oussama El-Rawas},
booktitle = {Icsp2009},
pages = {186--197},
title = {{On the Relative Merits of Software Reuse}},
year = {2009}
}
@misc{me96c,
author = {Menzies, T and Haynes, P},
title = {{Empirical Observations of Class-level Encapsulation and Inheritance}},
year = {1996}
}
@book{cormen90,
annote = {ISBN: 0262031418},
author = {Cormen, T E and Leiserson, C E and Rivest, R L},
publisher = {MIT Press},
title = {{Introduction to Algorithms}},
year = {1990}
}
@article{NicDaeid2005,
abstract = {Over the last 20 years there has been an increasing interest in the development of robust systems, both analytical and statistical, to enable the linkage of seizures of illicit drug to each other. Much of this work has concentrated on the analysis of synthetic drugs, such as amphetamine and its analogues. In recent years, the analysis of both organic and elemental impurities as well as isotope ratios has advanced the usefulness of the techniques available. The application of specific chemometric methods to the derived analytical data has begun to provide the possibility of robust methods by which the resultant information can be interrogated.},
author = {{Nic Da\'{e}id}, Niamh and Waddell, Ruth J H},
doi = {10.1016/j.talanta.2005.05.018},
file = {:Users/timm/svns/doc/nic05.pdf:pdf},
issn = {1873-3573},
journal = {Talanta},
keywords = {chemometrics,drug analysis,forensic analysis},
month = aug,
number = {2},
pages = {280--5},
pmid = {18970168},
title = {{The analytical and chemometric procedures used to profile illicit drug seizures.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18970168},
volume = {67},
year = {2005}
}
@inproceedings{me96m,
author = {Menzies, Tim},
booktitle = {Proceedings of the ECAI '96 workshop on Modelling Conflicts in AI},
title = {{Expert Systems Inference = Modeling Conflicts}},
year = {1996}
}
@article{shannon53,
author = {Shannon, Claude E},
journal = {Trans. of the IRE Professional Group on Information Theory (TIT)},
pages = {169--174},
title = {{Discussion on Dr. Shannon's papers}},
volume = {1},
year = {1953}
}
@article{Liu2000,
author = {Liu, Bing and Ma, Yiming and Wong, C.},
doi = {10.1007/3-540-45372-5\_58},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/liu00.pdf:pdf},
journal = {Principles of Data Mining and Knowledge Discovery},
pages = {293--317},
title = {{Improving an association rule based classifier}},
url = {http://www.springerlink.com/index/cdldmeqbbj8qruey.pdf},
year = {2000}
}
@inproceedings{me08h,
abstract = {Prediction of fault prone software components is one of the most researched$\backslash$nproblems in software engineering. Many statistical techniques have$\backslash$nbeen proposed but there is no consensus on the methodology to select$\backslash$nthe ``best model" for the specific project. In this paper, we introduce$\backslash$nand discuss the merits of cost curve analysis of fault prediction$\backslash$nmodels. Cost curves allow software quality engineers to introduce$\backslash$nproject-specific cost of module misclassification into model evaluation.$\backslash$nClassifying a software module as fault-prone implies the application$\backslash$nof some verification activities, thus adding to the development cost.$\backslash$nMisclassifying a module as fault free carries the risk of system$\backslash$nfailure, also associated with cost implications. Through the analysis$\backslash$nof sixteen projects from public repositories, we observe that software$\backslash$nquality does not necessarily benefit from the prediction of fault$\backslash$nprone components. The inclusion of misclassification cost in model$\backslash$nevaluation may indicate that even the ``best" models achieve performance$\backslash$nno better than trivial classification. Our results support a recommendation$\backslash$nfavoring the use of cost curves in practice with the hope they will$\backslash$nbecome a standard tool for software quality model performance evaluation.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08costcurves.pdf\}},
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim},
booktitle = {ISSRE'08: Proceedings of the 19th International Symposium on Software Reliability Engineering},
pages = {197--206},
title = {{Costs Curve Evaluation of Fault Prediction Models}},
year = {2008}
}
@article{charniak91,
author = {Charniak, E},
journal = {AI Magazine},
number = {4},
pages = {50--63},
title = {{Bayesian networks without tears}},
volume = {12},
year = {1991}
}
@book{filman04,
author = {Filman, R E},
publisher = {Addison-Wesley, Boston},
title = {{Aspect-Oriented Software Development}},
year = {2004}
}
@book{chung00,
author = {Chung, L and Nixon, B A and Yu, E and Mylopoulos, J},
publisher = {Kluwer Academic Publishers},
title = {{Non-Functional Requirements in Software Engineering}},
year = {2000}
}
@article{Lu,
author = {Lu, Jingli and Yang, Ying and Webb, Geoffrey I},
file = {:Users/timm/svns/doc/webb08.pdf:pdf},
journal = {Learning},
title = {{Incremental Discretization for Na\"{\i}ve-Bayes Classifier}}
}
@inproceedings{gel03a,
abstract = { Model-based software has become quite popular in recent years, making its way into a broad range of areas, including the aerospace industry. The models provide an easy graphical interface to develop systems, which can generate the sometimes tedious code that follows. While there are many tools available to assess standard procedural code, there are limits to the testing of model-based systems. A major problem with the models are that their internals often contain gray areas of unknown system behavior. These possible behaviors form what is known as a data cloud, which is an overwhelming range of possibilities of a system that can overload analysts (Menzies et al., 2003). With large data clouds, it is hard to demonstrate which particular decision leads to a particular outcome. Even if definite decisions can't be made, it is possible to reduce the variance of and condense the clouds (Menzies et al., 2003). This paper presents two case studies; one with a simple illustrative model and another with a more complex application. The TAR3 treatment learning tool summarizes the particular attribute ranges that selects for particular behaviors of interest, reducing the data clouds.},
author = {Geletko, D. and Menzies, T.},
booktitle = {28th Annual NASA Goddard Software Engineering Workshop, 2003. Proceedings.},
doi = {10.1109/SEW.2003.1270729},
isbn = {0-7695-2064-2},
title = {{Model-based software testing via incremental treatment learning}},
year = {2003}
}
@inproceedings{feather06a,
abstract = {For several years we have been employing a riskbased decision process to guide development and application of advanced technologies, and for research and technology portfolio planning. The process is supported by custom software, in which visualization plays an important role. During requirements gathering, visualization is used to help scrutinize the status (completeness, extent) of the information. During decision making based on the gathered information, visualization is used to help decisionmakers understand the space of options and their consequences. In this paper we summarize the visualization capabilities that we have employed, indicating when and how they have proven useful.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06rev.pdf\}},
author = {Feather, Martin S. and Cornford, Steven L. and Kiper, James D. and Menzies, Tim},
booktitle = {First International Workshop on Visualization in Requirements Engineering, REV 2006},
doi = {10.1109/REV.2006.2},
isbn = {0769527116},
title = {{Experiences using visualization techniques to present requirements, risks to them, and options for risk mitigation}},
year = {2007}
}
@inproceedings{chee96,
author = {Chee, C L and Jarzabek, S and Ramamoorthy, C V},
booktitle = {SEKE '96: the Eight International Conference of Software Engineering and Knowledge Engineering},
pages = {309--316},
title = {{An Intelligent Process for Formulating and Answering Project Queries}},
year = {1996}
}
@inproceedings{me98e,
author = {Menzies, T J and Waugh, S},
booktitle = {Proceedings Pacific Knowledge Acquisition Workshop, Singapore, November, 1998},
title = {{More Results on the Practical Lower Limits of Test Set Size}},
year = {1998}
}
@book{boehm91,
author = {Boehm, B},
publisher = {Prentice Hall},
title = {{Software Engineering Economics}},
year = {1981}
}
@article{offen97,
author = {Offen, R J and Jeffery, R},
journal = {IEEE Software},
pages = {45--53},
title = {{Establishing Software Measurement Programs}},
year = {1997}
}
@article{wang05,
author = {Wang, Jason T L and Wang, Xiong and Shasha, Dennis and Zhang, Kaizhong},
journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B},
pages = {2005},
title = {{MetricMap: An embedding technique for processing distance-based queries in metric spaces}},
volume = {35}
}
@misc{taylor02,
author = {Taylor, B},
title = {{Development of Methodologies for IV\&V Neural Networks: Literature Survey of Current V\&V Technology}},
year = {2004}
}
@article{reiter87,
author = {Reiter, R},
journal = {Artificial Intelligence},
pages = {57--96},
title = {{A \{T\}heory of \{D\}iagnosis from \{F\}irst \{P\}rinciples}},
volume = {32},
year = {1987}
}
@article{Ambainisa,
author = {Ambainis, Andris and Jakobsson, Markus and Lipmaa, Helger},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Ambainis, Jakobsson, Lipmaa - Unknown - Cryptographic Randomized Response Techniques.pdf:pdf},
journal = {Response},
keywords = {classical cryptography,oblivious transfer,polling,preserving data-mining,privacy,privacy-,quantum cryptography,randomized response technique},
title = {{Cryptographic Randomized Response Techniques}}
}
@inproceedings{me02n,
abstract = { Adaptive systems are systems whose function evolves while adapting to current environmental conditions, Due to the real-time adaptation, newly learned data have a significant impact on system behavior When online adaptation is included in system control, anomalies could cause abrupt loss of system functionality and possibly result in a failure. In this paper we present a framework for reasoning about the online adaptation problem. We describe a machine learning tool that sniffs data and detects anomalies before they are passed to the adaptive components for learning. Anomaly detection is based on distance computation. An algorithm for framework evaluation as well as sample implementation and empirical results are discussed. The method we propose is simple and reasonably effective, thus it can be easily adopted for testing.},
author = {Liu, Yan Liu Yan and Menzies, T. and Cukic, B.},
booktitle = {14th IEEE International Conference on Tools with Artificial Intelligence, 2002. (ICTAI 2002). Proceedings.},
doi = {10.1109/TAI.2002.1180783},
isbn = {0-7695-1849-4},
issn = {1082-3409},
title = {{Data sniffing - monitoring of machine learning for online adaptive systems}},
year = {2002}
}
@article{Menzies2013a,
author = {Menzies, Tim and Butcher, Andrew and Cok, David},
doi = {http://dx.doi.org/10.1109/TSE.2012.83},
file = {:Users/timm/svns/doc/cost/12gense.pdf:pdf},
journal = {Software Engineering, IEEE Transactions on},
number = {6},
pages = {822 -- 834},
title = {{Local versus Global Lessons for Defect Prediction and Effort Estimation}},
volume = {39},
year = {2013}
}
@inproceedings{owen04a,
annote = {Tech report, Computer Science, West Virginia University},
author = {Owen, David and Menzies, Tim},
title = {{Experiments with LURCH}},
year = {2004}
}
@incollection{mich90,
author = {Michalski, R S},
booktitle = {Reading in Knowledge Acquisition and Learning},
editor = {Buchanan, B G and Wilkins, D C},
pages = {7--38},
publisher = {Morgan Kaufmann},
title = {{Toward a Unified Theory of Learning}},
year = {1993}
}
@inproceedings{Faloutsos1995,
author = {Faloutsos, Christos and Lin, King-Ip},
booktitle = {Proceedings of the 1995 ACM SIGMOD international conference on Management of data},
isbn = {0-89791-731-6},
pages = {163--174},
series = {SIGMOD '95},
title = {{FastMap: a fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets}},
year = {1995}
}
@incollection{burg95,
author = {Burgett, J and Ohman, B},
booktitle = {OOPSLA'95 Appendum to the Proceedings},
pages = {138--142},
publisher = {Association for Computing Machinery},
title = {{Experiences with Object-Based Software Development Effort Estimates and Associated Metrics}},
year = {1995}
}
@inproceedings{me06f,
author = {Menzies, T and Lum, K and Hihn, J},
booktitle = {PROMISE, 2006},
title = {{The Deviance Problem in Effort Estimation}},
year = {2006}
}
@inproceedings{me02h,
author = {Menzies, Tim and Owen, David and Cukic, Bojan},
booktitle = {October},
issn = {03029743},
pages = {1--12},
title = {{You seem friendly , but can I trust you ?}},
year = {2002}
}
@article{Ambainis,
author = {Ambainis, Andris and Jakobsson, Markus and Lipmaa, Helger},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Ambainis, Jakobsson, Lipmaa - Unknown - Cryptographic Randomized Response Techniques.pdf:pdf},
journal = {Response},
keywords = {classical cryptography,oblivious transfer,polling,preserving data-mining,privacy,privacy-,quantum cryptography,randomized response technique},
title = {{Cryptographic Randomized Response Techniques}}
}
@article{koza03,
author = {Koza, J R and Keane, M A and Streeter, M J},
journal = {IEEE Intelligent Systems},
pages = {25--31},
title = {{What's AI Done for Me Lately? Genetic Programming's Human-Competitive Results}},
volume = {18},
year = {2003}
}
@article{richards03,
author = {Richards, Debbie},
journal = {Requirements Engineering},
title = {{Merging Individual Conceptual Models of Requirements}}
}
@inproceedings{platt05,
author = {Platt, John C},
booktitle = {In Proceedings of 10th International Workshop on Artificial Intelligence and Statistics},
pages = {261--268},
title = {{Fastmap, Metricmap, and landmark \{MDS\} are all Nystr\"{o}m algorithms}},
year = {2005}
}
@article{Hamerly2010,
author = {Hamerly, Greg},
file = {:Users/timm/svns/doc/10hameryKmeans.pdf:pdf},
journal = {2010 SIAM international conference on data mining (SDM 2010)},
pages = {130--140},
title = {{Making k -means even faster}},
url = {http://www.siam.org/proceedings/datamining/2010/dm10\_012\_hamerlyg.pdf$\backslash$nhttp://cs.baylor.edu/~hamerly/papers/sdm\_2010.pdf},
year = {2010}
}
@article{me08b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ddp.pdf\}},
author = {Feather, M and Cornford, S and Hicks, K and Kiper, J and Menzies, T},
journal = {IEEE Software},
month = may,
title = {{Application of a broad-spectrum quantitative requirements model to early-lifecycle decision making}},
year = {2008}
}
@inproceedings{me94z,
annote = {$\backslash$url\{http://menzies.us/pdf/banff94.pdf\}},
author = {Menzies, T J and Compton, P},
booktitle = {Proceedings of the 8th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge-Based Systems Workshop, Banff, Canada},
title = {{Knowledge Acquisition for Performance Systems; or: When can "tests" replace "tasks"?}},
year = {1994}
}
@inproceedings{me97d,
author = {Postema, M and Menzies, T J and Wu, X},
booktitle = {The Joint Pacific Asia Conference on Expert Systems/Singapore International Conference on Intelligent Systems. (PACES/SPICIS '97)},
title = {{A Decision Support Tool for Tuning Parameters in a Machine Leraning Algorithm}},
year = {1997}
}
@inproceedings{KAMEI08,
address = {New York, NY, USA},
author = {Kamei, Yasutaka and Keung, Jacky and Monden, Akito and Matsumoto, Ken-ichi},
booktitle = {ESEM '08: Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
doi = {http://doi.acm.org/10.1145/1414004.1414064},
isbn = {978-1-59593-971-5},
pages = {312--314},
publisher = {ACM},
title = {{An over-sampling method for analogy-based software effort estimation}},
year = {2008}
}
@article{morasca99,
author = {Morasca, S and Ruhe, Gunther},
journal = {International Journal of Software Engineering and Knowledge Engineering},
month = oct,
title = {{Guest editors' introduction of the Special issue on Knowledge Discovery from Software Engineering Data}},
year = {1999}
}
@phdthesis{Gueorguiev2008,
author = {Gueorguiev, S},
booktitle = {dcskclacuk},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Gueorguiev - 2008 - Using SBSE for Project Management Optimisation Finding Robust Project Plans.pdf:pdf},
number = {September},
school = {King's College London},
title = {{Using SBSE for Project Management Optimisation: Finding Robust Project Plans}},
url = {http://www.dcs.kcl.ac.uk/staff/mark/PastMScProjects2007/StefanGueorguiev.pdf},
year = {2008}
}
@article{Jong1994,
author = {Jong, Kenneth a. and Spears, William M. and Gordon, Diana F.},
doi = {10.1007/BF00993042},
file = {:Users/timm/svns/doc/92ga\_rules\_long.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {bias adjustment,concept learning,genetic algorithms},
number = {2-3},
pages = {161--188},
title = {{Using genetic algorithms for concept learning}},
volume = {13},
year = {1994}
}
@inproceedings{cimatti03,
author = {Cimatti, A and Pecheur, C and Cavada, R},
booktitle = {Proceedings of IJCAI'03, Acapulco, Mexico},
title = {{Formal Verification of Diagnosability via Symbolic Model Checking}},
year = {2003}
}
@article{me11n,
author = {Haapio, Topi and Menzies, Tim},
journal = {International Journal of Software Engineering and Knowledge Engineering},
number = {5},
pages = {725--753},
title = {{Exploring the Effort of General Software Project Activities with Data Mining}},
volume = {21},
year = {2011}
}
@misc{me07c,
annote = {$\backslash$url\{http://promisedata.org/repository\}},
author = {Boetticher, G and Menzies, T and Ostrand, T},
institution = {West Virginia University, Lane Department of Computer Science and Electrical Engineering},
title = {{The \{PROMISE\} \{R\}epository of \{E\}mpirical \{S\}oftware \{E\}ngineering \{D\}ata}},
year = {2007}
}
@inproceedings{goel92,
author = {Goel, V},
booktitle = {Proceedings of the AAAI Symposium on Diagrammatic Reasoning Stanford University, March 25-27},
pages = {66--71},
title = {{``Ill-Structured Diagrams'' for Ill-Structured Problems}},
year = {1992}
}
@article{batarekh91,
author = {Batarekh, A and Preece, A D and Bennett, A and Grogono, P},
journal = {Expert Systems with Applications},
pages = {285--303},
title = {{Specifying an Expert System}},
volume = {2},
year = {1991}
}
@inproceedings{khos02z,
address = {Los Alamitos, CA, USA},
author = {Khoshgoftaar, T M and Geleyn, E and Nguyen, L and Bullard, L},
booktitle = {IEEE Symposium on High Assurance Software Engineering},
doi = {http://doi.ieeecomputersociety.org/10.1109/HASE.2002.1173102},
issn = {1530-2059},
pages = {51},
publisher = {IEEE Computer Society},
title = {{Cost-Sensitive Boosting In Software Quality Modeling}},
volume = {00},
year = {2002}
}
@inproceedings{me04a,
author = {Menzies, T and Setamanit, S and Raffo, D},
booktitle = {PROSIM 2004},
title = {{Data Mining from Process Models}},
year = {2004}
}
@inproceedings{me99n,
author = {Menzies, T},
booktitle = {KAW'99: the 12th Workshop on Knowledge Acquisition, Modeling and Management, Voyager Inn, Banff, Alberta, Canada Oct 16-22, 1999},
title = {{h\{Q\}kb- The High Quality Knowledge Base Initiative (Sisyphus V: Learning Design Assessment Knowledge)}},
year = {1999}
}
@article{me07d,
abstract = {Although there are times when random search is dangerous and should be avoided, software analysis should start with random methods because they are so cheap, moving to the more complex methods only when random methods fail},
annote = {$\backslash$url\{http://menzies.us/pdf/07strange.pdf\}},
author = {Menzies, Tim and Owen, David and Richardson, Julian},
doi = {10.1109/MC.2007.37},
issn = {00189162},
journal = {Computer},
keywords = {Artificial intelligence,Data mining,LURCH,Software engineering,TAR3},
number = {1},
pages = {54--60},
title = {{The strangest thing about software}},
volume = {40},
year = {2007}
}
@article{wilson97a,
author = {Wilson, D R and Martinez, T R},
journal = {Journal of Artificial Intelligence Research},
pages = {1--34},
title = {{Improved Heterogeneous Distance Functions}},
volume = {6},
year = {1997}
}
@article{Zhang2005a,
address = {New York, New York, USA},
author = {Zhang, Nan and Wang, Shengquan and Zhao, Wei},
doi = {10.1145/1081870.1081913},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zhang, Wang, Zhao - 2005 - A New Scheme on Privacy-Preserving Data Classification â.pdf:pdf},
isbn = {159593135X},
journal = {Proceeding of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining - KDD '05},
keywords = {privacy,privacy-preserving data mining},
pages = {374},
publisher = {ACM Press},
title = {{A new scheme on privacy-preserving data classification}},
url = {http://portal.acm.org/citation.cfm?doid=1081870.1081913},
year = {2005}
}
@article{bals04,
author = {Balsamo, S and Marco, A Di and Inverardi, P and Simeoni, M},
journal = {IEEE Transactions on Software Engineering},
month = may,
number = {5},
title = {{Model-Based Performance Prediction in Software Development: A Survey}},
volume = {30},
year = {2004}
}
@inproceedings{Scanniello2013,
author = {Scanniello, Giuseppe and Gravino, Carmine and Marcus, Andrian and Menzies, Tim},
booktitle = {Automated Software Engineering (ASE), 2013 IEEE/ACM 28th International Conference on},
organization = {IEEE},
pages = {640--645},
title = {{Class level fault prediction using software clustering}},
year = {2013}
}
@inproceedings{crawford94,
author = {Crawford, J and Baker, A},
booktitle = {AAAI '94},
title = {{Experimental Results on the Application of Satisfiability Algorithms to Scheduling Problems}},
year = {1994}
}
@inproceedings{me93k,
author = {Menzies, T J},
booktitle = {DX-93: The International Workshop on Principles on Model-Based Diagnosis},
title = {{The Complexity of Model Review}},
year = {1993}
}
@article{clark03,
annote = {Available from $\backslash$url\{http://www.brunel.ac.uk/\~{}csstrmh/papers/sbse.ps\}},
author = {Clark, J and Dolado, J J and Harman, M and Hierons, R M and Jones, B and Lumkin, M and Mitchell, B and Mancoridis, S and Rees, K and Roper, M and Shepperd, M},
journal = {IEE Proceedings on Software},
number = {3},
pages = {161--175},
title = {{Reformulating Software Engineering as a Search Problem}},
volume = {150},
year = {2003}
}
@article{ElEmam2001,
author = {{El Emam}, K. and Benlarbi, S. and Goel, N. and Rai, S.N.},
doi = {10.1109/32.935855},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/El Emam et al. - 2001 - The confounding effect of class size on the validity of object-oriented metrics.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
month = jul,
number = {7},
pages = {630--650},
title = {{The confounding effect of class size on the validity of object-oriented metrics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=935855},
volume = {27},
year = {2001}
}
@article{Moise2009,
abstract = {Subspace and projected clustering have emerged as a possible solution to the challenges associated with clustering in high-dimensional data. Numerous subspace and projected clustering techniques have been proposed in the literature. A comprehensive evaluation of their advantages and disadvantages is urgently needed. In this paper, we evaluate systematically state-of-the-art subspace and projected clustering techniques under a wide range of experimental settings. We discuss the observed performance of the compared techniques, and we make recommendations regarding what type of techniques are suitable for what kind of problems.},
author = {Moise, Gabriela and Zimek, Arthur and Kr\"{o}ger, Peer and Kriegel, Hans Peter and Sander, J\"{o}rg},
doi = {10.1007/s10115-009-0226-y},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/moise09.pdf:pdf},
issn = {02191377},
journal = {Knowledge and Information Systems},
keywords = {Projected clustering,Subspace clustering},
number = {3},
pages = {299--326},
title = {{Subspace and projected clustering: Experimental evaluation and analysis}},
volume = {21},
year = {2009}
}
@inproceedings{men87a,
author = {Menzies, T J and Markey, B R},
booktitle = {Proceedings of the Third Australian Conference on Expert Systems, May 13-15},
title = {{A Micro-Computer, Rule-Based Prolog Expert-System for Process Control in a Petrochemical Plant}},
year = {1987}
}
@incollection{fea03a,
abstract = { We present an approach to matching software practitioners' needs to software researchers' activities. It uses an accepted taxonomical software classification scheme as intermediary, in terms of which practitioners express needs, and researchers express activities. A decision support tool is used to combine these expressions of needs/activities, and to assist in studying the implications of that combined knowledge. This enables identification of fruitful connections between researchers and practitioners, of areas of common interest among researchers, and practitioners, and of "gaps": areas of unfulfilled needs or unmotivated research. We discuss the software engineering underpinning this approach, illustrating its utility by reporting on experiments with a real-world dataset gathered from researchers and practitioners. We also suggest that this same approach would be applicable to understanding the distribution of interests represented by presenters and attendees of a conference such as APSEC.},
author = {Feather, M.S. and Menzies, T. and Connelly, J.R.},
booktitle = {Tenth Asia-Pacific Software Engineering Conference, 2003.},
doi = {10.1109/APSEC.2003.1254353},
isbn = {0-7695-2011-1},
month = dec,
title = {{Matching software practitioner needs to researcher activities}},
year = {2003}
}
@misc{koru08a,
annote = {Available from $\backslash$url\{http://promisedata.org/?p=30\}},
author = {Koru, G},
title = {{Errors in LOC counts}}
}
@article{pan10,
author = {Pan, Sinno and Yang, Qiang},
file = {:Users/timm/svns/doc/10transfer.pdf:pdf},
journal = {IEEE Trans. Knowl. Data Eng.},
number = {10},
pages = {1345--1359},
title = {{A Survey on Transfer Learning}},
volume = {22},
year = {2010}
}
@article{Fukunaga1986,
author = {Fukunaga, Koichi and Hirose, Shin-ichi},
doi = {10.1145/960112.28719},
file = {:Users/timm/svns/doc/ooprolog/p224-fukunaga.pdf:pdf},
isbn = {0897912047},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
number = {11},
pages = {224--231},
title = {{An experience with a Prolog-based object-oriented language}},
volume = {21},
year = {1986}
}
@inproceedings{SAMI2010,
address = {New York, NY, USA},
author = {Sami, Ashkan and Fakhrahmad, Seyed Mostafa},
booktitle = {SAC '10: Proceedings of the 2010 ACM Symposium on Applied Computing},
doi = {http://doi.acm.org/10.1145/1774088.1774612},
isbn = {978-1-60558-639-7},
pages = {2531--2535},
publisher = {ACM},
title = {{Design-level metrics estimation based on code metrics}},
year = {2010}
}
@article{andrews10,
author = {Andrews, James H and Menzies, Tim and Li, Felix C H},
journal = {IEEE Transactions on Software Engineering},
month = mar,
number = {1},
pages = {1--33},
title = {{Controlling Randomized Unit Testing With Genetic Algorithms}},
volume = {1},
year = {2001}
}
@article{basili99,
author = {Basili, V R and Shull, F and Lanubile, F},
journal = {IEEE Transactions on Software Engineering},
number = {4},
pages = {456--473},
title = {{Building Knowledge through Families of Experiments}},
volume = {25},
year = {1999}
}
@article{clancey93,
author = {Clancey, W},
journal = {Cognitive Science},
pages = {87--116},
title = {{Situated \{A\}ction: \{A\} \{N\}europsychological \{I\}nterpretation (\{R\}esponse to \{V\}era and \{S\}imon)}},
volume = {17},
year = {1993}
}
@book{ok90,
author = {O'Keefe, R A},
publisher = {MIT Press},
title = {{The Craft of Prolog}},
year = {1990}
}
@article{krall14,
author = {Krall, J and Menzies, T},
file = {:Users/timm/svns/doc/optimalML/galeTse.pdf:pdf},
journal = {IEEE Transactions on Software Engineering (submitted)},
title = {{GALE: Geometric Active Learning for Search-based Software Engineering}},
year = {2015}
}
@article{kellner99,
author = {Kellner, M and Madachy, R and Raffo, D},
journal = {Journal of Systems and Software},
number = {2/3},
title = {{Software Process Modeling and Simulation: Why, What, How,}},
volume = {46},
year = {1999}
}
@inproceedings{me09m,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09fssga.pdf\}},
author = {Andrews, Jamie and Menzies, Tim},
booktitle = {PROMISE'09},
title = {{On the Value of Combining Feature Subset Selection with Genetic Algorithms: Faster Learning of Coverage Models}},
year = {2009}
}
@book{dreyfus79,
author = {Dreyfus, H},
publisher = {Freeman},
title = {{What Computers Can't D: A Critique of Artifical Reason}},
year = {1979}
}
@article{Harman2010b,
author = {Harman, Mark and McMinn, Phil},
doi = {10.1109/TSE.2009.71},
file = {:Users/timm/svns/doc/harmanTSE10.pdf:pdf},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
month = mar,
number = {2},
pages = {226--247},
title = {{A Theoretical and Empirical Study of Search-Based Testing: Local, Global, and Hybrid Search}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5342440},
volume = {36},
year = {2010}
}
@article{Clifton2004,
author = {Clifton, Chris and Elmagarmid, Ahmed and Schadow, Gunther and Suciu, Dan},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Clifton et al. - 2004 - Privacy-Preserving Data Integration and Sharing.pdf:pdf},
journal = {Framework},
title = {{Privacy-Preserving Data Integration and Sharing}},
year = {2004}
}
@article{schmidt06,
author = {Schmidt, D C},
journal = {IEEE Computer},
month = feb,
number = {2},
pages = {25--31},
title = {{Model-Driven Engineering}},
volume = {39},
year = {2006}
}
@misc{allen90,
author = {{James Allen James Hendler}, Austin Tate},
isbn = {1558601309},
publisher = {Morgan Kaufmann},
title = {{Readings in Planning}},
year = {1990}
}
@article{koc11b,
author = {Kocaguneli, E and Menzies, T and Bener, A and Keung, J},
journal = {IEEE Transactions on Software Engineering},
number = {2},
pages = {425--438},
title = {{Exploiting the Essential Assumptions of Analogy-Based Effort Estimation}},
volume = {28},
year = {2012}
}
@article{dekleer86b,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {163--196},
title = {{Extending the ATMS}},
volume = {28},
year = {1986}
}
@misc{wilson01,
author = {Wilson-Smith, P},
title = {{Fund managers take fright over \{M\}yners, \{F\}inancial \{N\}ews, \{M\}arch 26}},
year = {2001}
}
@article{Oliveira2001,
author = {Oliveira, Stanley R M},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Oliveira - 2001 - Privacy Preserving Frequent Itemset Mining.pdf:pdf},
journal = {Reproduction},
keywords = {assosiation rule mining,frequent itemset mining,ing data mining,privacy preserv-,privacy preservation in association,rule mining,security},
title = {{Privacy Preserving Frequent Itemset Mining}},
year = {2001}
}
@article{wong95,
author = {Wong, W E and Mathur, A P},
journal = {The Journal of Systems and Software},
month = dec,
number = {3},
pages = {185--196},
title = {{Reducing the Cost of Mutation Testing: An Empirical Study}},
volume = {31},
year = {1995}
}
@article{Minku2013,
abstract = {Ensembles of learning machines are promising for$\backslash$nsoftware effort estimation (SEE), but need to be$\backslash$ntailored for this task to have their potential$\backslash$nexploited. A key issue when creating ensembles is to$\backslash$nproduce diverse and accurate base models. Depending on$\backslash$nhow differently different performance measures behave$\backslash$nfor SEE, they could be used as a natural way of$\backslash$ncreating SEE ensembles. We propose to view SEE model$\backslash$ncreation as a multiobjective learning problem. A$\backslash$nmultiobjective evolutionary algorithm (MOEA) is used to$\backslash$nbetter understand the tradeoff among different$\backslash$nperformance measures by creating SEE models through the$\backslash$nsimultaneous optimisation of these measures. We show$\backslash$nthat the performance measures behave very differently,$\backslash$npresenting sometimes even opposite trends. They are$\backslash$nthen used as a source of diversity for creating SEE$\backslash$nensembles. A good tradeoff among different measures can$\backslash$nbe obtained by using an ensemble of MOEA solutions.$\backslash$nThis ensemble performs similarly or better than a model$\backslash$nthat does not consider these measures explicitly.$\backslash$nBesides, MOEA is also flexible, allowing emphasis of a$\backslash$nparticular measure if desired. In conclusion, MOEA can$\backslash$nbe used to better understand the relationship among$\backslash$nperformance measures and has shown to be very effective$\backslash$nin creating SEE models.},
author = {Minku, Leandro L and Yao, Xin},
doi = {http://dx.doi.org/10.1145/2522920.2522928},
file = {:Users/timm/svns/doc/cost/13minku.pdf:pdf},
issn = {1049-331X (print), 1557-7392 (electronic)},
journal = {ACM Transactions on Software Engineering and Methodology},
number = {4},
pages = {1--32},
title = {{Software effort estimation as a multiobjective learning problem}},
url = {http://dl.acm.org/citation.cfm?doid=2522920.2522928$\backslash$npapers2://publication/doi/10.1145/2522920.2522928},
volume = {22},
year = {2013}
}
@inproceedings{dambrosio93,
author = {D'Ambrosio, Bruce},
booktitle = {UAI'93},
title = {{Incremental Probabilistic Inference}},
year = {1983}
}
@article{boehmturner03,
author = {Boehm, B and Turner, R},
journal = {IEEE Computer},
month = jun,
number = {6},
pages = {57--66},
title = {{Using risk to balance agile and plan-driven methods}},
volume = {36},
year = {2003}
}
@inproceedings{bird06,
author = {Bird, Christian and Gourley, Alex and Devanbu, Prem and Gertz, Michael and Swaminathan, Anand},
booktitle = {Proceedings of the 2006 international workshop on Mining software repositories},
pages = {137--143},
series = {MSR '06},
title = {{Mining email social networks}},
year = {2006}
}
@book{endres03,
author = {{A. Endres H.D}, Rombach},
publisher = {Addison Wesley},
title = {{A Handbook of Software and Systems Engineering: Empirical Observations, Laws and Theories}},
year = {2003}
}
@article{Song2010,
author = {Song, Qinbao and Jia, Zihan and Shepperd, Martin and Ying, Shi and Liu, Jin},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework.pdf:pdf;:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework(2).pdf:pdf},
keywords = {machine learning,scheme evaluation,software defect prediction,software defect-proneness prediction},
number = {X},
pages = {1--16},
title = {{A General Software Defect-Proneness Prediction Framework}},
volume = {X},
year = {2010}
}
@article{plex93,
author = {Plexousakis, D},
journal = {Computational Intelligence},
month = feb,
number = {1},
title = {{Semantical and Ontological Considerations in Telos: a Language for Knowledge Representation}},
volume = {9},
year = {1993}
}
@article{couto14,
author = {Couto, C and Valente, M T and Pires, P and Hora, A and Anquetil, N and Bigonha, R},
journal = {Journal of Software Engineering Research and Development},
title = {{BugMaps-Granger: a tool for visualizing and predicting bugs using Granger causality tests}},
volume = {2},
year = {1024}
}
@article{tosun2010,
author = {Tosun, A and Bener, A and Turhan, B and Menzies, T},
title = {{No Title}}
}
@inproceedings{zimmermann09,
author = {Zimmermann, T and Nagappan, N and Gall, H and Giger, E and Murphy, B},
booktitle = {ESEC/FSE'09},
month = aug,
title = {{Cross-Project Defect Prediction}},
year = {2009}
}
@article{Hein2011,
abstract = {Spectral clustering is based on the spectral relaxation of the normalized/ratio graph
cut criterion. While the spectral relaxation is known to be loose, it has been shown
recently that a non-linear eigenproblem yields a tight relaxation of the Cheeger
cut. In this paper, we extend this result considerably by providing a characterization
of all balanced graph cuts which allow for a tight relaxation. Although
the resulting optimization problems are non-convex and non-smooth, we provide
an efficient first-order scheme which scales to large graphs. Moreover, our approach
comes with the quality guarantee that given any partition as initialization
the algorithm either outputs a better partition or it stops immediately.},
author = {Hein, Matthias and Setzer, Simon},
file = {:Users/timm/svns/doc/10nipsSpectralClustering.pdf:pdf},
isbn = {9781618395993},
keywords = {Learning/Statistics \& Optimisation},
pages = {1--9},
title = {{Beyond Spectral Clustering - Tight Relaxations of Balanced Graph Cuts}},
url = {http://eprints.pascal-network.org/archive/00008707/},
year = {2011}
}
@article{brooks87,
author = {Brooks, F P},
journal = {IEEE Computer},
number = {4},
pages = {34--42},
title = {{No Silver Bullet: Essence and Accidents of Software Engineering}},
volume = {20},
year = {1987}
}
@misc{preston92,
author = {Preston, P},
title = {{Expert Systems, Knowledge Aquisition and Knowledge Modification}},
year = {1992}
}
@article{agnew93,
author = {Agnew, N M and Ford, K M and Hayes, P J},
journal = {International Journal of Expert Systems},
title = {{Expertise in Context: Personally Constructed, Socially elected, and Reality-Relevant?}},
volume = {7},
year = {1993}
}
@article{hatton98,
author = {Hatton, L},
journal = {IEEE Software},
pages = {46--54},
title = {{Does OO Sync with How We Think?}},
year = {1998}
}
@inproceedings{webb96,
author = {Webb, G I and Wells, J},
booktitle = {Proceedings PKAW '96: Pacific Knowledge Acquisition Workshop},
title = {{Experimental Evaluation of Integrating Machine Learning with Knowledge Acquisition Through Direct Interaction with Domain Experts}},
year = {1996}
}
@misc{breiman84,
annote = {cart algorithm},
author = {Breiman, L and Friedman, J H and Olshen, R A and Stone, C J},
institution = {Wadsworth International, Monterey, CA},
title = {{Classification and Regression Trees}},
year = {1984}
}
@inproceedings{gordon00,
author = {Gordon, Diana F},
booktitle = {Formal Approaches to Agent-Based Systems, First International Workshop, FAABS 2000 Greenbelt, MD, USA, April 5-7, 2000, Revised Papers},
pages = {278--293},
title = {{APT Agents: Agents That Are Adaptive, Predictable, and Timely}},
year = {2000}
}
@inproceedings{will93,
author = {Williams, M G and Ledder, W A and Buehler, J N and Canning, J T},
booktitle = {Proceedings 1993 IEEE Symposium on Visual Languages},
pages = {371--373},
publisher = {IEEE Comput. Soc. Press.},
title = {{An Empirical Study of Visual Labs}},
year = {1993}
}
@inproceedings{kohavi96,
author = {Kohavi, R and Sommerfield, D and Dougherty, J},
booktitle = {Tools with AI 1996},
title = {{Data Minining using MLC++: A Machine Learning Library in C++}},
year = {1996}
}
@article{me99j,
author = {Menzies, Tim},
doi = {10.1006/ijhc.1999.0329},
issn = {10715819},
journal = {International journal of human-computer studies},
month = oct,
number = {4},
pages = {783--799},
title = {{Critical success metrics: evaluation at the business level}},
url = {http://www.sciencedirect.com/science/article/pii/S1071581999903294},
volume = {51},
year = {1999}
}
@article{Minku2012,
author = {Minku, Ll and Yao, Xin},
file = {:Users/timm/svns/doc/transfer/12minku.pdf:pdf},
isbn = {9781450312417},
journal = {\ldots Conference on Predictive Models in Software \ldots},
keywords = {bles of learning machines,chronological split,concept drift,cross-company estimation mod-,els,ensem-,online learning,software effort estimation},
title = {{Can cross-company data improve performance in software effort estimation?}},
url = {http://dl.acm.org/citation.cfm?id=2365334},
year = {2012}
}
@article{king02,
author = {King, J and Diaz, M},
journal = {CROSSTALK},
month = mar,
title = {{How \{CMM\} Impacts Quality, Productivity, Rework, and the Bottom Line}},
year = {2002}
}
@inproceedings{me95za,
author = {Menzies, T J},
booktitle = {Proceedings of the Melbourne Workshop on Intelligent Decision Support Department of Information Systems Monash University, Caulfield Campus, Melbourne Monday, March 20, 1995},
title = {{Applications of Abduction \#1: Intelligent Decision Support Systems.}},
year = {1995}
}
@article{ntafos01,
author = {Ntafos, S C},
journal = {IEEE Transactions on Software Engineering},
month = oct,
number = {10},
title = {{On Comparisons of Random, Partition, and Propositional Partition Testing}},
volume = {27},
year = {2001}
}
@inproceedings{mink75,
author = {Minsky, M},
booktitle = {The Psychology of Computer Vision},
organization = {McGraw-Hill},
title = {{A Framework for Representing Knowledge}},
year = {1975}
}
@article{nelson11,
author = {Nelson, Adam and Menzies, Tim and Gay, Gregory},
journal = {Softw. Pract. Exper.},
month = mar,
number = {3},
pages = {283--305},
title = {{Sharing experiments using open-source software}},
volume = {41},
year = {2011}
}
@article{Bohm2004,
author = {B\"{o}hm, Christian and Kailing, Karin and Kr\"{o}ger, Peer and Zimek, Arthur},
doi = {10.1145/1007568.1007620},
file = {:Users/timm/svns/doc/04dbscanPCA.pdf:pdf},
isbn = {1581138598},
issn = {07308078},
journal = {Proceedings of the 2004 ACM SIGMOD international conference on Management of data - SIGMOD '04},
pages = {455},
title = {{Computing Clusters of Correlation Connected objects}},
url = {http://portal.acm.org/citation.cfm?doid=1007568.1007620},
year = {2004}
}
@article{tiang95,
author = {Tian, J and Zelkowitz, M V},
journal = {IEEE Transaction on Software Engineering},
month = aug,
number = {8},
pages = {641--649},
title = {{Complexity Measure Evaluation and Selection}},
volume = {21},
year = {1995}
}
@article{hunter98,
author = {Hunter, A and Nuseibeh, B},
journal = {ACM Transactions on Software Engineering and Methodology},
number = {4},
pages = {335--367},
title = {{Managing Inconsistent Specifications: Reasoning, Analysis and Action}},
volume = {7},
year = {1998}
}
@article{motta98,
author = {Motta, E and Zdrahal, Z},
journal = {International Journal of Human Computer Studies},
pages = {437--470},
title = {{A library of problem-solving components based on the intergration of the search paradigm with task and method ontologies.}},
volume = {49},
year = {1998}
}
@article{mittas13,
author = {Mittas, Nikolaos and Angelis, Lefteris},
file = {:Users/timm/svns/doc/cost/13Mittas.pdf:pdf},
journal = {IEEE Trans. Software Eng.},
number = {4},
pages = {537--551},
title = {{Ranking and Clustering Software Cost Estimation Models through a Multiple Comparisons Algorithm}},
volume = {39},
year = {2013}
}
@book{shaw96,
author = {Shaw, M and Garlan, D},
publisher = {Prentice Hall},
title = {{Software Architecture: Perspectives on an Emerging Discipline}},
year = {1996}
}
@inproceedings{me03o,
author = {Menzies, T and Gunnalan, R and Appukutty, K and A, Srinivasan and Hu, Y},
booktitle = {International Journal on Artificial Intelligence Tools (IJAIT), to appear},
title = {{Learning Tiny Theories}},
year = {2005}
}
@incollection{gross93,
author = {Grossner, C and Preece, A and Chander, P Gokul and Radhakrishnan, T and Suen., C},
booktitle = {Proc. 11th National Conference on Artificial Intelligence (AAAI-93)},
pages = {704--709},
publisher = {MIT Press},
title = {{Exploring the Structure of Rule Based Systems}},
year = {1993}
}
@article{feather03,
author = {Feather, Martin and Cornfordi, Steve},
journal = {Requirements Engineering Journal},
number = {4},
pages = {248--265},
publisher = {Springer},
title = {{Quantitative Risk-based Requirements Reasoning}},
volume = {8},
year = {2003}
}
@inproceedings{pearce88,
author = {Pearce, D},
booktitle = {Proc. AAAI-88},
title = {{The Induction of Fault Diagnosis Systems From Qualitative Models}},
year = {1988}
}
@article{Morik2012,
abstract = {Large media collections rapidly evolve in the World Wide Web. In addition to the targeted retrieval as is performed by search engines, browsing and explorative navigation is an important issue. Since the collections grow fast and authors most often do not annotate their web pages according to a given ontology, automatic structuring is in demand as a prerequisite for any pleasant human-computer interface. In this paper, we investigate the problem of finding alternative high-quality structures for navigation in a large collection of high-dimensional data. We express desired properties of frequent termset clustering \{(FTS)\} in terms of objective functions. In general, these functions are conflicting. This leads to the formulation of \{FTS\} clustering as a multi-objective optimization problem. The optimization is solved by a genetic algorithm. The result is a set of Pareto-optimal solutions. Users may choose their favorite type of a structure for their navigation through a collection or explore the different views given by the different optimal solutions. We explore the capability of the new approach to produce structures that are well suited for browsing on a social bookmarking data set.},
author = {Morik, Katharina and Kaspari, Andreas and Wurst, Michael and Skirzynski, Marcin},
doi = {10.1007/s10115-011-0431-3},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/morik08.pdf:pdf},
isbn = {1011501104},
issn = {02191377},
journal = {Knowledge and Information Systems},
keywords = {Collaborative clustering,Distributed data mining,Ensemble clustering,Multi-media collections},
number = {3},
pages = {715--738},
title = {{Multi-objective frequent termset clustering}},
volume = {30},
year = {2012}
}
@inproceedings{perkins03,
author = {Perkins, J and Greenberg, A and Sharp, J and Cassard, D and Massey, B},
booktitle = {USENIX 2003},
pages = {245--258},
title = {{Free Software and High-Power Rocketry: The Portland State Aerospace Society}}
}
@misc{Boetticher:Menzies:Ostrand:2007,
author = {Boetticher, G and Menzies, T and Ostrand, T},
institution = {West Virginia University, Department of Computer Science},
title = {{\{PROMISE\} Repository of empirical software engineering data}},
url = {http://promisedata.org/repository},
year = {2007}
}
@inproceedings{nikora03,
author = {Nikora, A P and Munson, J C},
booktitle = {Ninth International Software Metrics Symposium (METRICS'03)},
title = {{Developing Fault Predictors for Evolving Software Systems}},
year = {2003}
}
@inproceedings{MOSER2008,
address = {New York, NY, USA},
author = {Moser, Raimund and Pedrycz, Witold and Succi, Giancarlo},
booktitle = {ICSE '08: Proceedings of the 30th international conference on Software engineering},
doi = {http://doi.acm.org/10.1145/1368088.1368114},
isbn = {978-1-60558-079-1},
pages = {181--190},
publisher = {ACM},
title = {{A comparative analysis of the efficiency of change metrics and static code attributes for defect prediction}},
year = {2008}
}
@inproceedings{webb03,
address = {New York, NY, USA},
author = {Webb, Geoffrey I and Butler, Shane and Newlands, Douglas},
booktitle = {KDD '03: Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining},
doi = {http://doi.acm.org/10.1145/956750.956781},
isbn = {1-58113-737-0},
pages = {256--265},
publisher = {ACM Press},
title = {{On detecting differences between groups}},
year = {2003}
}
@article{zlatereva92b,
author = {Zlatereva, N},
journal = {Artificial Intelligence Review},
title = {{Truth Mainteance Systems and Their Application for Verifying Expert System Knowledge Bases}},
volume = {6},
year = {1992}
}
@book{brac85,
address = {Palo Alto},
author = {Brachmann, R J and Levesque, H J},
isbn = {0-934613-01-X},
publisher = {Morgan Kaufmann},
title = {{Readings in Knowledge Representation}},
year = {1985}
}
@article{Barreno2006,
address = {New York, New York, USA},
author = {Barreno, Marco and Nelson, Blaine and Sears, Russell and Joseph, Anthony D. and Tygar, J. D.},
doi = {10.1145/1128817.1128824},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Barreno, Joseph, Tygar - 2006 - Can Machine Learning Be Secure.pdf:pdf},
isbn = {1595932720},
journal = {Proceedings of the 2006 ACM Symposium on Information, computer and communications security - ASIACCS '06},
keywords = {adversarial learning,computer networks,computer secu-,game theory,intrusion detection,machine learning,rity,security metrics,spam filters,statistical learning},
number = {March},
pages = {16},
publisher = {ACM Press},
title = {{Can machine learning be secure?}},
url = {http://portal.acm.org/citation.cfm?doid=1128817.1128824},
year = {2006}
}
@article{Fulkerson1995b,
author = {Fulkerson, Bill and Michie, D. and Spiegelhalter, D. J. and Taylor, C. C.},
doi = {10.2307/1269742},
file = {:Users/timm/svns/doc/statlog.pdf:pdf},
issn = {00401706},
journal = {Technometrics},
month = nov,
number = {4},
pages = {459},
title = {{Machine Learning, Neural and Statistical Classification}},
url = {http://www.jstor.org/stable/1269742?origin=crossref},
volume = {37},
year = {1995}
}
@article{Zimmermann2004,
abstract = {A novel algorithm, CorClass, that integrates association rule mining$\backslash$nwith classification, is presented. It first discovers all correlated$\backslash$nassociation rules (adapting a technique by Morishita and Sese) and$\backslash$nthen applies the discovered rule sets to classify unseen data. The$\backslash$nkey advantage of CorClass, as compared to other techniques for associative$\backslash$nclassification, is that CorClass directly finds the associations$\backslash$nrules for classification by employing a branch-and-bound algorithm.$\backslash$nPrevious techniques (such as CBA [1] and CMAR [2]) first discover$\backslash$nall association rules satisfying a minimum support and confidence$\backslash$nthreshold and then post-process them to retain the best rules.$\backslash$n$\backslash$nCorClass is experimentally evaluated and compared to existing associative$\backslash$nclassification algorithms such as CBA [1], CMAR [2] and rule induction$\backslash$nalgorithms such as Ripper [3], PART [4] and C4.5 [5].},
author = {Zimmermann, Albrecht and {De Raedt}, Luc},
doi = {10.1007/b100845},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/Zimmermann.pdf:pdf},
issn = {03029743},
journal = {Discovery Science},
pages = {60--72},
title = {{CorClass : Correlated Association Rule Mining for Classification}},
volume = {3245/2004},
year = {2004}
}
@article{andrews10,
author = {Andrews, James H and Menzies, Tim and Li, Felix C H},
journal = {IEEE Transactions on Software Engineering},
month = mar,
title = {{Genetic Algorithms for Randomized Unit Testing}},
year = {2010}
}
@article{metropolis53,
author = {Metropolis, N and Rosenbluth, A W and Rosenbluth, M N and Teller, A H and Teller, E},
journal = {J. Chem. Phys},
pages = {1087--1092},
title = {{Equation of State Calculations by Fast Computing Machines}},
volume = {21},
year = {1953}
}
@article{verbeke11,
author = {Verbeke, Wouter and Martens, David and Mues, Christophe and Baesens, Bart},
journal = {Expert Syst. Appl.},
pages = {2354--2364},
title = {{Building comprehensible customer churn prediction models with advanced rule induction techniques}},
year = {2011}
}
@article{bent97,
author = {Bentley, R and Appelt, W and Busbach, U and Hinrichs, E and Kerr, D and Sikkel, K and Trevor, J and Woetzel, G},
journal = {International Journal of Human Computer Studies},
month = jun,
number = {6},
pages = {827--846},
title = {{Basic Support for Cooperative Work on the World Wide Web}},
volume = {46},
year = {1997}
}
@article{ERDOGMUS2008,
address = {Los Alamitos, CA, USA},
author = {Erdogmus, Hakan},
doi = {http://doi.ieeecomputersociety.org/10.1109/MS.2008.81},
issn = {0740-7459},
journal = {IEEE Software},
pages = {4--7},
publisher = {IEEE Computer Society},
title = {{The Infamous Ratio Measure}},
volume = {25},
year = {2008}
}
@misc{robb98,
author = {Robbins, Jason E},
month = nov,
title = {{Design Critiquing Systems}},
year = {1998}
}
@book{neuman95,
author = {Neumann, Peter G},
isbn = {0-201-55805-X},
publisher = {ACM Press / Addison Wesley},
title = {{Computer-Related Risks}},
year = {1995}
}
@misc{knuth84,
author = {Knuth, D E},
institution = {Department of Computer Science, Stanford University},
number = {STAN-CS-84-1027},
title = {{A Torture test for \{TEX\}}},
year = {1984}
}
@misc{bobntim2,
author = {Cohen, R F and Menzies, T},
number = {TR95-20},
title = {{Reverse Engineering a Software Engineering Curriculum}},
year = {1995}
}
@inproceedings{wyatt87,
author = {J., Wyatt},
booktitle = {Lecture Notes in Medical Informatics},
pages = {15--24},
title = {{The evaluation of clinical decision aids: a discussion of methodology used in the ACORN project}},
volume = {33},
year = {1987}
}
@article{lam98,
author = {van Lamsweerde, A and Willemet, L},
journal = {IEEE Transactions on Software Engineering, Special Issue on Scenario Management},
month = nov,
title = {{Inferring Declarative Requirements Specifications from Operational Scenarios}},
year = {1998}
}
@article{Kuncheva1998,
author = {Kuncheva, L.I.},
doi = {10.1109/5326.661099},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Kuncheva - 1998 - Nearest prototype classification clustering, genetic algorithms, or random search.pdf:pdf},
journal = {IEEE Transactions on Systems, Man and Cybernetics, Part C (Applications and Reviews)},
number = {6},
pages = {1041--164},
title = {{Nearest prototype classification: clustering, genetic algorithms, or random search?}},
volume = {30},
year = {1998}
}
@article{agre93,
author = {Agre, P H},
journal = {Cognitive Science},
pages = {61--69},
title = {{The Symbolic WorldView: Reply to Vera and Simon}},
volume = {17},
year = {1993}
}
@article{Hughes1990,
author = {Hughes, John},
file = {:Users/timm/svns/doc/hughes90.pdf:pdf},
number = {April 1989},
pages = {98--107},
title = {{Why Functional Programming Matters}},
volume = {32},
year = {1990}
}
@inproceedings{me09a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08drastic.pdf\}},
author = {Menzies, T and Williams, S and El-rawas, O and Boehm, B and Hihn, J},
booktitle = {ICSE'09},
title = {{How to Avoid Drastic Software Process Change (using Stochastic Statbility)}},
year = {2009}
}
@article{renn89,
author = {Rennels, G D and Shortliffe, E H and Stockdale, F E and Miller, P L},
journal = {AI Magazine},
pages = {49--57},
title = {{A Computational Model of Reasoning from the Clinical Literature}},
year = {1989}
}
@article{journals/ese/KhoshgoftaarS03,
author = {Khoshgoftaar, Taghi M and Seliya, Naeem},
journal = {Empirical Software Engineering},
number = {3},
pages = {255--283},
title = {{Fault Prediction Modeling for Software Quality Estimation: Comparing Commonly Used Techniques}},
url = {http://dx.doi.org/10.1023/A:1024424811345},
volume = {8},
year = {2003}
}
@article{Vargha00,
author = {Vargha, A and Delaney, H},
file = {:Users/timm/svns/doc/00varghaEffectSize.pdf:pdf},
journal = {Journal of Educational and Behavioral Statistics},
number = {2},
pages = {101--132},
title = {{A Critique and Improvement of the CL Common Language Effect Size Statistics of McGraw and Wong}},
volume = {25},
year = {2000}
}
@incollection{dechter-constraint,
author = {Dechter, Rina},
booktitle = {MIT Encyclopedia of the Cognitive Sciences (MITECS)},
month = jan,
publisher = {John Wiley and Sons.},
title = {{Constraint satisfaction}},
year = {1998}
}
@inproceedings{goldberg79,
author = {Goldberg, A},
booktitle = {Courant Computer Science Report, No. 16, New York University, NY},
title = {{On the complexity of the satisfiability problem}},
year = {1979}
}
@inproceedings{Haiduc2013a,
address = {San Francisco, USA},
annote = {Laura. Fixed on 10/16/2012 (missing fields - submitted)},
author = {{Haiduc Sonia}, Bavota Gabriele Marcus Andrian Oliveto Rocco De Lucia Andrea and Menzies, Tim},
booktitle = {35th IEEE/ACM International Conference on Software Engineering (ICSE'13)},
keywords = {queries information\_retrieval SEVERE},
pages = {842--851},
title = {{Automatic Query Reformulations for Text Retrieval in Software Engineering}}
}
@inproceedings{me12c,
annote = {Available from http://menzies.us/pdf/12idea.pdf},
author = {Borges, R and Menzies, T},
booktitle = {Proceedings of PROMISE'12, Lund, Sweden},
title = {{Learning to Change Projects}},
year = {2012}
}
@article{Lee2009,
abstract = {Community Question Answering (cQA) services, such as Yahoo! Answers and MSN QnA, facilitate knowledge sharing through question answering by an online community of users. These services include incentive mechanisms to entice participation and self-regulate the quality of the content contributed by the users. In order to encourage quality contributions, community members are asked to nominate the \&amp;\#x02018;best\&amp;\#x02019; among the answers provided to a question. The service then awards extra points to the author who provided the winning answer and to the voters who cast their vote for that answer. The best answers are typically selected by plurality voting, a scheme that is simple, yet vulnerable to random voting and collusion. We propose a weighted voting method that incorporates information about the voters\&amp;\#x02019; behavior. It assigns a score to each voter that captures the level of agreement with other voters. It uses the voter scores to aggregate the votes and determine the best answer. The mathematical formulation leads to the application of the Brouwer Fixed Point Theorem which guarantees the existence of a voter scoring function that satisfies the starting axiom. We demonstrate the robustness of our approach through simulations and analysis of real cQA service data.},
author = {Lee, Chong Tong and Rodrigues, Eduarda Mendes and Kazai, Gabriella and Mili\'{c}-Frayling, Nata\v{s}a and Ignjatovi\'{c}, Aleksandar},
doi = {10.1109/WI-IAT.2009.23},
file = {:Users/timm/svns/doc/Milic-Frayling\_2009.pdf:pdf},
isbn = {9780769538013},
journal = {Proceedings - 2009 IEEE/WIC/ACM International Conference on Web Intelligence, WI 2009},
keywords = {Community question answering,FPS method,Fixed point theorem,Vote spam,Voter score,Weighted voting},
pages = {116--123},
title = {{Model for voter scoring and best answer selection in community Q\&A services}},
volume = {1},
year = {2009}
}
@inproceedings{me00b,
abstract = {The behavior of nondeterminate systems can be hard to predict,
since similar inputs at different times can generate different outputs.
In other words, the behavior seen during the testing process may not be
seen at runtime. Due to the uncertainties associated with
nondeterminism, the standard view is that we should avoid such
nondeterminate systems, especially for systems requiring high
reliability. While this is a valid guideline, at least in two
application areas such nondeterminacy is unavoidable. Early life-cycle
requirements and AI software are becoming widely used, yet both are
imprecise and may exhibit nondeterminate behaviour if explored
rigorously by a test device. Based on a literature review and some
theoretical studies, we argue that many stable properties exist within
the space of all possible nondeterminate behaviors. However, we also
show that seemingly trivial changes to a nondeterministic system can
turn an easily testable system into an impossibly hard system to test.
Finally, we stress that this analysis does not imply a correlation
between stable zones of nondeterminate testability and the ultimate
maintainability of nondeterminate systems. That is, while we are
optimistic about testing nondeterminate systems, we remain cautious
about the maintenance of such systems},
author = {Menzies, T. and Cukic, B. and Singh, H. and Powell, J.},
booktitle = {Proceedings 11th International Symposium on Software Reliability Engineering. ISSRE 2000},
doi = {10.1109/ISSRE.2000.885874},
isbn = {0-7695-0807-3},
issn = {1071-9458},
title = {{Testing nondeterminate systems}},
year = {2000}
}
@inproceedings{mega94,
author = {Menzies, T J and Gambetta, W},
booktitle = {ECAI '94 Workshop on Validation of Knowledge-Based Systems},
title = {{Exhaustive \{A\}bduction: A \{P\}ractical \{M\}odel \{V\}alidation \{T\}ool}},
year = {1994}
}
@inproceedings{me03p,
abstract = { One of the goals of verification and validation (V\&amp;V) activities for online adaptive control systems is providing assurance that they are able to detect novel system behaviors and provide adequate (safe) control actions. Novel (or abnormal) system behaviors cannot be enumerated or fully and explicitly described in requirements documentation. Therefore, they have to be observed and recognized during the operation. Novelty detection methods, therefore, provide an adequate approach for the V\&amp;V purposes. We propose a novelty detection method based on support sector data description (SVDD) as a candidate approach for validating adaptive control systems. As a one-class classifier, the support vector data description is able to form a decision boundary around the learned data domain with very little or no knowledge of data points outside the boundary (outliers). We apply the SVDD techniques for novelty detection as part of the validation on an intelligent flight control system (IFCS). Experimental results show that the SVDD can be adopted as an effective tool for finding indications of the safe region for the learned domain, whereby we are able to separate faulty behavior from normal events.},
author = {Liu, Yan Liu Yan and Gururajan, S. and Cukic, B. and Menzies, T. and Napolitano, M.},
booktitle = {Proceedings. 15th IEEE International Conference on Tools with Artificial Intelligence},
doi = {10.1109/TAI.2003.1250215},
isbn = {0-7695-2038-3},
issn = {1082-3409},
title = {{Validating an online adaptive system using SVDD}},
year = {2003}
}
@article{Warning,
author = {Warning, Notice and Copyright, Concerning},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Warning, Copyright - Unknown - Notice warning concerning copyright restrictions.pdf:pdf},
title = {{Notice warning concerning copyright restrictions}}
}
@book{sed88,
author = {Sedgewick, R},
publisher = {Addison-Wesley},
title = {{Algorithms}},
year = {1988}
}
@article{boehm02,
author = {Boehm, B},
journal = {IEEE Computer},
pages = {2--7},
title = {{Get Ready for Agile Methods}},
year = {2002}
}
@article{Zheng2010,
author = {Zheng, Zhao and Lei, Wang and Huan, Liu},
file = {:Users/timm/svns/doc/10SpectralFss.pdf:pdf},
isbn = {9781577354642},
journal = {Twenty-Fourth AAAI Conference on Artificial Intelligence},
keywords = {Technical Papers -- Machine Learning},
pages = {1----6},
title = {{Efficient Spectral Feature Selection with Minimum Redundancy}},
year = {2010}
}
@inproceedings{robertson96,
author = {Robertson, D},
booktitle = {ECAI '96, Budapest},
pages = {390--394},
title = {{Distributed Specification}},
year = {1996}
}
@book{MillingtonIandFunge2009,
author = {{Millington, I and Funge}, J},
booktitle = {International dental journal},
file = {:Users/timm/svns/doc/millington09.pdf:pdf},
issn = {0020-6539},
keywords = {Artificial Intelligence,Games},
month = aug,
number = {4},
pages = {269--72},
pmid = {20949757},
title = {{Artificial intelligence for games}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20949757},
volume = {60},
year = {2009}
}
@misc{me07c,
annote = {$\backslash$url\{http://promisedata.org/repository\}},
author = {Boetticher, G and Menzies, T and Ostrand, T},
institution = {West Virginia University, Lane Department of Computer Science and Electrical Engineering},
title = {{The \{PROMISE\} \{R\}epository of \{E\}mpirical \{S\}oftware \{E\}ngineering \{D\}ata}},
year = {2007}
}
@inproceedings{mcallestor80,
author = {McAllester, D},
booktitle = {MIT AI Laboratory},
title = {{Memo 551, an outlook on truth maintenance}},
year = {1980}
}
@article{simon52,
author = {Simon, H A},
journal = {Journal Philosphy},
pages = {517--528},
title = {{On the Definition of the Causal Relationship}},
volume = {49},
year = {1952}
}
@incollection{bosch10,
author = {Bagheri, Ebrahim and Asadi, Mohsen and Gasevic, Dragan and Soltani, Samaneh},
booktitle = {Software Product Lines: Going Beyond},
doi = {10.1007/978-3-642-15579-6\_21},
editor = {Bosch, Jan and Lee, Jaejoon},
pages = {300--315},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Stratified Analytic Hierarchy Process: Prioritization and Selection of Software Features}},
url = {http://dx.doi.org/10.1007/978-3-642-15579-6\_21},
volume = {6287},
year = {2010}
}
@incollection{zit04,
author = {Zitzler, Eckart and K\"{u}nzli, Simon},
booktitle = {Parallel Problem Solving from Nature - PPSN VIII},
doi = {10.1007/978-3-540-30217-9\_84},
editor = {Yao, Xin and Burke, EdmundK. and Lozano, Jos\'{e}A. and Smith, Jim and Merelo-Guerv\'{o}s, JuanJuli\'{a}n and Bullinaria, JohnA. and Rowe, JonathanE. and TiÅo, Peter and Kab\'{a}n, Ata and Schwefel, Hans-Paul},
file = {:Users/timm/svns/doc/04zitzlerIBEA.pdf:pdf},
isbn = {978-3-540-23092-2},
pages = {832--842},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Indicator-Based Selection in Multiobjective Search}},
url = {http://dx.doi.org/10.1007/978-3-540-30217-9\_84},
volume = {3242},
year = {2004}
}
@book{cormen90,
annote = {ISBN: 0262031418},
author = {Cormen, T E and Leiserson, C E and Rivest, R L},
publisher = {MIT Press},
title = {{Introduction to Algorithms}},
year = {1990}
}
@article{Pfleeger1990,
author = {Pfleeger, S L and McGowan, C},
journal = {Journal of Systems and Software},
month = jul,
pages = {255--261},
title = {{Software Metrics in a Process Maturity Framework}},
volume = {12},
year = {1990}
}
@article{clarkeng89,
author = {Clark, P and Ng, T},
journal = {Machine Learning},
pages = {261--283},
title = {{The CN2 Induction Algorithm}},
volume = {3},
year = {1989}
}
@inproceedings{menz91,
author = {Menzies, T J},
booktitle = {Tools Pacific 4},
editor = {Meyer, B},
title = {{\{ISA\} \{O\}bject \{PARTOF\} \{K\}nowledge \{R\}epresentation (Part Two)?}},
year = {1991}
}
@misc{bsc99,
author = {Page, Web},
title = {{No Title}}
}
@inproceedings{reiss89,
author = {Reiss, S P and Meyers, S and Duby, C},
booktitle = {Proceedings of the Second Annual Symposium on User Interface Software and Technology},
month = nov,
pages = {149--157},
title = {{Using GELO to Visualize Software Systems}},
year = {1989}
}
@article{parnas76,
author = {Parnas, D},
journal = {IEEE Transactions on Software Engineering},
month = mar,
title = {{On the design and development of program families}},
year = {1976}
}
@article{domingos03,
author = {Domingos, Pedro and Hulten, Geoff},
journal = {Journal of Computational and Graphical Statistics},
number = {12},
title = {{A General Framework for Mining Massive Data Streams}},
year = {2003}
}
@article{Gao2010a,
author = {Gao, Jing and Fan, Wei and Han, Jiawei},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Gao, Fan, Han - 2010 - On the Power of Ensemble Supervised and Unsupervised Methods Reconciled.pdf:pdf},
journal = {Science},
title = {{On the Power of Ensemble : Supervised and Unsupervised Methods Reconciled *}},
year = {2010}
}
@misc{1278.4,
author = {Society, IEEE Computer},
title = {{IEEE Recommended Practice 1278.4-1007 -2004 for Distributed Interactive Simulation- Verification, Validation, and Accreditation}},
year = {1997}
}
@article{brown06,
author = {Brown, A W and Iyengar, S and Johnston, S},
journal = {IBM Systems Journal},
number = {3},
pages = {463--480},
title = {{A Rational approach to model-driven development}},
volume = {45},
year = {2006}
}
@article{vines14,
author = {Vines, T and Albert, A and Arianne, K and Bock, D and Franklin, M and Gilbert, K and Moore, J and Renaut, S and Rennison, D},
journal = {Current Biology},
number = {1},
title = {{The Availability of Research Data Declines Rapidly with Article Age}},
volume = {24},
year = {2014}
}
@article{mylo99,
author = {Mylopoulos, J and Cheng, L and Yu, E},
journal = {Communications of the ACM},
month = jan,
number = {1},
pages = {31--37},
title = {{From Object-Oriented to Goal-Oriented Requirements Analysis}},
volume = {42},
year = {1999}
}
@article{Levine2007,
abstract = {Systematic evolution of ligands by exponential enrichment (SELEX) is a procedure by which a mixture of nucleic acids that vary in sequence can be separated into pure components with the goal of isolating those with specific biochemical activities. The basic idea is to combine the mixture with a specific target molecule and then separate the target-NA complex from the resulting reaction. The target-NA complex is then separated by mechanical means (for example by filtration), the NA is then eluted from the complex, amplified by polymerase chain reaction (PCR) and the process repeated. After several rounds, one should be left with a pool of [NA] that consists mostly of the species in the original pool that best binds to the target. In Irvine et al. [Irvine, D., Tuerk, C., Gold, L., 1991. SELEXION, systematic evolution of nucleic acids by exponential enrichment with integrated optimization by non-linear analysis. J. Mol. Biol. 222, 739-761] a mathematical analysis of this process was given. In this paper we revisit Irvine et al. [Ibid]. By rewriting the equations for the SELEX process, we considerably reduce the labor of computing the round to round distribution of nucleic acid fractions. We also establish necessary and sufficient conditions for the SELEX process to converge to a pool consisting solely of the best binding nucleic acid to a fixed target in a manner that maximizes the percentage of bound target. The assumption is that there is a single nucleic acid binding site on the target that permits occupation by not more than one nucleic acid. We analyze the case for which there is no background loss (no support losses and no free [NA] left on the support). We then examine the case in which such there are such losses. The significance of the analysis is that it suggests an experimental approach for the SELEX process as defined in Irvine et al. [Ibid] to converge to a pool consisting of a single best binding nucleic acid without recourse to any a priori information about the nature of the binding constants or the distribution of the individual nucleic acid fragments. ?? 2006 Elsevier Ltd. All rights reserved.},
author = {Levine, Howard a. and Nilsen-Hamilton, Marit},
doi = {10.1016/j.compbiolchem.2006.10.002},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Levine07.pdf:pdf},
isbn = {1476-9271},
issn = {14769271},
journal = {Computational Biology and Chemistry},
keywords = {Aptamer,Mathematical analysis,SELEX},
number = {1},
pages = {11--35},
pmid = {17218151},
title = {{A mathematical analysis of SELEX}},
volume = {31},
year = {2007}
}
@article{silver90,
author = {Silverman, B G},
journal = {AI Magazine},
pages = {60--79},
title = {{Critiquing Human Judgmet Using Knowledge-Acquisition Systems}},
year = {1990}
}
@phdthesis{lee97,
author = {Lee, M},
school = {Computer Science \& Engineering},
title = {{From Multiple Representations to Causal Explanation}},
year = {1997}
}
@article{nelson11,
author = {{Adam Nelson Tim Menzies}, Gregory Gay},
journal = {Software- Practice and Experience (to appear)},
title = {{Sharing Experiments Using Open Source Software}},
year = {2011}
}
@article{Niu2008,
author = {Niu, Kun and Zhang, Shubo and Chen, Junliang},
doi = {10.1007/s11460-008-0010-x},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/niu08.pdf:pdf},
issn = {16733460},
journal = {Frontiers of Electrical and Electronic Engineering in China},
keywords = {Attribute clustering,High dimensional data,Subspace clustering},
number = {1},
pages = {44--48},
title = {{Subspace clustering through attribute clustering}},
volume = {3},
year = {2008}
}
@inproceedings{me95a,
author = {Menzies, T J},
booktitle = {Australian Cognitive Science Society, 3rd Conference},
title = {{Situated \{S\}emantics is a \{S\}ide-\{E\}ffect of the \{C\}omputational \{C\}omplexity of \{A\}bduction}},
year = {1995}
}
@inproceedings{Gu97,
author = {Gu, Jun and Purdom, Paul W and Franco, John and Wah, Benjamin W},
booktitle = {DIMACS Series in Discrete Mathematics and Theoretical Computer Science},
pages = {19--152},
publisher = {American Mathematical Society},
title = {{Algorithms for the Satisfiability (SAT) Problem: A Survey}},
year = {1997}
}
@inproceedings{bobntim1,
author = {Cohen, R F and Menzies, T J},
booktitle = {Software Education Conference (SRIG-ET'94)},
pages = {71--76},
title = {{Providing \{S\}oftware \{E\}ngineering \{S\}tudents with an \{E\}xperience in "\{B\}ig-\{C\}omputing"}},
year = {1995}
}
@book{fen95b,
author = {Fensel, D},
publisher = {Kluwer Academic Publisher},
title = {{The Knowledge Acquisition And Representation Language KARL}},
year = {1995}
}
@inproceedings{me03k,
abstract = { Traditional methods of generating quality code indicators (e.g. linear regression, decision tree induction) can be demonstrated to be inappropriate for IV\&amp;V purposes. IV\&amp;V is a unique aspect of the software lifecycle, and different methods are necessary to produce quick and accurate results. If quality code indicators could be produced on a per-project basis, then IV\&amp;V could proceed in a more straight-forward fashion, saving time and money. We present one case study on just such a project, showing that by using the proper metrics and machine learning algorithms, quality indicators can be found as early as 3 months into the IV\&amp;V process.},
author = {Menzies, T. and Stefano, J.S. Di and Chapman, M.},
booktitle = {Proceedings. 5th International Workshop on Enterprise Networking and Computing in Healthcare Industry (IEEE Cat. No.03EX717)},
doi = {10.1109/METRIC.2003.1232458},
isbn = {0-7695-1987-3},
issn = {1530-1435},
title = {{Learning early lifecycle IV \&amp;amp; V quality indicators}},
year = {2003}
}
@inproceedings{feather08c,
author = {Feather, M S and Hicks, K A and Mackey, R M and Uckun, S},
booktitle = {IEEE International Conference on Requirements Engineering, Industrial Practice and Experience track Barcelona, Spain},
title = {{Guiding Technology Deployment Decisions using a Quantitative Requirements Analysis Technique}},
year = {2008}
}
@article{poole90a,
author = {Poole, D},
journal = {International Journal of Intelligent Systems},
pages = {521--548},
title = {{A \{M\}ethodology for \{U\}sing a \{D\}efault and \{A\}bductive \{R\}easoning \{S\}ystem}},
volume = {5},
year = {1990}
}
@inproceedings{Hinneburg1999,
author = {Hinneburg, A. and Keim, D.A.},
booktitle = {25th VLDB},
file = {:Users/timm/svns/doc/hinneburg99.pdf:pdf},
keywords = {Grid cluster},
publisher = {Citeseer},
title = {{Optimal grid-clustering: Towards breaking the curse of dimensionality in high-dimensional clustering}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.44.4721\&amp;rep=rep1\&amp;type=pdf},
year = {1999}
}
@article{myer90,
author = {Myers, B A},
journal = {Journal of Visual Languages and Computing},
pages = {97--123},
title = {{Taxonomies of visual programming and program visualization}},
volume = {1},
year = {1990}
}
@inproceedings{hori97,
author = {Hori, M and Yoshida, T},
booktitle = {Workshop on Problem-Solving Methods for Knowledge-based Systems, IJCAI '97, August 23.},
title = {{Domain-oriented library of scheduling methods: Design Principle and real-life application}},
year = {1997}
}
@inproceedings{goa06,
abstract = {Model-checking techniques are successfully used in the verification of both hardware and software systems of industrial relevance. Unfortunately, the capability of current techniques is still limited and the effort required for verification can be prohibitive (if verification is possible at all). As a complement, fast, but incomplete, search tools may provide practical benefits not attainable with full verification tools, for example, reduced need for manual abstraction and fast detection of property violations during model development. In this report we investigate the performance of a simple random search technique. We conducted an experiment on a production-sized formal model of the mode-logic of a flight guidance system. Our results indicate that random search quickly finds the vast majority of property violations in our case-example. In addition, the times to detect various property violations follow an acutely right-skewed distribution and are highly biased toward the easy side. We hypothesize that the observations reported here are related to the phase transition phenomenon seen in Boolean satisfiability and other NP-complete problems. If so, these observations could be revealing some of the fundamental aspects of software (model) faults and have implications on how software engineering activities, such as analysis, testing, and reliability modeling, should be performed},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06compsac.pdf\}},
author = {Gao, Jimin and Heimdahl, Mats and Owen, David and Menzies, Tim},
booktitle = {Proceedings - International Computer Software and Applications Conference},
doi = {10.1109/COMPSAC.2006.64},
isbn = {0769526551},
issn = {07303157},
pages = {150--157},
title = {{On the distribution of property violations in formal models: An initial study}},
volume = {1},
year = {2006}
}
@inproceedings{mebfd92,
author = {Menzies, T J and Black, J and Fleming, J and Dean, M},
booktitle = {The first Conference on Practical Applications of Prolog},
title = {{An Expert System for Raising Pigs}},
year = {1992}
}
@inproceedings{me08f,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ispa.pdf\}},
author = {Hihn, J and Menzies, T and Lum, K and Baker, D and Jalali, O},
booktitle = {ISPA'08: International Society of Parametric Analysis},
title = {{\{2CEE\}, A \{T\}WENTY \{F\}IRST \{C\}ENTURY \{E\}FFORT \{E\}STIMATION \{M\}ETHODOLOGY}},
year = {2008}
}
@inproceedings{WEDEL2008,
address = {New York, NY, USA},
author = {Wedel, Michael and Jensen, Uwe and G\"{o}hner, Peter},
booktitle = {ESEM '08: Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
doi = {http://doi.acm.org/10.1145/1414004.1414052},
isbn = {978-1-59593-971-5},
pages = {282--284},
publisher = {ACM},
title = {{Mining software code repositories and bug databases using survival analysis models}},
year = {2008}
}
@article{kakas00aclp,
author = {Kakas, Antonis C and Michael, A and Mourlas, C},
journal = {Journal of Logic Programming},
number = {1-3},
pages = {129--177},
title = {{\{ACLP\}: Abductive Constraint Logic Programming}},
volume = {44},
year = {2000}
}
@inproceedings{me92n,
author = {Menzies, T J and Compton, P and Mahidadia, a},
booktitle = {Communicating Scientific and Technical Knowledge, an AAAI '92 workshop},
title = {{Communicating Research Models of Human Physiology using Qualitative Compartmental Modeling}},
year = {1992}
}
@inproceedings{me02h,
author = {Menzies, T and Owen, D and Cukic, B},
booktitle = {Formal Aspects of Agent-Based Systems},
title = {{You seem friendly, but can I trust you?}},
year = {2002}
}
@inproceedings{men92s,
author = {Menzies, Tim and Compton, Paul and Feldman, Bart and Toth, Thomas},
booktitle = {AAAI Techical Report},
title = {{Qualitative Compartmental Modelling}},
volume = {SS-92-02},
year = {1992}
}
@inproceedings{compton93,
author = {Compton, P and Kang, B and Preston, P and Mulholland, M},
booktitle = {European Knowledge Acquisition Workshop},
title = {{Knowledge Acquisition Without Analysis}},
year = {1993}
}
@book{Grady1992,
author = {Grady, R B},
publisher = {Prentice-Hall, Englewood Cliffs},
title = {{Practical Software Metrics for Project Management and Process Improvement}},
year = {1992}
}
@inproceedings{etre83,
author = {Etherington, D W and Reiter, R},
booktitle = {\{AAAI\}-83},
pages = {104--108},
title = {{On Inheritance Hierarchies with Exceptions}},
year = {1983}
}
@inproceedings{Buntine1999a,
author = {Buntine, W. and Fischer, B. and Pressburger, T.},
booktitle = {Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining},
file = {:Users/timm/svns/doc/Buntine99.pdf:pdf},
isbn = {1581131437},
publisher = {ACM},
title = {{Towards automated synthesis of data mining programs}},
url = {http://portal.acm.org/citation.cfm?id=312286},
year = {1999}
}
@article{Vigder1994,
author = {Vigder, M.R. and a.W. Kark},
file = {:Users/timm/svns/doc/cost/94Vigder.pdf:pdf},
journal = {\ldots National Research Council Canada, Ottowa, Ontario \ldots},
number = {37116},
title = {{Software cost estimation and control}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.45.9301\&rep=rep1\&type=pdf},
year = {1994}
}
@inproceedings{me91b,
author = {Menzies, T J},
booktitle = {IJCAI '91 Knowledge Acquisition Workshop},
title = {{Concerning the User of Procedural Construct as a Knowledge Acquisition Technique}},
year = {1991}
}
@misc{boehm03,
author = {Boehm, B},
title = {{Personnel communication}},
year = {2003}
}
@book{cohen95,
author = {Cohen, P R},
publisher = {MIT Press},
title = {{Empirical Methods for Artificial Intelligence}},
year = {1995}
}
@article{me13a,
author = {Kocaguneli, Ekrem and Menzies, Tim and Keung, Jacky and Cok, David and Madachy, Ray},
file = {:Users/timm/svns/doc/cost/13quick.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
number = {8},
pages = {1040--1053},
title = {{Active Learning and Effort Estimation: Finding the Essential Content of Software Effort Estimation Data}},
volume = {39},
year = {2013}
}
@article{geigner93,
author = {Geigner, D and Pax, A and Pearl, J},
journal = {International Journal of Intelligent Systems},
pages = {231--247},
title = {{Learning Simple Causal Structures}},
volume = {8},
year = {1993}
}
@article{vasil13,
author = {{Vasil Papakroni Tim Menzies}, Fayola Peters Susan Partington and Marcus, Andrian},
journal = {Submitted to the International Conference on Automated Software Engineering (ASE'13)},
title = {{Peeking at Defect Data Considered Harmful?}},
year = {2013}
}
@inproceedings{AZZEH2009,
address = {New York, NY, USA},
author = {Azzeh, Mohammad and Neagu, Daniel and Cowling, Peter},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540450},
isbn = {978-1-60558-634-2},
pages = {1--10},
publisher = {ACM},
title = {{Software effort estimation based on weighted fuzzy grey relational analysis}},
year = {2009}
}
@inproceedings{arisholm06,
author = {Arisholm, E and Briand, L},
booktitle = {5th ACM-IEEE International Symposium on Empirical Software Engineering (ISESE), Rio de Janeiro, Brazil, September 21-22},
title = {{Predicting Fault-prone Components in a Java Legacy System}},
year = {2006}
}
@book{spinbook,
author = {Holzmann, G},
publisher = {Addison-Wesley},
title = {{\{T\}he \{SPIN\} \{M\}odel \{C\}hecker: \{P\}rimer and \{R\}eference \{M\}anual}},
year = {2003}
}
@article{wu94,
author = {Wu, X},
journal = {Informatica: An International Journal of Computing and Informatics},
number = {2},
pages = {197--218},
title = {{Lecture notes in machine learning}},
volume = {18},
year = {1994}
}
@article{Merugu2003a,
author = {Merugu, Srujana and Ghosh, Joydeep},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Merugu, Ghosh - 2003 - Privacy-preserving Distributed Clustering using Generative Models.pdf:pdf},
pages = {0--7},
title = {{Privacy-preserving Distributed Clustering using Generative Models}},
year = {2003}
}
@book{efron93,
address = {London},
author = {Efron, Bradley and Tibshirani, Robert J},
publisher = {Chapman and Hall},
series = {Mono. Stat. Appl. Probab.},
title = {{An introduction to the bootstrap}},
year = {1993}
}
@inproceedings{me96f,
author = {Menzies, T J and Goss, S},
booktitle = {Proceedings PKAW '96: Pacific Knowledge Acquisition Workshop and Monash University Department of Software Development Technical Report TR96-15},
title = {{Vague Models and Their Implications for the KBS Design Cycle}},
year = {1996}
}
@article{Wilkinson2011,
author = {Wilkinson, Leland},
file = {:Users/timm/svns/doc/11clusterHyperCube.pdf:pdf},
isbn = {9781450308137},
keywords = {random projections,supervised classification},
pages = {6--14},
title = {{CHIRP : A N ew C lassifier B ased o n Composite Hypercubes on Iterated Random Projections}},
year = {2011}
}
@article{glass98,
author = {Glass, R L},
journal = {Communciation of the ACM},
number = {12},
title = {{How not to prepare for a consulting assignment and other ugly consultancy truths}},
volume = {41},
year = {1998}
}
@inproceedings{clarke93,
author = {Clark, E M and Filkorn, T},
booktitle = {Fifth International Conference on Computer Aided Verification},
publisher = {Springer-Verlag},
title = {{Exploiting Symmetry in Temporal Logic Model Checking}},
year = {1993}
}
@inproceedings{me00q,
abstract = {Early testing of requirements can decrease the cost of removing errors in software projects. However unless done carefully, that testing process can significantly add to the cost of requirements analysis. We show that requirements expressed as topoi diagrams can be built and tested cheaply <sup>s</sup>ing our SP2 algorithm, the formal temporal properties of a large class of topoi can be proven very quickly, in time nearly linear in the number of nodes and edges in the diagram. There are two limitations to our approach. Firstly, topoi diagrams cannot express certain complex concepts such as iteration and sub-routine calls. Hence, our approach is more useful for requirements engineering than for traditional model checking domains. Secondly, our approach is better for exploring the temporal occurrence of properties than the temporal ordering of properties. Within these restrictions, we can express a useful range of concepts currently seen in requirements engineering, and a wide range of interesting temporal properties.},
author = {Menzies, T and Powell, J and Houle, M E},
booktitle = {Software Engineering, 2001. ICSE 2001. Proceedings of the 23rd International Conference on},
doi = {10.1109/ICSE.2001.919112},
isbn = {0270-5257   VO  -},
issn = {02705257},
keywords = {SP2 algorithm,fast formal requirements analysis,formal specification,formal temporal properties,program verification,requirements engineering,software projects,testing process,topoi diagrams},
pages = {391--400},
title = {{Fast formal analysis of requirements via "topoi diagrams"}},
year = {2001}
}
@misc{basili09,
author = {Basili, Victor},
title = {{Personnel communication}},
year = {2009}
}
@phdthesis{cooper01a,
author = {Cooper, K},
school = {Department of Electrical and Computer Engineering, The University of British Columbia},
title = {{Assessing Requirements Engineering Languages}},
year = {2001}
}
@article{kuipers93a,
author = {Kuipers, B},
journal = {Artificial Intelligence},
pages = {133--140},
title = {{Qualitative Simulation: then and now}},
volume = {59},
year = {1993}
}
@misc{kern98,
author = {Kerningham, B W and Wyk, C J Van},
title = {{Timing Trials, or, the Trials of Timing: Experiments with Scripting and User-Interface Languages}},
year = {1998}
}
@article{khoshgoftaar03,
address = {Hingham, MA, USA},
author = {Khoshgoftaar, Taghi M and Seliya, Naeem},
doi = {http://dx.doi.org/10.1023/A:1025316301168},
issn = {1382-3256},
journal = {Empirical Softw. Engg.},
number = {4},
pages = {325--350},
publisher = {Kluwer Academic Publishers},
title = {{Analogy-Based Practical Classification Rules for Software Quality Estimation}},
volume = {8},
year = {2003}
}
@inproceedings{me97b,
author = {Menzies, T J and Mahidadia, A},
booktitle = {Workshop on Problem-Solving Methods for Knowledge-based Systems, IJCAI '97, August 23.},
title = {{Ripple-Down Rationality: A Framework for Maintaining PSMs}},
year = {1997}
}
@misc{me96o,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/96ie.pdf\}},
author = {Menzies, T and Tucker, S},
title = {{Subject Handbook SFT3500/SYS3030: Industrial Experience Project}},
year = {1996}
}
@inproceedings{port08,
abstract = {Agile and traditional plan-based approaches to software system development both agree that prioritizing requirements is an essential activity. They differ in basic strategy - when to prioritize, to what degree, and how to guide implementation. As with many software engineering methods, verifying the benefit of following a particular approach is a challenge. Industry and student/classroom based experimental studies are generally impractical to use for large numbers of controlled experiments and benefits are difficult to measure directly. We use simulation to validate the fundamental, yet typically intangible benefits of requirements prioritization strategies. Our simulation is directly based on detailed empirical studies of agile and plan-based requirements management studies. Our simulation shows, as many have claimed, that an agile strategy excels when requirements are highly volatile, whereas a plan-based strategy excels when requirements are stable, and that there exist mixed strategies that are better than either for typical development efforts.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08simrequire.pdf\}},
author = {Port, Dan and Olkov, Alexy and Menzies, Tim},
booktitle = {ASE 2008 - 23rd IEEE/ACM International Conference on Automated Software Engineering, Proceedings},
doi = {10.1109/ASE.2008.37},
isbn = {9781424421886},
issn = {1527-1366},
keywords = {Agile,Plan-based,Requirements,Simulation},
pages = {268--277},
title = {{Using simulation to investigate requirements prioritization strategies}},
year = {2008}
}
@article{Ding2004,
author = {Ding, C and He, X},
file = {:Users/timm/svns/doc/04dingClusteringPca.pdf:pdf},
journal = {International Conference on Machine Learning},
title = {{K-means Clustering via Principal Component Analysis}},
year = {2004}
}
@article{linster92,
author = {Linster, M and Musen, M},
journal = {Knowledge Acquisition},
pages = {55--88},
title = {{Use of \{KADS\} to \{C\}reate a \{C\}onceptual \{M\}odel of the \{ONCOCIN\} task}},
volume = {4},
year = {1992}
}
@article{Li2009,
author = {Li, Y and Xie, M and Goh, T},
doi = {10.1016/j.jss.2008.06.001},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {analogy based estimation,software cost estimation},
number = {2},
pages = {241--252},
title = {{A study of project selection and feature weighting for analogy based software cost estimation}},
volume = {82},
year = {2009}
}
@article{Harman2010a,
author = {Harman, Mark and McMinn, Phil},
doi = {10.1109/TSE.2009.71},
file = {:Users/timm/svns/doc/harmanTSE10.pdf:pdf;:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Harman, Court - 2010 - A Theoretical and Empirical Study of Search Based Testing Local , Global and Hybrid Search(2).pdf:pdf},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
month = mar,
number = {2},
pages = {226--247},
title = {{A Theoretical and Empirical Study of Search-Based Testing: Local, Global, and Hybrid Search}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5342440},
volume = {36},
year = {2010}
}
@misc{gibson06,
author = {Gibson, D L and Goldenson, D R and Kost, K},
institution = {Software Engineering Institute},
title = {{Performance Results of CMMI-Based Process Improvement}},
year = {2006}
}
@incollection{casady96,
author = {Casady, G},
booktitle = {Design Rationale: Concepts, Techniques, and Use},
editor = {Moran, T P and Carroll, J M},
pages = {351--372},
publisher = {Lawerence Erlbaum Associates},
title = {{Rationale in Practice: templates for Capturing and Applying Design Expertise}},
year = {1996}
}
@article{Du2008a,
author = {Du, Q. and Fowler, J. E.},
doi = {10.1177/1094342007088380},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Du, Fowler - 2008 - Low-Complexity Principal Component Analysis for Hyperspectral Image Compression.pdf:pdf},
issn = {1094-3420},
journal = {International Journal of High Performance Computing Applications},
month = nov,
number = {4},
pages = {438--448},
title = {{Low-Complexity Principal Component Analysis for Hyperspectral Image Compression}},
url = {http://hpc.sagepub.com/cgi/doi/10.1177/1094342007088380},
volume = {22},
year = {2008}
}
@article{Fayyad96,
author = {{Usama Fayyad Gregory Piatetsky-Shapiro} and Smyth, Padhraic},
journal = {AI Magazine},
pages = {37--54},
title = {{From Data Mining to Knowledge Discovery in Databases}},
year = {1996}
}
@inproceedings{satoh01,
author = {Satoh, K},
booktitle = {Handbook of Software and Knowledge Engineering},
editor = {Chung, C K},
title = {{Nonmonotonic reasoning and consistency requirements in SE}},
volume = {2},
year = {2001}
}
@article{Levy-Nissenbaum2008,
abstract = {Nucleic acid ligands, also known as aptamers, are a class of macromolecules that are being used in several novel nanobiomedical applications. Aptamers are characterized by high affinity and specificity for their target, a versatile selection process, ease of chemical synthesis and a small physical size, which collectively make them attractive molecules for targeting diseases or as therapeutics. These properties will enable aptamers to facilitate innovative new nanotechnologies with applications in medicine. In this review, we will highlight recent developments in using aptamers in nanotechnology solutions for treating and diagnosing disease. Â© 2008 Elsevier Ltd. All rights reserved.},
author = {Levy-Nissenbaum, Etgar and Radovic-Moreno, Aleksandar F. and Wang, Andrew Z. and Langer, Robert and Farokhzad, Omid C.},
doi = {10.1016/j.tibtech.2008.04.006},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Levy08.pdf:pdf},
isbn = {0167-7799},
issn = {01677799},
journal = {Trends in Biotechnology},
number = {8},
pages = {442--449},
pmid = {18571753},
title = {{Nanotechnology and aptamers: applications in drug delivery}},
volume = {26},
year = {2008}
}
@article{adlassnig89,
author = {Adlassnig, K P and Scheithauer, W},
journal = {Computers and Biomedical Research},
number = {4},
pages = {297--313},
title = {{Performance evaluation of medical expert systems using ROC curves}},
volume = {22},
year = {1989}
}
@inproceedings{me00f,
abstract = {Modern software is often constructed using \&amp;ldquo;spiral
specification\&amp;rdquo;; i.e. the specification is a dynamic document that
is altered by experience with the current version of the system.
Mathematically, many of the sub-tasks within spiral specification belong
to the NP-complete class of tasks. In the traditional view of computer
science, such tasks are fundamentally intractable and only solvable
using incomplete, approximate methods that can be undependable. This
traditional view suggests that we should routinely expect spiral
specification to always be performed very poorly. This paper is an
antidote to such pessimism. Contrary to the traditional view, we can
expect that spiral specification can usually be performed adequately,
providing that analysts augment their current tools with random probing
},
author = {Menzies, T.},
booktitle = {Tenth International Workshop on Software Specification and Design. IWSSD-10 2000},
doi = {10.1109/IWSSD.2000.891157},
isbn = {0-7695-0884-7},
title = {{The complexity of TRMCS-like spiral specification}},
year = {2000}
}
@inproceedings{for95,
author = {Forbus, K},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and {N.H. Narayanan}, B Chandrasekaran},
pages = {183--204},
publisher = {The AAAI Press},
title = {{Qualitative Spatial Reasoning: Framework and Frontiers}},
year = {1995}
}
@article{kocaguneli2014transfer,
author = {Kocaguneli, Ekrem and Menzies, Tim and Mendes, Emilia},
journal = {Empirical Software Engineering},
pages = {1--31},
publisher = {Springer US},
title = {{Transfer learning in effort estimation}},
year = {2014}
}
@incollection{maclean96,
author = {MacLean, A and Young, R M and Bellotti, V and Moran, T P},
booktitle = {Design Rationale: Concepts, Techniques, and Use},
editor = {Moran, T P and Carroll, J M},
pages = {53--106},
publisher = {Lawerence Erlbaum Associates},
title = {{Questions, options and criteria: Elements of design space analysis}},
year = {1996}
}
@article{Jiang2003,
author = {Jiang, Lei and Yang, Wenhui},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/pi06.pdf:pdf},
number = {02},
pages = {10--12},
title = {{A Modified Fuzzy C-Means Algorithm for}},
year = {2003}
}
@misc{womenincs,
author = {Dean, Cornelia},
month = apr,
title = {{Computer Science Takes Steps to Bring Women to the Fold}},
year = {2007}
}
@article{simon86,
author = {Iwasaki, Y and Simon, H A},
journal = {Artificial Intelligence},
pages = {3--31},
title = {{Causality in Device Behaviour}},
volume = {29},
year = {1986}
}
@article{me07b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06learnPredict.pdf\}},
author = {Menzies, Tim and Greenwald, Jeremy and Frank, Art},
journal = {IEEE Transactions on Software Engineering},
month = jan,
title = {{Data Mining Static Code Attributes to Learn Defect Predictors}},
year = {2007}
}
@book{quinlan92,
annote = {ISBN: 1558602380},
author = {Quinlan, R},
publisher = {Morgan Kaufman},
title = {{C4.5: Programs for Machine Learning}},
year = {1992}
}
@phdthesis{ma07,
author = {Ma, Y},
month = jan,
school = {West Virginia University, Lane Department of Computer Science and Electrical Engineering},
title = {{An Empirical Investigation of Tree Ensembles in Biometrics and Bioinformatics}},
year = {2007}
}
@inproceedings{mebfd92,
author = {Menzies, T J and Black, J and Fleming, J and Dean, M},
booktitle = {The first Conference on Practical Applications of Prolog},
title = {{An Expert System for Raising Pigs}},
year = {1992}
}
@phdthesis{sahlin91,
address = {Stockholm, Sweden},
author = {Sahlin, D},
month = may,
school = {The Royal Institute of Technology (KTH)},
title = {{An Automatic Partial Evaluator for Full Prolog}},
year = {1991}
}
@article{yang98,
author = {J.\~{}Yang and V.\~{}Honavar},
journal = {IEEE Intelligent Systems},
number = {2},
pages = {44--49},
title = {{Feature subset selection using a genetic algorithm}},
volume = {13},
year = {1998}
}
@misc{bsc99,
author = {Page, Web},
title = {{No Title}}
}
@book{Sutton1998,
author = {Sutton, R.S. and Barto, A.G.},
booktitle = {Policy},
file = {:Users/timm/svns/doc/sutton98.pdf:pdf},
isbn = {0262193981},
publisher = {The MIT press},
title = {{Reinforcement learning: An introduction}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=CAFR6IBF4xYC\&amp;oi=fnd\&amp;pg=PA3\&amp;dq=Reinforcement+Learning+:+An+Introduction\&amp;ots=e8WUNPbbWC\&amp;sig=9P8h\_oRbAy7uAtVkbWwdFGvz2SQ},
year = {1998}
}
@article{NicDaeid2005,
abstract = {Over the last 20 years there has been an increasing interest in the development of robust systems, both analytical and statistical, to enable the linkage of seizures of illicit drug to each other. Much of this work has concentrated on the analysis of synthetic drugs, such as amphetamine and its analogues. In recent years, the analysis of both organic and elemental impurities as well as isotope ratios has advanced the usefulness of the techniques available. The application of specific chemometric methods to the derived analytical data has begun to provide the possibility of robust methods by which the resultant information can be interrogated.},
author = {{Nic Da\'{e}id}, Niamh and Waddell, Ruth J H},
doi = {10.1016/j.talanta.2005.05.018},
file = {:Users/timm/svns/doc/nic05.pdf:pdf},
issn = {1873-3573},
journal = {Talanta},
keywords = {chemometrics,drug analysis,forensic analysis},
month = aug,
number = {2},
pages = {280--5},
pmid = {18970168},
title = {{The analytical and chemometric procedures used to profile illicit drug seizures.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18970168},
volume = {67},
year = {2005}
}
@article{mccabe76,
author = {McCabe, T J},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
month = dec,
number = {4},
pages = {308--320},
title = {{A Complexity Measure}},
volume = {2},
year = {1976}
}
@inproceedings{raffo04,
author = {Raffo, D and Nayak, U and Setamanit, S and Wakeland, W},
booktitle = {Proceedings of the International Workshop on Software Process Simulation and Modeling (ProSim'04), Held in conjunction with the International Conference of Software Engineering (ICSE), Held in Edinburgh, Scotland},
month = may,
title = {{Using Software Process Simulation Models to Assess the Impact of \{IV\&V\} Activities}},
year = {2004}
}
@inproceedings{compton89,
author = {Compton, P and Horn, K and Quinlan, J R and Lazarus, L},
booktitle = {Applications of Expert Systems},
editor = {Quinlan, J R},
pages = {366--385},
publisher = {Addison Wesley},
title = {{Maintaining an Expert System}},
year = {1989}
}
@article{me00o,
author = {Menzies, T and Althoff, K D and Kalfoglou, Y and Motta, E},
journal = {International Journal of Software Engineering and Knowledge Engineering},
month = aug,
number = {4},
title = {{Issues with Meta-Knowledge}},
volume = {10},
year = {2000}
}
@inproceedings{levina04,
author = {Levina, Elizaveta and Bickel, Peter J},
booktitle = {NIPS},
file = {:Users/timm/svns/doc/04intrinsicDimension.pdf:pdf},
title = {{Maximum Likelihood Estimation of Intrinsic Dimension.}},
year = {2004}
}
@inproceedings{cheng95,
author = {Cheng, P C and Simon, H A},
booktitle = {Scientific Discovery and Creative Reasoning with Diagrams},
editor = {Smith, S M and Ward, T B and Finke, R A},
pages = {205--228},
publisher = {A Bradford Book},
title = {{The Creative Cognitive Approach}},
year = {1995}
}
@article{Koch2015,
author = {Koch, Patrick and Wagner, Tobias and Emmerich, Michael T.M. and B\"{a}ck, Thomas and Konen, Wolfgang},
doi = {10.1016/j.asoc.2015.01.005},
file = {:Users/timm/svns/doc/sbse/15tunings.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing},
pages = {357--370},
publisher = {Elsevier B.V.},
title = {{Efficient multi-criteria optimization on noisy machine learning problems}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S156849461500006X},
volume = {29},
year = {2015}
}
@inproceedings{kautz96,
address = {Menlo Park},
author = {Kautz, Henry and Selman, Bart},
booktitle = {Proceedings of the Thirteenth National Conference on Artificial Intelligence and the Eighth Innovative Applications of Artificial Intelligence Conference},
isbn = {0-262-51091-X},
pages = {1194--1201},
publisher = {AAAI Press / MIT Press},
title = {{Pushing the Envelope: Planning, Propositional Logic and Stochastic Search}},
year = {1996}
}
@article{pugh90,
author = {Pugh, W},
journal = {Communications of the ACM},
number = {6},
pages = {668--676},
title = {{Skip Lists: a Probabilistic Alternative to Balanced Trees}},
volume = {33},
year = {1990}
}
@inproceedings{pearl91,
author = {Pearl, J and Verma, T S},
booktitle = {Proceedings of the Principles of Knowledge Representation and Reasoning Conference},
editor = {{J.A. Allan}, R Fikes and Sandewall, E},
pages = {441--452.},
publisher = {Morgan Kaufmann},
title = {{A Theory of Inferred Causation}},
year = {1991}
}
@article{Wang,
author = {Wang, Ke and Va, Canada and Fung, Benjamin C M and Yu, Philip S},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Wang et al. - Unknown - Template-Based Privacy Preservation in Classification Problems â.pdf:pdf},
journal = {Work},
title = {{Template-Based Privacy Preservation in Classification Problems â}}
}
@article{silver92,
author = {Silverman, B G},
journal = {Communications of the ACM},
pages = {106--127},
title = {{Survey of Expert Critiquing Systems: Practical and Theoretical Frontiers}},
volume = {35},
year = {1992}
}
@book{akao90,
author = {Akao, Y},
publisher = {Productivity Press, Cambridge, Massachusetts},
title = {{Quality Function Deployment}},
year = {1990}
}
@inproceedings{reggia85,
author = {Reggia, J A},
booktitle = {Proceedigns of the Expert Systems in Government Symposium},
pages = {484--489},
title = {{Abductive Inference}},
year = {1985}
}
@inproceedings{tidhar99,
author = {Tidar, G and Heinze, C and Goss, S and Murray, G and Appla, D and Lloyd, I},
booktitle = {Proc. of Eleventh Innovative Applications of Artificial Intelligence Conference, American Association of Artificial Intelligence},
title = {{Using intelligent agents in military simulations or 'using agents intelligently.'}},
year = {1999}
}
@article{Li2001,
author = {Li, Jiuyong},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Li - 2001 - Current Developments of k-Anonymous Data Releasing.pdf:pdf},
pages = {1--12},
title = {{Current Developments of k-Anonymous Data Releasing}},
year = {2001}
}
@book{Barski2010,
author = {Barski, Conrad},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Barski - 2010 - The Land of Lisp.pdf:pdf},
publisher = {NoStrach Press},
title = {{The Land of Lisp}},
year = {2010}
}
@inproceedings{me10c,
author = {Kocaguneli, Ekrem and Gay, Gregory and Menzies, Tim and Yang, Ye and Keung, Jacky W},
booktitle = {IEEE ASE'10},
title = {{When to Use Data from Other Projects for Effort Estimation}},
year = {2010}
}
@inproceedings{minku12b,
author = {Minku, Leandro L and Yao, Xin},
booktitle = {Proceedings of the 8th International Conference on Predictive Models in Software Engineering},
file = {:Users/timm/svns/doc/transfer/12minku.pdf:pdf},
isbn = {978-1-4503-1241-7},
pages = {69--78},
series = {PROMISE '12},
title = {{Can cross-company data improve performance in software effort estimation?}},
year = {2012}
}
@article{deKleer86d,
author = {DeKleer, J and Brown, J S},
journal = {Artificial Intelligence},
pages = {33--61},
title = {{Theories of Causal Ordering}},
volume = {29},
year = {1986}
}
@book{gleick87,
author = {Gleick, J},
pages = {352},
publisher = {Cardinal},
title = {{Chaos}},
year = {1987}
}
@article{me12d,
author = {Menzies, Tim and Butcher, Andrew and Cok, David},
doi = {http://dx.doi.org/10.1109/TSE.2012.83},
journal = {Software Engineering, IEEE Transactions on},
number = {6},
pages = {822 -- 834},
title = {{Local versus Global Lessons for Defect Prediction and Effort Estimation}},
volume = {39},
year = {2013}
}
@article{Belli1990,
author = {Belli, F},
file = {:Users/timm/svns/doc/ooprolog/p1153-schmidt.pdf:pdf},
isbn = {0897913728},
journal = {Brand},
pages = {1153--1161},
title = {{An Extension of PROLOG for Object-Oriented in Logic Programming}},
year = {1990}
}
@article{poole93,
author = {Poole, D},
journal = {Artificial Intelligence},
number = {1},
pages = {81--129},
title = {{Probabilistic Horn Abduction and Bayesian Networks}},
volume = {64},
year = {1993}
}
@inproceedings{cohen97,
author = {Cohen, William W and Devanbu, Prem},
booktitle = {Proc. 14th International Conference on Machine Learning},
pages = {66--74},
publisher = {Morgan Kaufmann},
title = {{A comparative study of inductive logic programming methods for software fault prediction}},
year = {1997}
}
@book{pressman04,
author = {Pressman, R S},
publisher = {McGraw-Hill},
title = {{Software Engineering: A Practitioner's Approach (6th edition)}},
year = {2004}
}
@misc{me99i,
annote = {NASA IVV Facility Technical Report},
author = {Menzies, T and Houle, M E and Powell, J},
title = {{RAPTURE/SP2: Efficient Testing of Temporal Properties Without Search Space Explosion}},
year = {1999}
}
@inproceedings{Bavota2010,
abstract = {The structure of a software system has a major impact on its maintainability. To improve maintainability, software systems are usually organized into subsystems using the constructs of packages or modules. However, during software evolution the structure of the system undergoes continuous modifications, drifting away from its original design, often reducing its quality. In this paper we propose an approach for helping maintainers to improve the quality of software modularization. The proposed approach analyzes the (structural and semantic) relationships between classes in a package identifying chains of strongly related classes. The identified chains are used to define new packages with higher cohesion than the original package. The proposed approach has been empirical evaluated through a case study. The context of the study is represented by an open source system, JHotDraw, and two software systems developed by teams of students at the University of Salerno. The analysis of the results reveals that the proposed approach generates meaningful re-modularization of the studied systems, which can lead to higher quality.},
address = {Beverly, MA, USA},
annote = {Laura. Fixed on 06/16/2012},
author = {{Bavota Gabriele}, De Lucia Andrea Marcus Andrian and Oliveto, Rocco},
booktitle = {17th IEEE Working Conference on Reverse Engineering (WCRE'10)},
keywords = {cohesion coupling refactoring semantic\_information},
pages = {195--204},
title = {{Software Re-Modularization Based on Structural and Semantic Metrics}}
}
@book{lewis93,
author = {Lewis, C and Rieman, J},
publisher = {University of Colorado},
title = {{Task-Centred User Interface Design}},
year = {1993}
}
@article{Das2011,
author = {Das, Swagatam and Suganthan, Ponnuthurai Nagaratnam},
doi = {10.1109/TEVC.2010.2059031},
file = {:Users/timm/svns/doc/11de-state-of-the-art.pdf:pdf},
isbn = {1089-778X VO - 15},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
number = {1},
pages = {4--31},
title = {{Differential evolution: A survey of the state-of-the-art}},
volume = {15},
year = {2011}
}
@inproceedings{me03h,
author = {Chiang, E and Menzies, T},
booktitle = {Prosim '03},
title = {{Position Paper: Summary of simulations for Very Early Lifecycle Quality Evaluations}},
year = {2003}
}
@article{rum94,
author = {Rumbaugh, J},
journal = {JOOP},
pages = {8--23},
title = {{\{G\}etting \{S\}tarted: \{U\}sing \{U\}se \{C\}ases to \{C\}apture \{R\}equirements}},
year = {1994}
}
@article{Adomavicius2005,
author = {Adomavicius, G. and Tuzhilin, a.},
doi = {10.1109/TKDE.2005.99},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Adomavicius, Tuzhilin - 2005 - Toward the next generation of recommender systems a survey of the state-of-the-art and possible extension.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = jun,
number = {6},
pages = {734--749},
title = {{Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1423975},
volume = {17},
year = {2005}
}
@article{Hand2006,
archivePrefix = {arXiv},
arxivId = {arXiv:math/0606441v1},
author = {Hand, David J.},
doi = {10.1214/088342306000000060},
eprint = {0606441v1},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Hand - 2006 - Classifier Technology and the Illusion of Progress.pdf:pdf},
issn = {0883-4237},
journal = {Statistical Science},
keywords = {and phrases,empirical com-,error rate,flat maximum effect,lectivity bias,misclas-,population drift,principle of parsimony,problem uncertainty,se-,sification rate,simplicity,supervised classification},
month = feb,
number = {1},
pages = {1--14},
primaryClass = {arXiv:math},
title = {{Classifier Technology and the Illusion of Progress}},
url = {http://projecteuclid.org/Dienst/getRecord?id=euclid.ss/1149600839/},
volume = {21},
year = {2006}
}
@book{Simon1969a,
abstract = {Continuing his exploration of the organization of complexity and the science of design, this new edition of Herbert Simon's classic work on artificial intelligence adds a chapter that sorts out the current themes and tools - chaos, adaptive systems, genetic algorithms - for analyzing complexity and complex systems. There are updates throughout the book as well. These take into account important advances in cognitive psychology and the science of design while confirming and extending the book's basic thesis: that a physical symbol system has the necessary and sufficient means for intelligent action. The chapter "Economic Reality" has also been revised to reflect a change in emphasis in Simon's thinking about the respective roles of organizations and markets in economic systems.},
author = {Simon, Ha},
booktitle = {Cambridge, MA},
doi = {10.1016/S0898-1221(97)82941-0},
file = {:Users/timm/svns/doc/96Herbert Simon - Sciences\_of\_the\_Artificial.pdf:pdf},
isbn = {0262691914},
issn = {08981221},
pages = {123},
pmid = {4470018},
title = {{The sciences of the artiï¬cial}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:The+Sciences+of+the+Artificial\#0},
volume = {1},
year = {1969}
}
@inproceedings{me01h,
author = {Menzies, T and Hu, Y},
booktitle = {Agent Technology from a Formal Perspective},
editor = {Rouff, C and Hinchey, M and Rash, J and Truszkowski, W and Gordon-Spears, D},
isbn = {1-85233-947-0},
publisher = {Springer},
title = {{Agents in a Wild World}},
year = {2006}
}
@article{me99m,
author = {Menzies, T and van Harmelen, Frank},
doi = {10.1006/ijhc.1999.0336},
issn = {1071-5819},
journal = {International Journal of HumanComputer Studies special issue on evaluation of Knowledge Engineering Techniques},
month = oct,
number = {4},
pages = {717--727},
title = {{Editorial: Evaluating Knowledge Engineering Techniques}},
volume = {51},
year = {1999}
}
@phdthesis{greenwald06,
annote = {Available from $\backslash$url\{http://unbox.org/wisp/var/jeremy/Greenwald06Thesis.pdf\}},
author = {Greenwald, J},
school = {Computer Science, Portland State University},
title = {{A Novel Metaheuristic Search Technique: Iterative Treatment Learning}},
year = {2007}
}
@article{shepperd12a,
author = {Shepperd, Martin J and MacDonell, Steven G},
journal = {Information \{\&\} Software Technology},
number = {8},
pages = {820--827},
title = {{Evaluating prediction systems in software project estimation}},
volume = {54},
year = {2012}
}
@article{shn08,
author = {Shneiderman, B},
journal = {Science},
month = mar,
number = {7},
pages = {1349--1350},
title = {{Science 2.0}},
volume = {319},
year = {2008}
}
@article{nilsson91,
author = {Nilsson, N J},
journal = {Artificial Intelligence},
pages = {31--56},
title = {{Logic and Artificial Intelligence}},
volume = {47},
year = {1991}
}
@inproceedings{fea02a,
author = {Feather, M S and Menzies, T},
booktitle = {IEEE Joint Conference On Requirements Engineering ICRE'02 and RE'02, 9-13th September, University of Essen, Germany},
title = {{Converging on the Optimal Attainment of Requirements}},
year = {2002}
}
@article{Dy2004a,
author = {Dy, Jennifer G. and Brodley, Carla E.},
file = {:Users/timm/svns/doc/04dy.pdf:pdf},
issn = {1536-1241},
journal = {Journal of Macine Learning Research},
keywords = {clustering,expectation-maximization,feature selection,unsupervised learning},
pages = {845--889},
title = {{Feature Selection for Unsupervised Learning}},
volume = {5},
year = {2004}
}
@inproceedings{cox86,
author = {Cox, P T and Pietrzykowski, T},
booktitle = {8th International Conference on Automated Deduction},
pages = {608--621},
publisher = {Springer-Verlag},
title = {{Causes for Events: Their Computation and Applications}},
year = {1986}
}
@inproceedings{jiang08a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08transform.pdf\}},
author = {Jiang, Y and Cukic, B and Menzies, T},
booktitle = {Defects 2008},
title = {{Does Transformation Help?}},
year = {2008}
}
@article{jorgensen05a,
author = {Jorgensen, M},
journal = {IEEE Software},
number = {3},
title = {{Practical Guidelines for Expert Judgment Based-Software-Effort Estimation}},
volume = {22},
year = {2005}
}
@book{harrell00,
author = {Harrell, H and Ghosh, L and Bowden, S},
publisher = {McGraw-Hill},
title = {{Simulation Using ProModel}},
year = {2000}
}
@misc{boehm09a,
annote = {Keynote address, PROMISE'09},
author = {Boehm, B},
title = {{No Title}},
year = {2009}
}
@book{mitchell97,
author = {Mitchell, T},
publisher = {McGraw-Hill},
title = {{Machine Learning}},
year = {1997}
}
@article{me03e,
author = {Menzies, T},
journal = {IEEE Intelligent Systems},
title = {{21\^{}\{st\} century \{AI\}: proud, not smug}},
year = {2003}
}
@article{demillo78,
author = {DeMillo, R A and Lipton, R J and Sayward, F G},
journal = {Computer},
keywords = {mutation,testing},
number = {4},
pages = {34--41},
title = {{Hints on Test Data Selection: Help for the Practicing Programmer}},
volume = {11},
year = {1978}
}
@article{Prelic2006,
abstract = {MOTIVATION: In recent years, there have been various efforts to overcome the limitations of standard clustering approaches for the analysis of gene expression data by grouping genes and samples simultaneously. The underlying concept, which is often referred to as biclustering, allows to identify sets of genes sharing compatible expression patterns across subsets of samples, and its usefulness has been demonstrated for different organisms and datasets. Several biclustering methods have been proposed in the literature; however, it is not clear how the different techniques compare with each other with respect to the biological relevance of the clusters as well as with other characteristics such as robustness and sensitivity to noise. Accordingly, no guidelines concerning the choice of the biclustering method are currently available. RESULTS: First, this paper provides a methodology for comparing and validating biclustering methods that includes a simple binary reference model. Although this model captures the essential features of most biclustering approaches, it is still simple enough to exactly determine all optimal groupings; to this end, we propose a fast divide-and-conquer algorithm (Bimax). Second, we evaluate the performance of five salient biclustering algorithms together with the reference model and a hierarchical clustering method on various synthetic and real datasets for Saccharomyces cerevisiae and Arabidopsis thaliana. The comparison reveals that (1) biclustering in general has advantages over a conventional hierarchical clustering approach, (2) there are considerable performance differences between the tested methods and (3) already the simple reference model delivers relevant patterns within all considered settings.},
author = {Preli\'{c}, Amela and Bleuler, Stefan and Zimmermann, Philip and Wille, Anja and B\"{u}hlmann, Peter and Gruissem, Wilhelm and Hennig, Lars and Thiele, Lothar and Zitzler, Eckart},
doi = {10.1093/bioinformatics/btl060},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/Prelic06.pdf:pdf},
isbn = {1460-2059},
issn = {13674803},
journal = {Bioinformatics},
number = {9},
pages = {1122--1129},
pmid = {16500941},
title = {{A systematic comparison and evaluation of biclustering methods for gene expression data}},
volume = {22},
year = {2006}
}
@article{pong83,
author = {Pong, M C and Ng, N},
journal = {Software Practice Experience},
number = {9},
pages = {847--855},
title = {{PIGS - A System for Programming with Interactive Graphical Support}},
volume = {13},
year = {1983}
}
@article{me10d,
author = {Menzies, Tim and Jalali, Omid and Hihn, Jairus and Baker, Dan and Lum, Karen},
journal = {Automated Software Engineering},
month = dec,
number = {4},
title = {{Stable Rankings for Different Effort Models}},
year = {2010}
}
@article{harman01,
author = {Harman, M and Jones, B F},
journal = {Journal of Information and Software Technology},
month = dec,
pages = {833--839},
title = {{Search-based software engineering}},
volume = {43},
year = {2001}
}
@misc{bax95,
annote = {Available from $\backslash$url\{http://citeseer.ist.psu.edu/baxter95mdl.html\}},
author = {Baxter, R A and Oliver, J J},
institution = {Computer Science, Monash University, Melbourne, Australia},
month = mar,
title = {{\{MDL\} and \{MML\}: Similarities and Differences}},
year = {1995}
}
@article{heitmeyer96automated,
author = {Heitmeyer, C L and Jeffords, R D and Labaw, B G},
journal = {ACM Transactions on Software Engineering and Methodology},
month = jul,
number = {3},
pages = {231--261},
publisher = {ACM Press},
title = {{Automated Consistency Checking of Requirements Specifications}},
volume = {5},
year = {1996}
}
@misc{aranda11,
annote = {Available from $\backslash$url\{http://goo.gl/Tfjpc\}},
author = {{Jorge Aranda}, Margaret-Anne Storey and Damian, Daniela and Petre, Marian and Wilson., Greg},
title = {{How do practitioners perceive software engineering research?}}
}
@misc{me01c,
author = {Bonnett, Alastair},
isbn = {0130193240, 9780130193247},
pages = {116},
title = {{How to argue}},
year = {2001}
}
@inproceedings{leake93,
author = {Leake, D B},
booktitle = {\{IJCAI\} '93},
pages = {24--29},
title = {{Focusing \{C\}onstruction and \{S\}election of \{A\}bductive \{H\}ypotheses}},
year = {1993}
}
@article{hamilton91,
author = {{D. Hamilton K. Kelley}, C Culbert},
journal = {Expert Systems with Applications},
pages = {403--410},
title = {{State-of-the-Practice in Knowledge-based System Verification and Validation.}},
volume = {3},
year = {1991}
}
@article{Giannellaa,
archivePrefix = {arXiv},
arxivId = {arXiv:0911.2942v1},
author = {Giannella, Chris R and Liu, Kun and Kargupta, Hillol and Member, Senior},
eprint = {arXiv:0911.2942v1},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Giannella et al. - Unknown - On the Privacy of Euclidean Distance Preserving Data Perturbation.pdf:pdf},
journal = {Science},
pages = {1--46},
title = {{On the Privacy of Euclidean Distance Preserving Data Perturbation}}
}
@inproceedings{Xiao2007a,
author = {Xiao, Lurong and Hung, E.},
booktitle = {Computational Intelligence and Data Mining, 2007. CIDM 2007. IEEE Symposium on},
file = {:Users/timm/svns/doc/distanceBetweenClusters07.pdf:pdf},
number = {i},
pages = {10--17},
publisher = {IEEE},
title = {{An efficient distance calculation method for uncertain objects}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4221270},
year = {2007}
}
@article{Li2005,
abstract = {Clustering is the problem of identifying the distribution of patterns and intrinsic correlations in large data sets by partitioning the data points into similarity classes. This paper studies the problem of clustering binary data. This is the case for market basket datasets where the transactions contain items and for document datasets where the documents contain âbag of wordsâ. The contribution of the paper is three-fold. First a general binary data clustering model is presented. The model treats the data and features equally, based on their symmetric association relations, and explicitly describes the data assignments as well as feature assignments. We character- ize several variations with different optimization procedures for the general model. Second, we also establish the connections between our clustering model with other existing clustering methods. Third, we also discuss the problem for determining the number of clusters for binary clustering. Experimental results show the effectiveness of the proposed clustering model.},
author = {Li, Tao},
doi = {10.1145/1081870.1081894},
file = {:Users/timm/svns/doc/erin/references/BinarySparseClustering/li05.pdf:pdf},
isbn = {159593135X},
issn = {159593135X},
journal = {Proceeding of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining - KDD '05},
keywords = {binary data,clustering,general model,matrix approximation},
pages = {188},
title = {{A general model for clustering binary data}},
url = {http://portal.acm.org/citation.cfm?doid=1081870.1081894},
year = {2005}
}
@inproceedings{me02d,
abstract = {Formal analysis of software is a powerful analysis tool, but can be too costly. Random search of formal models can reduce that cost, but is theoretically incomplete. However, random search of finite-state machines exhibits an early saturation effect, i.e., random search quickly yields all that can be found, even after a much longer search. Hence, we avoid the theoretical problem of incompleteness, provided that testing continues until after the saturation point. Such a random search is rapid, consumes little memory, is simple to implement, and can handle very large formal models (in one experiment shown here, over 10<sup>178</sup> states).},
author = {Menzies, T. and Owen, D. and Cukic, B.},
booktitle = {13th International Symposium on Software Reliability Engineering, 2002. Proceedings.},
doi = {10.1109/ISSRE.2002.1173208},
isbn = {0-7695-1763-3},
issn = {1071-9458},
title = {{Saturation effects in testing of formal models}},
year = {2002}
}
@inproceedings{turhan08,
abstract = {Several research in defect prediction focus on building models with available local data (i.e. within company predictors). To employ these models, a company should have a data repository, where project metrics and defect information from past projects are stored. However, few companies apply this practice. In a recent work, we have shown that cross company data can be used for building predictors with the cost of increased false alarms. Thus, we argued that the practical application of cross-company predictors is limited to mission critical projects and companies should starve for local data. In this paper, we show that nearest neighbor (NN) sampling of cross-company data removes the increased false alarm rates. We conclude that cross company defect predictors can be practical tools with NN sampling, yet local predictors are still the best and companies should keep starving for local data. Copyright 2008 ACM.},
annote = {hW},
author = {Turhan, B and Bener, a and Menzies, T},
booktitle = {DEFECTS'08: 2008 International Symposium on Software Testing and Analysis - Proceedings of the 2008 Workshop on Defects in Large Software Systems 2008, DEFECTS'08},
doi = {10.1145/1390817.1390824},
isbn = {9781605580517 (ISBN)},
keywords = {Alarm systems,Building models,Computer software,Computer software selection and evaluation,Data repositories,Defect predictions,Defects,Errors,False Alarm rates,False alarms,Local datums,Mission critical,Nearest neighbors,Project metrics,Software testing,Technical presentations},
pages = {26},
title = {{Nearest neighbor sampling for cross company defect predictors (Abstract only)}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-57349150689\&partnerID=40\&md5=49e517a851134cb3ea7c5addee82d5e6},
year = {2008}
}
@misc{schmann07,
author = {Schumann, J and Gundy-Burlet, K and Menzies, T},
institution = {Computer Science, West Virginia University},
title = {{Learning Predictors \& Controllers for Software Functional Requirements}},
year = {2007}
}
@article{Ona,
author = {On, Focus},
file = {:Users/timm/svns/doc/HowRareIsThat.pdf:pdf},
journal = {Search},
title = {{How Rare is that Fingerprint ? Computational Forensics Provides the First Clues}}
}
@misc{boehm09a,
annote = {Keynote address, PROMISE'09},
author = {Boehm, B},
title = {{No Title}},
year = {2009}
}
@inproceedings{crawford92,
author = {Crawford, J and Farquhar, A and Kuipers, B},
booktitle = {Recent Advances in Qualitative Physics},
editor = {Faltings, B and Struss, P},
publisher = {The MIT Press},
title = {{QPC: A Compiler from Physical Models into Qualitative Differential Equations}},
year = {1992}
}
@article{Neubauer2009a,
author = {Neubauer, Thomas and Ekelhart, Andreas},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Neubauer, Ekelhart - 2009 - An Evaluation of Technologies for the Pseudonymization of Medical Data.pdf:pdf},
journal = {System},
keywords = {Health Care,Privacy,Security,e-health,pseudonymization},
pages = {857--858},
title = {{An Evaluation of Technologies for the Pseudonymization of Medical Data}},
year = {2009}
}
@article{boehm88,
author = {Boehm, B and Papaccio, P},
journal = {IEEE Trans. on Software Engineering},
month = oct,
number = {10},
pages = {1462--1477},
title = {{Understanding and controlling software costs}},
volume = {14},
year = {1988}
}
@incollection{stamper94,
author = {Stamper, R},
booktitle = {Requirements Engineering: Social and Technical Issues},
editor = {Jirotka, M and Goguen, J A},
pages = {107--139},
publisher = {Academic Press},
title = {{Social Norms in Requirements Analysis: an outline of MEASUR}},
year = {1994}
}
@inproceedings{hayes05,
author = {Hayes, J H and Chemannoor, I and Surisetty, V and Andrews, A},
booktitle = {Proceedings of European Dependable Computing Conference (EDCC), Budapest, Hungary},
month = apr,
title = {{Fault Links:Exploring the Relationship Between Module and Fault Types}},
year = {2005}
}
@article{ck94,
author = {Chidamber, S R and Kemerer, C F},
journal = {Software Engineering, IEEE Transactions on},
month = jun,
number = {6},
pages = {476--493},
title = {{A metrics suite for object oriented design}},
volume = {20},
year = {1994}
}
@article{pendharkar05,
address = {Piscataway, NJ, USA},
author = {Pendharkar, Parag C and Subramanian, Girish H and Rodger, James A},
doi = {http://dx.doi.org/10.1109/TSE.2005.75},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {7},
pages = {615--624},
publisher = {IEEE Press},
title = {{A Probabilistic Model for Predicting Software Development Effort}},
volume = {31},
year = {2005}
}
@incollection{iwasaki89,
author = {Iwasaki, Y},
booktitle = {The Handbook of Artificial Intelligence},
editor = {{A. Barr}, P R Cohen and Feigenbaum, E A},
pages = {323--413},
publisher = {Addison Wesley},
title = {{Qualitative Physics}},
volume = {4},
year = {1989}
}
@article{Saclay,
author = {Saclay, Inria and Sud, U Paris and Orsay, F- and Schoenauer, Marc and Sebag, Mich\`{e}le},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Saclay et al. - Unknown - A Mono Surrogate for Multiobjective Optimization.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {multiobjective optimization,support vec-,surrogate models},
pages = {471--478},
title = {{A Mono Surrogate for Multiobjective Optimization}}
}
@article{Garvey1995,
author = {Garvey, Paul R.},
doi = {10.1080/08823871.1995.10462296},
file = {:Users/timm/svns/doc/cost/95Garvey.pdf:pdf},
issn = {0882-3871},
journal = {The Journal of Cost Analysis},
number = {1},
pages = {156--200},
title = {{Garvey: A Family of Joint Probability Models for Cost and Schedule Uncertainties}},
volume = {12},
year = {1995}
}
@article{me03e,
author = {Menzies, T},
journal = {IEEE Intelligent Systems},
number = {3},
pages = {18--24},
title = {{21\{\^{}\{st\}\} Century $\backslash$uppercase\{AI\}: Proud, Not Smug}},
volume = {18},
year = {2003}
}
@inproceedings{iwasaki95,
author = {Iwasaki, Y},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and Narayanan, H and Chandrasekaran, B},
pages = {657--668},
publisher = {MIT Press},
title = {{Problem Solving with Diagrams}},
year = {1995}
}
@inproceedings{lum06,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06ispa.pdf\}},
author = {Lum, K and Hihn, J and Menzies, T},
booktitle = {ISPA Conference Proceedings},
title = {{Sudies in Software Cost Model Behavior: Do we Really Understand Cost Model Performance?}},
year = {2006}
}
@article{Zhao2004,
author = {Zhao, H.},
doi = {10.1109/TKDE.2004.3},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zhao - 2004 - Constrained cascade generalization of decision trees.pdf:pdf;:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zhao - 2004 - Constrained cascade generalization of decision trees(2).pdf:pdf},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = jun,
number = {1},
pages = {1175--739},
title = {{Constrained cascade generalization of decision trees}},
volume = {2},
year = {2004}
}
@inproceedings{czer11,
author = {Czerwonka, J and Das, R and Nagappan, N and Tarvo, A and Teterev, A},
booktitle = {Software Testing, Verification and Validation (ICST), 2011 IEEE Fourth International Conference on},
month = mar,
pages = {357--366},
title = {{CRANE: Failure Prediction, Change Analysis and Test Prioritization in Practice -- Experiences from Windows}},
year = {2011}
}
@inproceedings{webb00,
author = {Webb, G},
booktitle = {Proceeding of KDD-2000 Boston, MA},
title = {{Efficient search for association rules}},
year = {2000}
}
@article{fikes72,
author = {Fikes, Richard E and Hart, Peter E and Nilsson, Nils J},
journal = {Artificial Intelligence},
pages = {251--288},
title = {{Learning and Executing Generalized Robot Plans}},
volume = {3},
year = {1972}
}
@article{Du2003,
author = {Du, Wenliang and Zhan, Zhijun and Science, Computer},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Du, Zhan, Science - 2003 - Using Randomized Response Techniques for Privacy-Preserving Data Mining.pdf:pdf},
journal = {Building},
keywords = {data mining,decision tree,privacy,security},
pages = {505--510},
title = {{Using Randomized Response Techniques for Privacy-Preserving Data Mining}},
year = {2003}
}
@inproceedings{deMoura08,
author = {{De Moura}, Leonardo and Bj\o rner, Nikolaj},
booktitle = {Proceedings of the Theory and Practice of Software, 14th International Conference on Tools and Algorithms for the Construction and Analysis of Systems},
series = {TACAS'08/ETAPS'08},
title = {{Z3: An Efficient SMT Solver}},
year = {2008}
}
@inproceedings{abrahamsson07,
author = {Abrahamsson, P and Moser, R and Pedrycz, W and Sillitti, A and Succi, G},
booktitle = {First International Symposium on Empirical Software Engineering and Measurement (ESEM 2007)},
pages = {344--353},
title = {{Effort Prediction in Iterative Software Development Processes -- Incremental Versus Global Prediction Models}},
year = {2007}
}
@misc{ying02,
author = {Hu, Y},
title = {{Treatment learning}},
year = {2002}
}
@book{Simon1969,
abstract = {Continuing his exploration of the organization of complexity and the science of design, this new edition of Herbert Simon's classic work on artificial intelligence adds a chapter that sorts out the current themes and tools - chaos, adaptive systems, genetic algorithms - for analyzing complexity and complex systems. There are updates throughout the book as well. These take into account important advances in cognitive psychology and the science of design while confirming and extending the book's basic thesis: that a physical symbol system has the necessary and sufficient means for intelligent action. The chapter "Economic Reality" has also been revised to reflect a change in emphasis in Simon's thinking about the respective roles of organizations and markets in economic systems.},
author = {Simon, Ha},
booktitle = {Cambridge, MA},
doi = {10.1016/S0898-1221(97)82941-0},
file = {:Users/timm/svns/doc/96Herbert Simon - Sciences\_of\_the\_Artificial.pdf:pdf},
isbn = {0262691914},
issn = {08981221},
pages = {123},
pmid = {4470018},
title = {{The sciences of the artiï¬cial}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:The+Sciences+of+the+Artificial\#0},
volume = {1},
year = {1969}
}
@misc{shaw97,
address = {$\backslash$url\{http://Tiger.cpsc.ucalgary.ca/WebGrid/WebGrid.html\}},
author = {Shaw, M},
institution = {Knowledge Systems Institute, University of Calgary},
title = {{WebGrid: a WWW PCP Server}},
year = {1997}
}
@inproceedings{sayyad13c,
author = {Sayyad, Abdel and Ammar, Hany},
booktitle = {RAISE'13, San Fransisco},
month = may,
title = {{Pareto-Optimal Search-Based Software Engineering (POSBSE): A Literature Survey}},
year = {2013}
}
@misc{boehm04,
annote = {Available from $\backslash$url\{http://ase-conferences.org/ase/past/ase2004/download/KeynoteBoehm.pdf\}},
author = {Boehm, B},
title = {{Automating Value-Based Software Engineering, \{K\}eynote address to \{IEEE\} \{ASE\}}},
year = {2004}
}
@article{hall00,
author = {Hall, G A and Munson, J C},
journal = {Journal of Systems and Software},
pages = {111--118},
title = {{Software evolution: code delta and code churn}},
year = {2000}
}
@article{Du2008,
author = {Du, Q. and Fowler, J. E.},
doi = {10.1177/1094342007088380},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Du, Fowler - 2008 - Low-Complexity Principal Component Analysis for Hyperspectral Image Compression.pdf:pdf},
issn = {1094-3420},
journal = {International Journal of High Performance Computing Applications},
month = nov,
number = {4},
pages = {438--448},
title = {{Low-Complexity Principal Component Analysis for Hyperspectral Image Compression}},
url = {http://hpc.sagepub.com/cgi/doi/10.1177/1094342007088380},
volume = {22},
year = {2008}
}
@article{Voinea2007,
abstract = {In this article we describe an ongoing effort to integrate information visualization techniques into the process of configuration management for software systems. Our focus is to help software engineers manage the evolution of large and complex software systems by offering them effective and efficient ways to query and assess system properties using visual techniques. To this end, we combine several techniques from different domains, as follows. First, we construct an infrastructure that allows generic querying and data mining of different types of software repositories such as CVS and Subversion. Using this infrastructure, we construct several models of the software source code evolution at different levels of detail, ranging from project and package up to function and code line. Second, we describe a set of views that allow examining the code evolution models at different levels of detail and from different perspectives. We detail three views: the file view shows changes at line level across many versions of a single, or a few, files. The project view shows changes at file level across entire software projects. The decomposition view shows changes at subsystem level across entire projects. We illustrate how the proposed techniques, which we implemented in a fully operational toolset, have been used to answer non-trivial questions on several real-world, industry-size software projects. Our work is at the crossroads of applied software engineering (SE) and information visualization, as our toolset aims to tightly integrate the methods promoted by the InfoVis field into the SE practice.},
author = {Voinea, Lucian and Telea, Alexandru},
doi = {10.1016/j.cag.2007.01.031},
file = {:Users/timm/svns/doc/xplain/07Voinea.pdf:pdf},
isbn = {0097-8493},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {data mining,maintenance,software engineering,software evolution,software visualization},
number = {3},
pages = {410--428},
title = {{Visual data mining and analysis of software repositories}},
volume = {31},
year = {2007}
}
@misc{ctc86,
annote = {Vol. 2, No. 3},
howpublished = {Control Theory and Advanced Technology},
month = sep,
title = {{Special Issue on Expert Systems}},
year = {1986}
}
@misc{me00c,
author = {Menzies, Tim and Cukic, Bojan and Singh, Harhsinder},
month = apr,
title = {{Agents Talking Faster}},
year = {2000}
}
@inproceedings{whittle06,
author = {Whittle, J and Jayaraman, P},
booktitle = {IEEE International Conference on Requirements Engineering (RE2006)},
title = {{Generating Hierarchical State Machines from Use Case Charts}},
year = {2006}
}
@article{caraca00,
annote = {To appear.},
author = {Caraca-Valente, J P and Gonzalez, L and Morant, J L and Pozas, J},
journal = {International Journal of Human-Computer Studies},
title = {{Knowledge-based Systems Validation: When to Stop Running Test Cases}},
year = {2000}
}
@article{emse12,
author = {Menzies, Tim and Shepperd, Martin},
journal = {Empirical Software Engineering},
number = {1},
pages = {1--17},
title = {{Special issue on repeatable results in software engineering prediction}},
volume = {17},
year = {2012}
}
@article{Dy2004,
author = {Dy, J G and Brodley, C E},
doi = {10.1016/j.patrec.2014.11.006},
file = {:Users/timm/svns/doc/04dyUnsupervisedDiscretization.pdf:pdf},
isbn = {1532-4435},
issn = {01678655},
journal = {The Journal of Machine Learning Research},
keywords = {clustering,expectation-maximization,feature selection,unsupervised learning},
pages = {845--889},
title = {{Feature selection for unsupervised learning}},
volume = {5},
year = {2004}
}
@book{kelly55,
author = {Kelly, G A},
publisher = {Norton},
title = {{The Psychology of Persona] Constructs. Volume 1: A Theory of Personality. Volume 2: Clinical Diagnosis and Psychotherapy}},
year = {1955}
}
@article{me99r,
abstract = {So, Iâm to be marooned on a desert island with a handful of books relating to software engineering? I have two immediate, conflicting, reactions. One is to complete the punchline to a music-hall joke: "Second prize, marooned with two handfuls of software engineering books". The other is to think, I take a handful of books on a short train journey, because Iâm terrified of being caught without reading material: how will I last on the island? This wins over the joke, and I start to compose my list. ...},
annote = {Available from $\backslash$url\{http://menzies.us/desert.html\}},
author = {Potts, C.},
doi = {10.1023/A:1008684813868},
issn = {09288910},
journal = {Automated Software Engineering},
number = {4},
pages = {463--466},
title = {{Desert island column}},
volume = {4},
year = {1997}
}
@inproceedings{jureta08,
author = {Jureta, I J and Mylopoulos, J and Faulkner, S},
booktitle = {International Requirements Engineering, 2008. RE '08. 16th IEEE},
pages = {71--80},
title = {{Revisiting the Core Ontology and Problem in Requirements Engineering}},
year = {2008}
}
@article{burgess01,
author = {Burgess, C J and Lefley, Martin},
journal = {Information and Software Technology},
month = dec,
number = {14},
pages = {863--873},
title = {{Can genetic programming improve software effort estimation? A comparative evaluation}},
volume = {43},
year = {2001}
}
@article{Friedman1977a,
author = {Friedman, J.H. and Bentley, J.L. and Finkel, R.A.},
file = {:Users/timm/svns/doc/kdTress76.pdf:pdf},
journal = {ACM Transactions on Mathematical Software (TOMS)},
number = {3},
pages = {209--226},
publisher = {ACM},
title = {{An algorithm for finding best matches in logarithmic expected time}},
url = {http://portal.acm.org/citation.cfm?id=355745},
volume = {3},
year = {1977}
}
@phdthesis{shah93,
author = {Shahsavar, N},
school = {Department of Medical Informatics, Linkoping University, Sweden},
title = {{Design, Implementation and Evaluation of a Knowledge-Based System to Support Ventilator Therapy Management}},
year = {1993}
}
@article{me97a,
abstract = {It is difficult to assess hypothetical models in poorly measured domains such as neuroendocrinology. Without a large library of observations to constrain inference, the execution of such incomplete models implies making assumptions. Mutually exclusive assumptions must be kept in separate worlds. We define a general abductive multiple-worlds engine that assesses such models by (i) generating the worlds and (ii) tests if these worlds contain known behaviour. World generation is constrained via the use of relevant envisionment. We describe QCM, a modeling language for compartmental models that can be processed by this inference engine. This tool has been used to find faults in theories published in international refereed journals; i.e. QCM can detect faults which are invisible to other methods. The generality and computational limits of this approach are discussed. In short, this approach is applicable to any representation that can be compiled into an and-or graph, provided the graphs are not too big or too intricate (fanout < 7).},
author = {Menzies, Tim and Compton, Paul},
doi = {10.1016/S0933-3657(97)00391-6},
issn = {09333657},
journal = {Artificial Intelligence in Medicine},
keywords = {Abduction,Hypothesis testing,Neuroendocrinology,Qualitative reasoning},
number = {2},
pages = {145--175},
pmid = {9201384},
title = {{Applications of abduction: Hypothesis testing of neuroendocrinological qualitative compartmental models}},
volume = {10},
year = {1997}
}
@article{Du2008,
author = {Du, Q and Fowler, J E},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Du, Fowler - 2008 - Low-Complexity Principal Component Analysis for Hyperspectral Image Compression.pdf:pdf},
journal = {International Journal of High Performance Computing Applications},
month = nov,
number = {4},
pages = {438--448},
title = {{Low-Complexity Principal Component Analysis for Hyperspectral Image Compression}},
volume = {22},
year = {2008}
}
@article{turing50,
author = {Turing, Alan M},
journal = {Mind},
month = oct,
pages = {433--460},
title = {{Computing machinery and intelligence}},
year = {1950}
}
@article{hinton92,
author = {Hinton, G E},
journal = {Scientific American},
month = sep,
pages = {144--151},
title = {{How Neural Networks Learn from Experience}},
year = {1992}
}
@article{nus00,
author = {Nuseibeh, B and Easterbrook, S and Russo, A},
journal = {IEEE Computer},
month = apr,
number = {4},
pages = {24--29},
title = {{Leveraging Inconsistency in Software Developoment}},
volume = {33},
year = {2000}
}
@inproceedings{mockus05,
address = {New York, NY, USA},
author = {Mockus, Audris and Zhang, Ping and Li, Paul Luo},
booktitle = {ICSE '05: Proceedings of the 27th international conference on Software engineering},
pages = {225--233},
publisher = {ACM},
title = {{Predictors of customer perceived software quality}},
year = {2005}
}
@article{Rodriguez-Baena2011,
abstract = {Binary datasets represent a compact and simple way to store data about the relationships between a group of objects and their possible properties. In the last few years, different biclustering algorithms have been specially developed to be applied to binary datasets. Several approaches based on matrix factorization, suffix trees or divide-and-conquer techniques have been proposed to extract useful biclusters from binary data, and these approaches provide information about the distribution of patterns and intrinsic correlations.},
author = {Rodriguez-Baena, Domingo S. and Perez-Pulido, Antonio J. and Aguilar-Ruiz, Jesus S.},
doi = {10.1093/bioinformatics/btr464},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/rodriguez-Baena11.pdf:pdf},
isbn = {1367-4811 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
number = {19},
pages = {2738--2745},
pmid = {21824973},
title = {{A biclustering algorithm for extracting bit-patterns from binary datasets}},
volume = {27},
year = {2011}
}
@misc{Coiera99,
annote = {Technical Report, 1999, to appear},
author = {Coiera, E},
institution = {Hewlett-Packard Laboratories},
title = {{Communication under scarcity of resources}},
year = {1999}
}
@article{me08b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ddp.pdf\}},
author = {Feather, M and Cornford, S and Hicks, K and Kiper, J and Menzies, T},
journal = {IEEE Software},
month = may,
title = {{Application of a broad-spectrum quantitative requirements model to early-lifecycle decision making}},
year = {2008}
}
@article{lea94,
author = {Lea, D},
journal = {ACM SIGSOFT Software Engineering Notes},
month = jan,
number = {1},
pages = {39--45},
title = {{Christopher Alexander: An introduction for object-oriented designers}},
volume = {19},
year = {1994}
}
@inproceedings{deb96a,
author = {Debenham, J},
booktitle = {Proceedings 9th International Sympoisum on Methodologies for Intelligent Systems ISMIS '96, Zakopane, Poland, June},
pages = {314--705},
title = {{Knowledge Simplificiation}},
year = {1996}
}
@article{ross85,
author = {Ross, D T},
journal = {IEEE Computer},
pages = {25--34},
title = {{Applications and Extensions of SADT}},
volume = {18},
year = {1985}
}
@article{koc11a,
author = {Kocaguneli, E and Menzies, Tim and Keung, J},
file = {:Users/timm/svns/doc/cost/11comba.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
title = {{On the Value of Ensemble Effort Estimation}},
year = {2012}
}
@article{Razek1992,
author = {Razek, Gottfried},
doi = {10.1145/142181.142199},
file = {:Users/timm/svns/doc/ooprolog/p66-razek.pdf:pdf},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
number = {12},
pages = {66--70},
title = {{Combining objects and relations}},
volume = {27},
year = {1992}
}
@inproceedings{KITCHENHAM2009,
address = {New York, NY, USA},
author = {Kitchenham, Barbara and Mendes, Emilia},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540444},
isbn = {978-1-60558-634-2},
pages = {1--5},
publisher = {ACM},
title = {{Why comparative effort prediction studies may be invalid}},
year = {2009}
}
@misc{menz85,
annote = {School of Econometrics, University of New England},
author = {Menzies, G D},
title = {{An Econometric Analysis of the Dark Figure of Crime}},
year = {1985}
}
@article{searle95,
author = {Searle, J},
journal = {The New York Review of Books},
month = dec,
pages = {83--84},
title = {{'The Mystery of Consciousness': An Exchange}},
year = {1995}
}
@article{mccon00,
author = {McConnell, Steve},
journal = {IEEE Software},
title = {{The Best Influences on Software Engineering}},
year = {2000}
}
@article{shn08,
author = {Shneiderman, B},
journal = {Science},
month = mar,
number = {7},
pages = {1349--1350},
title = {{Science 2.0}},
volume = {319},
year = {2008}
}
@inproceedings{jeff01,
author = {Jeffery, R and Ruhe, M and Wieczorek, I},
booktitle = {Proceedings of the 7th International Software Metrics Symposium},
pages = {16--27},
title = {{Using public domain metrics to estimate software development effort}},
year = {2001}
}
@article{6175912,
author = {Dejaeger, K and Verbraken, T and Baesens, B},
doi = {10.1109/TSE.2012.20},
issn = {0098-5589},
journal = {Software Engineering, IEEE Transactions on},
month = feb,
number = {2},
pages = {237--257},
title = {{Toward Comprehensible Software Fault Prediction Models Using Bayesian Network Classifiers}},
volume = {39},
year = {2013}
}
@inproceedings{hoos00,
author = {Hoos, H H and Boutilier, C},
booktitle = {Proc. of AAAI-2000},
pages = {22--29},
publisher = {MIT Press},
title = {{Solving Combinatorial Auctions using Stochastic Local Search}},
year = {2000}
}
@inproceedings{me03i,
author = {Cornford, S L and Feather, M S and Dunphy, J R and Salcedo, J and Menzies, T},
booktitle = {Proceedings of the IEEE Aerospace Conference, Big Sky, Montana},
title = {{Optimizing Spacecraft Design Optimization Engine Development: Progress and Plans}},
year = {2003}
}
@article{harr99,
author = {Harrison, W and Raffo, D and Settle, J and Eickelmann, N},
journal = {Software Quality Journal},
number = {3},
title = {{Adapting Financial Measures: Making a Business Case for Software Process Improvement}},
volume = {8},
year = {1999}
}
@incollection{linster92a,
author = {Linster, M},
booktitle = {Knowledge Acquisition for Knowledge-Based Systems},
editor = {Aussenac, N and Boy, G and Gaines, B and Linser, M and Ganascia, J.-G. and Kordratoff, Y},
pages = {159--182},
publisher = {Springer-Verlag},
title = {{A review of Sisyphus 91 and 92: Models of Problem-Solving Knowledge}},
year = {1992}
}
@misc{Norvig2011a,
author = {Norvig, Peter},
booktitle = {New York Post},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Norvig - 2011 - The machine age.pdf:pdf},
title = {{The machine age}},
url = {http://www.getcited.org/pub/102527552},
year = {2011}
}
@inproceedings{me90,
author = {Menzies, T J},
booktitle = {Proceedings \{AI\} '90},
title = {{Isa Object Part-of Knowledge Representation?}},
year = {1990}
}
@article{Duchi2006,
author = {Duchi, John C and Mackey, Lester W and Jordan, Michael I},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Duchi, Mackey, Jordan - 2006 - On the Consistency of Ranking Algorithms.pdf:pdf},
journal = {In Practice},
keywords = {ranking, consistency, surrogate loss},
title = {{On the Consistency of Ranking Algorithms}},
year = {2006}
}
@inproceedings{lee92,
author = {Lee, M and Compton, P and Jansen, B},
booktitle = {Proceedings of the Second Japan Knowledge Acquisition for Knowledge-Based Systems Workshop, Kobe, Japan},
pages = {357--370},
title = {{Modelling with Context-Dependant Causality}},
year = {1992}
}
@book{poole98,
author = {Poole, D and Mackworth, A and Goebel, R},
title = {{Computational Intelligence: A Logical Approach}},
year = {1998}
}
@misc{xie09,
author = {Xie, Tao},
title = {{\{NSF\} career award, \{C\}ooperative \{D\}eveloper \{T\}esting with \{T\}est \{I\}ntentions, http://goo.gl/ytw3g}},
year = {2009}
}
@inproceedings{me97q,
author = {Menzies, T J},
booktitle = {Banff KA '98 workshop.},
title = {{Evaluation Issues with Critical Success Metrics}},
year = {1998}
}
@article{weil92,
author = {Wielinga, B J and Schreiber, A T and Breuker, J A},
journal = {Knowledge Acquisition},
pages = {1--162},
title = {{\{KADS\}: a \{M\}odeling \{A\}pproach to \{K\}nowledge \{E\}ngineering.}},
volume = {4},
year = {1992}
}
@inproceedings{WEISS07,
address = {Washington, DC, USA},
author = {Weiss, Cathrin and Premraj, Rahul and Zimmermann, Thomas and Zeller, Andreas},
booktitle = {MSR '07: Proceedings of the Fourth International Workshop on Mining Software Repositories},
doi = {http://dx.doi.org/10.1109/MSR.2007.13},
isbn = {0-7695-2950-X},
pages = {1},
publisher = {IEEE Computer Society},
title = {{How Long Will It Take to Fix This Bug?}},
year = {2007}
}
@article{Boraso1996,
author = {Boraso, M and Montangero, C and Sedehi, H},
file = {:Users/timm/svns/doc/cost/96Boraso.pdf:pdf},
title = {{Software cost estimation: An experimental study of model performances}},
year = {1996}
}
@inproceedings{zhang10,
author = {Zhang, Hongyu and Nelson, Adam and Menzies, Tim},
title = {{Proceedings of PROMISE'10}},
year = {2010}
}
@inproceedings{terps93,
author = {Terpstra, P and van Heijst, G and Wielinga, B and Shadbolt, N},
booktitle = {Second Generation Expert Systems},
editor = {$\backslash$etal, M Davis},
publisher = {Springer-Verlag},
title = {{Knowledge Acquisition Support Through Generalised Directive Models}},
year = {1993}
}
@inproceedings{valerdi11,
annote = {Available from http://goo.gl/Zo9HT},
author = {Valerdi, R},
booktitle = {Incose International Symposium, Denver, USA},
title = {{Convergence of Expert Opinion via the Wideband Delphi Method: An Application in Cost Estimation Models}},
year = {2011}
}
@inproceedings{iwasaki95a,
author = {Iwasaki, Y and Tesseler, S and Law, K H},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and Narayanan, H and Chandrasekaran, B},
pages = {711--729},
publisher = {MIT Press},
title = {{Qualitative Structural Analysis Through Mixed Diagrammatic and Symbolic Reasoning}},
year = {1995}
}
@article{tambe94,
author = {Tambe, M and Rosenbloom, P S},
journal = {Artificial Intelligence},
number = {1},
title = {{Investigating Production System Representations for Non-combinatorial Match}},
volume = {68},
year = {1994}
}
@inproceedings{arcuri11,
author = {Arcuri, A and Briand, L},
booktitle = {ICSE'11},
pages = {1--10},
title = {{A practical guide for using statistical tests to assess randomized algorithms in software engineering}},
year = {2011}
}
@misc{burge96,
author = {Burge, A R},
title = {{Test and Evaluation, Based on Metrics, Measures, Thresholds, and Indicators}},
year = {1996}
}
@article{Barreno2006a,
author = {Barreno, Marco and Joseph, Anthony D and Tygar, J D},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Barreno, Joseph, Tygar - 2006 - Can Machine Learning Be Secure.pdf:pdf},
journal = {Online},
keywords = {adversarial learning,computer networks,computer secu-,game theory,intrusion detection,machine learning,rity,security metrics,spam filters,statistical learning},
number = {March},
title = {{Can Machine Learning Be Secure ?}},
year = {2006}
}
@inproceedings{shaw88,
author = {Shaw, M L G},
booktitle = {Proceedings of the International Conference on Fifth Generation Computer Systems},
pages = {1259--1266},
title = {{Validation in a Knowledge Acquisition System with Multiple Experts}},
year = {1988}
}
@article{haag96,
author = {Haag, Stephen and Raja, M K and Schkade, L L},
journal = {Commun. ACM},
number = {1},
pages = {41--49},
title = {{Quality function deployment usage in software development}},
volume = {39},
year = {1996}
}
@article{Zhou2011,
abstract = {A multiobjective optimization problem involves several conflicting objectives and has a set of Pareto optimal solutions. By evolving a population of solutions, multiobjective evolutionary algorithms (MOEAs) are able to approximate the Pareto optimal set in a single run. MOEAs have attracted a lot of research effort during the last 20 years, and they are still one of the hottest research areas in the field of evolutionary computation. This paper surveys the development of MOEAs primarily during the last eight years. It covers algorithmic frameworks such as decomposition-based MOEAs (MOEA/Ds), memetic MOEAs, coevolutionary MOEAs, selection and offspring reproduction operators, MOEAs with specific search methods, MOEAs for multimodal problems, constraint handling and MOEAs, computationally expensive multiobjective optimization problems (MOPs), dynamic MOPs, noisy MOPs, combinatorial and discrete MOPs, benchmark problems, performance indicators, and applications. In addition, some future research issues are also presented. Â© 2011 Elsevier B.V. All rights reserved.},
author = {Zhou, Aimin and Qu, Bo-Yang and Li, Hui and Zhao, Shi-Zheng and Suganthan, Ponnuthurai Nagaratnam and Zhang, Qingfu},
doi = {10.1016/j.swevo.2011.03.001},
file = {:Users/timm/svns/doc/11deSurvey.pdf:pdf},
isbn = {2210-6502},
issn = {22106502},
journal = {Swarm and Evolutionary Computation},
keywords = {evolutionary multiobjective optimization,multiobjective evolutionary algorithms,multiobjective optimization},
number = {1},
pages = {32--49},
publisher = {Elsevier B.V.},
title = {{Multiobjective evolutionary algorithms: A survey of the state of the art}},
url = {http://dx.doi.org/10.1016/j.swevo.2011.03.001},
volume = {1},
year = {2011}
}
@article{france03,
author = {France, R and Ghosh, S and Song, E and Kim, D},
journal = {IEEE Software},
number = {5},
pages = {52--58},
title = {{A Metamodeling Approach to Pattern-Based Moel Refractoringt}},
volume = {20},
year = {2003}
}
@inproceedings{shepperd07,
author = {Shepperd, M},
booktitle = {International Conference on Software Engineering 2007: Future of Software Engineering},
title = {{Software Project Economics: A Roadmap}},
year = {2007}
}
@inproceedings{thumm09,
address = {Washington, DC, USA},
author = {Thummalapenta, Suresh and Xie, Tao},
booktitle = {ICSE '09: Proceedings of the 31st International Conference on Software Engineering},
doi = {http://dx.doi.org/10.1109/ICSE.2009.5070548},
isbn = {978-1-4244-3453-4},
pages = {496--506},
publisher = {IEEE Computer Society},
title = {{Mining exception-handling rules as sequence association rules}},
year = {2009}
}
@inproceedings{GOKHALE2008,
address = {New York, NY, USA},
author = {Gokhale, Swapna S and Mullen, Robert},
booktitle = {PROMISE '08: Proceedings of the 4th international workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1370788.1370810},
isbn = {978-1-60558-036-4},
pages = {93--100},
publisher = {ACM},
title = {{Software defect repair times: a multiplicative model}},
year = {2008}
}
@article{Storn1996,
abstract = {Differential evolution (DE) has recently proven to be an efficient method for optimizing real-valued multi-modal objective functions. Besides its good convergence properties and suitability for parallelization, DE's main assets are its conceptual simplicity and ease of use. This paper describes several variants of DE and elaborates on the choice of DE's control parameters, which corresponds to the application of fuzzy rules. Finally, the design of a howling removal unit with DE is described to provide a real-world example for DE's applicability},
author = {Storn, Rainer},
doi = {10.1109/NAFIPS.1996.534789},
file = {:Users/timm/svns/doc/96stornDE.pdf:pdf},
isbn = {0-7803-3225-3},
issn = {15205118},
journal = {Proceedings of North American Fuzzy Information Processing},
pages = {519--523},
pmid = {21476566},
title = {{On the usage of differential evolution for function optimization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=534789},
year = {1996}
}
@article{pendharkar05,
address = {Piscataway, NJ, USA},
author = {Pendharkar, Parag C and Subramanian, Girish H and Rodger, James A},
doi = {http://dx.doi.org/10.1109/TSE.2005.75},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {7},
pages = {615--624},
publisher = {IEEE Press},
title = {{A Probabilistic Model for Predicting Software Development Effort}},
volume = {31},
year = {2005}
}
@misc{Misue93,
author = {Misue, K and Sugiyama, K},
institution = {ISIS, Fujitsu Laboratories},
number = {IIAS-RR-93-3E},
title = {{An overview of diagram based idea organizer: D-ABDUCTOR}},
year = {1993}
}
@article{shepperd94,
author = {Shepperd, M and Ince, D C},
journal = {The Journal of Systems and Software},
month = sep,
number = {3},
pages = {197--210},
title = {{A Critique of Three Metrics}},
volume = {26},
year = {1994}
}
@inproceedings{dou95,
author = {Dougherty, James and Kohavi, Ron and Sahami, Mehran},
booktitle = {International Conference on Machine Learning},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Dougherty, Kohavi, Sahami - 1995 - Supervised and unsupervised discretization of continuous features.pdf:pdf},
pages = {194--202},
title = {{Supervised and Unsupervised Discretization of Continuous Features}},
year = {1995}
}
@inproceedings{me03o,
author = {Menzies, Tim and Gunnalan, Rajesh and Appukutty, Kalaivani},
booktitle = {Business},
number = {1},
pages = {1--19},
title = {{Learning Tiny Theories}},
year = {2003}
}
@phdthesis{bredeweg92,
author = {Bredeweg, B},
school = {University of Amsterdam},
title = {{Expertise in Qualitative Prediction of Behaviour}},
year = {1992}
}
@book{winter83,
author = {Winter, Frank},
publisher = {Smithsonian Institution Press},
title = {{Prelude to the Space Age: The Rocket Societies 1924-1940}},
year = {1983}
}
@inproceedings{Basson1993,
annote = {unread},
author = {Basson, H and Haton, M C and Derniame, J C},
booktitle = {Proceedings of Software Quality Management, Elsevier Science and CMP, Southampton},
pages = {807--818},
title = {{Use of quality characteristics graphs for a knowledge-based assistance in software quality management}},
year = {1993}
}
@incollection{leve85,
address = {Palo Alto},
author = {Levesque, H J and Brachman, R J},
booktitle = {Readings in Knowledge Representation},
editor = {Brachmann, R J and Levesque, H J},
isbn = {0-934613-01-X},
pages = {41--70},
publisher = {Morgan Kaufmann},
title = {{A Fundamental Tradeoff in Knowledge Representation and Reasoning (Revised Version)}},
year = {1985}
}
@book{hayes83,
author = {Hayes-Roth, F and Waterman, D A and Lenat, D B},
publisher = {Addison-Wesley},
title = {{Building Expert Systems}},
year = {1983}
}
@article{Fowlkes2004,
author = {Fowlkes, Charless and Belongie, Serge and Chung, Fan and Malik, Jitendra},
file = {:Users/timm/svns/doc/04SpectralNystromClustering.pdf:pdf},
journal = {Analysis},
number = {2},
pages = {214--225},
title = {{Â¨ m Method Spectral Grouping Using the Nystro}},
volume = {26},
year = {2004}
}
@inproceedings{jackson96,
author = {Jackson, D and Jha, S and Damon, C A},
booktitle = {Proc. ACM Conf. on Principles of Programming Languages},
month = jan,
title = {{Faster Checking of Software Specifications By Eliminating Isomorphs}},
year = {1996}
}
@inproceedings{deb98b,
author = {Debenham, J},
booktitle = {Proceedings Tenth International Conference on Software Engineering and Knowledge Engineering SEKE'98, San Francisco, US, June},
title = {{Representing Knowledge Normalisation}},
year = {1998}
}
@inproceedings{me01a,
author = {Menzies, Tim},
booktitle = {AAAI Stanford Spring Symposium on Model-based Validation of AI Systems},
pages = {0--5},
title = {{Average Case Coverage for Validation of AI Systems}},
year = {1995}
}
@incollection{paris89,
author = {Paris, C L},
booktitle = {User Models in Dialog Systems},
editor = {Kobsa, A and Wahlster, W},
pages = {200--232},
publisher = {Springer-Verlag},
title = {{The \{U\}se of \{E\}xplicit \{U\}ser \{M\}odels in a \{G\}eneration \{S\}ystem for \{T\}ailoring \{A\}nswers to the \{U\}ser's \{L\}evel of \{E\}xpertise}},
year = {1989}
}
@inproceedings{lokan06,
author = {Lokan, C and Mendes, E},
booktitle = {The ACM-IEEE International Symposium on Empirical Software Engineering, November 21-22, Rio de Janeiro},
title = {{Cross-company and Single-company Effort Models Using the ISBSG Database: a Further Replicated Study}},
year = {2006}
}
@article{keung12,
author = {Keung, J and Kocaguneli, E and Menzies, T},
journal = {Automated Software Engineering},
month = may,
pages = {1--25},
title = {{Finding conclusion stability for selecting the best effort predictor in software effort estimation}},
year = {2012}
}
@article{harrold98,
author = {Harrold, M J and Jones, J A and Rothermel, G},
journal = {Empirical Software Engineering},
pages = {203--211},
title = {{Empirical Studies of Control Dependence Graph Size for C Programs}},
volume = {3},
year = {1998}
}
@article{Lim2011,
abstract = {Many experiments require a fast and cost-effective method to monitor nucleic acid sequence diversity. Here we describe a method called diversity visualization by endonuclease (DiVE) that allows rapid visualization of sequence diversity of polymerase chain reaction (PCR) products based on DNA hybridization kinetics coupled with the activity of a single-strand specific nuclease. The assay involves only a limited number of steps and can be performed in less than 4 h, including the initial PCR. After PCR, the homoduplex double-stranded DNA (dsDNA) is denatured and reannealed under stringent conditions. During the reannealing process, incubation with S1 nuclease removes single-stranded loops of formed heteroduplexes and the resulting digest is visualized on agarose gel. The sequence diversity is inversely proportional to the band intensities of S1 nuclease surviving dsDNA molecules of expected size. As an example, we employed DiVE to monitor the diversity of panning rounds from a single-framework, semisynthetic single-chain antibody fragment (scFv) phage display library. The results are in good agreement with the observed decrease in diversity in phage display panning rounds toward the selection of monoclonal scFv. We conclude that the DiVE assay allows rapid and cost-effective monitoring of diversities of various nucleotide libraries and proves to be particularly suitable for scaffold-based randomized libraries. Â© 2010 Elsevier Inc. All rights reserved.},
author = {Lim, Theam Soon and Sch\"{u}tze, Tatjana and Lehrach, Hans and Gl\"{o}kler, J\"{o}rn and Konthur, Zolt\'{a}n},
doi = {10.1016/j.ab.2010.12.024},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/LimSchutze11.pdf:pdf},
isbn = {1096-0309 (Electronic)$\backslash$n0003-2697 (Linking)},
issn = {00032697},
journal = {Analytical Biochemistry},
keywords = {Diversity Assay,Mutagenesis,Nucleotide library,Phage display,S1 nuclease},
number = {1},
pages = {16--21},
pmid = {21185254},
publisher = {Elsevier Inc.},
title = {{Diversity visualization by endonuclease: A rapid assay to monitor diverse nucleotide libraries}},
url = {http://dx.doi.org/10.1016/j.ab.2010.12.024},
volume = {411},
year = {2011}
}
@article{beng98,
author = {Benjamins, R and Fensel, D},
journal = {International Journal of Human Computer Studies},
number = {4},
title = {{Special Issue on Problem Solving Methods}},
volume = {49},
year = {1998}
}
@incollection{me95g,
author = {Menzies, T J},
booktitle = {Proceedings of the Melbourne Workshop on Intelligent Decision Support},
publisher = {Department of Information Systems, Monash University, Melbourne},
title = {{Applications of Abduction: Intelligent Decision Support Systems}},
year = {1996}
}
@book{aho88,
author = {Aho, A V and Kernigham, B W and Wienberger, P J},
publisher = {Addison-Wesley},
title = {{The AWK Programming Language}},
year = {1988}
}
@phdthesis{clark97,
annote = {Available from $\backslash$url\{http://sunset.usc.edu/\~{}bkclark/Research/PMAT990406.pdf\}},
author = {Clark, B},
school = {University of Southern California},
title = {{The Effects of Process Maturity on Software Development Effort}},
year = {1997}
}
@inproceedings{me96e,
author = {Menzies, T J},
booktitle = {Proceedings of the 10th Knowledge Acquisition Workshop for Knowledge-Based Systems, Banff,Canada},
title = {{Assessing Responses to Situated Congition}},
year = {1996}
}
@misc{cock00,
address = {Cagliari, Sardinia, Italy},
author = {Cockburn, Alistair and Williams, Laurie},
booktitle = {Proceedings of the First International Conference on Extreme Programming and Flexible Processes in Software Engineering (\{XP2000\})},
month = jun,
title = {{The Costs and Benefits of Pair Programming}},
url = {citeseer.nj.nec.com/cockburn00costs.html},
year = {2000}
}
@book{saaty80,
author = {Saaty, T},
isbn = {0-07-054371-2},
publisher = {McGraw-Hill},
title = {{The Analytic Hierarchy Process: Planning, Priority Setting, Resource Allocation}},
year = {1980}
}
@article{ho94,
author = {Ho, T K and Hull, J J and Srihari, S N},
journal = {IEEE Trans Pattern Analysis and Machine Intelligence},
number = {1},
pages = {66--75},
title = {{Decision combination in multiple classifier systems}},
volume = {16},
year = {1994}
}
@inproceedings{cora10,
author = {Corazza, A and {Di Martino}, S and Ferrucci, F and Gravino, C and Sarro, F and Mendes, E},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering},
pages = {4:1----4:10},
series = {PROMISE '10},
title = {{How effective is Tabu search to configure support vector regression for effort estimation?}},
year = {2010}
}
@misc{me99d,
annote = {In preperation},
author = {Menzies, T and Cukic, B},
howpublished = {NASA/WVU IVV tech report.},
month = mar,
title = {{An Average-Case Model of Reachability}},
year = {1999}
}
@misc{purify,
author = {$\backslash$urlhttp://www.pureatria.com/products, Pure Atria},
title = {{Purify}}
}
@article{Yang2005a,
author = {Yang, Zhiqiang and Zhong, Sheng and Wright, Rebecca N},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Yang, Zhong, Wright - 2005 - Privacy-Preserving Classification of Customer Data without Loss of Accuracy â.pdf:pdf},
journal = {Science},
pages = {1--11},
title = {{Privacy-Preserving Classification of Customer Data without Loss of Accuracy â}},
year = {2005}
}
@article{Li2009a,
author = {Li, Y and Xie, M and T., Goh},
journal = {Empirical Software Engineering},
pages = {603--643},
title = {{A study of the non-linear adjustment for analogy based software cost estimation}},
year = {2009}
}
@article{wernick03,
author = {Wernick, Paul and Scacchi, Walt},
doi = {10.1002/spip.195},
issn = {1099-1670},
journal = {Software Process: Improvement and Practice},
number = {2},
pages = {51--53},
publisher = {John Wiley \& Sons, Ltd.},
title = {{Special Issue on ProSim 2003, The 4th International Workshop on Software Process Simulation and Modeling, Portland, OR, May 2003}},
url = {http://dx.doi.org/10.1002/spip.195},
volume = {9},
year = {2004}
}
@inproceedings{gaines89a,
annote = {Available on-line at $\backslash$url\{http://ksi.cpsc.ucalgary.ca/articles/Induct/ML89/\}},
author = {Gaines, B R},
booktitle = {Proceedings of the Sixth International Workshop on Machine Learning},
pages = {156--159},
title = {{An ounce of knowledge is worth a ton of data: quantitative studies of the trade-off between expertise and data based on statistically well-founded empirical induction}},
year = {1989}
}
@article{Ordonez2001,
abstract = {Clustering is a data mining problem that has received significant
attention by the database community. Data set size, dimensionality and
sparsity have been identified as aspects that make clustering more
difficult. The article introduces a fast algorithm to cluster large
binary data sets where data points have high dimensionality and most of
their coordinates are zero. This is the case with basket data
transactions containing items, that can be represented as sparse binary
vectors with very high dimensionality. An experimental section shows
performance, advantages and limitations of the proposed approach},
author = {Ordonez, C. and Omiecinski, E. and Ezquerra, N.},
doi = {10.1109/ICDM.2001.989586},
file = {:Users/timm/svns/doc/erin/references/BinarySparseClustering/Ordonez01.pdf:pdf},
isbn = {0-7695-1119-8},
issn = {15504786},
journal = {Proceedings 2001 IEEE International Conference on Data Mining},
pages = {1--4},
title = {{A fast algorithm to cluster high dimensional basket data}},
volume = {1},
year = {2001}
}
@article{child06,
annote = {Available from $\backslash$url\{http://projects.cis.ksu.edu/docman/view.php/7/129/CALM-Cadena-IEEE-Computer-Feb-2006.pdf\}},
author = {Childs, A and Greenwald, J and Jung, G and Hoosier, M and Hatcliff, John},
journal = {IEEE Computer},
number = {2},
title = {{CALM and Cadena: Metamodeling for Component-Based Product-Line Development}},
volume = {39},
year = {2006}
}
@inproceedings{me00p,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/00ml.pdf\}},
author = {Menzies, T},
booktitle = {Handbook of Software Engineering and Knowledge Engineering},
isbn = {981-02-4973-X},
month = dec,
publisher = {World-Scientific},
title = {{Practical Machine Learning for Software Engineering and Knowledge Engineering}},
year = {2001}
}
@inproceedings{eickel96,
author = {Eickelmann, N S and Richardson, D J},
booktitle = {Proccesings, International Conference on Software Engineering},
pages = {353--364},
title = {{An Evaluation of Software Test Environment Architectures}},
year = {1996}
}
@article{Ali2006,
author = {Ali, S and Smith, K},
doi = {10.1016/j.asoc.2004.12.002},
file = {:Users/timm/svns/doc/On learning algorithm selection for classification (1).pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing},
keywords = {algorithm selection,classification,no free lunch theorem},
month = jan,
number = {2},
pages = {119--138},
title = {{On learning algorithm selection for classification}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1568494605000049},
volume = {6},
year = {2006}
}
@inproceedings{me03a,
abstract = { When it is impractical to rigorously assess all parts of complex systems, test engineers use defect detectors to focus their limited resources. We define some properties of an ideal defect detector and assess different methods of generating one. In the case study presented here, traditional methods of generating such detectors (e.g. reusing detectors from the literature, linear regression, model trees) were found to be inferior to those found via a PACE analysis.},
author = {Menzies, T. and Stefano, J.D. and Ammar, K. and McGill, K. and Callis, P. and Davis, J. and Chapman, R.},
booktitle = {Proceedings. 5th International Workshop on Enterprise Networking and Computing in Healthcare Industry (IEEE Cat. No.03EX717)},
doi = {10.1109/METRIC.2003.1232459},
isbn = {0-7695-1987-3},
issn = {1530-1435},
title = {{When can we test less?}},
year = {2003}
}
@misc{TheMendeleySupportTeam2010,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
keywords = {Mendeley,how-to,user manual},
pages = {1--14},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2010}
}
@article{krueger92,
author = {Krueger, C W},
journal = {ACM Computing Surveys},
number = {2},
pages = {131--183},
title = {{Software reuse}},
volume = {24},
year = {1992}
}
@inproceedings{mcluskey87,
author = {McCluskey, T L},
booktitle = {IJCAI'87},
pages = {331--333},
title = {{Combining Weak Learning Heuristics in General Problem Solvers}},
year = {1987}
}
@article{pearson1901.,
author = {Pearson, K},
journal = {Philosophical Magazine},
number = {11},
pages = {559--572},
title = {{On Lines and Planes of Closest Fit to Systems of Points in Space}},
volume = {2},
year = {1901}
}
@book{hump95,
author = {Humphrey, W},
publisher = {McGraw Hill},
title = {{A Discipline for Software Engineering}},
year = {1995}
}
@article{Deb2002,
annote = {Stateof the art in GAs},
author = {Deb, K. and Pratap, A. and Agarwal, S. and Meyarivan, T.},
doi = {10.1109/4235.996017},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Deb et al. - 2002 - A fast and elitist multiobjective genetic algorithm NSGA-II.pdf:pdf},
issn = {1089-778X},
journal = {IEEE transactions on evolutionary computation},
keywords = {pareto},
month = apr,
number = {2},
pages = {182--197},
title = {{A fast and elitist multiobjective genetic algorithm: NSGA-II}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?\&amp;arnumber=996017},
volume = {6},
year = {2002}
}
@article{Garvey1997,
author = {Garvey, Paul R. and Taub, Audrey E.},
doi = {10.1080/08823871.1997.10462305},
file = {:Users/timm/svns/doc/cost/97Garvey.pdf:pdf},
issn = {0882-3871},
journal = {The Journal of Cost Analysis},
number = {1},
pages = {3--27},
title = {{A Joint Probability Model for Cost and Schedule Uncertainties}},
volume = {14},
year = {1997}
}
@book{simon72,
author = {Newell, A and Simon, H A},
publisher = {Prentice-Hall Englewood Cliffs, N.J.},
title = {{Human Problem Solving}},
year = {1972}
}
@inproceedings{me00a,
author = {Menzies, T and Sinsel, E and Kurtz, T},
booktitle = {Workshop on Intelligent Software Engineering, an ICSE workshop, and NASA/WVU Software Research Lab, Fairmont, WV, Tech report \# NASA-IVV-99-027},
keywords = {COCOMO-II,Keywords: Machine learning,Monte-Carlo simulations,decision support systems,effort estimation,risk assessment},
title = {{Learning to Reduce Risks with COCOMO-II}},
year = {2000}
}
@incollection{roa95,
annote = {slides},
author = {Roa, A},
title = {{Review of Agent-Oriented Systems: Research Issues and Commercial Applications}},
year = {1995}
}
@article{me12a,
author = {Menzies, Tim and Shepperd, Martin},
journal = {Empirical Software Engineering},
number = {1-2},
pages = {1--17},
title = {{Special issue on repeatable results in software engineering prediction}},
volume = {17},
year = {2012}
}
@inproceedings{lokan13,
author = {Tsunoda, Masateru and Amasaki, Sousuke and Lokan, Chris},
booktitle = {Proceedings of the 2013 International Conference on Software and System Process},
file = {:Users/timm/svns/doc/transfer/13lokan.pdf:pdf},
isbn = {978-1-4503-2062-7},
pages = {10--19},
series = {ICSSP 2013},
title = {{How to treat timing information for software effort estimation?}},
year = {2013}
}
@article{me06d,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06coseekmo.pdf\}},
author = {Menzies, Tim and Chen, Zhihao and Hihn, Jairus and Lum, Karen},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Menzies et al. - 2006 - Selecting Best Practices for Effort Estimation.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
month = nov,
title = {{Selecting Best Practices for Effort Estimation}},
year = {2006}
}
@article{coiera92,
author = {Coiera, E},
journal = {The Knowledge Engineering Review},
pages = {1--23},
title = {{The \{Q\}ualitative \{R\}epresentation of \{P\}hysical \{S\}ystems}},
volume = {7},
year = {1992}
}
@misc{lum05scat,
author = {Lum, Karen},
booktitle = {JPL D-26304},
title = {{Software Cost Analysis Tool User Document}},
year = {2005}
}
@inproceedings{zit02,
author = {Zitzler, Eckart and Laumanns, Marco and Thiele, Lothar},
booktitle = {Evolutionary Methods for Design, Optimisation, and Control},
pages = {95--100},
publisher = {CIMNE, Barcelona, Spain},
title = {{SPEA2: Improving the Strength Pareto Evolutionary Algorithm for Multiobjective Optimization}},
year = {2002}
}
@article{Jiang2011,
abstract = {In recent years, some spectral feature selec- tion methods are proposed to choose those features with high power of preserving sam- ple similarity. However, when there exist lots of irrelevant or noisy features in data, the similarity matrix constructed from all the un-weighted features may be not reli- able, which then misleads existing spectral feature selection methods to select âwrongâ features. To solve this problem, we pro- pose that feature importance should be eval- uated according to their impacts on similar- ity matrix, which means features with high impacts on similarity matrix should be cho- sen as important ones. Since graph Lapla- cian(Luxburg, 2007) is defined on the simi- larity matrix, then the impact of each feature on similarity matrix can be reflected on the change of graph Laplacian, especially on its eigen-system. Based on this point of view, we propose an Eigenvalue Sensitive Crite- ria (EVSC) for feature selection, which aims at seeking those features with high impact on graph Laplacianâs eigenvalues. Empirical analysis demonstrates our proposed method outperforms some traditional spectral feature selection methods. 1.},
author = {Jiang, Yi and Ren, Jiangtao},
file = {:Users/timm/svns/doc/11fssSpectral.pdf:pdf},
isbn = {978-1-4503-0619-5},
journal = {Icml},
pages = {89--96},
title = {{Eigenvalue Sensitive Feature Selection}},
year = {2011}
}
@misc{NSB06,
author = {(U.S.), National Science Board},
keywords = {Scientists Employment United States. Engineers Emp},
publisher = {National Science Foundation, National Science Board},
title = {{Science and engineering indicators 2006}}
}
@inproceedings{me97n,
author = {Menzies, T J},
booktitle = {Banff Knowledge Acquisition workshop, 1998},
title = {{Evaluation Issues for Problem Visual Programming Languages}},
year = {1998}
}
@misc{mendonca99,
author = {Mendonca, M and Sunderhaft, N L},
month = sep,
title = {{Mining Software Engineering Data: A Survey}},
year = {1999}
}
@inproceedings{Hinneburg1998b,
author = {Hinneburg, A. and Keim, D.A.},
file = {:Users/timm/svns/doc/hinneburg98.pdf:pdf},
publisher = {Bibliothek der Universit$\backslash$$\backslash$"at Konstanz},
title = {{An efficient approach to clustering in large multimedia databases with noise}},
url = {http://www.aaai.org/Papers/KDD/1998/KDD98-009.pdf},
year = {1998}
}
@article{Zitzler1998,
abstract = {Since 1985 various evolutionary approaches to multiobjective optimization have been developed, capable of searching for multiple solutions concurrently in a single run. But the few comparative studies of different methods available to date are mostly qualitative and restricted to two approaches. In this paper an extensive, quantitative comparison is presented, applying four multiobjective evolutionary algorithms to an extended 0/1 knapsack problem.},
author = {Zitzler, Eckart and Thiele, Lothar},
doi = {10.1007/BFb0056872},
file = {:Users/timm/svns/doc/98speaa.pdf:pdf},
isbn = {3-540-65078-4},
journal = {Proceedings of the International Conference on Parallel Problem Solving from Nature},
number = {September},
pages = {292--304},
title = {{Multiobjective Optimization Using Evolutionary Algorithms - A Comparative Case Study}},
year = {1998}
}
@inproceedings{gokhale97,
author = {Gokhale, S S and Lyu, M R},
booktitle = {Proceedings of the Third ISSAT International Conference on Reliability and Quality in Design, Anaheim, CA},
month = mar,
pages = {31--36},
title = {{Regression Tree Modeling for the Prediction of Software Quality}},
year = {1997}
}
@inproceedings{curtis00,
author = {Curtis, S A and Mica, J and Nuth, J and Marr, G and Rilee, M and Bhat, M},
booktitle = {International Astronautical Federation, 51st Congress},
month = oct,
title = {{ANTS (Autonomous Nano-Technology Swarm): An Artificial Intelligence Approach to Asteroid Belt Resource Exploration}},
year = {2000}
}
@inproceedings{Gupta2004,
author = {Gupta, Chetan and Grossman, R},
booktitle = {2004 SIAM International Conference on Data Mining},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Gupta, Grossman - 2004 - Genic A single pass generalized incremental algorithm for clustering.pdf:pdf},
title = {{Genic: A single pass generalized incremental algorithm for clustering}},
year = {2004}
}
@inproceedings{beck89,
author = {Beck, K and Cunnignham, W},
booktitle = {Proceedings OOPSLA '89, ACM SIGPLAN Notices},
number = {October},
pages = {1--6},
title = {{A Laboratory for Teaching Object-Oriented Thinking}},
volume = {24},
year = {1989}
}
@article{Brown2009,
author = {Brown, Nathan},
doi = {10.1145/1459352.1459353},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Brown - 2009 - Chemoinformaticsâan introduction for computer scientists.pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
month = feb,
number = {2},
pages = {1--38},
title = {{Chemoinformaticsâan introduction for computer scientists}},
url = {http://portal.acm.org/citation.cfm?doid=1459352.1459353},
volume = {41},
year = {2009}
}
@article{Martens2011,
abstract = {This paper proposes a complete framework to assess the overall performance of classification models from a user perspective in terms of accuracy, comprehensibility, and justifiability. A review is provided of accuracy and comprehensibility measures, and a novel metric is introduced that allows one to measure the justifiability of classification models. Furthermore, taxonomy of domain constraints is introduced, and an overview of the existing approaches to impose constraints and include domain knowledge in data mining techniques is presented. Finally, justifiability metric is applied to a credit scoring and customer churn prediction case. ?? 2011 Elsevier B.V. All rights reserved.},
author = {Martens, David and Vanthienen, Jan and Verbeke, Wouter and Baesens, Bart},
doi = {10.1016/j.dss.2011.01.013},
file = {:Users/timm/svns/doc/xplain/11Martens.pdf:pdf},
isbn = {0167-9236},
issn = {01679236},
journal = {Decision Support Systems},
keywords = {Classification,Comprehensibility,Data mining,Justifiability,Metrics},
number = {4},
pages = {782--793},
publisher = {Elsevier B.V.},
title = {{Performance of classification models from a user perspective}},
url = {http://dx.doi.org/10.1016/j.dss.2011.01.013},
volume = {51},
year = {2011}
}
@article{raffo99,
author = {Raffo, D M and Vandeville, J V and Martin, R},
journal = {Journal of Systems and Software},
month = apr,
number = {2/3},
title = {{Software Process Simulation to Achieve Higher CMM Levels}},
volume = {46},
year = {1999}
}
@inproceedings{me96b,
annote = {Available from $\backslash$url\{http:/menzies.us/pdf/96ok.pdf\}},
author = {Menzies, T J},
booktitle = {ECAI '96},
title = {{On the Practicality of Abductive Validation}},
year = {1996}
}
@inproceedings{cunn95,
author = {Cunningham, W},
booktitle = {Pattern Languages of Program Design},
editor = {Coplien, J and Schmidt, D},
publisher = {Addison-Wesley},
title = {{The CHECKS Pattern Language of Information Integrity}},
year = {1995}
}
@inproceedings{orrego09,
abstract = {Using process simulation and AI search methods, we compare software reuse against other possible changes to a project. such as reducing functionality or improving the skills of the programmer population. In one case, two generations of reuse were as good or better than any other project change (but a third and fourth generation of reuse was not useful). In another case, applying reuse to a project was demonstrable worse than several other possible changes to a project. Our conclusion is that the general claims regarding the benefits of software reuse do not hold for specific projects. We argue that the merits of software reuse need to be evaluated in a project by project basis. AI search over process models is useful for such an assessment, particularly when there is not sufficient data for precisely tuning a simulation model.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09reuse.pdf\}},
author = {{Andres Orrego, Tim Menzies}, Oussama El-Rawas},
booktitle = {Icsp2009},
pages = {186--197},
title = {{On the Relative Merits of Software Reuse}},
year = {2009}
}
@article{Challenges2005,
author = {Challenges, Symbol Table and Trees, Binary Search},
file = {:Users/timm/svns/doc/05bst.pdf:pdf},
title = {{4 . 3 Binary Search Trees}},
year = {2005}
}
@inproceedings{glas95a,
author = {Glasgow, J and Papadias, D},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and Narayanan, N H and Chandrasekaran, B},
pages = {435--480},
publisher = {The AAAI Press},
title = {{Computational Imagery}},
year = {1995}
}
@article{me00o,
abstract = {At the SEKE'99 conference, knowledge engineering researchers held a panel on the merits of meta-knowledge (i.e. problem solving methods and ontologies) for the development of knowledge-based systems. The original panel was framed as a debate on the merits of meta-knowledge for knowledge maintenance. However, the debate quickly expanded. In the end, we were really discussing the merits of different technologies for the specification of reusable components for KBS. In this brief article we record some of the lively debate from that panel and the email exchanges it generated.},
author = {Menzies, Tim and Althoff, Klaus Dieter and Kalfoglou, Yannis and Motta, Enrico},
doi = {10.1016/S0218-1940(00)00026-2},
issn = {02181940},
journal = {International Journal of Software Engineering and Knowledge Engineering},
month = aug,
number = {4},
pages = {549--555},
title = {{Issues with meta-knowledge}},
volume = {10},
year = {2000}
}
@article{loggia89,
author = {Ramsey, C Loggia and Basili, V R},
journal = {IEEE Transactions on Software Engineering},
pages = {747--759},
title = {{An Evaluation for Expert Systems for Software Engineering Management}},
volume = {15},
year = {1989}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@book{bratko89,
author = {Bratko, I and Mozetic, I and Lavrac, N},
publisher = {MIT Press},
title = {{KARDIO: a Study in Deep and Qualitative Knowledge for Expert Systems}},
year = {1989}
}
@book{gof95,
author = {Gamma, E and Helm, R and Johnson, R and Vlissides, J},
publisher = {Addison-Wesley},
title = {{Design Patterns: Elements of Reusable Object-Oriented Software}},
year = {1995}
}
@inproceedings{zhang10,
author = {Zhang, Hongyu and Nelson, Adam and Menzies, Tim},
booktitle = {Proceedings of PROMISE'10},
title = {{On the Value of Learning From Defect Dense Components for Software Defect Prediction}},
year = {2010}
}
@article{mackworth77,
author = {Mackworth, A K},
journal = {Artificial Intelligence},
pages = {99--118},
title = {{Consistency in \{N\}etworks of \{R\}elations}},
volume = {8},
year = {1977}
}
@inproceedings{Gangemi98,
author = {Gangemi, A and Pisanelli, D and Steve, G},
booktitle = {Proceedings of the 1st International Conference on Formal Ontology in Information Systems, FOIS'98, Trento, Italy},
editor = {Guarino, N},
month = jun,
pages = {163--178},
title = {{Ontology Integration: Experiences with Medical Terminologies}},
year = {1998}
}
@article{me08i,
annote = {Avialable from $\backslash$url\{http://menzies.us/pdf/08promised.pdf\}},
author = {Menzies, T},
journal = {Empirical Software Engineering},
month = oct,
title = {{Editorial, special issue, repeatable experiments in software engineering}},
year = {2008}
}
@inproceedings{comp98,
author = {Compton, P and Ramadan, Z and Preston, P and Le-Gia, T and V.Chellen and Mulholland, M and Hibbert, D B and Haddad, P R and Kang, B},
booktitle = {Banff Workshop on Knowledge Acquisition},
title = {{A Trade-off Between Domain Knowledge and Problem-Solving Method Power,}},
year = {1998}
}
@article{vell87,
author = {Vellino, A},
journal = {Artificial Intelligence},
pages = {213--261},
title = {{Book Review of Winograd \& Flores, Understanding Computers and Cognition: A New Foundation for Design}},
volume = {31},
year = {1987}
}
@article{tosun2010,
author = {Tosun, A and Bener, A and Turhan, B and Menzies, T},
title = {{No Title}}
}
@inproceedings{shu02,
author = {Shull, F and {ad B. Boehm}, V R Basili and Brown, A W and Costa, P and Lindvall, M and Port, D and Rus, I and Tesoriero, R and Zelkowitz, M V},
booktitle = {Proceedings of 8th International Software Metrics Symposium, Ottawa, Canada},
pages = {249--258},
title = {{What We Have Learned About Fighting Defects}},
year = {2002}
}
@book{buch84,
author = {Buchanan, B G and Shortliffe, E H},
publisher = {Addison-Wesley},
title = {{Rule-\{B\}ased \{E\}xpert \{S\}ystems: The \{MYCIN\} \{E\}xperiments of the \{S\}tanford \{H\}euristic \{P\}rogramming \{P\}roject}},
year = {1984}
}
@misc{mmcarthy00,
author = {McCarthy, J},
title = {{Lessons from the \{L\}ighthill \{F\}lap}},
year = {2000}
}
@inproceedings{Ohlemacher2011b,
abstract = {There has been a great deal of research into the use of Information Retrieval (IR)-based techniques to support concept location in source code. Much of this research has been focused on determining how to use various IR techniques to support concept location. Very little attention has been given to the effect of different configurations of corpus building and indexing on query results. In this paper, we propose a tool designed to support large-scale studies of IR techniques in varying configurations of parameters with the intention of automatically calibrating these parameters. We also discuss preliminary efforts to create the benchmark data such studies require.},
address = {Kingston, ON, Canada},
annote = {Laura. Fixed on 09/25/2012},
author = {Ohlemacher, Scott and Marcus, Andrian},
booktitle = {19th IEEE International Conference on Program Comprehension (ICPC'11)},
keywords = {information\_retrieval concept\_feature\_concern\_loca},
pages = {246--249},
title = {{Towards a Benchmark and Automatic Calibration for IR-based Concept Location}}
}
@misc{me95i,
author = {Menzies, T J and Taylor, a},
institution = {Department of Software Development, Monash University},
number = {TR95-36},
title = {{Abduction and Memoing}},
year = {1995}
}
@article{Ritchie2010a,
abstract = {OBJECTIVES: The goal was to determine the sensitivity and specificity of family history in identifying children with severe or genetic hyperlipidemias in a rural, predominantly white population. METHODS: A total of 20,266 fifth-grade children in West Virginia, from the Coronary Artery Risk Detection in Appalachian Communities (CARDIAC) Project, who completed a family history and fasting lipid profile were used in analyses. The relationship between hyperlipidemia and family history was determined, and the use of family history to predict the need for pharmacologic treatment among children with dyslipidemia was evaluated. RESULTS: A total of 71.4\% of children met the National Cholesterol Education Program (NCEP) guidelines for cholesterol screening on the basis of positive family history. Of those, 1204 (8.3\%) were considered to have dyslipidemia (low-density lipoprotein > or =130 mg/dL), and 1.2\% of these children with dyslipidemia warranted possible pharmacologic treatment (low-density lipoprotein > or =160 mg/dL). Of the 28.6\% who did not have a positive family history (did not meet NCEP guidelines), 548 (9.5\%) had dyslipidemia, 1.7\% of whom warranted pharmacologic treatment. Sensitivity and specificity data demonstrated that family history does not provide a strong indication as to whether pharmacologic treatment may be warranted. CONCLUSIONS: Results indicate that the use of family history to determine the need for cholesterol screening in children would have (1) missed many with moderate dyslipidemia and (2) failed to detect a substantial number with likely genetic dyslipidemias that would require pharmacologic treatment. The use of universal cholesterol screening would identify all children with severe dyslipidemia, allowing for proper intervention and follow-up and leading to the prevention of future atherosclerotic disease.},
author = {Ritchie, Susan K and Murphy, Emily C-S and Ice, Christa and Cottrell, Lesley a and Minor, Valerie and Elliott, Eloise and Neal, William},
doi = {10.1542/peds.2009-2546},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Ritchie et al. - 2010 - Universal versus targeted blood cholesterol screening among youth The CARDIAC project.pdf:pdf},
issn = {1098-4275},
journal = {Pediatrics},
keywords = {cardiovascular disease,children,genetics,lipids},
month = aug,
number = {2},
pages = {260--5},
pmid = {20624798},
title = {{Universal versus targeted blood cholesterol screening among youth: The CARDIAC project.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20624798},
volume = {126},
year = {2010}
}
@book{rakitin01,
author = {Rakitin, S R},
isbn = {1-58053-296-9},
publisher = {Artech House},
title = {{Software Verification and Validation for Practitioners and Managers, Second Edition}},
year = {2001}
}
@article{Manegold2010c,
author = {Manegold, S. and Laurent, D. and Lupu, M. and Onose, N. and R\'{e}, C. and Sans, V. and Senellart, P. and Wu, T. and Shasha, D. and Manolescu, I. and Afanasiev, L. and Feng, J. and Gou, G. and Hadjieleftheriou, M. and Harizopoulos, S. and Kalnis, P. and Karanasos, K.},
doi = {10.1145/1815933.1815944},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Manegold et al. - 2010 - Repeatability \& workability evaluation of SIGMOD 2009(2).pdf:pdf},
issn = {01635808},
journal = {ACM SIGMOD Record},
month = dec,
number = {3},
pages = {40},
title = {{Repeatability \& workability evaluation of SIGMOD 2009}},
url = {http://portal.acm.org/citation.cfm?doid=1815933.1815944},
volume = {38},
year = {2010}
}
@article{cope97,
author = {Coplien, J O},
journal = {IEEE Software},
month = jan,
pages = {36--42},
title = {{Idioms and Patterns as Architectural Literature}},
year = {1997}
}
@article{deerwester90,
author = {Deerwester, Scott and Dumais, Susan T and Furnas, George W and Landauer, Thomas K and Harshman, Richard},
journal = {Journal of the American Society for Information Science},
number = {6},
pages = {391--407},
title = {{Indexing by latent semantic analysis}},
volume = {41},
year = {1990}
}
@incollection{me10e,
author = {Menzies, Tim and Shull, Forrest},
booktitle = {Making Software: What Really Works, and Why We Believe It},
editor = {Oram, A and Wilson, G},
publisher = {O'Reilly},
title = {{The Quest for Convincing Evidence}},
year = {2010}
}
@article{chandra92,
author = {Chandrasekaran, B and Johnson, T R and Smith, J W},
journal = {Communications of the ACM},
number = {9},
pages = {124--137},
title = {{Task Structure Analysis for Knowledge Modeling}},
volume = {35},
year = {1992}
}
@book{lewis90,
author = {Lewis, R O},
isbn = {0471570117},
publisher = {Wiley-Interscience},
title = {{Independent Verification and Validation: A Life Cycle Engineering Process for Quality Software}},
year = {1992}
}
@article{Leveson94,
author = {Leveson, N G and Heimdahl, M P E and Hildreth, H and Reese, J D},
journal = {IEEE Transactions on Software Engineering},
month = sep,
number = {9},
pages = {684--706},
title = {{Requirements Specification for Process-Control Systems}},
volume = {20},
year = {1994}
}
@inproceedings{sammut92,
author = {Sammut, C and Hurst, S and Kedzier, D and Michie, D},
booktitle = {Ninth International Conference on Machine Learning},
editor = {Sleeman, D},
pages = {385--393},
publisher = {Morgan Kaufmann},
title = {{Learning to Fly}},
year = {1992}
}
@misc{lee04,
author = {Lee, S C and Santo, A G},
title = {{Tradeoffs in functional allocation between spacecraft autonomy and ground operations: the \{NEAR\} (\{N\}ear \{E\}arth \{A\}steroid \{R\}endezvous) \{E\}xperience, \{J\}ohn \{H\}opkins \{APL\}, \{A\}ugust 9-12, \{U\}tah \{S\}tate \{U\}niversity , \{E\}ccles \{C\}onference \{C\}enter, \{L}}},
year = {2004}
}
@article{Domingos2004,
author = {Domingos, Pedro},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Domingos - 2004 - Adversarial Classification.pdf:pdf},
journal = {Training},
keywords = {cost-sensitive learning,game theory,naive bayes,spam de-},
title = {{Adversarial Classification}},
year = {2004}
}
@inproceedings{masada08,
address = {Berlin, Heidelberg},
author = {Masada, Tomonari and Kiyasu, Senya and Miyahara, Sueharu},
booktitle = {LKR'08: Proceedings of the 3rd international conference on Large-scale knowledge resources},
isbn = {3-540-78158-7, 978-3-540-78158-5},
pages = {13--26},
publisher = {Springer-Verlag},
title = {{Comparing LDA with pLSI as a dimensionality reduction method in document clustering}},
year = {2008}
}
@inproceedings{althoff99a,
author = {Althoff, K.-D. and Nick, M and Tautz, C},
booktitle = {Proc. of the Workshop on Learning Software Organizations (LSO) (in conjunction with the11th International Conference on Software Engineering and Knowledge Engineering, SEKE'99, Kaiserslauten, Germany)},
editor = {Bomarius, F},
month = jun,
pages = {27--44},
title = {{Improving Organizational Memories Through User Feedback}},
year = {1999}
}
@inproceedings{ayel88,
author = {Ayel, M},
booktitle = {Proceedings of the 8th European Conference on Artificial Intelligence (ECAI'88)},
pages = {220--225},
title = {{Protocols for Consistency Checking in Expert System Knowledge Bases}},
year = {1988}
}
@inproceedings{willzh96,
author = {Williams, G J and Huang, Z},
booktitle = {Proceedings PKAW '96: Pacific Knowledge Acquisition Workshop},
title = {{A Case Study in Knowledge Acquisition for Insurance Risk Assessment using a KDD Methodology}},
year = {1996}
}
@article{gaines92,
author = {Gaines, B},
journal = {\{AI\} Magazine},
pages = {24},
title = {{\{AAAI\} 1992 \{S\}pring \{S\}ymposium \{S\}eries \{R\}eports: \{C\}ognitive \{A\}spects of \{K\}nowledge \{A\}cquisition}},
year = {1992}
}
@inproceedings{me06b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06hicss.pdf\}},
author = {Fisher, M S and Menzies, T},
booktitle = {HICSS'06},
title = {{Learning IVV Strategies}},
year = {2006}
}
@inproceedings{me93k,
author = {Menzies, T J},
booktitle = {DX-93: The International Workshop on Principles on Model-Based Diagnosis},
title = {{The Complexity of Model Review}},
year = {1993}
}
@inproceedings{mccallum00,
author = {McCallum, Andrew and Nigam, Kamal and Ungar, Lyle H},
booktitle = {Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining},
pages = {169--178},
series = {KDD '00},
title = {{Efficient clustering of high-dimensional data sets with application to reference matching}},
year = {2000}
}
@article{mantyla09,
annote = {Available from $\backslash$url\{http://sequoia.cs.byu.edu/files/reser2010/proceedings/Mantyla\%20-\%20Rethinking\%20Replication.pdf\}},
author = {{Mika V. Mï¿½ntylï¿½ Casper Lassenius} and Vanhanen, Jari},
journal = {First International Workshop on Replication in Empirical Software Engineering Research, ICSE'09},
title = {{Rethinking Replication in Software Engineering: Can We See the Forest for the Trees?}},
year = {2009}
}
@inproceedings{harel95,
author = {Harel, D},
booktitle = {Diagrammatic Reasoning},
chapter = {8},
editor = {Glasgow, J and {N.H. Narayanan}, B Chandrasekaran},
pages = {235--271},
publisher = {The AAAI Press},
title = {{On Visual Formalisms}},
year = {1995}
}
@inproceedings{cormode05,
author = {Cormode, Graham and Korn, Flip and Muthukrishnan, S and Srivastava, Divesh},
booktitle = {Proceedings of the 21st International Conference on Data Engineering},
pages = {20--31},
series = {ICDE '05},
title = {{Effective Computation of Biased Quantiles over Data Streams}},
year = {2005}
}
@article{dolado01,
author = {Dolado, J J},
journal = {Information and Software Technology},
pages = {61--72},
title = {{On the problem of the software cost function}},
volume = {43},
year = {2001}
}
@misc{gay07,
author = {Gay, G and Menzies, T},
institution = {Lane Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{Under- vs Over- Sampling for C4.5 and Naive Bayes Defect Predictors}},
year = {2007}
}
@article{vera93b,
author = {Vera, A H and Simon, H A},
journal = {Cognitive Science},
pages = {117--133},
title = {{Situated Action: Reply to William Clancey}},
volume = {17},
year = {1993}
}
@book{fayol1916,
author = {Fayol, Henri},
publisher = {H. Dunod et E. Pinat, Paris, OCLC 40204128},
title = {{Administration industrielle et g\'{e}n\'{e}rale; pr\'{e}voyance, organisation, commandement, coordination, controle}},
year = {1916}
}
@inproceedings{me05e,
author = {Menzies, T and Richardson, J},
booktitle = {COCOMO forum, 2005},
title = {{XOMO: Understanding Development Options for Autonomy}},
year = {2005}
}
@inproceedings{elkan01,
annote = {Available from $\backslash$url\{http://www-cse.ucsd.edu/users/elkan/rescale.pdf\}},
author = {Elkan, Charles},
booktitle = {Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence (IJCAIâ01)},
title = {{The Foundations of Cost-Sensitive Learning}},
year = {2001}
}
@article{stefik82,
author = {Stefik, M and Aikins, J and Balzer, R and Benoit, J and Birnhaum, L and Hayes-Roth, F and Sacerdoti, E},
journal = {Artificial Intelligence},
pages = {127--135},
title = {{The \{O\}rganisation of \{E\}xpert \{S\}ystems, \{A\} \{T\}utorial}},
volume = {18},
year = {1982}
}
@inproceedings{Schikuta1993,
author = {Schikuta, Erich},
booktitle = {15th Joint. Conf. on Pattern Recognition},
file = {:Users/timm/svns/doc/schikuta93.pdf:pdf},
keywords = {grid clustering},
pages = {101--105},
title = {{GRID -CLUSTERING : A FAST HIERARCHICAL CLUSTERING METHOD FOR VERY LARGE DATA SETS}},
year = {1993}
}
@incollection{CARBONELL-ML2-BOOK,
address = {Los Altos, CA},
author = {Carbonell, J G},
booktitle = {Machine Learning: An Artificial Intelligence Approach, Volume II},
editor = {Michalski, J G Carbonell R S and Mitchell, T M},
pages = {371--392},
publisher = {Morgan Kaufmann},
title = {{Derivational Analogy: \{A\} Theory of Reconstructive Problem Solving and Expertise Acquisition}},
year = {1986}
}
@article{dekleer86c,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {197--224},
title = {{Problem Solving with the ATMS}},
volume = {28},
year = {1986}
}
@inproceedings{li07,
author = {Li, Ninghui and Li, Tiancheng and Venkatasubramanian, Suresh},
booktitle = {ICDE},
pages = {106--115},
title = {{t-Closeness: Privacy Beyond k-Anonymity and l-Diversity}},
year = {2007}
}
@book{lyu96,
author = {Lyu, M R},
publisher = {McGraw-Hill},
title = {{The Handbook of Software Reliability Engineering}},
year = {1996}
}
@article{me00d,
author = {Menzies, Tim and Cukic, Bojan},
doi = {10.1142/S0218213000000112},
issn = {0218-2130},
journal = {International Journal on Artificial Intelligence Tools},
month = jun,
number = {01},
pages = {153--172},
title = {{Adequacy of Limited Testing for Knowledge Based Systems}},
volume = {09},
year = {2000}
}
@inproceedings{koc13b,
author = {Kocaguneli, Ekrem and Cukic, Bojan and Menzies, Tim and Lu, Huihua},
booktitle = {PROMSE'13},
month = oct,
title = {{Building a Second Opinion: Learning Cross-Company Data}},
year = {2013}
}
@article{paris96,
author = {Paris, C and Vander-Linden, K},
journal = {IEEE Computer},
month = jul,
title = {{DRAFTER: An Interactive Support Tool for Writing Multilingual Manuals}},
year = {1996}
}
@book{glinert90a,
editor = {Glinert, E P},
publisher = {IEEE Computer Society Press},
title = {{Visual Programming Environments: Paradigms and Systems}},
year = {1990}
}
@inproceedings{me09l,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09irrf.pdf\}},
author = {Cukic, B and Menzies, T and Jiang, Y},
booktitle = {IEEE ISSRE'09},
title = {{Variance analysis in software fault prediction models}},
year = {2009}
}
@inproceedings{MORAN2009,
address = {London, U.K.},
author = {Moran, Stuart and He, Yulan and Liu, Kecheng},
booktitle = {Proceedings of the World Congress on Engineering 2009 Vol I},
title = {{An Empirical Framework for Automatically Selecting the Best Bayesian Classifier}},
year = {2009}
}
@phdthesis{Whalen00:ms-thesis,
author = {{M.P. Whalen}},
school = {University of Minnesota},
title = {{A Formal Semantics for RSML}},
year = {2000}
}
@misc{cpp06,
booktitle = {Proceedings of the 2006 International Conference of the International Society of Parametric Analysts, Seattle, WA},
title = {{Certified Parametric Practioner Tutorial}},
year = {2006}
}
@article{Song2010c,
author = {Song, Qinbao and Jia, Zihan and Shepperd, Martin and Ying, Shi and Liu, Jin},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework.pdf:pdf},
keywords = {machine learning,scheme evaluation,software defect prediction,software defect-proneness prediction},
number = {X},
pages = {1--16},
title = {{A General Software Defect-Proneness Prediction Framework}},
volume = {X},
year = {2010}
}
@inproceedings{me03m,
author = {Menzies, Tim and Ammar, Kareem},
booktitle = {Tech report, Computer Science, Portland State University},
keywords = {artificial intelligence,defect detectors,empirical studies and metrics,fault models,feature subset selection,learning,metrics,nents analysis,principal compo-,product metrics,software testing and verification},
pages = {1--28},
title = {{How Simple is Software Defect Detection ?}},
year = {2003}
}
@article{storn97,
author = {Storn, Rainer and Price, Kenneth},
doi = {10.1023/A:1008202821328},
file = {:Users/timm/svns/doc/97stornPriceDE.pdf:pdf},
issn = {0925-5001},
journal = {Journal of Global Optimization},
number = {4},
pages = {341--359},
publisher = {Kluwer Academic Publishers},
title = {{Differential Evolution â A Simple and Efficient Heuristic for global Optimization over Continuous Spaces}},
volume = {11},
year = {1997}
}
@phdthesis{elrawas08,
annote = {Available from $\backslash$url\{http://unbox.org/wisp/var/ous/thesis/thesis.pdf\}},
author = {El-Rawas, O},
school = {Lane Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{Software Process Control Without Calibration}},
year = {2008}
}
@misc{menz85,
annote = {School of Econometrics, University of New England},
author = {Menzies, G D},
title = {{An Econometric Analysis of the Dark Figure of Crime}},
year = {1985}
}
@inproceedings{fischer89,
author = {Fischer, G and McCall, R and Morch, A},
booktitle = {CHI '89},
title = {{Design environments for constructive and argumentative design}},
year = {1989}
}
@article{compton90,
author = {Compton, P J and Jansen, R},
journal = {Knowledge Acquisition},
pages = {241--257},
title = {{A \{P\}hilosophical \{B\}asis for \{K\}nowledge \{A\}cquisition.}},
volume = {2},
year = {1990}
}
@inproceedings{Haiduc2013b,
abstract = {Text retrieval approaches have been used to address many software engineering tasks. In most cases, their use involves issuing a textual query to retrieve a set of relevant software artifacts from the system. The performance of all these approaches depends on the quality of the given query (i.e., its ability to describe the information need in such a way that the relevant software artifacts are retrieved during the search). Currently, the only way to tell that a query failed to lead to the expected software artifacts is by investing time and effort in analyzing the search results. In addition, it is often very difficult to ascertain what part of the query leads to poor results. We propose a novel pre-retrieval metric, which reflects the quality of a query by measuring the specificity of its terms. We exemplify the use of the new specificity metric on the task of concept location in source code. A preliminary empirical study shows that our metric is a good effort predictor for text retrieval-based concept location, outperforming existing techniques from the field of natural language document retrieval.},
address = {Zurich, Switzerland},
annote = {Laura. Fixed on 09/24/2012},
author = {{Haiduc Sonia}, Bavota Gabriele Oliveto Rocco Marcus Andrian and {De Lucia}, Andrea},
booktitle = {34th IEEE/ACM International Conference on Software Engineering (ICSE'12)},
keywords = {searching queries concept\_feature\_concern\_location},
pages = {1273--1276},
publisher = {IEEE},
title = {{Evaluating the Specificity of Text Retrieval Queries to Support Software Engineering Tasks}}
}
@article{Kaiser2008,
abstract = {Over the last decade, bicluster methods have become more and more popular in different fields of two way data analysis and a wide variety of algorithms and analysis methods have been published. In this paper we introduce the R package $\backslash$verb1\{1$\backslash$tt biclust$\backslash$verb1\}1, which contains a collection of bicluster algorithms, preprocessing methods for two way data, and validation and visualization techniques for bicluster results. For the first time, such a package is provided on a platform like R, where data analysts can easily add new bicluster algorithms and adapt them to their special needs.},
author = {Kaiser, Sebastian and Leisch, Friedrich},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/S\_Kaiser\_biclust.pdf:pdf},
isbn = {978-3-7908-2083-6},
journal = {Compstat 2008---Proceedings in Computational Statistics},
keywords = {biclustering,compstat 2008-proceedings in computational,has been accepted for,of an article which,r,software,statistics,the,this is a pre-print,two-way-clustering},
number = {028},
pages = {201--208},
title = {{A Toolbox for Bicluster Analysis in \{R\}}},
year = {2008}
}
@article{strike01,
author = {Strike, Kevin and Emam, Khaled El and Madhavji, Nazim H},
journal = {Software Engineering},
number = {10},
pages = {890--908},
title = {{Software Cost Estimation with Incomplete Data}},
url = {citeseer.ist.psu.edu/strike00software.html},
volume = {27},
year = {2001}
}
@inproceedings{me88,
annote = {Adelaide, Australia},
author = {Menzies, T J and Dean, M and Black, J and Fleming, J},
booktitle = {Ai '88},
title = {{Combining Heuristics with Simulation Models: An Expert System for the Optimal Management of Pig}},
year = {1988}
}
@inproceedings{fea01,
author = {Feather, M and In, H and Kiper, J and Kurtz, J and Menzies, T},
booktitle = {ECE UBC tech report},
title = {{First Contract: Better, Earlier Decisions for Software Projects}},
year = {2001}
}
@inproceedings{palmer95,
author = {Palmer, G J and Craw, S},
booktitle = {EUROVAV-95: The Third European Symposium on Validation and Verification of Knowledge-Based Systems},
pages = {201--211},
title = {{Utilising Explanation to Assist the Refinement of Knowledge-Based Systems}},
year = {1995}
}
@inproceedings{cohen99,
author = {Cohen, P and Chaudhri, V and Pease, A and Schrag, R},
booktitle = {AAAI'99},
title = {{Does Prior Knowledge Facilitate the Development of Knowledge-based Systems?}},
year = {1999}
}
@misc{grey03,
author = {Grey, W and Katircioglu, K and Bagchi, S and Shi, D and Gallego, G and Seybold, D and Stefanis, S},
booktitle = {IBM Systems Journal},
number = {3},
title = {{An analytic approach for quantifying the value of e-business initiatives}},
volume = {42},
year = {2003}
}
@book{greenfield04,
author = {Greenfield, Jack and Short, Keith},
publisher = {Wiley Publishing, Indianapolis, IN},
title = {{Software factories : assembling applications with patterns, models, frameworks, and tools}},
year = {2004}
}
@book{feigen83,
author = {Feigenbaum, E and McCorduck, P},
publisher = {Addison-Wesley},
title = {{The \{F\}ifth \{G\}eneration}},
year = {1983}
}
@article{murphy12,
author = {Murphy, Brendan},
journal = {Empirical Software Engineering},
number = {1},
pages = {18--22},
title = {{The difficulties of building generic reliability models for software}},
volume = {17},
year = {2012}
}
@misc{nasa91,
author = {NASA},
howpublished = {Software \{T\}echnology \{B\}ranch, \{l\}yndon \{B\}. \{J\}ohnson \{S\}pace \{C\}enter},
title = {{\{CLIPS\} \{R\}eference \{M\}anual}},
year = {1991}
}
@article{Ordonez2003,
abstract = {Clustering data streams is an interesting Data Mining prob- lem. This article presents three variants of the K-means algorithm to cluster binary data streams. The variants in- clude On-line K-means, Scalable K-means, and Incremental K-means, a proposed variant introduced that finds higher quality solutions in less time. Higher quality of solutions are obtained with a mean-based initialization and incremen- tal learning. The speedup is achieved through a simplified set of sufficient statistics and operations with sparse matri- ces. A summary table of clusters is maintained on-line. The K-means variants are compared with respect to quality of results and speed. The proposed algorithms can be used to monitor transactions.},
author = {Ordonez, Carlos},
doi = {10.1145/882085.882087},
file = {:Users/timm/svns/doc/erin/references/BinarySparseClustering/Ordonez03.pdf:pdf},
journal = {Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery},
keywords = {binary data},
pages = {12--19},
title = {{Clustering binary data streams with K-means}},
url = {http://portal.acm.org/citation.cfm?doid=882082.882087},
year = {2003}
}
@article{davis79,
author = {Davis, R},
journal = {Artificial Intelligence},
number = {2},
pages = {121--157},
title = {{Interactive Transfer of Expertise: Acqusiition of New Inference Rules}},
volume = {12},
year = {1979}
}
@book{date95,
author = {Date, C J},
publisher = {Addison-Wesley},
title = {{An Introduction to Database Systems}},
volume = {6},
year = {1995}
}
@inproceedings{me96j,
author = {Menzies, T and Ramakrishnan, S},
booktitle = {Tools Pacific, Melbourne},
title = {{Comparing and Generalising Models for Metrics Repositories}},
year = {1996}
}
@inproceedings{BOETTICHER2005,
address = {New York, NY, USA},
author = {Boetticher, Gary D},
booktitle = {PROMISE '05: Proceedings of the 2005 workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1083165.1083173},
isbn = {-159593-125-2},
pages = {1--6},
publisher = {ACM},
title = {{Nearest neighbor sampling for better defect prediction}},
year = {2005}
}
@inproceedings{greese99,
author = {v. Wangenheim, C Gresse and Althoff, K.-D. and Barcia, R},
booktitle = {Proceedings of SEKE '99},
title = {{Intelligent Retrieval of Software Engineering Experienceware}},
year = {1999}
}
@inproceedings{glover93tabu,
address = {Oxford, England},
author = {Glover, Fred and Laguna, M},
booktitle = {Modern Heuristic Techniques for Combinatorial Problems},
editor = {Reeves, C},
publisher = {Blackwell Scientific Publishing},
title = {{Tabu Search}},
url = {citeseer.ist.psu.edu/glover97tabu.html},
year = {1993}
}
@book{deb98e,
author = {Debenham, J},
publisher = {Springer-Verlag},
title = {{Knowledge Engineering: Unifying Knowledge Base and Database Design}},
year = {1998}
}
@article{Brickell,
author = {Brickell, Justin and Shmatikov, Vitaly},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Brickell, Shmatikov - Unknown - The Cost of Privacy Destruction of Data-Mining Utility in Anonymized Data Publishing Categories and S(2).pdf:pdf},
journal = {ReCALL},
title = {{The Cost of Privacy : Destruction of Data-Mining Utility in Anonymized Data Publishing Categories and Subject Descriptors}}
}
@misc{rich05,
author = {Richardson, M and Domingos, Pedro},
booktitle = {Machine learning},
month = feb,
number = {1-2},
title = {{Markov Logic Networks}},
volume = {62},
year = {206}
}
@inproceedings{yang06,
author = {Yang, Ying and Webb, Geoffrey I and Cerquides, Jes\'{u}s and Korb, Kevin B and Boughton, Janice R and Ting, Kai Ming},
booktitle = {ECML},
pages = {533--544},
title = {{To Select or To Weigh: A Comparative Study of Model Selection and Model Weighing for SPODE Ensembles}},
year = {2006}
}
@book{putnam80,
author = {Putnam, Lawrence H},
publisher = {The Institute of Electrical and Electronics Engineers, Inc.},
title = {{Software Cost Estimating and Life-Cycle Control: Getting the Software Numbers, New York}},
year = {1980}
}
@book{pearl84,
address = {Boston, MA, USA},
author = {Pearl, Judea},
isbn = {0-201-05594-5},
publisher = {Addison-Wesley Longman Publishing Co., Inc.},
title = {{Heuristics: intelligent search strategies for computer problem solving}},
year = {1984}
}
@article{Claffy2010,
author = {Claffy, Kc and Kenneally, Erin},
doi = {10.1109/MSP.2010.57},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Framework - 2010 - Dialing Privacy and Utility.pdf:pdf},
issn = {1540-7993},
journal = {IEEE Security \& Privacy Magazine},
month = jul,
number = {4},
pages = {31--39},
title = {{Dialing Privacy and Utility: A Proposed Data-Sharing Framework to Advance Internet Research}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5432148},
volume = {8},
year = {2010}
}
@article{Chandola2009a,
author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
doi = {10.1145/1541880.1541882},
file = {:Users/timm/svns/doc/anomalies09.pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
month = jul,
number = {3},
pages = {1--58},
title = {{Anomaly detection}},
url = {http://portal.acm.org/citation.cfm?doid=1541880.1541882},
volume = {41},
year = {2009}
}
@article{Hu2001,
author = {Hu, Qing and Plant, Robert T and Hertz, David B},
file = {:Users/timm/svns/doc/cost/98Qing.pdf:pdf},
number = {I},
pages = {143--163},
title = {{Software Cost Estimation Using Economic Production Models}},
volume = {1},
year = {2001}
}
@book{Shere88,
author = {Shere, K D},
publisher = {Prentice Hall},
title = {{Software Engineering and Management}},
year = {1988}
}
@inproceedings{jenn94,
author = {Jenn, Eric and Arlat, Jean and Rimn, Marcus and Ohlsson, Joakim and Karlsson, Johan},
booktitle = {Proceedings of the 24th International Symposium on Fault Tolerant Computing, (FTCS-24), IEEE, Austin, Texas, USA},
pages = {66--75},
title = {{Fault Injection into VHDL Models: The MEFISTO Tool}},
year = {1994}
}
@article{wilson00,
author = {Wilson, D.Randall and Martinez, TonyR.},
doi = {10.1023/A:1007626913721},
issn = {0885-6125},
journal = {Machine Learning},
number = {3},
pages = {257--286},
title = {{Reduction Techniques for Instance-Based Learning Algorithms}},
volume = {38},
year = {2000}
}
@article{willems91,
author = {Willems, J L and Abreu-Lima, C and Arnaud, P and van Bemmel, J H and Brohet, C and Degani, R and Denis, B and Gehring, J and Graham, I and van Herpen, G},
journal = {The New England Journal of Medicine, December 19},
number = {25},
pages = {1767--1773},
title = {{The diagnostic performance of computer programs for the interpretation of electrocardiograms}},
volume = {325},
year = {1991}
}
@article{he12,
author = {He, Zhimin and Shu, Fengdi and Yang, Ye and Li, Mingshu and Wang, Qing},
file = {:Users/timm/svns/doc/transfer/12he.pdf:pdf},
journal = {Automated Software Engineering},
number = {2},
pages = {167--199},
title = {{An investigation on the feasibility of cross-project defect prediction}},
volume = {19},
year = {2012}
}
@inproceedings{krall14b,
author = {Krall, J and Menzies, T and Davies, M},
booktitle = {Modeling in Human Machine Systems: Challenges for Formal Verification, an AAAI 2014 Spring Symposium},
title = {{Learning the Task Management Space of an Aircraft Approach Model}},
year = {2014}
}
@inproceedings{me03q,
abstract = { Assessing software costs money and better assessment costs exponentially more money. Given finite budgets, assessment resources are typically skewed towards areas that are believed to be mission critical. This leaves blind spots: portions of the system that may contain defects which may be missed. Therefore, in addition to rigorously assessing mission critical areas, a parallel activity should sample the blind spots. This paper assesses defect detectors based on static code measures as a blind spot sampling method. In contrast to previous results, we find that such defect detectors yield results that are stable across many applications. Further, these detectors are inexpensive to use and can be tuned to the specifics of the current business situations.},
author = {Menzies, T. and Stefano, J.S. Di},
booktitle = {Eighth IEEE International Symposium on High Assurance Systems Engineering, 2004. Proceedings.},
doi = {10.1109/HASE.2004.1281737},
isbn = {0-7695-2094-4},
issn = {1530-2059},
title = {{How good is your blind spot sampling policy}},
year = {2004}
}
@inproceedings{kitch04,
address = {Washington, DC, USA},
author = {Kitchenham, Barbara A and Dyba, Tore and Jorgensen, Magne},
booktitle = {ICSE '04: Proceedings of the 26th International Conference on Software Engineering},
isbn = {0-7695-2163-0},
pages = {273--281},
publisher = {IEEE Computer Society},
title = {{Evidence-Based Software Engineering}},
year = {2004}
}
@article{kuipers93,
author = {Kuipers, B J},
journal = {Artificial Intelligence},
pages = {125--132},
title = {{Reasoning with Qualitative Models}},
volume = {59},
year = {1993}
}
@inproceedings{me09i,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09value.pdf\}},
author = {Green, P and Menzies, T and Williams, S and El-waras, O},
booktitle = {IEEE ASE'09},
title = {{Understanding the Value of Software Engineering Technologies}},
year = {2009}
}
@inproceedings{bird11,
author = {Bird, Christian and Murphy, Brendan and Nagappan, Nachiappan and Zimmermann, Thomas},
booktitle = {Proceedings of the ACM 2011 conference on Computer supported cooperative work},
pages = {143--150},
series = {CSCW '11},
title = {{Empirical software engineering at Microsoft Research}},
year = {2011}
}
@article{Hale2010,
abstract = {Information systems portfolio management assumes that software will evolve to maintain alignment with operational needs, a goal that must be met through effective ongoing maintenance. Thus, a primary goal of software maintainers is to ensure that production code is updated without the introduction of defects. However, there is a dearth of research that examines the work product defects that occur as these applications evolve. The goal of this study is to characterize software evolution lifecycle work product defects and factors that may increase or reduce their occurrence. The study takes place within a global consulting organization conducting ongoing software maintenance for a Fortune 100 telecommunications firm by a project team assessed at Capability Maturity Model Integration (CMMI) Level 3. This study reports on 961 work product reviews conducted across the evolution activities of the ISO/IEC 12207 Software Development Life Cycle Processes. After controlling for team and expertise differences, the study's major finding is that corrective evolution projects inject a greater number of work product defects than enhancive evolution projects. This result does not arise from the schedule compression often associated with corrective evolution. Rather, it is concluded that the increase in work product defects is associated with the increased complexity of analysis-stage problem diagnosis found in corrective evolution projects. The analysis is augmented by additional covariates including the number of work product reviewers, preparation time of reviewers, and size of the project.},
author = {Hale, David P. and Hale, Joanne E. and Smith, Randy K.},
doi = {10.1145/1952712.1952716},
file = {:Users/timm/svns/doc/11hale.pdf:pdf},
isbn = {0095-0033},
issn = {00950033},
journal = {ACM SIGMIS Database},
keywords = {development,documentation,inspections,maintenance,management,measurement,problem diagnosis,reliability,reviews,software engineering,verification,walkthrough},
number = {1},
pages = {59},
title = {{Evaluation of work product defects during corrective \& enhancive software evolution}},
volume = {42},
year = {2010}
}
@misc{ism06,
annote = {Available from $\backslash$url\{http://www.sti.nasa.gov/tto/Spinoff2006/ct\_1.html\}},
author = {Turner, Janelle},
title = {{A Predictive Approach to Eliminating Errors in Software Code}},
year = {2006}
}
@article{Webb2000,
author = {Webb, GI},
file = {:Users/timm/svns/doc/webb00.pdf:pdf},
journal = {Machine learning},
keywords = {aggregation,bagging,boosting,decision committee,decision tree,wagging},
pages = {159--197},
title = {{Multiboosting: A technique for combining boosting and wagging}},
url = {http://www.springerlink.com/index/G7K410V232R15363.pdf},
volume = {39},
year = {2000}
}
@article{Storn1999,
abstract = {A simple optimization procedure for constraint-based problems is
described which works with a simplified cost function or even without
one. The simplification of the problem formulation makes this method
particularly attractive. The new method lends itself to parallel
computation and is well suited for constraint satisfaction, constrained
optimization, and design centering problems. A further asset is its
self-steering property which makes the new method easy to use},
author = {Storn, Rainer},
doi = {10.1109/4235.752918},
file = {:Users/timm/svns/doc/99de.pdf:pdf},
isbn = {1089-778X},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
number = {1},
pages = {22--34},
pmid = {2016},
title = {{System design by constraint adaptation and differential evolution}},
volume = {3},
year = {1999}
}
@book{riel96,
author = {Riel, A J},
publisher = {Addison-Wesley},
title = {{Object-Oriented Design Heuristics}},
year = {1996}
}
@article{dekleer86a,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {163--196},
title = {{An \{A\}ssumption-\{B\}ased \{TMS\}}},
volume = {28},
year = {1986}
}
@inproceedings{horvitz05,
author = {Horvitz, Eric and Apacible, Johnson and Sarin, Raman and Liao, Lin},
booktitle = {UAI'05},
pages = {275--283},
title = {{Prediction, Expectation, and Surprise: Methods, Designs, and Study of a Deployed Traffic Forecasting Service}},
year = {2005}
}
@inproceedings{Muns91,
author = {Munson, J C and Khoshgoftaar, T M},
booktitle = {Proceedings of the International Symposium on Software Reliability Engineering, Austin, TX},
month = may,
title = {{The Use of Software Complexity Metrics in Software Reliability Modeling}},
year = {1991}
}
@inproceedings{harman12,
author = {Harman, Mark and Jia, Yue and Zhang, Yuanyuan},
booktitle = {MSR},
pages = {108--111},
title = {{App store mining and analysis: MSR for app stores}},
year = {2012}
}
@inproceedings{taylor05,
author = {Taylor, B J and Darrah, M A},
booktitle = {IJCNN '05: Proceedings. 2005 IEEE International Joint Conference on Neural Networks},
pages = {2915--2920},
title = {{Rule extraction as a formal method for the verification and validation of neural networks}},
volume = {5},
year = {2005}
}
@article{Verbeke2011,
abstract = {Customer churn prediction models aim to detect customers with a high propensity to attrite. Predictive accuracy, comprehensibility, and justifiability are three key aspects of a churn prediction model. An accurate model permits to correctly target future churners in a retention marketing campaign, while a comprehensible and intuitive rule-set allows to identify the main drivers for customers to churn, and to develop an effective retention strategy in accordance with domain knowledge. This paper provides an extended overview of the literature on the use of data mining in customer churn prediction modeling. It is shown that only limited attention has been paid to the comprehensibility and the intuitiveness of churn prediction models. Therefore, two novel data mining techniques are applied to churn prediction modeling, and benchmarked to traditional rule induction techniques such as C4.5 and RIPPER. Both AntMiner+ and ALBA are shown to induce accurate as well as comprehensible classification rule-sets. AntMiner+ is a high performing data mining technique based on the principles of Ant Colony Optimization that allows to include domain knowledge by imposing monotonicity constraints on the final rule-set. ALBA on the other hand combines the high predictive accuracy of a non-linear support vector machine model with the comprehensibility of the rule-set format. The results of the benchmarking experiments show that ALBA improves learning of classification techniques, resulting in comprehensible models with increased performance. AntMiner+ results in accurate, comprehensible, but most importantly justifiable models, unlike the other modeling techniques included in this study. ?? 2010 Elsevier Ltd. All rights reserved.},
author = {Verbeke, Wouter and Martens, David and Mues, Christophe and Baesens, Bart},
doi = {10.1016/j.eswa.2010.08.023},
file = {:Users/timm/svns/doc/xplain/11Verbeke.pdf:pdf},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {ALBA,Ant Colony Optimization,Churn prediction,Classification,Comprehensible rule induction,Data mining},
number = {3},
pages = {2354--2364},
publisher = {Elsevier Ltd},
title = {{Building comprehensible customer churn prediction models with advanced rule induction techniques}},
url = {http://dx.doi.org/10.1016/j.eswa.2010.08.023},
volume = {38},
year = {2011}
}
@misc{budgen06,
annote = {Keynote address, CSEET'06},
author = {Budgen, D},
title = {{No Title}},
year = {2006}
}
@inproceedings{me92zb,
author = {Menzies, T J and Compton, P},
booktitle = {ECAI '92 Workshop on Improving the Use of Knowledge-Based Systems with Explanations, Vienna},
title = {{Causal Explanations as a Tool for Refining Qualitative Models}},
year = {1992}
}
@inproceedings{AZZEH2008,
address = {New York, NY, USA},
author = {Azzeh, Mohammad and Neagu, Daniel and Cowling, Peter},
booktitle = {PROMISE '08: Proceedings of the 4th international workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1370788.1370805},
isbn = {978-1-60558-036-4},
pages = {71--78},
publisher = {ACM},
title = {{Improving analogy software effort estimation using fuzzy feature subset selection algorithm}},
year = {2008}
}
@article{Deb2005,
abstract = {Since the suggestion of a computing procedure of multiple Pareto-optimal solutions in multi-objective optimization problems in the early Nineties, researchers have been on the look out for a procedure which is computationally fast and simultaneously capable of finding a well-converged and well-distributed set of solutions. Most multi-objective evolutionary algorithms (MOEAs) developed in the past decade are either good for achieving a well-distributed solutions at the expense of a large computational effort or computationally fast at the expense of achieving a not-so-good distribution of solutions. For example, although the Strength Pareto Evolutionary Algorithm or SPEA (Zitzler and Thiele, 1999) produces a much better distribution compared to the elitist non-dominated sorting GA or NSGA-II (Deb et al., 2002a), the computational time needed to run SPEA is much greater. In this paper, we evaluate a recently-proposed steady-state MOEA (Deb et al., 2003) which was developed based on the epsilon-dominance concept introduced earlier(Laumanns et al., 2002) and using efficient parent and archive update strategies for achieving a well-distributed and well-converged set of solutions quickly. Based on an extensive comparative study with four other state-of-the-art MOEAs on a number of two, three, and four objective test problems, it is observed that the steady-state MOEA is a good compromise in terms of convergence near to the Pareto-optimal front, diversity of solutions, and computational time. Moreover, the epsilon-MOEA is a step closer towards making MOEAs pragmatic, particularly allowing a decision-maker to control the achievable accuracy in the obtained Pareto-optimal solutions.},
author = {Deb, Kalyanmoy and Mohan, Manikanth and Mishra, Shikhar},
doi = {10.1162/106365605774666895},
file = {:Users/timm/svns/doc/05epsilonMoea.pdf:pdf},
isbn = {1063-6560},
issn = {1063-6560},
journal = {Evolutionary computation},
keywords = {-dominance,computational effort,convergence measure,evolutionary algorithms,genetic algorithms,hyper-volume metric,measure,multi-objective optimization,optimal solutions,pareto-,sparsity},
number = {4},
pages = {501--525},
pmid = {16297281},
title = {{Evaluating the epsilon-domination based multi-objective evolutionary algorithm for a quick computation of Pareto-optimal solutions.}},
volume = {13},
year = {2005}
}
@misc{costello05,
author = {Costello, Kenneth},
title = {{Software Integrity Level Assessment Process (\{SILAP\}) , \{NASA\} \{IV\&V\} Facility}},
year = {2005}
}
@article{Lindell2002,
author = {Lindell, Yehuda and Pinkas, Benny},
doi = {10.1007/s00145-001-0019-2},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Lindell - Unknown - Privacy Preserving Data Mining â.pdf:pdf},
issn = {0933-2790},
journal = {Journal of Cryptology},
keywords = {11,an earlier version of,and,data mining,decision trees,most of this work,oblivious polynomial evaluation,oblivious transfer,science and the hebrew,secure two-party computation,the weizmann institute of,this work appeared in,university of jerusalem,was done while at},
month = jun,
number = {3},
pages = {177--206},
title = {{Privacy Preserving Data Mining}},
url = {http://www.springerlink.com/openurl.asp?genre=article\&id=doi:10.1007/s00145-001-0019-2},
volume = {15},
year = {2002}
}
@misc{john96,
annote = {(personal communication)},
author = {Johnson, R},
title = {{No Title}}
}
@inproceedings{Ester1996a,
author = {Ester, Martin and Kriegel, H.P. and Sander, J\"{o}rg and Xu, Xiaowei},
booktitle = {Proceedings of the 2nd International Conference on Knowledge Discovery and Data mining},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Ester et al. - 1996 - A density-based algorithm for discovering clusters in large spatial databases with noise.pdf:pdf},
keywords = {arbitrary shape of clus-,clustering algorithms,databases,efficiency on large spatial,handling noise,ters},
pages = {226--231},
publisher = {Portland: AAAI Press},
title = {{A density-based algorithm for discovering clusters in large spatial databases with noise}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:A+Density-Based+Algorithm+for+Discovering+Clusters+in+Large+Spatial+Databases+with+Noise\#0},
volume = {1996},
year = {1996}
}
@article{stukes98,
author = {Stukes, S and Ferens, D},
journal = {Journal of Parametrics},
number = {1},
pages = {77--98},
title = {{Software Cost Model Calibration}},
volume = {18},
year = {1998}
}
@article{Lipkin2008,
abstract = {Increasingly, chemical libraries are being produced which are focused on a biological target or group of related targets, rather than simply being constructed in a combinatorial fashion. A screening collection compiled from such libraries will contain multiple analogues of a number of discrete series of compounds. The question arises as to how many analogues are necessary to represent each series in order to ensure that an active series will be identified. Based on a simple probabilistic argument and supported by in-house screening data, guidelines are given for the number of compounds necessary to achieve a "hit", or series of hits, at various levels of certainty. Obtaining more than one hit from the same series is useful since this gives early acquisition of SAR (structure-activity relationship) and confirms a hit is not a singleton. We show that screening collections composed of only small numbers of analogues of each series are sub-optimal for SAR acquisition. Based on these studies, we recommend a minimum series size of about 200 compounds. This gives a high probability of confirmatory SAR (i.e. at least two hits from the same series). More substantial early SAR (at least 5 hits from the same series) can be gained by using series of about 650 compounds each. With this level of information being generated, more accurate assessment of the likely success of the series in hit-to-lead and later stage development becomes possible.},
author = {Lipkin, Michael J and Stevens, Adrian P and Livingstone, David J and Harris, C John},
doi = {10.2174/138620708784911492},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/LipkinStevens08.pdf:pdf},
isbn = {1386-2073},
issn = {13862073},
journal = {Combinatorial chemistry \& high throughput screening},
keywords = {chemotype,combinatorial chemistry,diversity,hit rate,library size,parallel array,series,structure activity rela-},
number = {6},
pages = {482--493},
pmid = {18673276},
title = {{How large does a compound screening collection need to be?}},
volume = {11},
year = {2008}
}
@inproceedings{mans91,
author = {Mansuri, Y and Compton, P and Sammut, C},
booktitle = {Australian workshop on knowledge acquisition for knowledge based systems, Pokolbin},
editor = {Boose, J and Debenham, J and Gaines, B and Quinlan, J},
pages = {114--132},
publisher = {University of Technology, Sydney},
title = {{A comparison of a manual knowledge acquisition method and an inductive learning method}},
year = {1991}
}
@inproceedings{ceruti00,
author = {Ceruti, M and Anken, C and Lin, A and Rubin, S},
booktitle = {Proceedings of IEEE Systems Man and Cybernetics},
title = {{Applications of High-Performance Knowledge-Based Technology}},
year = {2000}
}
@inproceedings{me00r,
author = {Menzies, T and Easterbrook, S and Nuseibeh, B and Waugh, S},
booktitle = {Submitted for journal review},
title = {{Validating Inconsistent Requirements Models using Graph-based Abduction}},
year = {2001}
}
@inproceedings{sjoberg07,
author = {Sjoberg, D and {aand B. Anda}, T Byba and Hannay, J},
booktitle = {Guide to Advanced Empirical Software Engineering},
editor = {{F. Shull J. Singer} and Sjoberg, D},
pages = {312--336},
publisher = {Spring},
title = {{Building Theories in Software Engineering}},
year = {2007}
}
@inproceedings{fea99,
author = {Feather, M and Smith, B},
booktitle = {Proceedings of the Fourteenth IEEE International Conference on Automated Software Engineering (ASE-99), Cocoa Beach, Florida},
month = oct,
pages = {63--72},
title = {{Automatic Generation of Test Oracles: From Pilot Studies to Applications}},
year = {1999}
}
@inproceedings{clarke91,
author = {{H.H. Clarke}, S Brennan},
booktitle = {Perspectives on Socially Shared Cognition},
publisher = {American Psychological Association},
title = {{Grounding in Communication}},
year = {1991}
}
@inproceedings{mega94,
author = {Menzies, T J and Gambetta, W},
booktitle = {ECAI '94 Workshop on Validation of Knowledge-Based Systems},
title = {{Exhaustive \{A\}bduction: A \{P\}ractical \{M\}odel \{V\}alidation \{T\}ool}},
year = {1994}
}
@inproceedings{me96n,
author = {Menzies, T},
booktitle = {Proceedings of the ECAI '96 workshop on Validation, Verification, and Refinement of KBS},
title = {{Generalised Test = Generalised Inference}},
year = {1996}
}
@inproceedings{kakas98,
author = {Kakas, A C and Kowalski, R A and Toni, F},
booktitle = {Handbook of Logic in Artificial Intelligence and Logic Programming 5},
editor = {{D.M. Gabbay}, C J Hogger and Robinson, J A},
pages = {235--324},
publisher = {Oxford University Press},
title = {{The Role of Abduction in Logic Programming}},
year = {1998}
}
@article{Parnas72,
author = {Parnas, D},
file = {:Users/timm/svns/doc/72parnas.pdf:pdf},
journal = {Communications of the ACM},
month = dec,
number = {12},
pages = {1053--1058},
title = {{On the Criteria to be Used in Decomposing Systems into Modules}},
volume = {5},
year = {1972}
}
@article{brown85,
author = {Brown, M B and Sedgewick, R},
journal = {IEEE Software},
month = jan,
pages = {28--39},
title = {{Techniques for Algorithm Animation}},
year = {1985}
}
@article{Kiernan,
author = {Kiernan, J. and Xu, Y.},
doi = {10.1109/ICDE.2003.1260824},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Kiernan, Road, Jose - Unknown - Implementing P3P Using Database Technology.pdf:pdf},
isbn = {0-7803-7665-X},
journal = {Proceedings 19th International Conference on Data Engineering (Cat. No.03CH37405)},
pages = {595--606},
publisher = {Ieee},
title = {{Implementing P3P using database technology}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1260824}
}
@misc{bsc99,
author = {Page, Web},
title = {{No Title}}
}
@article{wallace68,
author = {Wallace, C S and Boulton, D M},
journal = {Computer Journal},
pages = {185--194},
title = {{An Information Measure for Classification}},
volume = {vol 11.2},
year = {1968}
}
@misc{lowry99,
author = {Lowry, M},
title = {{Personnel communication}},
year = {1999}
}
@inproceedings{weissgerber07,
author = {Weissgerber, P and Pohl, M and Burch, M},
booktitle = {Mining Software Repositories, 2007. ICSE Workshops MSR '07. Fourth International Workshop on},
doi = {10.1109/MSR.2007.34},
month = may,
pages = {9},
title = {{Visual Data Mining in Software Archives to Detect How Developers Work Together}},
year = {2007}
}
@book{Witten05,
address = {Los Altos, US},
author = {Witten, Ian H and Frank, Eibe},
publisher = {Morgan Kaufmann},
title = {{Data mining. 2nd edition}},
year = {2005}
}
@book{Bloom1956,
annote = {unread},
author = {Bloom, B},
publisher = {David McKay, New York},
title = {{Taxonomy of Educational Objectives: Handbook I: Cognitive Domain}},
year = {1956}
}
@article{Oliveira2001a,
author = {Oliveira, Stanley R M},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Oliveira - 2001 - Privacy Preserving Frequent Itemset Mining.pdf:pdf},
journal = {Reproduction},
keywords = {assosiation rule mining,frequent itemset mining,ing data mining,privacy preserv-,privacy preservation in association,rule mining,security},
title = {{Privacy Preserving Frequent Itemset Mining}},
year = {2001}
}
@article{kemerer87,
author = {Kemerer, C F},
file = {:Users/timm/svns/doc/cost/87Kemerer.pdf:pdf},
journal = {Communications of the ACM},
month = may,
number = {5},
pages = {416--429},
title = {{An Empirical Validation of Software Cost Estimation Models}},
volume = {30},
year = {1987}
}
@article{console91,
author = {Console, L and Torasso, P},
journal = {Computational Intelligence},
pages = {133--141},
title = {{A \{S\}pectrum of \{D\}efinitions of \{M\}odel-\{B\}ased \{D\}iagnosis}},
volume = {7},
year = {1991}
}
@article{betta95,
author = {Betta, G and D'Apuzzo, M and Pietrosanto, A},
journal = {IEEE Transactions of Instrumentation and Measurement},
month = dec,
number = {6},
pages = {1016--1109},
title = {{A Knowledge-Based Approach to Instrument Fault Detection and Isolation}},
volume = {44},
year = {1995}
}
@article{Clark1998,
abstract = {The COCOMO II model was created to meet the need for a cost model
that accounted for future software development practices. This paper
describes some of the experiences learned in calibrating COCOMO II
Post-Architecture model from eighty-three observations. The results of
the multiple regression analysis, their implications, and a future
calibration strategy are discussed},
author = {Clark, B. and Devnani-Chulani, S. and Boehm, B.},
doi = {10.1109/ICSE.1998.671610},
file = {:Users/timm/svns/doc/cost/98Sunita.pdf:pdf},
isbn = {0-8186-8368-6},
issn = {0270-5257},
journal = {Proceedings of the 20th International Conference on Software Engineering},
keywords = {cocomo ii,cost estimation,metrics,multiple regression},
title = {{Calibrating the COCOMO II Post-Architecture model}},
year = {1998}
}
@article{free90,
author = {Freeman-Benson, B N and Maloney, J and Borning, A},
journal = {Communications of the ACM},
pages = {54--63},
title = {{An Incremental Constraint Solver}},
volume = {33},
year = {1990}
}
@inproceedings{me00w,
author = {Menzies, T J},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{Knowledge Elicitation: the State of the Art}},
year = {2002}
}
@article{greeno93,
author = {Greeno, J G and Moore, J L},
journal = {Cognitive Science},
pages = {49--59},
title = {{Situativity and Symbols: Response to Vera and Simon}},
volume = {17},
year = {1993}
}
@article{yip91,
author = {Yip, K M},
journal = {Artificial Intelligence},
pages = {179--221},
title = {{Understanding Complex Dynamics by Visual and Symbolic Reasoning}},
volume = {51},
year = {1991}
}
@inproceedings{Haiduc2012a,
address = {Essen, Germany},
author = {{Haiduc Sonia}, Bavota Gabriele Oliveto Rocco De Lucia Andrea and Marcus, Andrian},
booktitle = {27th IEEE/ACM International Conference on Automated Software Engineering (ASE'12)},
pages = {90--99},
publisher = {ACM},
title = {{Automatic Query Performance Assessment during the Retrieval of Software Artifacts}}
}
@inproceedings{yang11,
author = {Yang, Ye and Xie, Lang and He, Zhimin and Li, Qi and Nguyen, Vu and Boehm, Barry W and Valerdi, Ricardo},
booktitle = {PROMISE},
title = {{Local bias and its impacts on the performance of parametric estimation models}},
year = {2011}
}
@article{Wu1991,
author = {Wu, Shaun-inn},
doi = {10.1145/122438.122440},
file = {:Users/timm/svns/doc/ooprolog/p28-wu.pdf:pdf},
issn = {10556400},
journal = {ACM SIGPLAN OOPS Messenger},
number = {1},
pages = {28--37},
title = {{Integrating logic and object-oriented programming}},
volume = {2},
year = {1991}
}
@article{me00d,
author = {Menzies, Tim and Cukic, Bojan},
doi = {10.1142/S0218213000000112},
issn = {0218-2130},
journal = {International Journal on Artificial Intelligence Tools},
month = jun,
number = {01},
pages = {153--172},
title = {{Adequacy of Limited Testing for Knowledge Based Systems}},
volume = {09},
year = {2000}
}
@book{tecuci98,
author = {Tecuci, G},
publisher = {Academic Press},
title = {{Building Intelligent Agents: An Apprenticeship Multistrategy Learning Theory, Methodology, Tool and Case Studies}},
year = {1998}
}
@article{Zhang2007,
author = {Zhang, Nan},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zhang - 2007 - Privacy-Preserving Data Mining Systems.pdf:pdf},
journal = {Computer},
title = {{Privacy-Preserving Data Mining Systems}},
year = {2007}
}
@misc{briand11,
author = {Briand, L},
title = {{Personnel communication}},
year = {2011}
}
@article{jones99,
author = {Jones, Randolph M and Laird, John E and Nielsen, Paul E and Coulter, Karen J and Kenny, Patrick G and Koss, Frank V},
journal = {AI Magazine},
number = {1},
pages = {27--41},
title = {{Automated Intelligent Pilots for Combat Flight Simulation}},
volume = {20},
year = {1999}
}
@inproceedings{me04h,
abstract = { COCONUT calibrates effort estimation models using an exhaustive search over the space of calibration parameters in a Cocomo I model. This technique is much simpler than other effort estimation method yet yields PRED levels comparable to those other methods. Also, it does so with less project data and fewer attributes (no scale factors). However, a comparison between COCONUT and other methods is complicated by differences in the experimental methods used for effort estimation. A review of those experimental methods concludes that software effort estimation models should be calibrated to local data using incremental holdout (not jack knife) studies, combined with randomization and hypothesis testing, repeated a statistically significant number of times.},
author = {Menzies, T. and Port, D. and Chen, Zhihao Chen Zhihao and Hihn, J.},
booktitle = {Proceedings. 27th International Conference on Software Engineering, 2005. ICSE 2005.},
doi = {10.1109/ICSE.2005.1553605},
isbn = {1-59593-963-2},
title = {{Validation methods for calibrating software effort models}},
year = {2005}
}
@article{DH88,
author = {Harel, D},
journal = {Communications of the ACM},
number = {5},
pages = {514--530},
title = {{On visual formalisms}},
volume = {31},
year = {1988}
}
@article{Mair,
author = {Mair, C. and Shepperd, M.},
doi = {10.1109/ISESE.2005.1541858},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Mair, Shepperd - Unknown - The consistency of empirical comparisons of regression and analogy-based software project cost prediction.pdf:pdf},
isbn = {0-7803-9507-7},
journal = {2005 International Symposium on Empirical Software Engineering, 2005.},
pages = {491--500},
publisher = {Ieee},
title = {{The consistency of empirical comparisons of regression and analogy-based software project cost prediction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1541858}
}
@article{kowal75,
author = {Kowalski, R},
journal = {Journal of the Association for Computing Machinery},
month = oct,
number = {4},
pages = {572--595},
title = {{A Proof Procedure Using Connection Graphs}},
volume = {22},
year = {1975}
}
@misc{sisti94,
annote = {CMU/SEI-94-TR-19},
author = {Sisti, F J and Joseph, S},
institution = {Software Engineering Institute},
month = dec,
title = {{Software Risk Evaluation Method, Version 1}},
year = {1994}
}
@article{Farnstrom00scalabilityfor,
author = {Farnstrom, Fredrik and Lewis, James and Elkan, Charles},
journal = {SIGKDD Explorations},
pages = {51--57},
title = {{Scalability for Clustering Algorithms Revisited}},
volume = {2},
year = {2000}
}
@inproceedings{dinv98,
author = {D'Inverno, M and M., Kinny and D., Luck and Wooldridge, M},
booktitle = {Intelligent Agents IV: Proc. of the Fourth International Workshop on Agent Theories. Architectures and Languages, Springer Verlag},
editor = {Singh, A R and M.Wooldridge},
title = {{A formal specification of dMars}},
year = {1998}
}
@inproceedings{tosun09,
author = {Tosun, A and Bener, A and Turhan, B},
booktitle = {PROMISE'09},
title = {{Practical Considerations of Deploying AI in Defect Prediction: A Case Study within the \{T\}urkish Telecommunication Industry}},
year = {2009}
}
@misc{sullivan05,
author = {Sullivan, K and Shaw, M and Baldwin, C and Jackson, M},
title = {{Panel, ICSE'05: The Science of Design, May 18}},
year = {2005}
}
@article{woolridge95,
author = {Wooldridge, M J and Jennings, N R},
journal = {The Knowledge Engineering Review},
number = {2},
pages = {115--152},
title = {{Intelligent agents: Theory and practice}},
volume = {10},
year = {1995}
}
@article{Dejaeger2013,
author = {Dejaeger, Karel and Verbraken, Thomas and Baesens, Bart},
file = {:Users/timm/svns/doc/xplain/13Dejaeger.pdf:pdf},
number = {2},
pages = {237--257},
title = {{Prediction Models Using Bayesian Network Classifiers}},
volume = {39},
year = {2013}
}
@article{mylo92,
author = {Mylopoulos, J and Chung, L and Nixon, B},
journal = {IEEE Transactions of Software Engineering},
month = jun,
number = {6},
pages = {483--497},
title = {{Representing and Using Nonfunctional Requirements: A Process-Oriented Approach}},
volume = {18},
year = {1992}
}
@article{lim94,
author = {Lim, W},
journal = {IEEE Software},
pages = {23--30},
title = {{Effects of reuse on quality, productivity, and economics}},
year = {1994}
}
@inproceedings{andrews07,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07ase-nighthawk.pdf\}},
author = {Andrews, J H and Li, F C H and Menzies, T},
booktitle = {IEEE ASE'07},
title = {{Nighthawk: A Two-Level Genetic-Random Unit Test Data Generator}},
year = {2007}
}
@book{lim95,
author = {Lim, W C},
publisher = {Prentice Hall},
title = {{Managing Software Reuse}},
year = {1995}
}
@inproceedings{mitchell92hard,
address = {Menlo Park, California},
author = {Mitchell, David G and Selman, Bart and Levesque, Hector J},
booktitle = {Proceedings of the Tenth National Conference on Artificial Intelligence},
editor = {Rosenbloom, Paul and Szolovits, Peter},
pages = {459--465},
publisher = {AAAI Press},
title = {{Hard and Easy Distributions for \{SAT\} Problems}},
year = {1992}
}
@inproceedings{me02o,
author = {Menzies, Tim and Mason, Lindsay},
booktitle = {Proceedings of the 2002 ACM SIGPLAN workshop on Rule-based programming - RULE '02},
doi = {10.1145/570186.570194},
isbn = {1581136064},
keywords = {history,prolog,rule-based programming},
pages = {79--92},
title = {{Some prolog macros for rule-based programming}},
url = {http://portal.acm.org/citation.cfm?doid=570186.570194},
year = {2002}
}
@book{BERGE89,
author = {Berge, Claude},
publisher = {North-Holland},
title = {{Hypergraphs}},
year = {1989}
}
@inproceedings{menzies12,
author = {Menzies, T and Zimmermann, T},
booktitle = {ICSE'12},
pages = {1032--1033},
title = {{Goldfish Bowl Panel: Software Development Analytics}}
}
@article{Seo2010,
abstract = {SELEX (Systematic Evolution of Ligands by Exponential Enrichment) is a procedure by which a mixture of nucleic acids can be fractionated with the goal of identifying those with specific biochemical activities. One combines the mixture with a specific target molecule and then separates the target-NA complex from the resulting reactions. The target-NA complex is separated from the unbound NA by mechanical means (such as by filtration), the NA is eluted from the complex, amplified by PCR (polymerase chain reaction), and the process repeated. After several rounds, one should be left with the nucleic acids that best bind to the target. The problem was first formulated mathematically in Irvine et al. (J. Mol. Biol. 222:739-761, 1991). In Levine and Nilsen-Hamilton (Comput. Biol. Chem. 31:11-25, 2007), a mathematical analysis of the process was given. In Vant-Hull et al. (J. Mol. Biol. 278:579-597, 1998), multiple target SELEX was considered. It was assumed that each target has a single nucleic acid binding site that permits occupation by no more than one nucleic acid. Here, we revisit Vant-Hull et al. (J. Mol. Biol. 278:579-597, 1998) using the same assumptions. The iteration scheme is shown to be convergent and a simplified algorithm is given. Our interest here is in the behavior of the multiple target SELEX process as a discrete "time" dynamical system. Our goal is to characterize the limiting states and their dependence on the initial distribution of nucleic acid and target fraction components. (In multiple target SELEX, we vary the target component fractions, but not their concentrations, as fixed and the initial pool of nucleic acids as a variable starting condition). Given N nucleic acids and a target consisting of M subtarget component species, there is an M Ã N matrix of affinities, the (i,j) entry corresponding to the affinity of the jth nucleic acid for the ith subtarget. We give a structure condition on this matrix that is equivalent to the following statement: For any initial pool of nucleic acids such that all N species are represented, the dynamical system defined by the multiple target SELEX process will converge to a unique subset of nucleic acids, each of whose concentrations depend only upon the total nucleic acid concentration, the initial fractional target distribution (both of which are assumed to be the same from round to round), and the overall limiting association constant. (The overall association constant is the equilibrium constant for the system of MN reactions when viewed as a composite single reaction). This condition is equivalent to the statement that every member of a certain family of chemical potentials at infinite target dilution can have at most one critical point. (The condition replaces the statement for single target SELEX that the dynamical system generated via the process always converges to a pool that contains only the nucleic acid that binds best to the target). This suggests that the effectiveness of multiple target SELEX as a separation procedure may not be as useful as single target SELEX unless the thermodynamic properties of these chemical potentials are well understood.},
author = {Seo, Yeon Jung and Chen, Shiliang and Nilsen-Hamilton, Marit and Levine, Howard a.},
doi = {10.1007/s11538-009-9491-x},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/mathSelex.pdf:pdf},
isbn = {1522-9602 (Electronic)$\backslash$r0092-8240 (Linking)},
issn = {00928240},
journal = {Bulletin of Mathematical Biology},
keywords = {Asymptotic stability,Chemical potential,Discrete dynamical system,Fractionation,SELEX},
number = {7},
pages = {1623--1665},
pmid = {20077028},
title = {{A Mathematical Analysis of Multiple-Target Selex}},
volume = {72},
year = {2010}
}
@article{holte93,
author = {Holte, R C},
journal = {Machine Learning},
pages = {63},
title = {{Very Simple Classification Rules Perform Well on Most Commonly Used Datasets}},
volume = {11},
year = {1993}
}
@article{pazzani97learning,
annote = {Available from$\backslash$url\{citeseer.ist.psu.edu/pazzani97learning.html\}},
author = {Pazzani, Michael J and Billsus, Daniel},
journal = {Machine Learning},
number = {3},
pages = {313--331},
title = {{Learning and Revising User Profiles: The Identification of Interesting Web Sites}},
volume = {27},
year = {1997}
}
@inproceedings{turhan08,
annote = {hW},
author = {Turhan, B and Bener, A and Menzies, T},
booktitle = {Proceedings, DEFECTS 2008},
title = {{Nearest Neighbor Sampling for Cross Company Defect Predictors}},
year = {2008}
}
@incollection{argy08,
author = {Argyriou, A and C.Micchelli and Pontil, M and Ying, Y},
booktitle = {Conf. Neural Information Processing Systems},
file = {:Users/timm/svns/doc/04BlankertzTransfer.pdf:pdf},
pages = {25--32},
title = {{A Spectral Regularization Framework for Multi-Task Structure Learning}},
year = {2008}
}
@book{Fenton1991,
author = {Fenton, N E},
publisher = {Chapman and Hall, London},
title = {{Software Metrics}},
year = {1991}
}
@article{Tsai2009,
abstract = {Many studies have shown that the total cost of employing joint replenishment for correlated items is less than the total cost of using single-item replenishment. Savings increase dramatically when the demand between items is closely related. Although the benefits of joint replenishment are significant, it is difficult to define the demand correlation among items, especially when the number of items increases. A large number of items reduces the efficiency and advantage of the multi-item inventory control. To overcome this difficulty, an association clustering algorithm this paper proposes to evaluate the correlated demands among items. The proposed algorithm utilizes the "support" concept in association rule analysis to measure the similarity among items. Based on these measurements a clustering method is developed to group items with close demand in a hierarchal way. The can-order policy is then applied to the optimal clustering result as decided by the proposed performance index. To illustrate the benefits of the proposed association clustering algorithm for replenishment systems, a set of simulations and a sensitivity analysis is conducted. The results of the experiments show that the proposed method outperforms several replenishment models. ?? 2008 Elsevier B.V. All rights reserved.},
author = {Tsai, Chieh Yuan and Tsai, Chi Yang and Huang, Po W.},
doi = {10.1016/j.ijpe.2008.08.056},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/tsai08.pdf:pdf},
issn = {09255273},
journal = {International Journal of Production Economics},
keywords = {Association clustering,Can-order polices,Inventory management,Joint replenishment},
number = {1},
pages = {30--41},
title = {{An association clustering algorithm for can-order policies in the joint replenishment problem}},
volume = {117},
year = {2009}
}
@article{denno03,
author = {Denno, P and Steves, M P and Libes, D and Barkmeyer, E J},
journal = {IEEE Software},
number = {5},
pages = {59--63},
title = {{Model-Drven Integration Using Existing Models}},
volume = {20},
year = {2003}
}
@article{madachy97,
author = {Madachy, R},
journal = {IEEE Software},
month = may,
number = {3},
pages = {51--59},
title = {{Heuristic Risk Assessment Using Cost Factors}},
volume = {14},
year = {1997}
}
@inproceedings{jalali08,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08keys.pdf\}},
author = {Jalali, O and Menzies, T and Feather, M},
booktitle = {Proceedings of the PROMISE 2008 Workshop (ICSE)},
title = {{Optimizing Requirements Decisions With KEYS}},
year = {2008}
}
@inproceedings{KORU2005,
address = {New York, NY, USA},
author = {Koru, A G\"{u}nes and Liu, Hongfang},
booktitle = {PROMISE '05: Proceedings of the 2005 workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1083165.1083172},
isbn = {-159593-125-2},
pages = {1--5},
publisher = {ACM},
title = {{An investigation of the effect of module size on defect prediction using static measures}},
year = {2005}
}
@inproceedings{prakash91,
author = {Prakash, G R and Subramanian, E and Mahabala, H N},
booktitle = {Proceedings of the 12th International Joint Conference on Artificial Intelligence (IJCAI'91)},
pages = {3--8},
title = {{A Methodology for Systematic Verification of OPS5-Based AI Applications}},
year = {1991}
}
@inproceedings{deb98c,
author = {Debenham, J},
booktitle = {Proceedings Seventh International Conference on Intelligent Systems ICIS'98, Paris, France, July},
title = {{An Integrated Conceptual Model of Knowledge-Based Systems Simplifies Mainteance}},
year = {1998}
}
@inproceedings{pa94,
author = {Pagnucco, M and Nayak, A C and Foo, N Y},
booktitle = {\{AI\} '94, Australia},
editor = {{C. Zhang}, J Debenham and Lukose, D},
title = {{Abductive \{E\}xpansion: \{A\}bductive \{I\}nference and the \{P\}rocess of \{B\}elief \{C\}hange}},
year = {1994}
}
@article{bryant92,
author = {Bryant, R E},
journal = {ACM Computing Surveys},
month = sep,
number = {3},
title = {{Symbolic Boolean Manipulation with Ordered Binary Decision Diagrams}},
volume = {24},
year = {1992}
}
@article{nich94,
author = {Nicholson, A E and Brady, J M},
journal = {IEEE Transactions on Systems, Man, and Cybernetics},
number = {11},
pages = {1593--1610},
title = {{Dynamic belief networks for discrete monitoring}},
volume = {24},
year = {1994}
}
@article{Xiao2009a,
author = {Xiao, Liang and Hu, Bo and Hederman, Lucy and Lewis, Paul and Dimitrov, Borislav D and Fahey, Tom},
doi = {10.1109/ITI.2009.5196061},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Xiao et al. - 2009 - Towards Knowledge Sharing and Patient Privacy in a Clinical Decision Support System.pdf:pdf},
isbn = {978-953-7138-15-8},
journal = {Proceedings of the ITI 2009 31st International Conference on Information Technology Interfaces},
month = jun,
pages = {99--104},
publisher = {Ieee},
title = {{Towards knowledge sharing and patient privacy in a clinical decision support system}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5196061},
year = {2009}
}
@article{Dietterich2008b,
author = {Dietterich, Thomas G. and Domingos, Pedro and Getoor, Lise and Muggleton, Stephen and Tadepalli, Prasad},
doi = {10.1007/s10994-008-5079-1},
file = {:Users/timm/svns/doc/mlTheNext10years.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {dietterich,editors,g,hendrik blockeel,inductive logic programming,jude shavlik,learning,p,relational learning,statistical relational,structured machine learning,t,tadepalli},
month = aug,
number = {1},
pages = {3--23},
title = {{Structured machine learning: the next ten years}},
url = {http://www.springerlink.com/index/10.1007/s10994-008-5079-1},
volume = {73},
year = {2008}
}
@inproceedings{me13f,
author = {Menzies, Tim},
booktitle = {PROMISE '13},
title = {{Beyond Data Mining; Towards "Idea Engineering"}},
year = {2013}
}
@inproceedings{murph95b,
author = {Murphy, G C and Notkin, D},
booktitle = {ACM SIGSOFT Symposium on the Foundations of Software Engineering (FSE '95)},
title = {{Software Reflexion Models: Bridging the Gap Between Source and High-Level Models}},
year = {1995}
}
@article{Patrikainen2004,
author = {Patrikainen, a. and Mannila, H.},
file = {:Users/timm/svns/doc/erin/references/BinarySparseClustering/Patrikainen04.pdf:pdf},
journal = {\ldots on Clustering High Dimensional Data and its \ldots},
pages = {57--65},
title = {{Subspace clustering of high-dimensional binary data-a probabilistic approach}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.3002\&rep=rep1\&type=pdf},
year = {2004}
}
@article{haye79,
author = {Hayes, P J},
journal = {Frame Conceptions and Text Understanding},
pages = {46--61},
publisher = {Walter de Gruyter and Co.},
title = {{The Logic of Frames}},
year = {1979}
}
@inproceedings{men87,
author = {Menzies, T J and Worral, C},
booktitle = {Proceedings of AI '87},
title = {{Worlds in Prolog}},
year = {1987}
}
@inproceedings{domingos00mining,
author = {Domingos, P and Hulten, G},
booktitle = {Knowledge Discovery and Data Mining},
pages = {71--80},
title = {{Mining high-speed data streams}},
url = {citeseer.ist.psu.edu/domingos00mining.html},
year = {2000}
}
@inproceedings{me02f,
abstract = { Software engineering (SE) truisms capture broadly-applicable principles of software construction. The trouble with truisms is that such general principles may not apply in specific cases. This paper tests the specificity of two SE truisms: (a) increasing software process level is a desirable goal; and (b) it is best to remove errors during the early parts of a software lifecycle. Our tests are based on two well-established SE models: (1) Boehm et.al.'s COCOMO II cost estimation model; and (2) Raffo's discrete event software process model of a software project life cycle. After extensive simulations of these models, the TAR2 treatment learner was applied to find the model parameters that most improved the potential performance of the real-world systems being modelled. The case studies presented here showed that these truisms are clearly sub-optimal for certain projects since other factors proved to be far more critical. Hence, we advise against truism-based process improvement. This paper offers a general alternative framework for model-based assessment of methods to improve software quality: modelling + validation + simulation + sensitivity. That is, after recording what is known in a model, that model should be validated, explored using simulations, then summarized to find the key factors that most improve model behavior.},
author = {Menzies, T. and Raffo, D. and Setamanit, S.-O. and Hu, Ying Hu Ying and Tootoonian, S.},
booktitle = {Proceedings 17th IEEE International Conference on Automated Software Engineering,},
doi = {10.1109/ASE.2002.1115012},
isbn = {0-7695-1736-6},
issn = {1527-1366},
title = {{Model-based tests of truisms}},
year = {2002}
}
@article{Zitzler1999,
author = {Zitzler, E. and Thiele, L.},
doi = {10.1109/4235.797969},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zitzler, Thiele - 1999 - Multiobjective evolutionary algorithms a comparative case study and the strength Pareto approach.pdf:pdf},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {pareto},
mendeley-tags = {pareto},
number = {4},
pages = {257--271},
title = {{Multiobjective evolutionary algorithms: a comparative case study and the strength Pareto approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=797969},
volume = {3},
year = {1999}
}
@article{clancey92,
author = {Clancey, W J},
journal = {Artificial Intelligence},
pages = {1--115},
title = {{Model \{C\}onstruction \{O\}perators}},
volume = {53},
year = {1992}
}
@article{clarke86,
author = {Clarke, E M and Emerson, E A and Sistla, A P},
journal = {ACM Transactions on Programming Languages and Systems},
month = apr,
number = {2},
pages = {244--263},
title = {{Automatic verification of finite-state concurrent systems using temporal logic specifications}},
volume = {8},
year = {1986}
}
@article{bratko95,
author = {Bratko, I and Muggleton, S},
journal = {Communications of the ACM},
number = {11},
pages = {65--70},
title = {{Applications of Inductive Logic Programming}},
volume = {38},
year = {1995}
}
@article{kowa96,
author = {Kowalski, R and Toni, F},
journal = {Artificial Intelligence and Law Journal},
number = {3-4},
pages = {275--296},
title = {{Abstract Argumentation}},
volume = {4},
year = {1996}
}
@misc{wu95b,
author = {Wu, X},
institution = {Department of Software Development, Monash University},
number = {95-1},
title = {{Noise handling with extension matrixes}},
year = {1995}
}
@article{Zabiht1987b,
author = {Zabiht, Ramin and Mcallester, David and Chapman, David},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zabiht, Mcallester, Chapman - 1987 - Non-Deterministic Lisp with Backtracking.pdf:pdf},
journal = {In Practice},
pages = {59--64},
title = {{Non-Deterministic Lisp with Backtracking}},
year = {1987}
}
@inproceedings{me08d,
abstract = {Context: There are many methods that input static code features and output a predictor for faulty code modules. These data mining methods have hit a "performance ceiling"; i.e., some inherent upper bound on the amount of information offered by, say, static code features when identifying modules which contain faults. Objective: We seek an explanation for this ceiling effect. Perhaps static code features have "limited information content"; i.e. their information can be quickly and completely discovered by even simple learners. Method: An initial literature review documents the ceiling effect in other work. Next, using three sub-sampling techniques (under-, over-, and micro-sampling), we look for the lower useful bound on the number of training instances. Results: Using micro-sampling, we find that as few as 50 instances yield as much information as larger training sets. Conclusions: We have found much evidence for the limited information hypothesis. Further progress in learning defect predictors may not come from better algorithms. Rather, we need to be improving the information content of the training data, perhaps with case-based reasoning methods. Copyright 2008 ACM.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ceiling.pdf\}},
author = {Menzies, Tim and Turhan, Burak and Bener, Ayse and Gay, Gregory and Cukic, Bojan and Jiang, Yue},
booktitle = {Proceedings of the 4th international workshop on Predictor models in software engineering - PROMISE '08},
doi = {10.1145/1370788.1370801},
isbn = {9781605580364},
issn = {02705257},
keywords = {Defect prediction,Naive bayes,Over-sampling,Under-sampling},
pages = {47},
title = {{Implications of ceiling effects in defect predictors}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-57049155106\&partnerID=tZOtx3y1},
year = {2008}
}
@inproceedings{me92m,
author = {Mahidadia, a J and Compton, P and Menzies, T J and Sammut, C and Smythe, G a},
booktitle = {AI '92, Horbart, Australia},
publisher = {World-Scientific},
title = {{Inventing Causal Qualitative Models: A Tool for Experimental Research}},
year = {1992}
}
@misc{me95i,
author = {Menzies, T J and Taylor, a},
institution = {Department of Software Development, Monash University},
number = {TR95-36},
title = {{Abduction and Memoing}},
year = {1995}
}
@inproceedings{aranda09,
author = {Aranda, Jorge and Venolia, Gina},
booktitle = {Proceedings of the 31st International Conference on Software Engineering},
pages = {298--308},
series = {ICSE '09},
title = {{The Secret Life of Bugs: Going Past the Errors and Omissions in Software Repositories}},
year = {2009}
}
@article{FreSch97,
author = {Freund, Y and Schapire, R E},
journal = {JCSS: Journal of Computer and System Sciences},
title = {{A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting}},
volume = {55},
year = {1997}
}
@article{deb14,
author = {Deb, K and Jain, H},
doi = {10.1109/TEVC.2013.2281535},
file = {:Users/timm/svns/doc/13nsga-III.pdf:pdf},
issn = {1089-778X},
journal = {Evolutionary Computation, IEEE Transactions on},
keywords = {genetic algorithms;sorting;EMO algorithms;MOEA/D m},
month = aug,
number = {4},
pages = {577--601},
title = {{An Evolutionary Many-Objective Optimization Algorithm Using Reference-Point-Based Nondominated Sorting Approach, Part I: Solving Problems With Box Constraints}},
volume = {18},
year = {2014}
}
@article{meseguer92,
author = {Meseguer, P},
journal = {Artificial Intelligence Communications},
number = {3},
pages = {119--135},
title = {{Towards a Conceptual Framework for Expert System Validation}},
volume = {5},
year = {1992}
}
@article{funt80,
author = {Funt, B V},
journal = {Artificial Intelligence},
pages = {201--230},
title = {{Problem-Solving with Diagrammatic Representations}},
volume = {13},
year = {1980}
}
@book{fenton97,
author = {Fenton, N E and Pfleeger, S L},
publisher = {International Thompson Press},
title = {{Software Metrics: A Rigorous \& Practical Approach}},
year = {1997}
}
@article{me09b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ccwc.pdf\}},
author = {Turhan, B and Menzies, T and Bener, A and Distefano, J},
journal = {Empirical Software Engineering},
number = {2},
pages = {278--290},
title = {{On the Relative Value of Cross-Company and Within-Company Data for Defect Prediction}},
volume = {68},
year = {2009}
}
@article{fenton99,
author = {Fenton, N E and Neil, M},
journal = {IEEE Transactions on Software Engineering},
number = {5},
pages = {675--689},
title = {{A Critique of Software Defect Prediction Models}},
volume = {25},
year = {1999}
}
@inproceedings{keogh05,
address = {Washington, DC, USA},
author = {Keogh, Eamonn and Lin, Jessica and Fu, Ada},
booktitle = {Proceedings of the Fifth IEEE International Conference on Data Mining},
doi = {10.1109/ICDM.2005.79},
isbn = {0-7695-2278-5},
keywords = {Anomaly Detection,Clustering,Time Series Data Mining},
pages = {226--233},
publisher = {IEEE Computer Society},
series = {ICDM '05},
title = {{HOT SAX: Efficiently Finding the Most Unusual Time Series Subsequence}},
url = {http://dx.doi.org/10.1109/ICDM.2005.79},
year = {2005}
}
@inproceedings{ritthoff01,
annote = {Available from $\backslash$url\{http://ls2-www.cs.uni-dortmund.de/\~{}fischer/publications/YaleLLWA01.pdf\}},
author = {Ritthoff, O and Klinkenberg, R and Fischer, S and Mierswa, I and Felske, S},
booktitle = {LLWA 01 - Tagungsband der GI-Workshop-Woche, Dortmund, Germany},
month = oct,
pages = {84--92},
title = {{YALE: Yet Another Learning Environment}},
year = {2001}
}
@article{chulani99,
author = {Chulani, S and Boehm, B and Steece, B},
journal = {IEEE Transaction on Software Engineerining},
number = {4},
title = {{Bayesian Analysis of Empirical Software Engineering Cost Models}},
volume = {25},
year = {1999}
}
@inproceedings{WINKLER2009,
address = {Washington, DC, USA},
author = {Winkler, Stefan},
booktitle = {TEFSE '09: Proceedings of the 2009 ICSE Workshop on Traceability in Emerging Forms of Software Engineering},
doi = {http://dx.doi.org/10.1109/TEFSE.2009.5069583},
isbn = {978-1-4244-3741-2},
pages = {49--56},
publisher = {IEEE Computer Society},
title = {{Trace retrieval for evolving artifacts}},
year = {2009}
}
@article{Knowles1999,
abstract = {Most popular evolutionary algorithms for multiobjective
optimisation maintain a population of solutions from which individuals
are selected for reproduction. In this paper, we introduce a simpler
evolution scheme for multiobjective problems, called the Pareto archived
evolution strategy (PAES). We argue that PAES may represent the simplest
possible non-trivial algorithm capable of generating diverse solutions
in the Pareto optimal set. The algorithm is identified as being a (1+1)
evolution strategy, using local search from a population of one but
using a reference archive of previously found solutions in order to
identify the approximate dominance ranking of the current and candidate
solution vectors. PAES is intended as a good baseline approach, against
which more involved methods may be compared, and may also serve well in
some real-world applications when local search seems superior to or
competitive with population-based methods. The performance of the new
algorithm is compared with that of a MOEA based on the niched Pareto GA
on a real world application from the telecommunications field. In
addition, we include results from experiments carried out on a suite of
four test functions, to demonstrate the algorithm's general capability
},
author = {Knowles, Joshua and Corne, David},
doi = {10.1109/CEC.1999.781913},
file = {:Users/timm/svns/doc/99paes.pdf:pdf},
isbn = {0-7803-5536-9},
issn = {1879-1026},
journal = {Proceedings of the 1999 Congress on Evolutionary Computation, CEC 1999},
pages = {98--105},
pmid = {19520416},
title = {{The Pareto archived evolution strategy: A new baseline algorithm for Pareto multiobjective optimisation}},
volume = {1},
year = {1999}
}
@inproceedings{back91,
address = {San Mateo, CA},
author = {B\"{a}ck, Thomas and Hoffmeister, Frank and Schwefel, Hans-Paul},
booktitle = {Proceedings of the Fourth International Conference on Genetic Algorithms},
editor = {Belew, Rick and Booker, Lashon},
pages = {2--9},
publisher = {Morgan Kaufman},
title = {{A survey of evolution strategies}},
year = {1991}
}
@inproceedings{me08d,
abstract = {Context: There are many methods that input static code features and output a predictor for faulty code modules. These data mining methods have hit a "performance ceiling"; i.e., some inherent upper bound on the amount of information offered by, say, static code features when identifying modules which contain faults. Objective: We seek an explanation for this ceiling effect. Perhaps static code features have "limited information content"; i.e. their information can be quickly and completely discovered by even simple learners. Method: An initial literature review documents the ceiling effect in other work. Next, using three sub-sampling techniques (under-, over-, and micro-sampling), we look for the lower useful bound on the number of training instances. Results: Using micro-sampling, we find that as few as 50 instances yield as much information as larger training sets. Conclusions: We have found much evidence for the limited information hypothesis. Further progress in learning defect predictors may not come from better algorithms. Rather, we need to be improving the information content of the training data, perhaps with case-based reasoning methods. Copyright 2008 ACM.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ceiling.pdf\}},
author = {Menzies, Tim and Turhan, Burak and Bener, Ayse and Gay, Gregory and Cukic, Bojan and Jiang, Yue},
booktitle = {Proceedings of the 4th international workshop on Predictor models in software engineering - PROMISE '08},
doi = {10.1145/1370788.1370801},
isbn = {9781605580364},
issn = {02705257},
keywords = {Defect prediction,Naive bayes,Over-sampling,Under-sampling},
pages = {47},
title = {{Implications of ceiling effects in defect predictors}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-57049155106\&partnerID=tZOtx3y1},
year = {2008}
}
@inproceedings{preece92,
author = {Preece, A D and Shinghal, R},
booktitle = {ECAI '92},
title = {{Verifying Knowledge Bases by Anomaly Detection: An Experience Report}},
year = {1992}
}
@inproceedings{me03n,
author = {Menzies, T and Kiper, J and Feather, M},
booktitle = {SEDECS'2003: the 2nd International Workshop on Software Engineering Decision Support (part of SEKE2003)},
month = jun,
title = {{Improved software engineering decision support through automatic argument reduction tools}},
year = {2003}
}
@article{kuipers91,
author = {Kuipers, B J and Chiu, C and Molle, D T Dalle and Throop, D R},
journal = {Artificial Intelligence},
pages = {343--379},
title = {{Higher-order derivative constraints in qualitative simulation}},
volume = {51},
year = {1991}
}
@article{Gao2010,
author = {Gao, Jing and Fan, Wei and Han, Jiawei},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Gao, Fan, Han - 2010 - On the Power of Ensemble Supervised and Unsupervised Methods Reconciled.pdf:pdf},
journal = {Science},
title = {{On the Power of Ensemble : Supervised and Unsupervised Methods Reconciled *}},
year = {2010}
}
@article{Askira-Gelman1998,
abstract = {Knowledge discovery in databases (KDD) and machine learning
researchers recognize that comprehensibility is an important condition
for the use, and therefore usefulness, of knowledge discovery methods.
An investigation of the comprehensibility of the discovered patterns may
benefit IS research as well. This paper identifies some of the issues
that such inquiry may face. Related findings and conclusions of four
case studies focusing on applications of decision tree induction
methods, are described. A discussion based on these studies suggests,
among the rest, that the problem of comprehensibility is complicated by
a complex context due to a diversity of problem domain attributes, user
and task characteristics, algorithmic methods, and concurrency of user
goals. Solutions to problems of discovered patterns that are not easy to
interpret and validate may involve integration of available information
technologies, and utilization of multiple information types and sources.
An investigation of comprehensibility issues may benefit from the
adoption of multiple definitions in relation to this concept},
author = {Askira-Gelman, I.},
doi = {10.1109/HICSS.1998.648319},
file = {:Users/timm/svns/doc/xplain/98Gelman.pdf:pdf},
isbn = {0-8186-8255-8},
issn = {10603425},
journal = {Proceedings of the Thirty-First Hawaii International Conference on System Sciences},
number = {c},
title = {{Knowledge discovery: comprehensibility of the results}},
volume = {5},
year = {1998}
}
@article{me98b,
abstract = {Situated cognition is not a mere philosophical concern: it has pragmatic implications for current practice in knowledge acquisition. Tools must move from being design-focused to being maintenance-focused. Reuse-based approaches (e.g. using problem-solving methods) will fail unless the reused descriptions can be extensively modified to suit the new situation. Knowledge engineers must model not only descriptions of expert knowledge, but also the environment in which a knowledge base will perform. Descriptions of knowledge must be constantly re-evaluated. This re-evaluation process has implications for assessing representations},
author = {Menzies, T I M},
doi = {10.1006/ijhc.1998.0230},
isbn = {1071-5819},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
number = {6},
pages = {867--893},
title = {{Towards situated knowledge acquisition}},
url = {http://www.sciencedirect.com/science/article/B6WGR-45J548X-6/2/d7a982a694598b232b8c2e7ec4c0263f},
volume = {49},
year = {1998}
}
@inproceedings{bobntim1,
author = {Cohen, R F and Menzies, T J},
booktitle = {Software Education Conference (SRIG-ET'94)},
pages = {71--76},
title = {{Providing \{S\}oftware \{E\}ngineering \{S\}tudents with an \{E\}xperience in "\{B\}ig-\{C\}omputing"}},
year = {1995}
}
@article{me97zg,
author = {Menzies, T},
journal = {The Knowledge Engineering Review},
number = {1},
pages = {1--46},
title = {{Knowledge Maintenance: The State of the Art}},
volume = {14},
year = {1999}
}
@inproceedings{me00r,
author = {Menzies, T and Easterbrook, S and Nuseibeh, B and Waugh, S},
booktitle = {Submitted for journal review},
title = {{Validating Inconsistent Requirements Models using Graph-based Abduction}},
year = {2001}
}
@misc{mills13,
annote = {From $\backslash$url\{http://www.tech-pundit.com/wp-content/uploads/2013/07/Cloud\_Begins\_With\_Coal.pdf?c761ac\}},
author = {Mills, Mark},
month = aug,
title = {{Big Data, Big Networks, Big Infrastructure, and Big Power}},
year = {2013}
}
@incollection{Poole87,
author = {Poole, David and Goebel, Randy and Aleliunas, Romas},
booktitle = {The Knowledge Frontier: Essays in the Representation of Knowledge},
editor = {Cercone, N J and McCalla, G},
pages = {331--352},
publisher = {Springer Verlag},
title = {{Theorist: a logical reasoning system for defaults and diagnosis}},
year = {1987}
}
@inproceedings{SARCIA2009,
address = {Washington, DC, USA},
author = {Sarcia, Salvatore Alessandro and Basili, Victor Robert and Cantone, Giovanni},
booktitle = {ESEM '09: Proceedings of the 2009 3rd International Symposium on Empirical Software Engineering and Measurement},
doi = {http://dx.doi.org/10.1109/ESEM.2009.5316020},
isbn = {978-1-4244-4842-5},
pages = {123--132},
publisher = {IEEE Computer Society},
title = {{Scope error detection and handling concerning software estimation models}},
year = {2009}
}
@article{Strouthidis2010,
abstract = {To evaluate the reproducibility of the Heidelberg retina tomograph (HRT) Glaucoma Probability Score (GPS) and assess its potential for monitoring progression.},
author = {Strouthidis, Nicholas G and Demirel, Shaban and Asaoka, Ryo and Cossio-Zuniga, Claudio and Garway-Heath, David F},
doi = {10.1016/j.ophtha.2009.09.036},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Strouthidis et al. - 2010 - The Heidelberg retina tomograph Glaucoma Probability Score reproducibility and measurement of progression.pdf:pdf},
issn = {1549-4713},
journal = {Ophthalmology},
keywords = {Adult,Aged,Aged, 80 and over,Diagnostic Techniques, Ophthalmological,Disease Progression,Female,Glaucoma, Open-Angle,Glaucoma, Open-Angle: diagnosis,Glaucoma, Open-Angle: physiopathology,Humans,Intraocular Pressure,Intraocular Pressure: physiology,Male,Middle Aged,Observer Variation,Ocular Hypertension,Ocular Hypertension: diagnosis,Ocular Hypertension: physiopathology,Probability,Reproducibility of Results,Sensitivity and Specificity,Tomography,Tomography: methods,Visual Fields,Visual Fields: physiology,Young Adult},
month = apr,
number = {4},
pages = {724--9},
pmid = {20045564},
title = {{The Heidelberg retina tomograph Glaucoma Probability Score: reproducibility and measurement of progression.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20045564},
volume = {117},
year = {2010}
}
@article{me08a,
abstract = {Abstract  After data mining National Aeronautics and Space Administration (NASA) independent verification and validation (IV\&V) data,$\backslash$n  we offer (a) an early life cycle predictor for project issue frequency and severity; (b) an IV\&V task selector (that used$\backslash$n  the predictor to find the appropriate IV\&V tasks); and (c) pruning heuristics describing what tasks to ignore, if the budget$\backslash$n  cannot accommodate all selected tasks. In ten-way cross-validation experiments, the predictor performs very well indeed: the$\backslash$n  average f-measure for predicting four classes of issue severity was over 0.9. This predictor is built using public-domain data and$\backslash$n  software. To the best of our knowledge, this is the first reproducible report of a predictor for issue frequency and severity$\backslash$n  that can be applied early in the life cycle.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07ivv.pdf\}},
author = {Menzies, Tim and Benson, Markland and Costello, Ken and Moats, Christina and Northey, Melissa and Richardson, Julian},
doi = {10.1007/s11334-008-0046-3},
issn = {16145046},
journal = {Innovations in Systems and Software Engineering},
keywords = {Data mining,Early life cycle defect prediction,IV\&V,NASA},
month = mar,
number = {2},
pages = {169--183},
title = {{Learning better IV\&V practices}},
volume = {4},
year = {2008}
}
@article{durillo11,
author = {Durillo, Juan J and Zhang, Yuanyuan and Alba, Enrique and Harman, Mark and Nebro, Antonio J},
journal = {Empirical Softw. Engg.},
month = feb,
number = {1},
pages = {29--60},
publisher = {Kluwer Academic Publishers},
title = {{A study of the bi-objective next release problem}},
year = {2011}
}
@inproceedings{me04e,
author = {Menzies, T and Pecheur, C},
booktitle = {Advances in Computing},
editor = {Zelkowtiz, M},
publisher = {Elsevier},
title = {{Verification and \{V\}alidation and \{A\}rtificial \{I\}ntelligence}},
volume = {65},
year = {2005}
}
@article{Proske2005,
abstract = {Since its discovery in the early 1990s, aptamer technology has progressed tremendously. Automated selection procedures now allow rapid identification of DNA and RNA sequences that can target a broad range of extra- and intracellular proteins with nanomolar affinities and high specificities. The unique binding properties of nucleic acids, which are amenable to various modifications, make aptamers perfectly suitable for different areas of biotechnology. Moreover, the approval of an aptamer for vascular endothelial growth factor by the US Food and Drug Administration highlights the potential of aptamers for therapeutic applications. This review summarizes recent developments and demonstrates that aptamers are valuable tools for diagnostics, purification processes, target validation, drug discovery, and even therapeutic approaches.},
author = {Proske, Daniela and Blank, Michael and Buhmann, Raymund and Resch, Ansgar},
doi = {10.1007/s00253-005-0193-5},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Proske05.pdf:pdf},
issn = {01757598},
journal = {Applied Microbiology and Biotechnology},
number = {4},
pages = {367--374},
pmid = {16283295},
title = {{Aptamers - Basic research, drug development, and clinical applications}},
volume = {69},
year = {2005}
}
@misc{Sayyad-Shirabad+Menzies:2005,
author = {{Sayyad Shirabad, J., Menzies}, T.J.},
booktitle = {University of Ottawa, Canada .},
howpublished = {School of Information Technology and Engineering, University of Ottawa, Canada},
title = {{The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering}},
url = {http://promise.site.uottawa.ca/SERepository},
year = {2005}
}
@inproceedings{men92s,
author = {Menzies, T J and Compton, P and Feldman, B and Toft, T},
booktitle = {Proceedings of the AAAI Symposium on Diagrammatic Reasoning Stanford University, March 25-27},
title = {{Qualitative Compartmental Modeling}},
year = {1992}
}
@article{provost01,
author = {Provost, F and Fawcett, T},
journal = {Machine Learning},
month = mar,
number = {3},
title = {{Robust Classification for Imprecise Environments}},
volume = {42},
year = {2001}
}
@inproceedings{me99g,
author = {Menzies, T and Michael, C C},
booktitle = {SEKE '99, June 17-19, Kaiserslautern, Germany.},
title = {{Fewer Slices of PIE: Optimising Mutation Testing via Abduction}},
year = {1999}
}
@article{furnkranz05,
address = {Hingham, MA, USA},
author = {F\"{u}rnkranz, Johannes and Flach, Peter A},
doi = {http://dx.doi.org/10.1007/s10994-005-5011-x},
issn = {0885-6125},
journal = {Machine Learning},
number = {1},
pages = {39--77},
publisher = {Kluwer Academic Publishers},
title = {{ROC 'n' rule learning: towards a better understanding of covering algorithms}},
volume = {58},
year = {2005}
}
@article{chandra83,
author = {Chandrasekaran, B},
journal = {AI Magazine},
pages = {9--17},
title = {{Towards a \{T\}axonomy of \{P\}roblem \{S\}olving \{T\}ypes}},
year = {1983}
}
@misc{feh12,
annote = {From $\backslash$url\{http://gigaom.com/2012/01/31/the-era-of-the-100-mw-data-center/\}},
author = {Febrenbacher, K},
month = jan,
title = {{The era of the 100 MW data center}},
year = {2012}
}
@article{Takahashi2006,
abstract = {Models for numerical simulations should be described in a coherent style. They are expected to have consistencies at the causal dependency level. However, System Dynamics causal loop diagrams can have inconsistencies. This diagram styleâs arrows, concerning flow and stock relationships, can have the opposite direction of stock flow diagrams which can numerically simulate models. These inconsistencies can cause inappropriate qualitative simulations so that it is sometimes recommended to use stock flow diagrams instead of causal loop diagrams even for qualitative simulations. However, causal loop diagrams have merits in their use. Causal loop diagrams are intuitively easy to draw and read. If causal loop diagrams are given information about each variableâs dynamic property, they can be changed to stock flow diagrams and simulation models can be generated. This paper suggests how to use causal loop diagrams as a starting point in numerical simulation research.},
author = {Takahashi, Yutaka},
file = {:Users/timm/svns/doc/optimalML/06takModelingWithIncomplete.pdf:pdf},
journal = {Proceedings of the 24th International Conference of the System Dynamics Society},
keywords = {automatic modelling,natural language,stock flow diagram},
pages = {122},
title = {{Stock Flow Diagram Making with Incomplete Information about Time Properties of Variables}},
year = {2006}
}
@article{boehm87,
author = {Boehm, B},
journal = {IEEE Software},
number = {5},
title = {{Industrial software metrics top 1O list}},
volume = {4},
year = {1987}
}
@article{chandra90,
author = {Chandrasekaran, B},
journal = {\{AI\} Magazine},
pages = {59--71},
title = {{Design Problem Solving: A Task Analysis}},
year = {1990}
}
@inproceedings{parkes97clustering,
author = {Parkes, A J},
booktitle = {\{AAAI\}/\{IAAI\}},
pages = {340--345},
title = {{Clustering at the Phase Transition}},
year = {1997}
}
@techreport{turhan11,
author = {Turhan, Burak},
institution = {Department of Information Processing Science, University of Oulu},
title = {{Technical Report: Conclusion Stability and OO Defect Predictors}},
year = {2011}
}
@inproceedings{biere99:bmc,
author = {Biere, A and Cimatti, A and Clarke, E M and Zhu, Y},
booktitle = {In Proceedings of Tools and Algorithms for the Analysis and Construction of Systems},
month = may,
pages = {193207},
title = {{Symbolic model checking without BDDs}},
year = {1999}
}
@article{eveleens10,
author = {{Laurenz Eveleens}, Johan and Verhoef, Chris},
issn = {0740-7459},
journal = {IEEE Softw.},
month = jan,
number = {1},
pages = {30--36},
publisher = {IEEE Computer Society Press},
title = {{The Rise and Fall of the Chaos Report Figures}},
volume = {27},
year = {2010}
}
@article{Plasse2007,
abstract = {A method to analyse links between binary attributes in a large sparse data set is proposed. Initially the variables are clustered to obtain homogeneous clusters of attributes. Association rules are then mined in each cluster. A graphical comparison of some rule relevancy indexes is presented. It is used to extract best rules depending on the application concerned. The proposed methodology is illustrated by an industrial application from the automotive industry with more than 80 000 vehicles each described by more than 3000 rare attributes. Â© 2007 Elsevier B.V. All rights reserved.},
author = {Plasse, Marie and Niang, Ndeye and Saporta, Gilbert and Villeminot, Alexandre and Leblond, Laurent},
doi = {10.1016/j.csda.2007.02.020},
file = {:Users/timm/svns/doc/erin/references/BinarySparseClustering/Plasse07.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {Association rules mining,Binary attributes,Large sparse matrix,Rule relevancy index,Variable clustering},
number = {1},
pages = {596--613},
title = {{Combined use of association rules mining and clustering methods to find relevant links between binary rare attributes in a large data set}},
volume = {52},
year = {2007}
}
@article{cend87,
author = {Cendrowska, J},
journal = {International Journal of Man-Machine Studies},
number = {4},
pages = {349--370},
title = {{PRISM: An Algorithm for Inducing Modular Rules}},
volume = {27},
year = {1987}
}
@misc{ang93,
author = {Angele, J},
howpublished = {Infix, St. Augustin},
title = {{Operationalisierung des Models der Expertise mit KARL Operationalisierung des Models der Expertise mit KARL}},
year = {1993}
}
@article{arthur99,
author = {Arthur, J D and Groner, M K and Hayhurst, K J and Holloway, C M},
journal = {IEEE Computer},
month = oct,
pages = {79--83},
title = {{Evaluating the Effectiveness of Independent Verification and Validation}},
year = {199}
}
@book{Fulkerson1995,
author = {Fulkerson, Bill and Michie, D. and Spiegelhalter, D. J. and Taylor, C. C.},
booktitle = {Technometrics},
doi = {10.2307/1269742},
file = {:Users/timm/svns/doc/statlog.pdf:pdf},
issn = {00401706},
month = nov,
number = {4},
pages = {459},
title = {{Machine Learning, Neural and Statistical Classification}},
url = {http://www.jstor.org/stable/1269742?origin=crossref},
volume = {37},
year = {1995}
}
@inproceedings{owen01,
author = {Owen, D and Menzies, T},
booktitle = {Proceedings of the First International Workshop on Model-based Requirements Engineering},
title = {{Random Search of AND-OR Graphs Representing Finite-State Models}},
year = {2001}
}
@article{me96a,
author = {Menzies, T J},
journal = {International Journal of Human Computer Studies},
pages = {305--355},
title = {{Applications of Abduction: Knowledge Level Modeling}},
volume = {45},
year = {1996}
}
@article{kern84,
author = {Kernigham, B W},
journal = {IEEE Transactions on Software Engineering},
pages = {513--518},
title = {{The Unix System and Software Reusability}},
volume = {SE-10},
year = {1984}
}
@inproceedings{zdrahal96,
author = {Zdrahal, Z and Motta, E},
booktitle = {10th Banff Knowledge Acquisition for Knowledge-Based Systems Workshop, November 9-14, 1996, Banff, Canada},
title = {{Improving Conpetence by Intergrating Case-Based Reasoning and Heuristic Search}},
year = {1996}
}
@inproceedings{vante97,
author = {van Harmelen, F and ten Teije, Annette},
booktitle = {European Symposium on the Validation and Verification of Knowledge Based Systems, Leuven, Belgium},
title = {{Validation and Verification of Conceptual Models of Diagnosis}},
year = {1997}
}
@inproceedings{meesad02,
author = {Meesad, P and Yen, G G},
booktitle = {Fuzzy Systems, 2002. FUZZ-IEEE'02. Proceedings of the 2002 IEEE International Conference on},
doi = {10.1109/FUZZ.2002.1005001},
file = {:Users/timm/svns/doc/xplain/02meesad.pdf:pdf},
pages = {284--289},
title = {{Quantitative measures of the accuracy, comprehensibility, and completeness of a fuzzy expert system}},
volume = {1},
year = {2002}
}
@phdthesis{Hall98,
author = {Hall., M A},
school = {Department of Computer Science, University of Waikato, Hamilton, New Zealand},
title = {{Correlation-based feature selection for machine learning}},
year = {1998}
}
@article{Warninga,
author = {Warning, Notice and Copyright, Concerning},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Warning, Copyright - Unknown - Notice warning concerning copyright restrictions.pdf:pdf},
title = {{Notice warning concerning copyright restrictions}}
}
@article{nus94,
author = {Nuseibeh, B and Kramer, J and Finkelstein, A C W},
journal = {IEEE Transactions on Software Engineering},
number = {10},
pages = {760--773},
title = {{A Framework for Expressing the Relationships Between Multiple Views in Requirements Specification}},
volume = {20},
year = {1994}
}
@article{Devnani-Chulani1998,
abstract = {This paper describes the calibration process$\backslash$nincorporated and summarizes the results obtained. The$\backslash$nEarly Design Model calibration is obtained by$\backslash$naggregating the calibrated Effort Multipliers of the$\backslash$nPost-Architecture Model as described in [USC-CSE1]. The$\backslash$nScale Factor calibration is the same in both the$\backslash$nmodels. The Applications Composition Model has not yet$\backslash$nbeen calibrated due to limitations in the availability$\backslash$nof project data. This paper describes our experience$\backslash$nand results of the first calibration of the$\backslash$nPostArchitecture model. The model determination process$\backslash$nbegan with an expert Delphi process to determine$\backslash$napriori values for the PostArchitecture model$\backslash$nparameters. A dataset of 83 projects was used in the$\backslash$nmultiple regression analysis. Projects with missing$\backslash$ndata or unexplainable anomalies were dropped. Model$\backslash$nparameters that exhibited high correlation were$\backslash$nconsolidated. Multiple regression analysis was used to$\backslash$nproduce coefficients. These coefficients were used to$\backslash$nadjust the previously assigned expertdetermined model$\backslash$nvalues. Stratification was used to improve model$\backslash$naccuracy. The resulting model produced estimates within$\backslash$n30\% of the actuals 52\% of the time for effort.$\backslash$nStratification by organization resulted in a model that$\backslash$nproduced estimates within 30\% of the actuals 64\% of the$\backslash$ntime for effort. It is therefore recommended that$\backslash$norganizations using the model calibrate it using their$\backslash$nown data. This increases model accuracy and produces a$\backslash$nlocal optimum estimate for similar type projects.$\backslash$nSection 2 of this paper describes the data used for$\backslash$ncalibration. Section 3 describes the calibration$\backslash$nprocedures, results, and future calibration strategy.},
author = {Devnani-Chulani, Sunita and Clark, Brad and Boehm, Barry and Steece, Bert},
file = {:Users/timm/svns/doc/cost/98Sunitaispapres.pdf:pdf},
journal = {Proceedings of the 20th},
title = {{Calibration approach and results of the COCOMO II postâarchitecture model}},
url = {http://sunset.usc.edu/Research\_Group/Sunita/down/ispadoc.pdf},
year = {1998}
}
@inproceedings{macdonell10a,
author = {MacDonell, Stephen G and Shepperd, Martin},
booktitle = {Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {31:1----31:4},
series = {ESEM '10},
title = {{Data accumulation and software effort prediction}},
year = {2010}
}
@inproceedings{conf/icse/NagappanB05a,
author = {Nagappan, Nachiappan and Ball, Thomas},
booktitle = {ICSE},
pages = {580--586},
title = {{Static analysis tools as early indicators of pre-release defect density}},
url = {http://doi.acm.org/10.1145/1062558},
year = {2005}
}
@book{darden91,
author = {Darden, L},
isbn = {0-19-506797-5},
publisher = {Oxford University Press},
title = {{Theory Change in Science: Strategies from Mendelian Genetics}},
year = {1991}
}
@inproceedings{Bird2009a,
author = {Bird, Christian and Nagappan, Nachiappan and Devanbu, Premkumar and Gall, Harald and Murphy, Brendan},
booktitle = {2009 IEEE 31st International Conference on Software Engineering},
doi = {10.1109/ICSE.2009.5070550},
file = {:Users/timm/svns/doc/bird09icse.pdf:pdf},
isbn = {978-1-4244-3453-4},
month = may,
pages = {518--528},
publisher = {Ieee},
title = {{Does distributed development affect software quality? An empirical case study of Windows Vista}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5070550},
year = {2009}
}
@misc{wyatt12,
author = {Wyatt, Patrick},
month = dec,
title = {{Whose bug is this anyway?!? $\backslash$url\{http://www.codeofhonor.com/blog/whose-bug-is-this-anyway\}}},
year = {2012}
}
@inproceedings{me04d,
author = {Owen, D and Menzies, T},
booktitle = {IEEE Trans. Sofw. Eng. (in preperation)},
title = {{Random Serial World Generation}},
year = {2004}
}
@article{Deutsch,
author = {Deutsch, Alin and Papakonstantinou, Yannis},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Deutsch, Papakonstantinou - Unknown - Privacy in Database Publishing.pdf:pdf},
title = {{Privacy in Database Publishing}}
}
@article{wino87,
author = {Winograd, T and Flores, F},
journal = {Artificial Intelligence},
pages = {250--261},
title = {{On Understanding Computers and Cognition: A New Foundation for Design: A respose to the reviews.}},
volume = {31},
year = {1987}
}
@inproceedings{easter00,
author = {Easterbrook, S and Chechik, M},
booktitle = {ICSE 2001},
title = {{Framework for Multi-Valued Reasoning over Inconsistent Viewpoints}},
year = {2001}
}
@article{Hall2011,
abstract = {Background: The accurate prediction of where faults are likely to occur in code can help direct test effort, reduce costs and improve the quality of software. Objective: We investigate how the context of models, the independent variables used and the modelling techniques applied, influence the performance of fault prediction models. Method:We used a systematic literature review to identify 208 fault prediction studies published from January 2000 to December 2010. We synthesise the quantitative and qualitative results of 36 studies which report sufficient contextual and methodological information according to the criteria we develop and apply. Results: The models that perform well tend to be based on simple modelling techniques such as Na??ve Bayes or Logistic Regression. Combinations of independent variables have been used by models that perform well. Feature selection has been applied to these combinations when models are performing particularly well. Conclusion: The methodology used to build models seems to be influential to predictive performance. Although there are a set of fault prediction studies in which confidence is possible, more studies are needed that use a reliable methodology and which report their context, methodology and performance comprehensively.},
author = {Hall, T and Beecham, S and Bowes, D and Gray, D and Counsell, S},
doi = {10.1109/TSE.2011.103},
file = {:Users/timm/svns/doc/11hall.pdf:pdf},
issn = {0098-5589},
journal = {Software Engineering, IEEE Transactions on},
number = {99},
pages = {1},
title = {{A Systematic Review of Fault Prediction Performance in Software Engineering}},
volume = {PP},
year = {2011}
}
@inproceedings{queen67,
author = {MacQueen, J B},
booktitle = {Proceedings of 5th Berkeley Symposium on Mathematical Statistics and Probability},
pages = {281--297},
title = {{Some Methods for classification and Analysis of Multivariate Observations}},
year = {1967}
}
@inproceedings{fayyad97,
author = {Fayyad, U},
booktitle = {Proceedings on Ninth International Conference on Scientific and Statistical Database Management},
pages = {2--11},
title = {{Data mining and knowledge discovery in databases: implications for scientific databases}},
year = {1997}
}
@inproceedings{LIEBCHEN08,
address = {New York, NY, USA},
author = {Liebchen, Gernot A and Shepperd, Martin},
booktitle = {PROMISE '08: Proceedings of the 4th international workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1370788.1370799},
isbn = {978-1-60558-036-4},
pages = {39--44},
publisher = {ACM},
title = {{Data sets and data quality in software engineering}},
year = {2008}
}
@inproceedings{offut89,
author = {Offut, A J},
booktitle = {Proc. Third Symposium on Software Testing, Analysis, and Verification},
pages = {131--140},
publisher = {ACM Press},
title = {{The Coupling Effect: Fact or Fiction?}},
year = {1989}
}
@inproceedings{madachy94,
author = {Madachy, R},
booktitle = {Proceedings Ninth Knowledge-Based Software Engineering Conference},
pages = {172--178},
title = {{Knowledge-based risk assessment and cost estimation}},
year = {1994}
}
@inproceedings{me12b,
author = {Menzies, Tim and Zimmermann, Thomas},
booktitle = {ICSE},
pages = {1032--1033},
title = {{Goldfish bowl panel: Software development analytics}},
year = {2012}
}
@article{kitchenham97,
address = {Los Alamitos, CA, USA},
author = {Kitchenham, Barbara and Linkman, Stephen},
doi = {http://dx.doi.org/10.1109/52.589239},
issn = {0740-7459},
journal = {IEEE Softw.},
number = {3},
pages = {69--74},
publisher = {IEEE Computer Society Press},
title = {{Estimates, Uncertainty, and Risk}},
volume = {14},
year = {1997}
}
@article{gomez96,
author = {Gomez-Perez, A},
journal = {Expert Systems with Applications},
number = {4},
pages = {519--529},
title = {{Towards a Framework to Verify Knowledge Sharing Technology}},
volume = {11},
year = {1996}
}
@article{me03j,
author = {Chiang, E and Menzies, T},
journal = {Software Process: Improvement and Practice},
number = {3-4},
pages = {141--159},
title = {{Simulations for very early lifecycle quality evaluations}},
volume = {7},
year = {2003}
}
@misc{omg03,
editor = {Miller, J and Mukerji, J},
institution = {Object Management Group},
month = jun,
number = {omg2003-06-01},
title = {{\{MDA\} Guide Version 1.0.1}},
url = {http://www.omg.org/mda/presentations.htm},
year = {2003}
}
@misc{warrenDS94,
author = {Warren, D S},
title = {{Personal Communication}},
year = {1994}
}
@article{jorgensen04a,
author = {J\o rgensen, M},
journal = {Journal of Systems and Software},
number = {1-2},
title = {{A Review of Studies on Expert Estimation of Software Development Effort}},
volume = {70},
year = {2004}
}
@article{Liu2004e,
abstract = {This paper concerns approximate nearest neighbor searching algorithms, which have become increasingly important, especially in high dimen- sional perception areas such as computer vision, with dozens of publica- tions in recent years. Much of this enthusiasm is due to a successful new approximate nearest neighbor approach called Locality Sensitive Hash- ing (LSH). In this paper we ask the question: can earlier spatial data structure approaches to exact nearest neighbor, such as metric trees, be altered to provide approximate answers to proximity queries and if so, how? We introduce a new kind of metric tree that allows overlap: certain datapoints may appear in both the children of a parent. We also intro- duce new approximate k-NN search algorithms on this structure. We show why these structures should be able to exploit the same random- projection-based approximations that LSH enjoys, but with a simpler al- gorithm and perhaps with greater efficiency. We then provide a detailed empirical evaluation on five large, high dimensional datasets which show up to 31-fold accelerations over LSH. This result holds true throughout the spectrum of approximation levels.},
author = {Liu, Ting and Moore, Andrew W and Gray, Alexander and Yang, Ke},
file = {:Users/timm/svns/doc/05rptrees.pdf:pdf},
isbn = {0262195348},
issn = {10495258},
journal = {Advances in Neural Information Processing Systemsnformation},
pages = {8},
title = {{An investigation of practical approximate nearest neighbor algorithms}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.8527\&rep=rep1\&type=pdf},
year = {2004}
}
@article{bezdek99,
author = {Bezdek, J C and Keller, J M and Krishnapuram, R and Kuncheva, L I and Pal, N R},
journal = {Fuzzy Systems, IEEE Transactions on},
month = jun,
number = {3},
pages = {368--369},
title = {{Will the real iris data please stand up?}},
volume = {7},
year = {1999}
}
@misc{fowl02,
author = {Fowler, Martin},
title = {{The New Methodology}},
year = {2002}
}
@inproceedings{cruz93,
author = {Cruz-Neira, C and Sandin, D and DeFanti, T},
booktitle = {Proceedings of SIGGRAPH '93, ACM SIGGRAPH},
month = aug,
pages = {135--142},
title = {{Surround-Screen Projection-Based Virtual Reality: The Design and Implementation of the CAVE}},
year = {1993}
}
@misc{hig96,
annote = {CMU/SEI-96-TR-012 },
author = {Higuera, R P and Haimes, Y Y},
institution = {Software Engineering Institute},
month = jun,
title = {{Software Risk Management}},
year = {1996}
}
@misc{althoff98,
author = {Althoff, K and Bomarius, F and Tautz, C},
title = {{Using case-based reasoning technology to build learning organizations}},
year = {1998}
}
@article{jorgensen04a,
author = {Jorgensen, M},
journal = {Journal of Systems and Software},
number = {1-2},
title = {{A Review of Studies on Expert Estimation of Software Development Effort}},
volume = {70},
year = {2004}
}
@article{Rosenwald2002,
abstract = {A chance encounter between members of a random repertoire and a molecular target is characteristic of different biological systems, including the immune and olfactory pathways as well as combinatorial libraries. In such systems, the affinity between the target and members of the repertoire is distributed with a probability function describing the propensity of obtaining a particular affinity value. We have previously proposed a phenomenological receptor affinity distribution (RAD) formalism, which describes this probability function based on simple statistical considerations. In the present analysis, we use published data from diverse experimental systems, including phage display libraries, immunoglobulins and enzymes, to test the RAD model and to compare it to other affinity distribution formalisms. The RAD model is found to provide the best description for binding data for over eight orders of magnitude on the affinity scale, and to account for a relationship between repertoire size and the maximal obtainable affinity within different repertoires. This approach points to a potential universality of the rules that govern affinity distributions in biology.},
author = {Rosenwald, Shai and Kafri, Ran and Lancet, Doron},
doi = {10.1006/jtbi.2002.2538},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Rosenwald02.pdf:pdf},
isbn = {0022-5193 (Print)},
issn = {0022-5193},
journal = {Journal of theoretical biology},
number = {3},
pages = {327--336},
pmid = {12183121},
title = {{Test of a statistical model for molecular recognition in biological repertoires.}},
volume = {216},
year = {2002}
}
@article{nguyen87,
author = {Nguyen, T A and Perkins, W A and Laffey, T J and Pecora, D},
journal = {AI Magazine},
number = {2},
pages = {69--75},
title = {{Knowledge Base Verification}},
volume = {8},
year = {1987}
}
@inproceedings{me03g,
author = {{T. Menzies J. Smith}, D Raffo},
title = {{When is Pair Programming Better?}},
year = {2003}
}
@inproceedings{markosian05,
author = {Markosian, L and Feather, M and Brinza, D and Figueroa, F},
booktitle = {1st \{I\}nternational \{F\}orum on \{I\}ntegrated \{S\}ystem \{H\}ealth \{E\}ngineering and \{M\}anagement in \{A\}erospace, \{Napa\}},
month = nov,
title = {{\{V\&V\} of \{ISHM\} software for space exploration}},
year = {2005}
}
@article{rittel73,
author = {Rittel, H W J and Webber, M M},
journal = {Policy Sciences},
pages = {155--169},
title = {{Dilemmas in a general theory of planning}},
volume = {4},
year = {1973}
}
@article{Shiu2006,
author = {Shiu, S.C.K. and Pal, S.K.},
doi = {10.1109/TKDE.2006.40},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Shiu, Pal - 2006 - Combining feature reduction and case selection in building CBR classifiers.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = mar,
number = {3},
pages = {415--429},
title = {{Combining feature reduction and case selection in building CBR classifiers}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1583589},
volume = {18},
year = {2006}
}
@article{VanUitert2008,
abstract = {Genomic datasets often consist of large, binary, sparse data matrices. In such a dataset, one is often interested in finding contiguous blocks that (mostly) contain ones. This is a biclustering problem, and while many algorithms have been proposed to deal with gene expression data, only two algorithms have been proposed that specifically deal with binary matrices. None of the gene expression biclustering algorithms can handle the large number of zeros in sparse binary matrices. The two proposed binary algorithms failed to produce meaningful results. In this article, we present a new algorithm that is able to extract biclusters from sparse, binary datasets. A powerful feature is that biclusters with different numbers of rows and columns can be detected, varying from many rows to few columns and few rows to many columns. It allows the user to guide the search towards biclusters of specific dimensions. When applying our algorithm to an input matrix derived from TRANSFAC, we find transcription factors with distinctly dissimilar binding motifs, but a clear set of common targets that are significantly enriched for GO categories.},
author = {van Uitert, Miranda and Meuleman, Wouter and Wessels, Lodewyk},
doi = {10.1089/cmb.2008.0066},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/vanUitert08.pdf:pdf},
issn = {1066-5277},
journal = {Journal of computational biology : a journal of computational molecular cell biology},
keywords = {biclustering,binary data,transcription factor binding},
number = {10},
pages = {1329--1345},
pmid = {19040367},
title = {{Biclustering sparse binary genomic data.}},
volume = {15},
year = {2008}
}
@inproceedings{me01g,
author = {Menzies, T and Hu, Y},
booktitle = {First International Workshop on Model-based Requirements Engineering},
title = {{Constraining discussions in requirements engineering}},
year = {2001}
}
@article{kohavi97,
author = {Kohavi, Ron and John, George H},
journal = {Artificial Intelligence},
number = {1-2},
pages = {273--324},
title = {{Wrappers for Feature Subset Selection}},
url = {citeseer.nj.nec.com/kohavi96wrappers.html},
volume = {97},
year = {1997}
}
@article{wallace89,
author = {Wallace, D R and Fujii, R U},
journal = {IEEE Software},
month = may,
pages = {10--17},
title = {{Software Verification and Validation: An Overview}},
year = {1989}
}
@inproceedings{green82,
author = {Greenspan, S J and Mylopoulos, J},
booktitle = {International Conference on Software Engineering},
pages = {225--234},
title = {{Capturing More World Knowledge in the Requirements Specification}},
year = {1982}
}
@inproceedings{heaven11,
author = {Heaven, W and Letier, E},
booktitle = {Requirements Engineering Conference (RE), 2011 19th IEEE International},
pages = {79--88},
title = {{Simulating and optimising design decisions in quantitative goal models}},
year = {2011}
}
@article{Campos-nanez2012,
author = {Campos-n\'{a}\~{n}ez, Enrique},
file = {:Users/timm/svns/doc/optimalML/introSystemDynamics.pdf:pdf},
title = {{Introduction to System Dynamics Causal-loop Diagrams}},
year = {2012}
}
@inproceedings{Basili1992,
author = {Basili, V R},
booktitle = {Experimental Software Engineering Issues: Critical Assessment and Future Directions, International Workshop, Germany, H D Rombach and V R Basili and R W Selby (Eds.), LNCS 706, Springer-Verlag},
pages = {3--12},
title = {{The Experimental Paradigm in Software Engineering}},
year = {1992}
}
@inproceedings{gruska10,
author = {Gruska, Natalie and Wasylkowski, Andrzej and Zeller, Andreas},
booktitle = {Proceedings of the 19th international symposium on Software testing and analysis},
pages = {119--130},
publisher = {ACM},
series = {ISSTA '10},
title = {{Learning from 6,000 projects: lightweight cross-project anomaly detection}},
year = {2010}
}
@book{lenz98,
author = {Et. al., M Lenz},
publisher = {Springer Verlag},
title = {{Case-Based Reasoning Technology- From Foundations to Applications}},
year = {1998}
}
@inproceedings{sayyad13b,
author = {Sayyad, A and Ingram, J and Menzies, T and Ammar, H},
booktitle = {ASE'13, Palo Alto, CA},
title = {{Scalable Product Line Configuration: A Straw to Break the Camel's Back}},
year = {2013}
}
@book{pressman96,
author = {Pressman, R S},
publisher = {McGraw-Hill},
title = {{Software Engineering: A Practitioner's Approach}},
year = {2002}
}
@inproceedings{me03q,
author = {Menzies, Tim and Di\~{}Stefano, Justin S},
booktitle = {2004 IEEE Conference on High Assurance Software Engineering},
title = {{How Good is Your Blind Spot Sampling Policy?}},
year = {2003}
}
@article{chechik03,
author = {Checkik, M and Devereux, Benet and Gurfinkel, Arie and Easterbrook, Steve},
journal = {ACM Transactions on Software Engineering and Methodology (to appear)},
title = {{Multi-Valued Symbolic Model-Checking}},
year = {2003}
}
@article{Fischer2003b,
author = {Fischer, Bernd and Schumann, Johann},
doi = {10.1017/S0956796802004562},
file = {:Users/timm/svns/doc/FISCHER03.pdf:pdf},
issn = {09567968},
journal = {Journal of Functional Programming},
month = may,
number = {3},
pages = {483--508},
title = {{AutoBayes: a system for generating data analysis programs from statistical models}},
url = {http://www.journals.cambridge.org/abstract\_S0956796802004562},
volume = {13},
year = {2003}
}
@misc{spear00,
title = {{No Title}}
}
@misc{compton96a,
annote = {Regarding time interval literal connections.},
author = {Compton, P},
title = {{Personal communication}},
year = {1996}
}
@inproceedings{zowghi96,
author = {Zowghi, D and Ghose, A and Peppas, P},
booktitle = {Proceedings of the 4th Pacific Rim International Conference on Artificial Intelligence (PRICAI96), Cairns, Australia, August},
title = {{A Framework for Reasoning about Requirements Evolution}},
year = {1996}
}
@inproceedings{hameph95,
author = {Haynes, P and Menzies, T and Phipps, G},
booktitle = {OOPSLA Workshop on OO Process and Metrics for Effort Estimation},
title = {{Using The Size of Classes and Methods as the Basis for Early Effort Prediction; Empirical Observations, Initial Application; A Practitioners Experience Report}},
year = {1995}
}
@article{sch94,
author = {Schreiber, A T H and Wielinga, B and Akkermans, J M and Velde, W Van De and de Hoog, R},
journal = {IEEE Expert},
number = {6},
pages = {28--37},
title = {{CommonKADS. A Comprehensive Methodology for KBS Development}},
volume = {9},
year = {1994}
}
@inproceedings{mich86,
author = {Michalski, I and Mozetic, J and Hong, J and Lavrac, N},
booktitle = {Proceedings of AAAI 1986},
pages = {1041--1045},
title = {{The multi-purpose incremental learning system AQL and its testing application to three medical domains}},
year = {1986}
}
@article{molina05,
author = {Molina, Julian and Laguna, Manuel and Marto, Rafael and Caballero, Rafael and Metaheuristics, Keywords Multiobjective and Optimization, Non-linear Multiobjective},
journal = {INFORMS Journal on Computing},
title = {{SSPMO: A scatter tabu search procedure for non-linear multiobjective optimization}},
year = {2005}
}
@article{easter98,
author = {Easterbrook, Steve and Lutz, Robyn R and Covington, Richard and Kelly, John and Ampo, Yoko and Hamilton, David},
journal = {IEEE Transactions on Software Engineering},
pages = {4--14},
title = {{Experiences Using Lightweight Formal Methods for Requirements Modeling}},
year = {1998}
}
@misc{me99e,
annote = {in preperation},
author = {Menzies, T and Cukic, B},
howpublished = {NASA/WVU IVV tech report},
month = mar,
title = {{An Average-Case Model of Reachability}},
year = {1999}
}
@article{Vaidya2003a,
author = {Vaidya, Jaideep and Lafayette, West and Clifton, Chris},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Vaidya, Lafayette, Clifton - 2003 - Privacy-Preserving K -Means Clustering over Vertically Partitioned Data.pdf:pdf},
journal = {Security},
title = {{Privacy-Preserving K -Means Clustering over Vertically Partitioned Data}},
year = {2003}
}
@article{fagan76,
author = {Fagan, M},
journal = {IBM Systems Journal},
number = {3},
title = {{Design and Code Inspections to Reduce Errors in Program Development}},
volume = {15},
year = {1976}
}
@inproceedings{me94,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/ai94.pdf\}},
author = {Menzies, T J and Compton, P},
booktitle = {Proceedings of Australian AI'94},
editor = {Zhang, C and Debenham, J and Lukose, D},
pages = {149--156},
publisher = {World Scientific},
title = {{A \{P\}recise \{S\}emantics for \{V\}ague \{D\}iagrams}},
year = {1994}
}
@inproceedings{meedng92,
author = {Menzies, T J and Edwards, J and Ng, K},
booktitle = {Tools Pacific 1992},
pages = {421--428},
publisher = {Prentice Hall},
title = {{The \{M\}ysterious \{C\}ase of the \{M\}issing \{R\}e-usable \{C\}lass \{L\}ibraries}},
year = {1992}
}
@inproceedings{rieger77,
author = {Rieger, C and Grinberg, M},
booktitle = {IJCAI '77},
pages = {250--256},
title = {{The Declarative Representation and Procedural Simulation of Causality in Physical Mechanisms}},
year = {1977}
}
@article{yang13,
author = {Yang, Ye and He, Zhimin and Mao, Ke and Li, Qi and Nguyen, Vu and Boehm, Barry W and Valerdi, Ricardo},
file = {:Users/timm/svns/doc/13ye.pdf:pdf},
journal = {Information \{\&\} Software Technology},
number = {8},
pages = {1496--1511},
title = {{Analyzing and handling local bias for calibrating parametric cost estimation models}},
volume = {55},
year = {2013}
}
@article{myers77,
author = {Myers, G J},
journal = {Communications of the ACM},
pages = {760--768},
title = {{A Controlled Experiment in Program Testing and Code Walkthroughs/Inspections}},
volume = {21},
year = {1977}
}
@article{by88,
author = {Bylander, T},
journal = {IEEE Transactions on Systems, Man, and Cybernetics},
number = {2},
pages = {252--263},
title = {{A Critique of Qualitative Simulation from a Consolidation Viewpoint}},
volume = {18},
year = {1988}
}
@article{Brain,
author = {Brain, Damien},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Brain - Unknown - On the effect of data set size on bias and variance in classification learning.pdf:pdf},
pages = {117--128},
title = {{On the effect of data set size on bias and variance in classification learning}}
}
@misc{me01c,
author = {Bonnett, Alastair},
isbn = {0130193240, 9780130193247},
pages = {116},
title = {{How to argue}},
year = {2001}
}
@article{kleijnen97,
author = {Kliijnen, J P C},
journal = {Journal Statistical Computation and Simulation},
number = {1--4},
pages = {111--142},
title = {{Sensitivity Analysis and Related Analyses: a Survey of Statistical Techniques}},
volume = {57},
year = {19987}
}
@book{char87,
author = {Charniak, E and McDermott, D},
pages = {701},
publisher = {Addison-Wesley},
title = {{Introduction to Artificial Intelligence}},
year = {1987}
}
@inproceedings{boy95,
author = {Boy, G},
booktitle = {Proceedings of the 6th IFAC Symposium on Analysis, Design and Evaluation of Man-Machine Systems},
title = {{Supportability-based design rationale}},
year = {1995}
}
@article{Krzywicki2009,
author = {Krzywicki, Alfred and Wobcke, Wayne},
doi = {10.1007/978-3-642-10439-8\_26},
file = {:Users/timm/svns/doc/AI 2009 Advances in Artificial Intelligence\_Krzywicki\_2009.pdf:pdf},
isbn = {364210438X},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {250--259},
title = {{Incremental e-mail classification and rule suggestion using simple term statistics}},
volume = {5866 LNAI},
year = {2009}
}
@article{me89zb,
author = {Menzies, T J},
journal = {AI Expert},
title = {{Domain-Specific Knowledge Representations}},
year = {1989}
}
@inproceedings{ishida89,
author = {Ishida, Y},
booktitle = {Proceedings of IJCAI '89},
pages = {1174--1179.},
title = {{Using Global Properties for Qualitative Reasoning: A Qualitative System Theory}},
year = {1989}
}
@inproceedings{hindle12,
author = {Hindle, A},
booktitle = {Proceedings, MSR'12},
title = {{Green Mining: A Methodology of Relating Software Change to Power Consumption}},
year = {2012}
}
@inproceedings{deb98a,
author = {Debenham, J},
booktitle = {Proceedings Seventh International Conference on Information Processing and Management of Uncertainty in Knowledge Based Systems IPMU '98, Paris, France, July},
title = {{Managing Knowledge Integrity}},
year = {1998}
}
@inproceedings{chulani98,
author = {{S. Chulani B. Clark}, B Boehm and Steece, B},
booktitle = {Proceceedings ISPA,98},
title = {{Calibration Approach and Results of the COCOMO II Post-Architecture Model}},
year = {1998}
}
@article{Noda1999,
author = {Noda, Edgar and Noda, Edgar},
file = {:Users/timm/svns/doc/xplain/98noda.pdf:pdf},
isbn = {0780355369},
pages = {1322--1329},
title = {{Discovering Pnteresting Prediction Rules with a Genetic Algorithm}},
year = {1999}
}
@article{demsar06,
annote = {Avaliable from $\backslash$url\{http://jmlr.csail.mit.edu/papers/v7/demsar06a.html\}},
author = {Demsar, J},
journal = {Journal of Machine Learning Research},
pages = {1--30},
title = {{Statistical Comparisons of Clasifiers over Multiple Data Sets}},
volume = {7},
year = {2006}
}
@inproceedings{me00e,
author = {Menzies, T and Sinsel, E},
booktitle = {Proceedings ASE 2000},
title = {{Practical Large Scale What-if Queries: Case Studies with Software Risk Assessment}},
year = {2000}
}
@article{boehm00m,
author = {Boehm, B and Basili, V R},
doi = {10.1109/MC.2000.841781},
issn = {0018-9162},
journal = {Computer},
month = may,
number = {5},
pages = {27--33},
title = {{Gaining intellectual control of software development}},
volume = {33},
year = {2000}
}
@article{Tritchler2005,
abstract = {This paper considers a clustering method motivated by a multivariate analysis of variance model and computationally based on eigenanalysis (thus the term âspectralâ in the title). Our focus is on large problems, and we present the method in the context of clustering genes using microarray expression data. We provide an efficient computational algorithm and discuss its properties and interpretation in statistical and geometric terms. Leukemia and Melanoma data sets are analyzed to demonstrate the use of the method, and simulations are carried out to compare our method with two other clustering algorithms. We extend the method to enable supervision by either gene or array characteristics.},
author = {Tritchler, David and Fallah, Shafagh and Beyene, Joseph},
doi = {10.1016/j.csda.2004.04.010},
file = {:Users/timm/svns/doc/05spectralDivisvePartitioning.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics \& Data Analysis},
keywords = {clustering,eigenanalysis,microarray,spectral,supervised learning},
number = {1},
pages = {63--76},
title = {{A spectral clustering method for microarray data}},
volume = {49},
year = {2005}
}
@article{pearl86,
author = {Pearl, J},
journal = {Artificial Intelligence},
pages = {241--288},
title = {{Fusion, propagation, and structuring in belief networks}},
volume = {29},
year = {1986}
}
@phdthesis{hu02,
annote = {Masters Thesis},
author = {Hu, Y},
school = {Department of Electrical Engineering, University of British Columbia},
title = {{Treatment Learning: Implementation and Application}},
year = {2003}
}
@article{dijk59,
author = {Dijkstra, E W},
journal = {Numerische Mathematik},
pages = {269--271},
title = {{A note on two problems in connexion with graphs}},
volume = {1},
year = {1959}
}
@misc{standish01,
title = {{The \{S\}tandish \{G\}roup \{R\}eport: \{C\}haos 2001}},
year = {2001}
}
@inproceedings{fouche92,
author = {Fouche, P and Kuipers, B},
booktitle = {Recent Advances in Qualitative Physics},
editor = {Faltings, B and Struss, P},
pages = {263--278},
publisher = {The MIT Press},
title = {{An Assessment of Current Qualitative Simulation Techniques}},
year = {1992}
}
@article{deb12a,
address = {Los Alamitos, CA, USA},
author = {Dejaeger, Karel and Verbeke, Wouter and Martens, David and Baesens, Bart},
doi = {http://doi.ieeecomputersociety.org/10.1109/TSE.2011.55},
file = {:Users/timm/svns/doc/11dejaeger.pdf:pdf},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
pages = {375--397},
publisher = {IEEE Computer Society},
title = {{Data Mining Techniques for Software Effort Estimation: A Comparative Study}},
volume = {38},
year = {2012}
}
@book{schon83,
author = {Schon, D A},
publisher = {Harper Collins/ Basic Books},
title = {{The Reflective Practioner}},
year = {1983}
}
@misc{clancey96,
annote = {Personal communcaition},
author = {Clancey, W},
title = {{No Title}},
year = {1996}
}
@inproceedings{feather06a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06rev.pdf\}},
author = {Feather, M and Cornford, S and Kiper, J and Menzies, T},
booktitle = {First International Workshop on Requirements Engineering Visualization},
title = {{Experiences using Visualization Techniques to Present Requirements, Risks to Them, and Options for Risk Mitigation}},
year = {2006}
}
@book{goldberg00,
author = {Goldberg, D E},
publisher = {Addison-Wesley},
title = {{Genetic Algorithms in Search, Optimization, and Machine Learning}},
year = {1989}
}
@inproceedings{Ramakrishnan1995,
author = {Ramakrishnan, S and Menzies, T},
booktitle = {Proceedings SEEP'96, New Zealand},
title = {{An Ongoing Experiment in O-O Software Process and Product Measurements}},
year = {1996}
}
@inproceedings{harman04,
address = {Washington, DC, USA},
author = {Harman, Mark and Wegener, Joachim},
booktitle = {ICSE '04: Proceedings of the 26th International Conference on Software Engineering},
isbn = {0-7695-2163-0},
pages = {728--729},
publisher = {IEEE Computer Society},
title = {{Getting Results from Search-Based Approaches to Software Engineering}},
year = {2004}
}
@inproceedings{me92k,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/ai92.pdf\}},
author = {Menzies, T J},
booktitle = {Proceedings of AI '92, Australia},
title = {{Maintaining Procedural Knowledge: Ripple-Down-Functions}},
year = {1992}
}
@inproceedings{me00y,
author = {Menzies, Tim and Cukic, Bojan},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
pages = {1--22},
title = {{How Many Tests are Enough ?}},
volume = {2},
year = {2000}
}
@article{brac85,
author = {Brachman, R},
journal = {The \{AI\} Magazine},
pages = {80--93},
title = {{I Lied About the Trees, or Defaults and Definitions in Knowledge Representation}},
year = {1985}
}
@book{pareto1906,
author = {Pareto, Vilfredo},
publisher = {MacMillian},
title = {{Manuale di Economia Politica}},
year = {1906}
}
@book{Madachy2008,
abstract = {This book is designed for professionals and students in software engineering or information technology who are interested in understanding the dynamics of software development in order to assess and optimize their own process strategies. It explains how simulation of interrelated technical and social factors can provide a means for organizations to vastly improve their processes. It is structured for readers to approach the subject from different perspectives, and includes descriptive summaries of the best research and applications.},
author = {Madachy, R J},
doi = {10.1002/9780470192719},
file = {:Users/timm/svns/doc/optimalML/madachyBook.pdf:pdf},
isbn = {9780471274551},
pages = {601},
title = {{Software Process Dynamics}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=Kb7lUdAgusMC\&amp;oi=fnd\&amp;pg=PR13\&amp;dq=SOFTWARE+PROCESS+DYNAMICS\&amp;ots=xHofQR3Tcp\&amp;sig=MyUMcZ8KlaaenwpEiSejbVREz-4},
year = {2008}
}
@misc{purify,
author = {$\backslash$urlhttp://www.pureatria.com/products, Pure Atria},
title = {{Purify}}
}
@inproceedings{owen03c,
abstract = { We have been exploring LURCH, an approximate (not necessarily complete) alternative to traditional model checking based on a randomized search algorithm. Randomized algorithms like LURCH have been known to outperform their deterministic counterparts for search problems representing a wide range of applications. The cost of an approximate strategy is the potential for inaccuracy. If complete algorithms terminate, they find all the features they are searching for. On the other hand, by its very nature, randomized search can miss important features. Our experiments suggest that this inaccuracy problem is not too serious. In the case studies presented here and elsewhere, LURCHS random search usually found the correct results. Also, these case studies strongly suggest that LURCH can scale to much larger models than standard model checkers like NuSMV and SPIN. The two case studies presented in this paper are selected for their simplicity and their complexity. The simple problem of the dining philosophers has been widely studied. By making the dinner more crowded, we can compare the memory and runtimes of standard methods (SPIN) and LURCH. When hundreds of philosophers sit down to eat, both LURCH and SPIN can find the deadlock case. However, SPINS memory and runtime requirements can grow exponentially while LURCHS requirements stay quite low. Success with highly symmetric, automatically generated problems says little about the generality of a technique. Hence, our second example is far more complex: a real-world flight guidance system from Rockwell Collins. Compared to NuSMV, LURCH performed very well on this model. Our random search finds the vast majority of faults (close to 90\%); runs much faster (seconds and minutes as opposed to hours); and uses very little memory (single digits to 10s of megabytes as opposed to 10s to 100s of megabytes). The rest of this paper is structured as follows. We begin with a theoretical rationale for why random search methods like LURCH can be incomplete, yet still successful. Next, we note that for a class of problems, the complete search of standard model checkers can be overkill. LURCH is then briefly introduced and our two case studies are presented.},
author = {Owen, D. and Menzies, T. and Heimdahl, M. and Gao, Jimin Gao Jimin},
booktitle = {28th Annual NASA Goddard Software Engineering Workshop, 2003. Proceedings.},
doi = {10.1109/SEW.2003.1270728},
isbn = {0-7695-2064-2},
title = {{On the advantages of approximate vs. complete verification: bigger models, faster, less memory, usually accurate}},
year = {2003}
}
@article{Simkevitz2009,
author = {Simkevitz, Howard},
doi = {10.1109/CONGRESS.2009.16},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Simkevitz - 2009 - Why Privacy Matters in Health Care Delivery A Value Proposition.pdf:pdf},
isbn = {978-1-4244-5344-3},
journal = {2009 World Congress on Privacy, Security, Trust and the Management of e-Business},
month = aug,
pages = {193--201},
publisher = {Ieee},
title = {{Why Privacy Matters in Health Care Delivery: A Value Proposition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5341698},
year = {2009}
}
@article{dwyer98,
author = {Dwyer, M B and Avrunin, G S and Corbett, J C},
journal = {Proceeding of the 2nd Workshop on Formal Methods in Software Practice},
pages = {7--15},
title = {{Patterns in Property SPecifications for Finite-state Verification}},
year = {1998}
}
@article{mashiko97,
author = {Mashiko, Yasuhiro and Basili, Victor R},
journal = {Journal of Systems and Software},
pages = {17--32},
title = {{Using the GQM Paradigm to Investigate Influential Factors for Software Process Improvement}},
volume = {36},
year = {1997}
}
@article{forgy82,
author = {Forgy, C L},
journal = {Artificial Intelligence},
pages = {17--37},
title = {{\{RETE\}: A \{F\}ast \{A\}lgorithm for the \{M\}any \{P\}attern/\{M\}any \{O\}bject \{P\}attern \{M\}atch \{P\}roblem}},
year = {1982}
}
@article{VanUitert2008a,
abstract = {Genomic datasets often consist of large, binary, sparse data matrices. In such a dataset, one is often interested in finding contiguous blocks that (mostly) contain ones. This is a biclustering problem, and while many algorithms have been proposed to deal with gene expression data, only two algorithms have been proposed that specifically deal with binary matrices. None of the gene expression biclustering algorithms can handle the large number of zeros in sparse binary matrices. The two proposed binary algorithms failed to produce meaningful results. In this article, we present a new algorithm that is able to extract biclusters from sparse, binary datasets. A powerful feature is that biclusters with different numbers of rows and columns can be detected, varying from many rows to few columns and few rows to many columns. It allows the user to guide the search towards biclusters of specific dimensions. When applying our algorithm to an input matrix derived from TRANSFAC, we find transcription factors with distinctly dissimilar binding motifs, but a clear set of common targets that are significantly enriched for GO categories.},
author = {van Uitert, Miranda and Meuleman, Wouter and Wessels, Lodewyk},
doi = {10.1089/cmb.2008.0066},
file = {:Users/timm/svns/doc/erin/references/BinarySparseClustering/Uitert08.pdf:pdf},
issn = {1066-5277},
journal = {Journal of computational biology : a journal of computational molecular cell biology},
keywords = {biclustering,binary data,transcription factor binding},
number = {10},
pages = {1329--1345},
pmid = {19040367},
title = {{Biclustering sparse binary genomic data.}},
volume = {15},
year = {2008}
}
@book{tomah89,
month = nov,
title = {{Tomahawk Nuclear Safety and Certification Program}},
year = {1989}
}
@inproceedings{me07,
author = {Menzies, T and Hu, Y},
booktitle = {Artificial Intelligence Review},
title = {{Just Enough Learning (of Association Rules): The \{TAR2\} Treatment Learner}},
year = {2007}
}
@misc{do178b,
annote = {December 1},
author = {RTCA, I N C},
title = {{RTCA DO178B: Software Considerations in Airborned Systems and Equipment Consideration}},
year = {1992}
}
@article{genes84,
author = {Genesereth, M R},
journal = {Artificial Intelligence},
pages = {411--436},
title = {{The \{U\}se of \{D\}esign \{D\}escriptions in \{A\}utomated \{D\}iagnosis}},
volume = {24},
year = {1984}
}
@article{Quickstart2010,
author = {Quickstart, A Beamer},
doi = {10.1002/mrd.21260},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Quickstart - 2010 - Table of contents, volume 77, december 2010.pdf:pdf},
issn = {1098-2795},
journal = {Molecular reproduction and development},
month = dec,
number = {12},
pmid = {21182113},
title = {{Table of contents, volume 77, december 2010.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21182113},
volume = {77},
year = {2010}
}
@inproceedings{MORASCA2009,
address = {New York, NY, USA},
author = {Morasca, Sandro},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540465},
isbn = {978-1-60558-634-2},
pages = {1--10},
publisher = {ACM},
title = {{Building statistically significant robust regression models in empirical software engineering}},
year = {2009}
}
@article{frankl93,
author = {Frankl, P G and Weiss, S N},
journal = {IEEE Transactions on Software Engineering},
month = aug,
number = {8},
pages = {774--787},
title = {{An Experimental Comparison of the Effectiveness of Branch Testing and Data Flow Testing}},
volume = {19},
year = {1993}
}
@article{Zhang2005,
author = {Zhang, Nan and Wang, Shengquan and Zhao, Wei},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zhang, Wang, Zhao - 2005 - A New Scheme on Privacy-Preserving Data Classification â.pdf:pdf},
journal = {Security},
keywords = {privacy,privacy-preserving data mining},
pages = {374--383},
title = {{A New Scheme on Privacy-Preserving Data Classification â}},
year = {2005}
}
@misc{brookes86,
author = {Brookes, C H P},
institution = {Information Systems, University of New South Wales},
number = {11},
title = {{Requirements \{E\}licitation for \{K\}nowledge \{B\}ased \{D\}ecision \{S\}upport \{S\}ystems}},
year = {1986}
}
@article{zlochin04,
author = {Zlochin, M and Birattari, M and Meuleau, N and Dorigo, M},
journal = {Annals of Operations Research},
pages = {373--395},
title = {{Model-based search for combinatorial optimization: A critical survey}},
volume = {131},
year = {2004}
}
@article{stukes99,
author = {Chulani, S and Boehm, B and Steece, B},
journal = {Journal of Parametrics},
number = {2},
pages = {175--188},
title = {{From Multiple Regression to Bayesian Analysis for Calibrating \{COCOMO\} \{II\}}},
volume = {15},
year = {1999}
}
@article{hart68,
author = {Hart, P E and Nilsson, N J and Raphael, B},
journal = {IEEE Transactions on Systems Science and Cybernetics},
pages = {100--107},
title = {{A formal basis for the heuristic determination of minimum cost paths}},
volume = {4},
year = {1968}
}
@article{Deutscha,
author = {Deutsch, Alin and Papakonstantinou, Yannis},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Deutsch, Papakonstantinou - Unknown - Privacy in Database Publishing.pdf:pdf},
title = {{Privacy in Database Publishing}}
}
@inproceedings{musilek02,
address = {Washington, DC, USA},
author = {Musilek, Petr and Pedrycz, Witold and Sun, Nan and Succi, Giancarlo},
booktitle = {METRICS '02: Proceedings of the 8th International Symposium on Software Metrics},
isbn = {0-7695-1339-5},
pages = {13},
publisher = {IEEE Computer Society},
title = {{On the Sensitivity of COCOMO II Software Cost Estimation Model}},
year = {2002}
}
@inproceedings{pople73,
author = {Pople, H E},
booktitle = {IJCAI '73},
pages = {147--152},
title = {{On the mechanization of abductive logic.}},
year = {1973}
}
@article{jmlr12,
author = {Fortin, F\'{e}lix-Antoine and {De Rainville}, Fran\c{c}ois-Michel and Gardner, Marc-Andr\'{e} and Parizeau, Marc and Gagn\'{e}, Christian},
journal = {Journal of Machine Learning Research},
month = jul,
pages = {2171--2175},
title = {{\{DEAP\}: Evolutionary Algorithms Made Easy}},
volume = {13},
year = {2012}
}
@article{Haaga04,
author = {Haaga, John and Commission., Appalachian Regional and Bureau., Population Reference},
keywords = {Educational attainment Appalachian Region.},
pages = {24 p.},
publisher = {Appalachian Regional Commission : Population Reference Bureau},
title = {{Educational attainment in Appalachia}},
year = {2004}
}
@inproceedings{dwyer98a,
author = {Dwyer, M B and Avrunin, G S and Corbett, J C},
booktitle = {ICSE98: Proceedings of the 21st International Conference on Software Engineering},
month = may,
title = {{Patterns in Property Specifications for Finite-state Verification}},
year = {1998}
}
@article{Fung2010a,
author = {Fung, Benjamin C. M. and Wang, Ke and Chen, Rui and Yu, Philip S.},
doi = {10.1145/1749603.1749605},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Fung et al. - 2010 - Privacy-preserving data publishing.pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
month = jun,
number = {4},
pages = {1--53},
title = {{Privacy-preserving data publishing}},
url = {http://portal.acm.org/citation.cfm?doid=1749603.1749605},
volume = {42},
year = {2010}
}
@incollection{buch84a,
author = {Buchanan, B G and Shortliffe, E H},
chapter = {10. Uncert},
pages = {209--232},
publisher = {Addison Wesley},
title = {{Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project}},
year = {1984}
}
@misc{Coiera96,
annote = {Technical Report HPL-96-65, May, 1996},
author = {Coiera, E},
institution = {Hewlett-Packard Laboratories},
title = {{Communication in Organisations}},
year = {1996}
}
@article{Li2001a,
author = {Li, Jiuyong},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Li - 2001 - Current Developments of k-Anonymous Data Releasing.pdf:pdf},
pages = {1--12},
title = {{Current Developments of k-Anonymous Data Releasing}},
year = {2001}
}
@inproceedings{rich98zb,
author = {Richards, D and Menzies, T J},
booktitle = {Banff Workshop on Knowledge Acquisition},
title = {{Extending the SISYPHUS III Experiment from a Knowledge Engineering Task to a Requirements Engineering Task}},
year = {1998}
}
@inproceedings{balbo95,
author = {S, Balbo},
booktitle = {Proceddings of the 6th International Conference on HCI, Pacificon Yokohama (Japan)},
editor = {Anzi, Y and Ogawa, K},
title = {{Software Tools for Evaluating the Usability of User Interfaces}},
year = {1995}
}
@book{Johnson2009,
author = {Johnson, J G},
booktitle = {Perspectives on cognition and action in sport},
file = {:Users/timm/svns/doc/11mehlhorn.pdf:pdf},
isbn = {9789036753227},
pages = {171--180},
title = {{Cognitive models of athlete decision making      }},
year = {2009}
}
@inproceedings{top91,
author = {Top, J L and Akkermans, J M},
booktitle = {IJCAI '91},
title = {{Computational and Physical Causality}},
year = {1991}
}
@inproceedings{robles10,
author = {Robles, G},
booktitle = {MSR'10},
title = {{Replicating MSR: A study of the potential replicability of papers published in the Mining Software Repositories Proceedings}},
year = {2010}
}
@article{frankl95,
author = {Frankl, P G and Weyuker, E J},
journal = {IEEE Transactions on Software Engineering},
month = oct,
number = {10},
pages = {861--863},
title = {{Reply to "Some Critical Remarks on a Hierarchy of Fault-Detecting Abilities of Test Methods"}},
volume = {21},
year = {1995}
}
@article{Kohavi1995d,
author = {Kohavi, Ron},
file = {:Users/timm/svns/doc/kohavi95a.pdf:pdf},
journal = {Machine Learning: ECML-95},
pages = {174--189},
publisher = {Springer},
title = {{The power of decision tables}},
url = {http://www.springerlink.com/index/P5N736U105315054.pdf},
year = {1995}
}
@inproceedings{poole85,
author = {Poole, D},
booktitle = {\{IJCAI\} '85},
pages = {144--147},
title = {{On the \{C\}omparison of \{T\}heories: \{P\}referring the \{M\}ost \{S\}pecific \{E\}xplanation}},
year = {1985}
}
@inproceedings{swart96,
author = {Swartout, B and Gill, Y},
booktitle = {1996 AAAI Spring Symposium on Acquisition, Learning, and Demonstration: Automating Tasks for Users},
title = {{Flexible Knowledge Acquisition Through Explicit Representation of Knowledge Roles}},
year = {1996}
}
@article{conk88,
author = {Conklin, J E and Begeman, M L},
journal = {ACM Transactions on Office Information Systems},
pages = {303--331},
title = {{gIBIS: A Hypertext Tool for Exploratory Policy Discussion}},
volume = {6},
year = {1988}
}
@book{leach97,
author = {Leach, J},
publisher = {McGraw-Hill},
title = {{Software Reuse: Methods, Models and Costs}},
year = {1997}
}
@inproceedings{come96,
author = {Connell, M and Menzies, T J},
booktitle = {Tools Pacific, 1996, Melbourne},
title = {{Quality Metrics: Test Coverage Analysis for Smalltalk}},
year = {1996}
}
@inproceedings{bey06,
annote = {Available from $\backslash$url\{http://hunch.net/\~{}jl/projects/cover\_tree/cover\_tree.html\}},
author = {Beygelzimer, A and Kakade, S and Langford, J},
booktitle = {ICML'06},
title = {{Cover Trees for Nearest Neighbor}},
year = {2006}
}
@article{dechter85,
address = {New York, NY, USA},
author = {Dechter, Rina and Pearl, Judea},
doi = {http://doi.acm.org/10.1145/3828.3830},
issn = {0004-5411},
journal = {J. ACM},
number = {3},
pages = {505--536},
publisher = {ACM},
title = {{Generalized best-first search strategies and the optimality af A*}},
volume = {32},
year = {1985}
}
@article{Gaber2005,
abstract = {The recent advances in hardware and software have enabled the capture of different measurements of data in a wide range of fields. These measurements are generated continuously and in a very high fluctuating data rates. Examples include sensor networks, web logs, and computer network traffic. The storage, querying and mining of such data sets are highly computationally challenging tasks. Mining data streams is concerned with extracting knowledge structures represented in models and patterns in non stopping streams of information. The research in data stream mining has gained a high attraction due to the importance of its applications and the increasing generation of streaming information. Applications of data stream analysis can vary from critical scientific and astronomical applications to important business and financial ones. Algorithms, systems and frameworks that address streaming challenges have been developed over the past three years. In this review paper, we present the state-of-the-art in this growing vital field.},
author = {Gaber, Mohamed Medhat and Zaslavsky, Arkady and Krishnaswamy, Shonali},
doi = {10.1145/1083784.1083789},
file = {:Users/timm/svns/doc/05stream.pdf:pdf},
isbn = {0163-5808},
issn = {0163-5808},
journal = {ACM Sigmod Record},
number = {2},
pages = {18--26},
pmid = {15749702},
title = {{Mining data streams: A Review}},
url = {http://portal.acm.org/citation.cfm?id=1083789},
volume = {34},
year = {2005}
}
@article{Babu2001,
author = {Babu, T.R. and Murty, M.N.},
file = {:Users/timm/svns/doc/gaProtoSelect.pdf:pdf},
journal = {Pattern Recognition},
number = {2},
pages = {523--525},
publisher = {Elsevier Ltd},
title = {{Comparison of genetic algorithm based prototype selection schemes}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Comparison+of+genetic+algorithm+based+prototype+selection+schemes\#0},
volume = {34},
year = {2001}
}
@misc{TheMendeleySupportTeam2010,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/The Mendeley Support Team - 2010 - Getting Started with Mendeley.pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--14},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2010}
}
@inproceedings{evertsz91,
author = {Evertsz, R},
booktitle = {Proceedings of the 12th International Joint Conference on Artificial Intelligence (IJCAI'91)},
pages = {22--27},
title = {{The Automatic Analysis of Rule-based System Based on their Procedural Semantics}},
year = {1991}
}
@article{dolado00,
author = {Dolado, J J},
journal = {IEEE Transactions of Software Engineering},
number = {10},
pages = {1006--1021},
title = {{A validation of the component-based method for software size estimation}},
volume = {26},
year = {2000}
}
@article{jackson02,
address = {New York, NY, USA},
author = {Jackson, Daniel},
doi = {http://doi.acm.org.proxy.lib.muohio.edu/10.1145/505145.505149},
issn = {1049-331X},
journal = {ACM Trans. Softw. Eng. Methodol.},
number = {2},
pages = {256--290},
publisher = {ACM Press},
title = {{Alloy: a lightweight object modelling notation}},
volume = {11},
year = {2002}
}
@article{me03f,
author = {Menzies, T},
journal = {Requirements Engineering},
title = {{Editorial, Requirements Engineering Journal, Special Issue on Model-based Requirements Engineering}},
year = {2003}
}
@inproceedings{darden90,
author = {Darden, L},
booktitle = {Computational Models of Scientific Discovery and Theory Formation},
editor = {Sharager, J and Langley, P},
publisher = {Morgan Kaufmann Publishers Inc.},
title = {{Diagnosing and Fixing Faults in Theories}},
year = {1990}
}
@article{deKleer86,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {163--196},
title = {{An \{A\}ssumption-\{B\}ased \{TMS\}}},
volume = {28},
year = {1986}
}
@article{Molecular2010,
author = {Molecular, Heterogeneous and Databases, Biology},
doi = {10.1089/cmb.1995.2.537.Published},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/vanUitertSearchResults.pdf:pdf},
issn = {10665277},
journal = {Journal of Computational Biology},
pages = {1--27},
title = {{Journal of Computational Biology Journal of Computational Biology}},
year = {2010}
}
@inproceedings{me02e,
author = {Menzies, Tim and DiStefeno, Justin S and Chapman, Mike and Mcgill, Kenneth},
booktitle = {27th NASA SEL workshop on Software Engineering},
title = {{Metrics that Matter}},
year = {2002}
}
@article{huang06,
author = {Huang, L and Boehm, B},
journal = {Software, IEEE},
number = {5},
pages = {88--95},
title = {{How Much Software Quality Investment Is Enough: A Value-Based Approach}},
volume = {23},
year = {2006}
}
@inproceedings{conf/ictai/TangK04,
author = {Tang, Wei and Khoshgoftaar, Taghi M},
booktitle = {ICTAI},
pages = {373--378},
title = {{Noise Identification with the k-Means Algorithm}},
url = {http://doi.ieeecomputersociety.org/10.1109/ICTAI.2004.93},
year = {2004}
}
@inproceedings{lu06,
annote = {Available from $\backslash$url\{http://www.csse.monash.edu/\~{}webb/Files/LuYangWebb06.pdf\}},
author = {Lu, J and Yang, Y and Webb, G I},
booktitle = {Lecture Notes in Computer Science 4093: Proceedings of the Second International Conference on Advanced Data Mining and Applications (ADMA 2006)},
file = {:Users/timm/svns/doc/webb08.pdf:pdf},
pages = {223--238},
title = {{Incremental Discretization for Naive-Bayes Classifier}},
year = {2006}
}
@article{me05c,
abstract = { Good software cost models can significantly help software project managers. With good models, project stakeholders can make informed decisions about how to manage resources, how to control and plan the project, or how to deliver the project on time, on schedule, and on budget. Real-world data sets, such as those coming from software engineering projects, often contain noisy, irrelevant, or redundant variables. We propose that cost modelers should perform data-pruning experiments after data collection and before model building. Such pruning experiments are simple and fast.},
author = {Chen, Z. and Menzies, T. and Port, D. and Boehm, D.},
doi = {10.1109/MS.2005.151},
issn = {0740-7459},
journal = {IEEE Software},
keywords = {COCOMO,cost modeling,feature subset selection,software engineering,time estimation,wrapper},
month = nov,
number = {6},
pmid = {21609814},
title = {{Finding the right data for software cost modeling}},
volume = {22},
year = {2005}
}
@misc{adams95,
annote = {Object Worlds},
author = {Adam, S},
title = {{Personal communication}},
year = {1995}
}
@article{compton90,
author = {Compton, P J and Jansen, R},
journal = {Knowledge Acquisition},
pages = {241--257},
title = {{A \{P\}hilosophical \{B\}asis for \{K\}nowledge \{A\}cquisition.}},
volume = {2},
year = {1990}
}
@misc{budgen06,
annote = {Keynote address, CSEET'06},
author = {Budgen, D},
title = {{No Title}},
year = {2006}
}
@inproceedings{drummond09,
annote = {Available on-line at $\backslash$url\{http://www.site.uottawa.ca/\~{}cdrummon/pubs/ICMLws09.pdf\}},
author = {Drummond, Chris},
booktitle = {Proceedings of the Twenty-Sixth International Conference on Machine Learning: Workshop on Evaluation Methods for Machine Learning IV},
title = {{Replicability is not reproducibility: Nor is it good science}},
year = {2009}
}
@article{feather08,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ddp.pdf\}},
author = {Feather, M and Cornford, S and Hicks, K and Kiper, J and Menzies, T},
journal = {IEEE Software},
title = {{Application of a broad-spectrum quantitative requirements model to early-lifecycle decision making}},
year = {2008}
}
@phdthesis{milton08,
author = {Milton, Z A},
school = {West Virginia University},
title = {{WHICH rules}},
year = {2008}
}
@article{me13d,
author = {Menzies, Tim and Brady, Adam and Keung, Jacky and Hihn, Jairus and Williams, Steven and El-Rawas, Oussama and Green, Phillip and Boehm, Barry},
journal = {IEEE Transactions on Software Engineering},
number = {12},
pages = {1698--1713},
title = {{Learning Project Management Decisions: A Case Study with Case-Based Reasoning Versus Data Farming}},
volume = {39},
year = {2013}
}
@inproceedings{me01h,
author = {Menzies, T and Hu, Y},
booktitle = {Agent Technology from a Formal Perspective},
editor = {Rouff, C and Hinchey, M and Rash, J and Truszkowski, W and Gordon-Spears, D},
isbn = {1-85233-947-0},
publisher = {Springer},
title = {{Agents in a Wild World}},
year = {2006}
}
@article{weyeuker08,
author = {Weyuker, E J and Ostrand, T J and Bell, R M},
journal = {Empirical Software Engineering},
month = oct,
title = {{Do too many cooks spoil the broth? Using the number of developers to enhance defect prediction models}},
year = {2008}
}
@inproceedings{laurent92,
author = {Laurent, J P},
booktitle = {Proceedings of the 10th European Conference on Artificial Intelligence, ECAI-92, Vienna, Austria},
pages = {829--834},
title = {{Proposals for a valid terminology in KBS Validation}},
year = {1992}
}
@inproceedings{god97,
author = {Godefroid, P},
booktitle = {The 1996 DIMACS workshop on Partial Order Methods in Verification, July 24-26, 1996},
pages = {289--303},
title = {{On the Costs and Benefits of Using Partial-Order Methods for the Verificiation of Concurrent Systems (invited papers)}},
year = {1997}
}
@article{Foundation2010,
author = {Foundation, Michael J Fox},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Foundation - 2010 - Rare Sharing of Data Leads to Progress on Alzheimer â s.pdf:pdf},
journal = {Order A Journal On The Theory Of Ordered Sets And Its Applications},
title = {{Rare Sharing of Data Leads to Progress on Alzheimer â s}},
year = {2010}
}
@article{rich92,
author = {Rich, C and Feldman, Y A},
journal = {IEEE Transactions on Software Engineering},
month = jun,
number = {6},
pages = {451--469},
title = {{Seven Layers of Knowledge Represeentation and Reasoning in Support of Software Development}},
volume = {18},
year = {1992}
}
@phdthesis{budd80,
author = {Budd, T A},
school = {Yale University},
title = {{Mutation analysis of programs test data}},
year = {1980}
}
@article{cohen95w,
author = {Cohen, W W},
journal = {Automated Software Engineering},
pages = {107--129},
publisher = {Kluwer Academic Publishers},
title = {{Inductive Specification recovery: Understanding software by learning from example behaviors}},
volume = {2},
year = {1995}
}
@article{To1968,
author = {To, Introduction and Second, T H E},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/To, Second - 1968 - Vlad\'{\i}mir Propp MORPHOLOGY OF THE FOLK TALE 1928.pdf:pdf},
journal = {Journal of American Folklore},
keywords = {folktale},
mendeley-tags = {folktale},
title = {{Vlad\'{\i}mir Propp MORPHOLOGY OF THE FOLK TALE 1928}},
year = {1968}
}
@book{Rajaraman2010,
author = {Rajaraman, Anand and Ullman, Jeffrey D},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Rajaraman, Ullman - 2010 - Mining of Massive Datasets.pdf:pdf},
title = {{Mining of Massive Datasets}},
year = {2010}
}
@inproceedings{yost89,
author = {Yost, G R and Newell, A},
booktitle = {\{IJCAI\} '89},
pages = {621--627},
title = {{A \{P\}roblem \{S\}pace \{A\}pproach to \{E\}xpert \{S\}ystem \{S\}pecification}},
year = {1989}
}
@inproceedings{me97p,
author = {Menzies, T J},
booktitle = {The Second Australian Workshop on Requirements Engineering (AWRE'97)},
title = {{Qualitative Causal Diagrams for Requirements Engineering}},
year = {1997}
}
@book{CASEV,
annote = {Volumes I and II},
author = {Inc, Silicon Graphics},
publisher = {Silicon Graphics Inc},
title = {{\{CASEV\}ision/workshop user's guide}},
year = {1992}
}
@book{paul13,
author = {Paul, L A and Hall, N},
publisher = {Oxford University Press},
title = {{Causation : A Userâs Guide}},
year = {2013}
}
@inproceedings{Daran96,
author = {Daran, M and Thevenod-Fosse, P},
booktitle = {Proc. ISSTA 96},
keywords = {Error propagation,mutation,testing},
pages = {158--171},
title = {{Software Error Analysis: \{A\} Real Case Study Involving Real Faults and Mutations}},
year = {1996}
}
@inproceedings{basili02,
author = {Basili, V and McGarry, F and Pajerski, R and Zelkowitz, M},
booktitle = {Proceedings of the 24th International Conference on Software Engineering (ICSE) 2002, Orlando, Florida},
title = {{Lessons Learned from 25 Years of Process Improvement: The Rise and Fall of the \{NASA\} Software Engineering Laboratory}},
year = {2002}
}
@book{sed88,
author = {Sedgewick, R},
publisher = {Addison-Wesley},
title = {{Algorithms}},
year = {1988}
}
@inproceedings{nach08,
author = {Nagappan, N and Murphy, B and V, Basili},
booktitle = {ICSE'08},
title = {{The Influence of Organizational Structure on Software Quality: An Empirical Case Study}},
year = {2008}
}
@inproceedings{me00a,
author = {Menzies, T and Sinsel, E and Kurtz, T},
booktitle = {Workshop on Intelligent Software Engineering, an ICSE workshop, and NASA/WVU Software Research Lab, Fairmont, WV, Tech report \# NASA-IVV-99-027},
keywords = {COCOMO-II,Keywords: Machine learning,Monte-Carlo simulations,decision support systems,effort estimation,risk assessment},
title = {{Learning to Reduce Risks with COCOMO-II}},
year = {2000}
}
@article{Cohen2010,
author = {Cohen, William W},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Cohen - 2010 - Power Iteration Clustering.pdf:pdf},
journal = {ReCALL},
title = {{Power Iteration Clustering}},
year = {2010}
}
@inproceedings{jureczko10,
author = {Jureczko, Marian and Madeyski, Lech},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering},
pages = {9:1----9:10},
publisher = {ACM},
series = {PROMISE '10},
title = {{Towards identifying software project clusters with regard to defect prediction}},
year = {2010}
}
@inproceedings{gaines89,
author = {Gaines, B R and Shaw, M L G},
booktitle = {IJCAI '89},
pages = {633--638},
title = {{Comparing the Conceptual Systems of Experts}},
year = {1989}
}
@article{Boots2011,
abstract = {Recently, a number of researchers have proposed spectral algorithms for learning models of dynam- ical systemsâfor example, Hidden Markov Models (HMMs), Partially Observable Markov Decision Pro- cesses (POMDPs), and Transformed Predictive State Representations (TPSRs). These algorithms are attrac- tive since they are statistically consistent and not sub- ject to local optima. However, they are batch methods: they need to store their entire training data set in mem- ory at once and operate on it as a large matrix, and so they cannot scale to extremely large data sets (ei- ther many examples or many features per example). In turn, this restriction limits their ability to learn accurate models of complex systems. To overcome these lim- itations, we propose a new online spectral algorithm, which uses tricks such as incremental Singular Value Decomposition (SVD) and random projections to scale to much larger data sets and more complex systems than previous methods. We demonstrate the new method on an inertial measurement prediction task and a high- bandwidth video mapping task and we illustrate desir- able behaviors such as âclosing the loop,â where the la- tent state representation changes suddenly as the learner recognizes that it has returned to a previously known place. Introduction},
author = {Boots, Byron and Gordon, Geoffrey J.},
file = {:Users/timm/svns/doc/11onlineSpectralLearning.pdf:pdf},
isbn = {9781577355083},
journal = {Proceedings of the 25th National Conference on Artificial Intelligence},
title = {{An Online Spectral Learning Algorithm for Partially Observable Nonlinear Dynamical Systems}},
year = {2011}
}
@misc{me98a,
author = {Menzies, T and Waugh, S and Goss, S},
howpublished = {Submitted to ECAI '98},
title = {{Taming Chatter with Relevant Envisionments}},
year = {1998}
}
@inproceedings{boett01,
author = {Boetticher, G},
booktitle = {Second International Workshop on Soft Computing Applied to Software Engineering, Enschade, NL},
title = {{An Assessment of Metric Contribution in the Construction of a Neural Network-Based Effort Estimator}},
year = {2001}
}
@article{Kim2001,
author = {Kim, Yang Sok and Kang, Sung Won and Kang, Byeong Ho and Compton, Paul},
file = {:Users/timm/svns/doc/kang09.pdf:pdf},
journal = {Knowledge Creation Diffusion Utilization},
keywords = {mcrdr,scheduling,web monitoring},
pages = {169--180},
title = {{Using Knowledge Base for Event-Driven Scheduling of Web Monitoring Systems}},
year = {2001}
}
@inproceedings{JIANG2009,
address = {New York, NY, USA},
author = {Jiang, Yue and Cukic, Bojan},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540466},
isbn = {978-1-60558-634-2},
pages = {1--10},
publisher = {ACM},
title = {{Misclassification cost-sensitive fault prediction models}},
year = {2009}
}
@misc{holzmann99,
author = {Holzmann, G J and Puri, A},
booktitle = {Software Tools for Technology Transfer},
title = {{A Minimized Automaton Representation of Reachable States}},
year = {1999}
}
@article{antoniol02,
author = {Antoniol, G and Canfora, G and Casazza, G and Lucia, A De and Merlo, E},
journal = {IEEE Transactions on Software Engineering},
month = oct,
number = {10},
pages = {970--983},
title = {{Recovering Traceability Links between Code and Documentation}},
volume = {28},
year = {2002}
}
@article{Kowa88,
author = {Kowalski, R A},
journal = {Communications of the ACM},
month = jan,
number = {1},
pages = {38--43},
title = {{The Early Years of Logic Programming}},
volume = {31},
year = {1988}
}
@article{harman12dec,
author = {Harman, Mark and Mansouri, S Afshin and Zhang, Yuanyuan},
issn = {0360-0300},
journal = {ACM Comput. Surv.},
month = dec,
number = {1},
pages = {11:1----11:61},
title = {{Search-based Software Engineering: Trends, Techniques and Applications}},
volume = {45},
year = {2012}
}
@misc{curtis95,
author = {Curtis, W},
month = may,
title = {{Building a Cost-Benefit Case for Software Process Improvement, Notes from Tutorial given at the Seventh \{S\}oftware \{E\}ngineering \{P\}rocess \{G\}roup \{C\}onference, \{B\}oston, \{M\}\{A\},}},
year = {1995}
}
@article{me11d,
author = {Kocaguneli, E and Menzies, T and Keung, J},
journal = {Empirical Software Engineering},
pages = {1--24},
publisher = {Springer Netherlands},
title = {{Kernel methods for software effort estimation}},
year = {2011}
}
@inproceedings{nov95,
author = {Jr., G S Novak},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and {N.H. Narayanan}, B Chandrasekaran},
pages = {753--774},
publisher = {The AAAI Press},
title = {{Diagrams for Solving Physical Problems}},
year = {1995}
}
@article{me97m,
abstract = { We can test a theory of "X" by checking if that theory can reproduce known behavior of "'X." In the general case, this check for time-based simulations is only practical for short simulation runs. We show that, given certain reasonable language restrictions, the complexity of this check reduces to the granularity of the measurements. That is, provided a very long simulation run is only measured infrequently, this check is feasible.},
author = {Menzies, Tim and Cohen, Robert F. and Waugh, Sam and Goss, Simon},
doi = {10.1109/TKDE.2002.1047773},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Abduction,Complexity,Qualitative reasoning,Validation},
number = {6},
pages = {1362--1375},
title = {{Applications of abduction: Testing very long qualitative simulations}},
volume = {14},
year = {2002}
}
@inproceedings{me97e,
author = {M.Posterma and Wu, X and Menzies, T J},
booktitle = {First Pacific Asia Conference on Knowledge Discovery and Data Mining (PAKDD97)},
title = {{A Tuning Aid for Discretization in Rule Induction}},
year = {1997}
}
@article{zlatereva92,
author = {Zlatareva, N},
journal = {International Journal of Expert Systems},
pages = {229--247},
title = {{CTMS: A General Framework for Plausible Reasoning}},
volume = {5},
year = {1992}
}
@misc{me98a,
author = {Menzies, T and Waugh, S and Goss, S},
howpublished = {Submitted to ECAI '98},
title = {{Taming Chatter with Relevant Envisionments}},
year = {1998}
}
@article{GOKHALE2010,
address = {Hingham, MA, USA},
author = {Gokhale, Swapna S and Mullen, Robert E},
doi = {http://dx.doi.org/10.1007/s10664-009-9115-y},
issn = {1382-3256},
journal = {Empirical Softw. Engg.},
number = {3},
pages = {296--319},
publisher = {Kluwer Academic Publishers},
title = {{A multiplicative model of software defect repair times}},
volume = {15},
year = {2010}
}
@article{brantley02,
annote = {Available from $\backslash$url\{http://www.dau.mil/pubs/images/download.gif\}},
author = {{M.W. Brantley}, W J McFadden and Davis, Mark J},
journal = {Acquisition Review Quarterly},
title = {{Expanding the trade space: an analysis of requirements tradeoffs affecting system design}},
year = {2002}
}
@incollection{dechter-constraint,
author = {Dechter, Rina},
booktitle = {MIT Encyclopedia of the Cognitive Sciences (MITECS)},
month = jan,
publisher = {John Wiley and Sons.},
title = {{Constraint satisfaction}},
year = {1998}
}
@inproceedings{bayana03,
author = {Bayana, S and Owen, D and Menzies, T and Mukhopadhyay, S},
title = {{God Does Play Dice: Diagnosis and Validation for Autonomous Systems}},
year = {2004}
}
@book{davis02,
author = {Davis, J and Fensel:q, D and {van Harmelen (eds.)}, F},
publisher = {John Wiley},
title = {{Towards the Semantic Web: Ontology-Driven Knowledge Management}},
year = {2002}
}
@article{Roulet2002,
abstract = {The ability to determine the location and relative strength of all transcription-factor binding sites in a genome is important both for a comprehensive understanding of gene regulation and for effective promoter engineering in biotechnological applications. Here we present a bioinformatically driven experimental method to accurately define the DNA-binding sequence specificity of transcription factors. A generalized profile was used as a predictive quantitative model for binding sites, and its parameters were estimated from in vitro-selected ligands using standard hidden Markov model training algorithms. Computer simulations showed that several thousand low- to medium-affinity sequences are required to generate a profile of desired accuracy. To produce data on this scale, we applied high-throughput genomics methods to the biochemical problem addressed here. A method combining systematic evolution of ligands by exponential enrichment (SELEX) and serial analysis of gene expression (SAGE) protocols was coupled to an automated quality-controlled sequence extraction procedure based on Phred quality scores. This allowed the sequencing of a database of more than 10,000 potential DNA ligands for the CTF/NFI transcription factor. The resulting binding-site model defines the sequence specificity of this protein with a high degree of accuracy not achieved earlier and thereby makes it possible to identify previously unknown regulatory sequences in genomic DNA. A covariance analysis of the selected sites revealed non-independent base preferences at different nucleotide positions, providing insight into the binding mechanism.},
author = {Roulet, Emmanuelle and Busso, St\'{e}phane and Camargo, Anamaria a and Simpson, Andrew J G and Mermod, Nicolas and Bucher, Philipp},
doi = {10.1038/nbt718},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Roulet02.pdf:pdf},
isbn = {1087-0156},
issn = {1087-0156},
journal = {Nature biotechnology},
number = {8},
pages = {831--835},
pmid = {12101405},
title = {{High-throughput SELEX SAGE method for quantitative modeling of transcription-factor binding sites.}},
volume = {20},
year = {2002}
}
@article{domingos97optimality,
author = {Domingos, Pedro and Pazzani, Michael J},
journal = {Machine Learning},
number = {2-3},
pages = {103--130},
title = {{On the Optimality of the Simple Bayesian Classifier under Zero-One Loss}},
url = {citeseer.ist.psu.edu/domingos97optimality.html},
volume = {29},
year = {1997}
}
@inproceedings{hassan10,
author = {Hassan, Ahmed E and Xie, Tao},
booktitle = {Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 2},
publisher = {ACM},
series = {ICSE '10},
title = {{Mining software engineering data}},
year = {2010}
}
@article{VonMering2007,
abstract = {Information on protein-protein interactions is still mostly limited to a small number of model organisms, and originates from a wide variety of experimental and computational techniques. The database and online resource STRING generalizes access to protein interaction data, by integrating known and predicted interactions from a variety of sources. The underlying infrastructure includes a consistent body of completely sequenced genomes and exhaustive orthology classifications, based on which interaction evidence is transferred between organisms. Although primarily developed for protein interaction analysis, the resource has also been successfully applied to comparative genomics, phylogenetics and network studies, which are all facilitated by programmatic access to the database backend and the availability of compact download files. As of release 7, STRING has almost doubled to 373 distinct organisms, and contains more than 1.5 million proteins for which associations have been pre-computed. Novel features include AJAX-based web-navigation, inclusion of additional resources such as BioGRID, and detailed protein domain annotation. STRING is available at http://string.embl.de/},
author = {von Mering, Christian and Jensen, Lars J. and Kuhn, Michael and Chaffron, Samuel and Doerks, Tobias and Kr\"{u}ger, Beate and Snel, Berend and Bork, Peer},
doi = {10.1093/nar/gkl825},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/vonMering06STRING.pdf:pdf},
isbn = {1362-4962 (Electronic)},
issn = {03051048},
journal = {Nucleic Acids Research},
number = {SUPPL. 1},
pages = {1--5},
pmid = {17098935},
title = {{STRING 7 - Recent developments in the integration and prediction of protein interactions}},
volume = {35},
year = {2007}
}
@book{for93,
author = {Forbus, K D and DeKleer, J},
publisher = {The MIT Press},
title = {{Building Problem Solvers}},
year = {1993}
}
@inproceedings{HATA08,
address = {New York, NY, USA},
author = {Hata, Hideaki and Mizuno, Osamu and Kikuno, Tohru},
booktitle = {MSR '08: Proceedings of the 2008 international working conference on Mining software repositories},
doi = {http://doi.acm.org/10.1145/1370750.1370772},
isbn = {978-1-60558-024-1},
pages = {89--98},
publisher = {ACM},
title = {{An extension of fault-prone filtering using precise training and a dynamic threshold}},
year = {2008}
}
@article{lutz01,
author = {Lutz, R},
journal = {Journal of Systems Architecture},
pages = {613--634},
title = {{Evolving good hierarchical decomposition of complex systems}},
volume = {47},
year = {2001}
}
@inproceedings{Kir92,
author = {Kira, K and Rendell, L},
booktitle = {The Ninth International Conference on Machine Learning},
pages = {pp. 249--256},
publisher = {Morgan Kaufmann},
title = {{A Practical Approach to Feature Selection}},
year = {1992}
}
@inproceedings{comp98,
author = {Compton, P and Ramadan, Z and Preston, P and Le-Gia, T and V.Chellen and Mulholland, M and Hibbert, D B and Haddad, P R and Kang, B},
booktitle = {Banff Workshop on Knowledge Acquisition},
title = {{A Trade-off Between Domain Knowledge and Problem-Solving Method Power,}},
year = {1998}
}
@article{clancey85,
author = {Clancey, W},
journal = {Artificial Intelligence},
pages = {289--350},
title = {{Heuristic \{C\}lassification}},
volume = {27},
year = {1985}
}
@phdthesis{acree80,
author = {Acree, A T},
school = {School of Information and Computer Science, Georgia Institute of Technology},
title = {{On Mutations}},
year = {1980}
}
@misc{davis00,
annote = {Space.com, 13 March 2000. Available from $\backslash$url\{http://www.space.com/businesstechnology/business/spear\_report\_000313.html\}.},
author = {David, L},
title = {{NASA report: Too Many Failures with Faster, Better, Cheaper}}
}
@article{Yang2001,
author = {Yang, Cheng and Fayyad, Usama and Bradley, Paul S.},
doi = {10.1145/502512.502539},
file = {:Users/timm/svns/doc/erin/references/BinarySparseClustering/Yang01.pdf:pdf},
isbn = {158113391X},
journal = {Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '01},
keywords = {based on relaxing the,clustering,collaborative filtering,error-tolerant frequent itemset,exact,high dimensions,query,selectivity estimation,the frequent itemset generalization},
pages = {194--203},
title = {{Efficient discovery of error-tolerant frequent itemsets in high dimensions}},
url = {http://portal.acm.org/citation.cfm?doid=502512.502539},
year = {2001}
}
@inproceedings{compton89,
author = {Compton, P and Horn, K and Quinlan, J R and Lazarus, L},
booktitle = {Applications of Expert Systems},
editor = {Quinlan, J R},
pages = {366--385},
publisher = {Addison Wesley},
title = {{Maintaining an Expert System}},
year = {1989}
}
@inproceedings{me04d,
author = {Owen, D and Menzies, T},
booktitle = {IEEE Transactions on Software Engineering (in preperation)},
title = {{Random Serial World Generation}},
year = {2004}
}
@article{hertz03,
author = {Hertz, Alain and Widmer, Marino},
journal = {European Journal of Operational Research},
number = {2},
pages = {247--252},
title = {{Guidelines for the use of meta-heuristics in combinatorial optimization}},
volume = {151},
year = {2003}
}
@misc{bsc99,
author = {Page, Web},
title = {{No Title}}
}
@incollection{hayes77,
author = {Hayes, J R and Simon, H A},
booktitle = {Cognitive Theory},
editor = {Costellan, N J and Pisoni, D B and Potts, G R},
pages = {21--41},
publisher = {Hillsdale N.J. Erlbaum},
title = {{Psychological Differences Among Problem Isomorphs}},
volume = {2},
year = {1977}
}
@inproceedings{dekhtyar07,
author = {Dekhtyar, A and Hayes, J H and Larsen, J},
booktitle = {3rd International Workshop on Predictive Modeling in Software Engineering (PROMISE'2007)},
title = {{Make the Most of Your Time: How Should the Analyst Work with Automated Traceability Tools?}},
year = {2007}
}
@incollection{ammarel86,
author = {Michalski, R S and Carbonell, J G and Mitchell, T M},
booktitle = {Machine Learning: An Artificial Intelligence Approach},
pages = {499--569},
publisher = {Morgan Kaufmann},
title = {{Program Synthesis as a Theory Formation Task: Problem Representations and Solution Methods,}},
volume = {2},
year = {1986}
}
@article{Bayardo,
author = {Bayardo, Roberto J},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Bayardo - Unknown - Data Privacy Through Optimal k-Anonymization.pdf:pdf},
journal = {Computing},
title = {{Data Privacy Through Optimal k-Anonymization}}
}
@article{boehm98,
author = {Boehm, B and Egyed, A and Port, D and Shah, A and Kwan, J and Madachy, R},
journal = {Annals of Software Engineering},
pages = {295--321},
title = {{A Stakeholder Win-Win Approach to Software Engineering Education}},
volume = {6},
year = {1998}
}
@article{clancey87,
author = {Clancey, W},
journal = {Artificial Intelligence},
pages = {233--250},
title = {{Book Review of Winograd \& Flores, Understanding Computers and Cognition: A New Foundation for Design}},
volume = {31},
year = {1987}
}
@misc{nasa92,
title = {{\{NASA\} Headquarters Safety and Mission Quality Office (Code Q) letter of 13 January 1992; Clarification of NASA's Independent Verification and Validation (IV\&V) Perspective}},
year = {1992}
}
@inproceedings{luqi96a,
author = {Luqi},
booktitle = {Proceedings of SEKE '96},
pages = {189--197},
title = {{Specifications in Software Prototyping}},
year = {1996}
}
@article{Vaidyab,
author = {Vaidya, Jaideep},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Vaidya - Unknown - Privacy Preserving Na Â¨ Ä±ve Bayes Classifier for Vertically Partitioned Data.pdf:pdf},
journal = {Evaluation},
keywords = {distributed classification,privacy,security},
title = {{Privacy Preserving Na Â¨ Ä±ve Bayes Classifier for Vertically Partitioned Data}}
}
@article{Rubner1998,
author = {Rubner, Y. and Tomasi, C. and Guibas, L.J.},
doi = {10.1109/ICCV.1998.710701},
file = {:Users/timm/svns/doc/earthMoverDistance.pdf:pdf},
isbn = {81-7319-221-9},
journal = {Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)},
pages = {59--66},
publisher = {Narosa Publishing House},
title = {{A metric for distributions with applications to image databases}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=710701},
year = {1998}
}
@article{Costs2009,
author = {Costs, Capital Program},
file = {:Users/timm/svns/doc/cost/GAOcostguide.pdf:pdf},
journal = {Office},
number = {March},
pages = {440},
title = {{GAO COst EstimAtinG}},
url = {http://www.gao.gov/products/GAO-09-3SP},
year = {2009}
}
@inproceedings{me03c,
abstract = {To meet the needs of busy people who$\backslash$nonly want to know enough to achieve$\backslash$nthe most benefits, the TAR2 treatment$\backslash$nlearner generates easy-to-read and$\backslash$nimmediately useful data mining rules.},
author = {Menzies, Tim and Menzies, Tim and Hu, Ying and Hu, Ying},
booktitle = {IEEE Computer Society},
month = nov,
title = {{Data Mining for$\backslash$nVery Busy People}},
year = {2003}
}
@article{lumsden07,
author = {Lumsden, Larry and Strigel, W},
journal = {IEEE Software},
pages = {54--57},
title = {{SE Challenges in Small Software Companies, Point/Counterpoint}}
}
@incollection{boehm06,
annote = {Available from $\backslash$url\{sunset.usc.edu/csse/TECHRPTS/2005/usccse2005-504/usccse2005-504.pdf\}},
author = {Boehm, B},
booktitle = {Value-based Software Engineering},
editor = {Biffl, Stefan and Aurum, Aybuke and Boehm, Barry and Erdogmus, Hakan and Grunbacher, Paul},
pages = {3--14},
publisher = {Spring Verlag},
title = {{Value-Based Software Engineering: Overview and Agenda}},
year = {2006}
}
@misc{prevue,
author = {$\backslash$urlhttp://www.pacorp.com, Performance Awareness Corporation},
title = {{preVue-C/S}},
year = {1998}
}
@article{Takahashi2005,
abstract = {Mental models are bases to recognise phenomena and make plans to improve situations. They can be expressed in model builders' natural language. It is also necessary to examine mental models using a computer simulation. The Computer simulation requires expressions, which can be translated into computer codes. Therefore, model builders need to translate their model from their own natural language to simulation-friendly language, i.e. stock flow diagrams in System Dynamics. It is widely recognised that this translation is sometimes difficult not only for people who are beginners of System Dynamics but also for people who are experienced in the field. This paper discusses a possible translation procedure and shows an application of it. The proposed procedure is designed to use a subset of a natural language as an intermediate language. This idea is applicable regardless of variety of natural language.},
author = {Takahashi, Yutaka},
file = {:Users/timm/svns/doc/optimalML/05nl2compartments.pdf:pdf},
journal = {Proceedings of the 23rd International Conference of the System Dynamics Society},
pages = {141},
title = {{Translation from Natural Language to Stock Flow Diagrams}},
year = {2005}
}
@inproceedings{men93j,
author = {Menzies, T J and Spurret, R},
booktitle = {Tools Pacific 12},
pages = {213--224},
publisher = {Prentice Hall},
title = {{How to \{E\}dit $\backslash$"it$\backslash$"; or a \{B\}lack-Box \{C\}onstraint \{B\}ased \{F\}ramework for \{U\}ser \{I\}nteraction with \{A\}rbitrary \{S\}tructures}},
year = {1993}
}
@misc{tri03,
author = {Rockets, Tripoli},
month = apr,
title = {{Tripoli Rocketry Association. Motor size classifications}},
year = {2003}
}
@inproceedings{runkel95,
author = {Runkel, J},
booktitle = {Proceedings of the 9th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge-Based Systems Workshop Banff, Canada},
title = {{Analyzing Tasks to Build Reusable Model-Based Tools}},
year = {1995}
}
@inproceedings{motta99,
author = {Motta, E and Fensel, D and Gaspari, M and Benjamins, A},
booktitle = {Proceedings of SEKE '99},
title = {{Specifications of Knowledge Components for Reuse}},
year = {1999}
}
@misc{me02j,
author = {T.Menzies},
institution = {Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{V and V of adaptive systems}},
year = {2002}
}
@inproceedings{kim11,
author = {Kim, Sunghun and Zhang, Hongyu and Wu, Rongxin and Gong, Liang},
booktitle = {ICSE'11},
pages = {481--490},
title = {{Dealing with noise in defect prediction}},
year = {2011}
}
@book{ahern01,
author = {Ahern, D M and Clouse, A and Turner, R},
isbn = {0-201-73500-8},
publisher = {Addison-Wesley},
title = {{CMMI Distilled}},
year = {2001}
}
@article{McFee2011,
abstract = {Many music information retrieval tasks require ï¬nding the nearest neighbors of a query item in a high-dimensional space. However, the complexity of computing nearest neigh- bors grows linearly with size of the database, making exact re- trieval impractical for large databases. We investigate modern variants of the classical KD-tree algorithm, which efï¬ciently index high-dimensional data by recursive spatial partitioning. Experiments on the Million Song Dataset demonstrate that content-based similarity search can be signiï¬cantly acceler- ated by the use of spatial partitioning structures.},
author = {McFee, B. and Lanckriet, Gert},
file = {:Users/timm/svns/doc/11rptrees.pdf:pdf},
isbn = {9780615548654},
journal = {12th International Society for Music Information Retrieval Conference (ISMIR 2011)},
pages = {55--60},
title = {{Large-Scale Music Similarity Search With Spatial Trees}},
url = {http://cseweb.ucsd.edu/~bmcfee/papers/ismir2011\_sptree.pdf},
year = {2011}
}
@article{sendall03,
author = {Sendall, S and Kozacaynski, W},
journal = {IEEE Software},
number = {5},
pages = {42--45},
title = {{Model Transformation: The Heart and Soul of Model-Driven Software Development}},
volume = {20},
year = {2003}
}
@article{Watson,
author = {Watson, Hugh J and Wixom, Barbara H},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Watson, Wixom - 2007 - The Current State of Business Intelligence.pdf:pdf},
journal = {Idea},
title = {{Intelligence}}
}
@book{Burnham2011,
abstract = {CoffeeScript: Accelerated JavaScript Development offers a thorough introduction to this new language, starting from the basics. Youll learn to use time-saving features like list comprehensions and splats, organize your code into modules with extensible classes, and see how to deploy your work to multiple environments. Each chapter is example-driven and includes challenging exercises to push your CoffeeScript know-how further. Through the course of the book, youll build a fast-paced multiplayer word game writing both the client (with jQuery) and server (with Node.js) in CoffeeScript. And because the two languages are so deeply intertwined, youll deepen your understanding of JavaScript along the way. CoffeeScript makes it easier than ever to write powerful, standards-compliant JavaScript code. This book lets you start doing it today.},
author = {Burnham, Trevor},
booktitle = {Managing},
file = {:Users/timm/svns/doc/coffeescript-landscape.pdf:pdf},
isbn = {9781934356784},
pages = {136},
title = {{CoffeeScript : Accelerated JavaScript Development}},
url = {http://pragprog.com/book/tbcoffee/coffeescript},
year = {2011}
}
@book{byrn99,
editor = {Baeza-Yates, R A and Ribeiro-Neto, B},
publisher = {Addison-Wesley},
title = {{Modern Information Retrieval}},
year = {1999}
}
@inproceedings{gotel97,
author = {Gotel, O and Finkelstein, A},
booktitle = {International Symposium on Requirements Engineering (RE'97)},
pages = {169--178},
title = {{Extended Requirements Traceability: Results of an Industrial Case Study}},
year = {1997}
}
@article{setamanit07,
author = {Setamanit, S and Wakeland, W and D.Raffo},
journal = {Software Process: Improvement and Practice, (Forthcoming)},
title = {{Using Simulation to Evaluate Global Software Development Task Allocation Strategies}},
year = {2007}
}
@inproceedings{korte08,
author = {Korte, Marcel and Port, Dan},
booktitle = {PROMISE '08: Proceedings of the 4th international workshop on Predictor models in software engineering},
pages = {63--70},
title = {{Confidence in software cost estimation results based on MMRE and PRED}},
year = {2008}
}
@misc{treinish98,
author = {Treinish, L A},
title = {{A Function-Based Data Model for Visualization}},
year = {1998}
}
@article{benj94z,
author = {Benjamins, V R and Jansweijer, W N H},
journal = {IEEE Expert},
month = oct,
number = {5},
pages = {43--53},
title = {{Toward a Competence Theory of Diagnosis}},
volume = {9},
year = {1994}
}
@inproceedings{liu98,
author = {Liu, B and Hsu, W and Ma, Y},
booktitle = {KDD},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/liu98.pdf:pdf},
month = sep,
pages = {80--86},
title = {{Integrating classification and association rule mining}},
year = {1998}
}
@misc{jorgensen05,
author = {Jorgensen, M and Shepperd, M},
month = jan,
title = {{A Systematic Review of Software Development Cost Estimation Studies}},
year = {2007}
}
@inproceedings{russo01,
author = {Russo, A},
booktitle = {Handbook of Software and Knowledge Engineering},
editor = {Chung, C K},
title = {{On the Use of Logical Abduction in Software Engineering}},
volume = {1},
year = {2001}
}
@article{Zhang2007a,
author = {Zhang, Nan and Zhao, Wei},
doi = {10.1109/MC.2007.142},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zhang - 2007 - Privacy-Preserving Data Mining Systems.pdf:pdf},
issn = {0018-9162},
journal = {Computer},
month = apr,
number = {4},
pages = {52--58},
title = {{Privacy-Preserving Data Mining Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4160223},
volume = {40},
year = {2007}
}
@article{jorgensen04,
author = {Jorgensen, M and Molokken-Ostvold, K},
journal = {IEEE Transactions on Software Engineering},
month = dec,
number = {12},
title = {{Reasons for Software Effort Estimation Error: Impact of Respondent Error, Information Collection Approach, and Data Analysis Method}},
volume = {30},
year = {2004}
}
@article{chen95,
author = {Chen, I and Tsao, T},
journal = {IEEE Transactions on Reliability},
month = mar,
pages = {54--62},
title = {{A Reliability Model for Real-Time Rule-Based Expert Systems}},
year = {1995}
}
@article{Khanna2010,
abstract = {The clinical use of information technology in the dental profession has increased substantially in the past 10 to 20 years. In most developing countries an insufficiency of medical and dental specialists has increased the mortality of patients suffering from various diseases. Employing technology, especially artificial intelligence technology, in medical and dental application could reduce cost, time, human expertise and medical error. This approach has the potential to revolutionise the dental public health scenario in developing countries. Clinical decision support systems (CDSS) are computer programs that are designed to provide expert support for health professionals. The applications in dental sciences vary from dental emergencies to differential diagnosis of orofacial pain, radiographic interpretations, analysis of facial growth in orthodontia to prosthetic dentistry. However, despite the recognised need for CDSS, the implementation of these systems has been limited and slow. This can be attributed to lack of formal evaluation of the systems, challenges in developing standard representations, cost and practitioner scepticism about the value and feasibility of CDSS. Increasing public awareness of safety and quality has accelerated the adoption of generic knowledge based CDSS. Information technology applications for dental practice continue to develop rapidly and will hopefully contribute to reduce the morbidity and mortality of oral and maxillofacial diseases and in turn impact patient care.},
author = {Khanna, Sunali},
file = {:Users/timm/svns/doc/millington09.pdf:pdf},
issn = {0020-6539},
journal = {International dental journal},
keywords = {Artificial Intelligence,Decision Making, Computer-Assisted,Decision Support Systems, Clinical,Dentistry,Fuzzy Logic,Humans,Knowledge Bases,Neural Networks (Computer),User-Computer Interface},
month = aug,
number = {4},
pages = {269--72},
pmid = {20949757},
title = {{Artificial intelligence: contemporary applications and future compass.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20949757},
volume = {60},
year = {2010}
}
@inproceedings{sammut92,
author = {Sammut, C and Hurst, S and Kedzier, D and Michie, D},
booktitle = {Ninth International Conference on Machine Learning},
editor = {Sleeman, D},
pages = {385--393},
publisher = {Morgan Kaufmann},
title = {{Learning to Fly}},
year = {1992}
}
@article{steels90,
author = {Steels, L},
journal = {\{AI\} Magazine},
pages = {29--49},
title = {{Components of \{E\}xpertise}},
volume = {11},
year = {1990}
}
@inproceedings{john95,
annote = {Available from $\backslash$url\{http://citeseer.ist.psu.edu/john95estimating.html\}},
author = {John, G H and Langley, P},
booktitle = {Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence Montreal, Quebec: Morgan Kaufmann},
pages = {338--345},
title = {{Estimating continuous distributions in Bayesian classifiers}},
year = {1995}
}
@article{poole88,
author = {Poole, D},
journal = {Artificial Intelligence},
pages = {27--47},
title = {{A Logical Framework for Default Reasoning}},
volume = {36},
year = {1988}
}
@inproceedings{me03d,
author = {Gunnalan, R and T, Menzies and Appukutty, K and A, Srinivasan and Hu, Y},
title = {{Feature Subset Selection with \{TAR2less\}}},
year = {2003}
}
@book{schank77a,
address = {Hillsdale, NJ.},
author = {Schank, R and Abelson, R},
publisher = {Lawrence Erlbaum Associates},
title = {{Scripts, plans, goals and understanding: An inquiry into human knowledge structures}},
year = {1977}
}
@inproceedings{green94,
author = {Greenspan, S and Mylopoulos, J and Borgida, A},
booktitle = {International Conference on Software Engineering},
pages = {135--147},
title = {{On Formal Requirements Modeling Languages: RML Revisited}},
year = {1994}
}
@inproceedings{rich97za,
author = {Richards, D and Menzies, T J},
booktitle = {Third Australian Knowledge Acquisition Workshop, Perth},
editor = {Menzies, T J and Richards, D and Compton, P},
title = {{Extending Knowledge Engineering to Requirements Engineering from Multiple Perspectives}},
year = {1997}
}
@inproceedings{me02g,
author = {Menzies, Tim and Lutz, Robyn and Mikulski, Carmen},
booktitle = {SEKE03},
title = {{Better Analysis of Defect Data at \{NASA\}}},
year = {2003}
}
@incollection{will92,
author = {Williams, Colin P},
booktitle = {Recent Advances in Qualitative Physics},
editor = {Faltings, Boi and Struss, Peter},
pages = {435--450},
publisher = {The MIT Press},
title = {{Analytic Abduction from Qualitative Simulation}},
year = {1992}
}
@inproceedings{clark93,
author = {Clark, P and Matwin, S},
booktitle = {Proceedings of the Tenth International Machine Learning Conference, ML-93},
editor = {Utgoff, P},
organization = {Department of Computer Science, Ottawa University, Canada},
pages = {49--56},
title = {{Using Qualitative Models to Guide Inductive Learning}},
year = {1993}
}
@article{shadbolt00,
annote = {(to appear)},
author = {Shadbolt, N and O'Hara, K and Crow, L},
journal = {International Journal of Human-Computer Studies},
title = {{The Experimental Evaluation of Knowledge Acquisition Techniques and Methods: History, Problems and New Directions}},
year = {2000}
}
@article{clancey89,
author = {Clancey, W},
journal = {IEEE Expert},
pages = {9--23},
title = {{Viewing Knowledge Bases as Qualitative Models}},
year = {1989}
}
@article{Meingast2006a,
abstract = {The face of health care is changing as new technologies are being incorporated into the existing infrastructure. Electronic patient records and sensor networks for in-home patient monitoring are at the current forefront of new technologies. Paper-based patient records are being put in electronic format enabling patients to access their records via the Internet. Remote patient monitoring is becoming more feasible as specialized sensors can be placed inside homes. The combination of these technologies will improve the quality of health care by making it more personalized and reducing costs and medical errors. While there are benefits to technologies, associated privacy and security issues need to be analyzed to make these systems socially acceptable. In this paper we explore the privacy and security implications of these next-generation health care technologies. We describe existing methods for handling issues as well as discussing which issues need further consideration.},
author = {Meingast, Marci and Roosta, Tanya and Sastry, Shankar},
doi = {10.1109/IEMBS.2006.260060},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Meingast, Roosta, Sastry - 2006 - Security and privacy issues with health care information technology.pdf:pdf},
issn = {1557-170X},
journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
keywords = {Biomedical Technology,Computer Communication Networks,Computer Security,Confidentiality,Database Management Systems,Equipment Design,Humans,Information Management,Internet,Medical Informatics Applications,Medical Records Systems, Computerized,Monitoring, Physiologic,Monitoring, Physiologic: instrumentation,Monitoring, Physiologic: methods,Privacy,Telemedicine,Telemedicine: instrumentation,Telemedicine: methods},
month = jan,
pages = {5453--8},
pmid = {17946702},
title = {{Security and privacy issues with health care information technology.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17946702},
volume = {1},
year = {2006}
}
@article{Sen,
author = {Sen, Arun and Ramamurthy, K Ram and Sinha, Atish P},
file = {:Users/timm/svns/doc/sen11.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
title = {{IEEE TRANSACTIONS ON SOFTWARE ENGINEERING A Model of Data Warehousing Process Maturity}}
}
@article{briand02,
author = {Briand, Lionel and Melo, Walc\'{e}lio and W\"{u}st, J\"{u}rgen},
journal = {IEEE Trans. Software Eng.},
number = {7},
pages = {706--720},
title = {{Assessing the Applicability of Fault-Proneness Models Across Object-Oriented Software Projects}},
volume = {28},
year = {2002}
}
@book{Alpaydin2004,
author = {Alpaydin, Ethem},
publisher = {MIT Press},
title = {{Introduction to Machine Learning}},
year = {2004}
}
@article{gutjahr99,
author = {Gutjhar, W J},
journal = {IEEE Transactions on Software Engineering},
number = {5},
pages = {661--674},
title = {{Partition vs. Random Testing: The Influence of Uncertainty}},
volume = {25},
year = {1999}
}
@article{reggia83,
author = {Reggia, J and Nau, D S and Wang, P Y},
journal = {Int. J. of Man-Machine Studies},
number = {5},
pages = {437--460},
title = {{Diagnostic \{E\}xpert \{S\}ystems \{B\}ased on a \{S\}et \{C\}overing \{M\}odel}},
volume = {19},
year = {1983}
}
@article{Menzies2006,
author = {Menzies, Tim and Chen, Zhihao and Hihn, Jairus and Lum, Karen},
doi = {10.1109/TSE.2006.114},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Menzies et al. - 2006 - Selecting Best Practices for Effort Estimation.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
keywords = {data mining,effort estimation method,heuristic rejection rule,project management,software cost estimation,standard statistical method,statistical analysisCOSEEKMO toolkit},
number = {11},
pages = {883--895},
title = {{Selecting Best Practices for Effort Estimation}},
volume = {32},
year = {2006}
}
@article{Bavota2013,
author = {{Bavota Gabriele}, De Lucia Andrea Marcus Andrian and Oliveto, Rocco},
journal = {Empirical Software Engineering},
pages = {1--48},
title = {{Automating extract class refactoring: an improved method and its evaluation}},
year = {2013}
}
@article{quinlan86,
author = {Quinlan, R},
journal = {Machine Learning},
pages = {81--106},
title = {{Induction of Decision Trees}},
volume = {1},
year = {1986}
}
@inproceedings{SUNDARAM2005,
address = {New York, NY, USA},
author = {Sundaram, Senthil Karthikeyan and Hayes, Jane Huffman and Dekhtyar, Alexander},
booktitle = {PROMISE '05: Proceedings of the 2005 workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1083165.1083169},
isbn = {-159593-125-2},
pages = {1--6},
publisher = {ACM},
title = {{Baselines in requirements tracing}},
year = {2005}
}
@inproceedings{kang95a,
author = {Kang, B H and Compton, P and Preston, P},
booktitle = {Proceedings 9th Banff Workshop on Knowledge Acquisition},
title = {{Multiple Classification Ripple Down Rules: Evaluation and Possibilities}},
year = {1995}
}
@inproceedings{wino75,
author = {Winograd, T},
booktitle = {Readings in Knowledge Representation},
pages = {185--210},
publisher = {Morgan Kaufman},
title = {{Frame Representations and the Declarative/Procedural Controversy}},
year = {1975}
}
@article{raffo05b,
author = {Raffo, D and Menzies, T},
journal = {Journal of Information, Software and Technology},
month = dec,
number = {15},
pages = {1009--1017},
title = {{Software project management using PROMPT: A hybrid metrics, modeling and utility framework}},
volume = {47},
year = {2005}
}
@article{dietterich97,
author = {Dietterich, T G},
journal = {AI Magazine},
number = {4},
pages = {97--136},
title = {{Machine Learning Research: Four Current Directions}},
volume = {18},
year = {1997}
}
@article{tian03,
author = {Tian, Liang and Noore, Afzel},
issn = {0094-2898},
journal = {Proceedings of the 35th Southeastern Symposium on System Theory},
pages = {232--236},
title = {{Multistage Software Estimation}},
year = {2003}
}
@article{gabow76,
author = {Gabow, H N and Maheshwari, S N and Osterweil, L},
journal = {IEEE Trans. Software Engrg},
pages = {227--231},
title = {{On Two Problems in the Generation of Program Test Paths}},
volume = {SE-2},
year = {1976}
}
@unpublished{spinmanual,
author = {Holzmann, Gerard J},
title = {{\{B\}asic \{SPIN\} \{M\}anual}}
}
@article{Foundation2010a,
author = {Foundation, Michael J Fox},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Foundation - 2010 - Rare Sharing of Data Leads to Progress on Alzheimer â s.pdf:pdf},
journal = {Order A Journal On The Theory Of Ordered Sets And Its Applications},
title = {{Rare Sharing of Data Leads to Progress on Alzheimer â s}},
year = {2010}
}
@unpublished{hod96,
author = {Hodgson, B},
title = {{Personal communication}},
year = {1996}
}
@article{shull00b,
author = {Shull, F and Lanubile, F and Basili, V R},
journal = {IEEE Transactions of Software Engineering},
number = {11},
pages = {1101--1118},
title = {{Investigating Reading Techniques for Object-Oriented Framework Learning}},
volume = {26},
year = {2000}
}
@article{basili99z,
author = {Basili, Victor and Belady, Laszlo and Boehm, Barry and Brooks, Frederick and Browne, James and DeMillo, Richard and Feldman, Stuart and Green, Cordell and Lampson, Bulter and Lawrie, Duncan and Leveson, Nancy and Lynch, Nancy and Weiser, Mark and Wing, Jeanette},
journal = {SIGSOFT Softw. Eng. Notes},
month = may,
number = {3},
pages = {37--44},
title = {{NSF workshop on a software research program for the 21st century}},
volume = {24},
year = {1999}
}
@article{me98d,
author = {Menzies, T J and Clancey, B},
journal = {International Journal of Human-Computer Studies},
title = {{Editorial, Special Issue on Situated Cognition}},
volume = {49},
year = {1998}
}
@misc{griener98,
author = {Greiner, C and Hawryszkiewycz, I T and Rose, T and Fliedner, T M},
howpublished = {In preperation},
title = {{Capturing Knowledge for Planning: An Application in Global Health Planning}},
year = {1998}
}
@article{Verykios04,
author = {Verykios, V S and Bertino, E and Fovin, I N and Provenza, L P and Saygin, Y and Theodoridis, Y},
journal = {SIGMOD RECORD},
month = mar,
number = {1},
pages = {50--57},
title = {{State-of-the-art in privacy preserving data mining}},
volume = {33},
year = {2004}
}
@article{Bennett2006,
abstract = {The fields of machine learning and mathematical programming are increasingly intertwined. Optimization problems lie at the heart of most machine learning approaches. The Special Topic on Machine Learning and Large Scale Optimization examines this interplay. Machine learning researchers have embraced the advances in mathematical programming allowing new types of models to be pursued. The special topic includes models using quadratic, linear, second-order cone, semi-definite, and semi-infinite programs. We observe that the qualities of good optimization algorithms from the machine learning and optimization perspectives can be quite different. Mathematical programming puts a premium on accuracy, speed, and robustness. Since generalization is the bottom line in machine learning and training is normally done off-line, accuracy and small speed improvements are of little concern in machine learning. Machine learning prefers simpler algorithms that work in reasonable computational time for specific classes of problems. Reducing machine learning problems to well-explored mathematical programming classes with robust general purpose optimization codes allows machine learning researchers to rapidly develop new techniques. In turn, machine learning presents new challenges to mathematical programming. The special issue include papers from two primary themes: novel machine learning models and novel optimization approaches for existing models. Many papers blend both themes, making small changes in the underlying core mathematical program that enable the develop of effective new algorithms.},
author = {Bennett, Kristin P},
doi = {10.1051/ps},
file = {:Users/timm/svns/doc/optimalML/06overview.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {convex optimization,machine learning,mathematical programming},
pages = {1265--1281},
title = {{The Interplay of Optimization and Machine Learning Research}},
url = {http://portal.acm.org/citation.cfm?id=1248593},
volume = {7},
year = {2006}
}
@inproceedings{FU09,
address = {New York, NY, USA},
author = {Fu, Yu and Koru, A G\"{u}ne$\backslash$cs and Chen, Zhiyuan and {El Emam}, Khaled},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540443},
isbn = {978-1-60558-634-2},
pages = {1--12},
publisher = {ACM},
title = {{A tree-based approach to preserve the privacy of software engineering data and predictive models}},
year = {2009}
}
@book{forr61,
author = {Forrester, J W},
publisher = {Pegasus Communications},
title = {{Industrial Dynamics}},
year = {1961}
}
@article{vanHarm96,
author = {van Harmelen, Frank and Aben, Manfred and Ruiz, Fidel and van de Plassche, Joke},
journal = {IEEE Expert},
month = feb,
number = {1},
pages = {56--62},
title = {{Evaluating a formal KBS specification language}},
volume = {11},
year = {1996}
}
@article{me13c,
author = {Zimmermann, Thomas and Menzies, Tim},
journal = {IEEE Software},
number = {4},
pages = {31--37},
title = {{Software Analytics: So What?}},
volume = {30},
year = {2013}
}
@article{porter90,
author = {Porter, A A and Selby, R W},
journal = {IEEE Software},
month = mar,
pages = {46--54},
title = {{Empirically Guided Software Development Using Metric-Based Classification Trees}},
year = {1990}
}
@book{Sedgewick,
author = {Sedgewick, Robert and Wayne, Kevin},
file = {:Users/timm/svns/doc/11sedgewick.pdf:pdf},
isbn = {9780321573513},
title = {{Algorithms (Java)}}
}
@article{marcus87,
author = {Marcus, S and Stout, J and McDermott, J},
journal = {AI Magazine},
pages = {41--58},
title = {{\{VT\}: An \{E\}xpert \{E\}levator \{D\}esigner \{T\}hat \{U\}ses \{K\}nowledge-\{B\}ased \{B\}acktracking}},
year = {1987}
}
@article{Malone1994,
author = {Malone, Thomas W and Crowston, Kevin},
file = {:Users/timm/svns/doc/malone94.pdf:pdf},
journal = {Computing},
number = {1},
title = {{The Interdisciplinary Study of Coordination}},
volume = {2},
year = {1994}
}
@book{Burnham2011a,
abstract = {CoffeeScript: Accelerated JavaScript Development offers a thorough introduction to this new language, starting from the basics. Youll learn to use time-saving features like list comprehensions and splats, organize your code into modules with extensible classes, and see how to deploy your work to multiple environments. Each chapter is example-driven and includes challenging exercises to push your CoffeeScript know-how further. Through the course of the book, youll build a fast-paced multiplayer word game writing both the client (with jQuery) and server (with Node.js) in CoffeeScript. And because the two languages are so deeply intertwined, youll deepen your understanding of JavaScript along the way. CoffeeScript makes it easier than ever to write powerful, standards-compliant JavaScript code. This book lets you start doing it today.},
author = {Burnham, Trevor},
booktitle = {Managing},
file = {:Users/timm/svns/doc/coffeescript.pdf:pdf},
isbn = {9781934356784},
pages = {136},
title = {{CoffeeScript : Accelerated JavaScript Development}},
url = {http://pragprog.com/book/tbcoffee/coffeescript},
year = {2011}
}
@inproceedings{QWFENG95,
author = {Feng, Q W and Cohen, R F and Eades, P},
booktitle = {Proc. of the First International Conference on Computing and Combinatorics (COCOON95)},
publisher = {Springer-Verlag},
series = {Lecture Notes in Computer Science},
title = {{How to Draw a Planar Clustered Graph}},
year = {1995}
}
@inproceedings{richards97,
author = {Richards, D and Compton, P},
booktitle = {SEKE '97: Proceedings of 1997 Conf. on Software Eng. \& Knowledge Eng, Madrid},
title = {{Combining Formal Concept Analysis and Ripple Down Rules to Support the Reuse of Knowledge}},
year = {1997}
}
@inproceedings{levy96a,
author = {Levy, A Y and Rousset, M},
booktitle = {Proceedings of the 12th European Conference on AI (ECAI-96), Budapest, Hungary},
title = {{CARIN: A Representation Language Combining Horn Rules and Description Logics}},
year = {1006}
}
@article{blei03,
author = {Blei, David M and Ng, Andrew Y and Jordan, Michael I},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = mar,
pages = {993--1022},
title = {{Latent dirichlet allocation}},
volume = {3},
year = {2003}
}
@book{bi05,
author = {editors. {S. Biffl A. Aurum}, B Boehm H Erogmus P Grï¿½nbacher},
publisher = {Springer},
title = {{Value-Based Software Engineering}},
year = {2005}
}
@phdthesis{yun04,
author = {Liu, Alexander Yun-chung},
school = {Graduate School, University of Texas at Austin},
title = {{The Effect of Oversampling and Undersampling on Classifying Imbalanced Text Datasets}},
year = {2004}
}
@inproceedings{wilkinson11,
author = {Wilkinson, Leland and Anand, Anushka and Tuan, Dang Nhon},
pages = {6--14},
series = {KDD '11},
title = {{CHIRP: a new classifier based on composite hypercubes on iterated random projections}},
year = {2011}
}
@inproceedings{polyak98b,
author = {Polyak, S and Lee, J and Gruninger, M and Menzel, C},
booktitle = {Proceedings of Workshop on Applications of Ontologies and Problem Solving Methods, ECAI'98, Brighton, England},
editor = {Gomez-Perez, A and Benjamins, R},
month = aug,
title = {{Applying the Process Interchange Format(PIF) to a Supply Chain Process Interoperability Scenario}},
year = {1998}
}
@inproceedings{owen2b,
abstract = { In the development of high-assurance systems, formal modeling, analysis and verification techniques are playing an increasingly important role. In spite of significant advances, formal modeling and verification using model checking, still suffer from limited applicability. The main reason is the exponential runtime space growth exhibited, in the general case, by model checkers. We describe a less rigorous alternative to model checking. We propose an algorithm that automatically translates finite state machine models used by model checkers into a variation of AND-OR graphs. State space verification of AND-OR graphs does not suffer from state space explosion, but its exhaustive search is an NP complete problem. Hence, we demonstrate that random search of AND-OR graphs is a viable alternative to model checking, suitable for system debugging and fast analysis during system development. We support our conclusions through the studies of two models, Dekker's two process mutual exclusion algorithm and the Space Shuttle's liquid hydrogen subsystem.},
author = {Owen, D. and Cukic, B. and Menzies, T.},
booktitle = {7th IEEE International Symposium on High Assurance Systems Engineering, 2002. Proceedings.},
doi = {10.1109/HASE.2002.1173112},
isbn = {0-7695-1769-2},
issn = {1530-2059},
pages = {119},
title = {{An alternative to model checking: verification by random search of AND-OR graphs representing finite-state models}},
volume = {1},
year = {2002}
}
@inproceedings{cai05,
address = {New York, NY, USA},
author = {Cai, Yuanfang and Sullivan, Kevin J},
booktitle = {ASE '05: Proceedings of the 20th IEEE/ACM international Conference on Automated software engineering},
doi = {http://doi.acm.org.proxy.lib.muohio.edu/10.1145/1101908.1101962},
isbn = {1-59593-993-4},
pages = {329--332},
publisher = {ACM Press},
title = {{Simon: modeling and analysis of design space structures}},
year = {2005}
}
@misc{nikora04,
author = {Nikora, A},
title = {{Personnel communication on the accuracy of severity determinations in NASA databases}},
year = {2004}
}
@article{me10a,
author = {Menzies, T J and Multon, Z and Turhan, B and Cukic, B and Jiang, Y and Bener, A},
journal = {Automated Software Engineering},
title = {{Defect Prediction from Static Code Features: Current Results, Limitations, New Approaches}},
year = {2010}
}
@inproceedings{sammut92,
author = {Sammut, C and Hurst, S and Kedzier, D and Michie, D},
booktitle = {Ninth International Conference on Machine Learning},
editor = {Sleeman, D},
pages = {385--393},
publisher = {Morgan Kaufmann},
title = {{Learning to Fly}},
year = {1992}
}
@article{DeSouza2006,
author = {{De Souza}, Jerffeson Teixeira and Matwin, Stan and Japkowicz, Nathalie},
doi = {10.1007/s00453-006-1220-3},
file = {:Users/timm/svns/doc/06jeffFSSparallel.pdf:pdf},
issn = {01784617},
journal = {Algorithmica (New York)},
keywords = {Feature selection,Hybrid system,Master-slave design pattern,Parallelism},
number = {3},
pages = {433--456},
title = {{Parallelizing feature selection}},
volume = {45},
year = {2006}
}
@inproceedings{zhang95,
author = {Zhang, Z},
booktitle = {Fourth Asian Test Symposium},
title = {{An Approach to Hierarchy Model Checking via Evaluating CTL Hierarchically}},
year = {1995}
}
@inproceedings{lowrey98,
author = {Lowry, M and Boyd, M and Kulkarni, D},
booktitle = {Proceedings, ASE'98: Automated Software Engineering},
pages = {322--331},
title = {{Towards a Theory for Integration of Mathematical Verification and Empirical Testing}},
year = {1998}
}
@article{Fikes99,
author = {Fikes, R and Farquhar, A},
journal = {IEEE Intelligent Systems},
month = mar,
number = {2},
pages = {73--79},
title = {{Distributed Repositories of Highly Expressive Reusable Ontologies}},
volume = {14},
year = {1999}
}
@article{myrtveit05,
author = {Myrtveit, Ingunn and Stensrud, Erik and Shepperd, Martin},
journal = {IEEE Transactions on Software Engineerining},
month = may,
number = {5},
pages = {380--391},
title = {{Reliability and Validity in Comparative Studies of Software Prediction Models}},
volume = {31},
year = {2005}
}
@misc{krill01,
author = {Krill, Paul},
month = oct,
title = {{Data quality issues plague CRM}},
year = {2001}
}
@inproceedings{me00e,
abstract = {When a lack of data inhibits decision-making, large-scale what-if
queries can be conducted over the uncertain parameter ranges. Such
queries can generate an overwhelming amount of data. We describe a
general method for understanding that data. Large-scale what-if queries
can guide Monte Carlo simulations of a model. Machine learning can then
be used to summarize the output. The summarization is an ensemble of
decision trees. The TARZAN system [so-called because it swings through
(or searches) the decision trees] can poll the ensemble looking for
majority conclusions regarding what factors change the classifications
of the data. TARZAN can succinctly present the results from very large
what-if queries. For example, in one of the studies presented, we can
view the significant features from 10<sup>9</sup> what-if queries on
half a page},
author = {Menzies, T. and Sinsel, E.},
booktitle = {Proceedings ASE 2000. Fifteenth IEEE International Conference on Automated Software Engineering},
doi = {10.1109/ASE.2000.873661},
isbn = {0-7695-0710-7},
issn = {1527-1366},
title = {{Practical large scale what-if queries: case studies with software
risk assessment}},
year = {2000}
}
@article{Sampson2003,
abstract = {DNA and RNA microarrays have become an important analytical technique in the understanding and characterisation of genomes and transcriptomes. A recent development in this field of combinatorial chemistry has concentrated on using artificial DNA/RNA sequences-aptamers-as the screening ligand. In reviewing this technology, the article covers the topic, following a general introduction, under the headings: Generating an aptamer library, aptamer library complexity, aspects of nucleotide chemistry, constant region primer design, and the SELEX protocol for exposing an aptamer library to the desired target. ?? 2003 Elsevier Science Ltd. All rights reserved.},
author = {Sampson, Tim},
doi = {10.1016/S0172-2190(03)00035-8},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Sampson03.pdf:pdf},
isbn = {0172-2190},
issn = {01722190},
journal = {World Patent Information},
keywords = {Aptamers,Combinatorial chemistry,Exponential enrichment,Microarrays,Molecular evolution,Oligonucleotide ligands,SELEX protocol,Screening library,Spiegelmers},
number = {2},
pages = {123--129},
title = {{Aptamers and SELEX: The technology}},
volume = {25},
year = {2003}
}
@book{kan95,
author = {Kan, Stephen H},
publisher = {Addison-Wesley},
title = {{Metrics and Models in Software Quality Engineering}},
year = {2002}
}
@article{Guyon2003,
author = {Guyon, Isabelle and Elisseefi, Andre},
doi = {10.1162/153244303322753616},
editor = {Kaelbling, Leslie Pack},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - r d V a a.pdf:pdf},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {bioinformatics,clustering,computational biology,feature selection,gene expression,genomics,information retrieval,information theory,microarray,model selection,pat-,proteomics,qsar,space dimensionality reduction,statistical testing,support vector machines,tern discovery,text classi\o cation,variable selection,wrappers,\o lters},
month = oct,
number = {7-8},
pages = {1157--1182},
title = {{An Introduction to Variable and Feature Selection}},
url = {http://www.crossref.org/jmlr\_DOI.html},
volume = {3},
year = {2003}
}
@article{me06e,
annote = {Available on-line at $\backslash$url\{http://menzies.us/pdf/06costs.pdf\}},
author = {Menzies, T and Hihn, J},
journal = {IEEE Software},
title = {{Evidence-Based Cost Estimation for Better Quality Software}},
year = {2006}
}
@misc{McCaugherty98,
author = {McCaugherty, D},
howpublished = {presentation by Averstar Inc.},
month = feb,
title = {{Criticality Analysis and Risk Assessment (CARA)}},
year = {1998}
}
@inproceedings{rich98zb,
author = {Richards, D and Menzies, T J},
booktitle = {Banff Workshop on Knowledge Acquisition},
title = {{Extending the SISYPHUS III Experiment from a Knowledge Engineering Task to a Requirements Engineering Task}},
year = {1998}
}
@misc{hulten02mining,
annote = {Available from $\backslash$url\{citeseer.ist.psu.edu/hulten02mining.html\}},
author = {Hulten, G and Domingos, P},
pages = {525--531},
title = {{Mining complex models from arbitrarily large databases in constant time}},
year = {2002}
}
@article{lukins10,
address = {Newton, MA, USA},
author = {Lukins, Stacy K and Kraft, Nicholas A and Etzkorn, Letha H},
issn = {0950-5849},
journal = {Inf. Softw. Technol.},
number = {9},
pages = {972--990},
publisher = {Butterworth-Heinemann},
title = {{Bug localization using latent Dirichlet allocation}},
volume = {52},
year = {2010}
}
@article{gruber93,
author = {Gruber, T R},
journal = {Knowledge Acquisition},
number = {2},
pages = {199--220},
title = {{A Translation Approach to Portable Ontology Specifications}},
volume = {5},
year = {1993}
}
@inproceedings{BRODER2008,
address = {New York, NY, USA},
author = {Broder, Andrei and Ciaramita, Massimiliano and Fontoura, Marcus and Gabrilovich, Evgeniy and Josifovski, Vanja and Metzler, Donald and Murdock, Vanessa and Plachouras, Vassilis},
booktitle = {CIKM '08: Proceeding of the 17th ACM conference on Information and knowledge management},
doi = {http://doi.acm.org/10.1145/1458082.1458216},
isbn = {978-1-59593-991-3},
pages = {1003--1012},
publisher = {ACM},
title = {{To swing or not to swing: learning when (not) to advertise}},
year = {2008}
}
@article{hor90,
author = {Horwitz, S and {T. Reps} and Binkley, D},
journal = {ACM Transactions on Programming Languages and Systems},
month = jan,
number = {12},
pages = {26--60},
title = {{Interprocedural slicing using dependence graphs}},
volume = {1},
year = {1990}
}
@article{dekleer87,
author = {DeKleer, J and Williams, B C},
journal = {Artificial Intelligence},
pages = {97--130},
title = {{Diagnosing \{M\}ultiple \{F\}aults}},
volume = {32},
year = {1987}
}
@inproceedings{Dougherty1995,
author = {Dougherty, J and Kohavi, R and Sahami, M.},
booktitle = {MACHINE LEARNING-INTERNATIONAL WORKSHOP THEN CONFERENCE-},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Dougherty, Kohavi, Sahami - 1995 - Supervised and unsupervised discretization of continuous features.pdf:pdf},
pages = {194--202},
publisher = {MORGAN KAUFMANN PUBLISHERS, INC.},
title = {{Supervised and unsupervised discretization of continuous features}},
url = {http://robotics.stanford.edu/users/sahami/papers-dir/disc.pdf},
year = {1995}
}
@article{me11f,
author = {Lumpe, M and Vasa, R and Menzies, T and Rush, R and Turhan, R},
journal = {International Journal of Software Engineering and Knowledge Engineering},
number = {45},
pages = {725--753},
title = {{Learning Better Inspection Optimization Policies}},
volume = {21},
year = {2011}
}
@article{smythe87,
author = {Smythe, G A},
journal = {Exp. Clin. Endocrinol. (Life Sci. Adv.)},
pages = {141--144},
title = {{Hypothalamic noradrenergic activation of stress-induced adrenocorticotropin (\{ACTH\}) release: Effects of acute and chronic dexamethasone pre-treatment in the rat}},
year = {1987}
}
@inproceedings{petersen09,
author = {Petersen, K and Wohlin, C},
booktitle = {Empirical Software Engineering and Measurement, 2009. ESEM 2009. 3rd International Symposium on},
pages = {401--404},
title = {{Context in industrial software engineering research}},
year = {2009}
}
@article{Hasselblad1995,
abstract = {Screening and diagnostic tests are common in the fields of psychology, medicine, and education. Often there are several competing tests, and decisions must be made about the relative accuracy of those tests. This article describes a general measure that can be used for both continuous and dichotomous outcome measures. It is the standardized distance between the means of the 2 populations. For continuous measures, it is the effect size measure. For dichotomous measures, it is proportional to the logarithm of the odds of the sensitivity plus the logarithm of the odds of the specificity. The measure is easily computed for both kinds of outcomes. Properties of this measure are discussed, and examples are given. Ths use of this measure to compare the average performance of different tests is described.},
author = {Hasselblad, V and Hedges, L V},
doi = {10.1037/0033-2909.117.1.167},
file = {:Users/timm/svns/doc/erin/references/ClusterQuality/Hasselblad95.pdf:pdf},
isbn = {0033-2909 (Print)},
issn = {0033-2909},
journal = {Psychological bulletin},
number = {1},
pages = {167--178},
pmid = {7870860},
title = {{Meta-analysis of screening and diagnostic tests.}},
volume = {117},
year = {1995}
}
@article{provost99survey,
author = {Provost, Foster J and Kolluri, Venkateswarlu},
journal = {Data Mining and Knowledge Discovery},
number = {2},
pages = {131--169},
title = {{A Survey of Methods for Scaling Up Inductive Algorithms}},
volume = {3},
year = {1999}
}
@article{jacob95,
author = {Jacobson, I and Christerson, M},
journal = {JOOP},
pages = {15--19},
title = {{A \{G\}rowing \{C\}onsensus on \{U\}se \{C\}ases}},
year = {1995}
}
@article{takagi05,
author = {Takagi, Y and Mizuno, O and Kikuno, T},
journal = {Empirical Software Engineering},
number = {4},
pages = {495--515},
title = {{An Empirical Approach to Characterizing Risky Software Projects Based on Logistic Regression Analysis}},
volume = {0},
year = {2005}
}
@article{Manegold2010,
author = {Manegold, S. and Laurent, D. and Lupu, M. and Onose, N. and R\'{e}, C. and Sans, V. and Senellart, P. and Wu, T. and Shasha, D. and Manolescu, I. and Afanasiev, L. and Feng, J. and Gou, G. and Hadjieleftheriou, M. and Harizopoulos, S. and Kalnis, P. and Karanasos, K.},
doi = {10.1145/1815933.1815944},
file = {:Users/timm/svns/doc/manegold09.pdf:pdf},
issn = {01635808},
journal = {ACM SIGMOD Record},
keywords = {repeatability},
mendeley-tags = {repeatability},
month = dec,
number = {3},
pages = {40},
title = {{Repeatability \& workability evaluation of SIGMOD 2009}},
url = {http://portal.acm.org/citation.cfm?doid=1815933.1815944},
volume = {38},
year = {2010}
}
@incollection{fea03a,
author = {Feather, M S and Menzies, T and Connelly, J R},
booktitle = {Proceedings of the 2003 Asia-Pacific Software Engineering Conference (APSEC 2003); Chiangmai, Thailand},
month = dec,
title = {{Matching Software Practitioner Needs to Researcher Activities}},
year = {2003}
}
@book{wier96,
author = {Wieringa, R J},
publisher = {Wiley},
title = {{Requirements Engineering: Frameworks for Understanding}},
year = {1996}
}
@inproceedings{dieng93,
author = {Dieng, R and Corby, O and Lapalut, S},
booktitle = {EKAW '93: Knowledge Acquisition for Knowledge-Based Systems: 7th European Workshop},
editor = {Aussenac, N and Boy, G and Gaines, B and {M. Linster}, T.-G. Ganascia and Kodratoff, Y},
pages = {407--426},
title = {{Acquisition of Gradual Knowledge}},
year = {1993}
}
@article{chandra86,
author = {Chandrasekaran, B},
journal = {IEEE Expert},
pages = {23--30},
title = {{Generic Tasks in Knowledge-Based Reasoning: High-Level Building Blocks for Expert System Design}},
year = {1986}
}
@article{suwa82,
author = {Suwa, M and Scott, A C and Shortliffe, E H},
journal = {AI Magazine},
number = {4},
pages = {16--21},
title = {{Completeness and Consistency in Rule-Based Expert Systems}},
volume = {3},
year = {1982}
}
@article{liu10,
author = {Liu, Yi and Khoshgoftaar, T M and Seliya, N},
file = {:Users/timm/svns/doc/transfer/10liu.pdf:pdf},
journal = {Software Engineering, IEEE Transactions on},
number = {6},
pages = {852--864},
title = {{Evolutionary Optimization of Software Quality Modeling with Multiple Repositories}},
volume = {36},
year = {2010}
}
@unpublished{goss95,
annote = {In preparation},
author = {Gledhill, J and Goss, S},
title = {{Modeling Situation Awareness}}
}
@inproceedings{kirsopp02,
author = {Kirsopp, C and Shepperd, M},
booktitle = {Proc. of 22nd SGAI International Conference on Knowledge-Based Systems and Applied Artificial Intelligence, Cambridge, UK},
title = {{Case and Feature Subset Selection in Case-Based Software Project Effort Prediction}},
year = {2002}
}
@article{Nebro2006,
author = {Nebro, A J and Luna, F and Alba, E and Beham, A},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Nebro et al. - 2008 - AbYSS Adapting Scatter Search to Multiobjective Optimization.pdf:pdf},
journal = {Science},
keywords = {diversity,external archive,hybridization,multiobjective optimization,performance comparison,scatter search},
number = {March},
pages = {1--32},
title = {{AbYSS : Adapting Scatter Search for Multiobjective Optimization}},
volume = {01},
year = {2006}
}
@article{Hq,
author = {Hq, By Nasa and Analysis, Program and Division, Cost Analysis and Policy, J C L and Level, Joint Confidence},
file = {:Users/timm/svns/doc/cost/JCLFaq.pdf:pdf},
title = {{Joint Confidence Level ( JCL ) FAQ}}
}
@inproceedings{me00u,
author = {Menzies, T and Singh, H},
booktitle = {Advances in Artificial Intelligence, 14th Biennial Conference of the Canadian Society for Computational Studies of Intelligence, AI 2001, Ottawa, Canada, June 7-9, 2001, Proceedings},
pages = {100--110},
title = {{How AI Can Help SE; or: Randomized Search Not Considered Harmful}},
year = {2001}
}
@inproceedings{me04c,
author = {Menzies, T and Di\~{}Stefano, Justin S and Cunanan, Chris and Chapman, Robert (Mike)},
booktitle = {International Workshop on Mining Software Repositories},
title = {{Mining Repositories to Assist in Project Planning and Resource Allocation}},
year = {2004}
}
@book{lave88,
author = {Lave, J},
publisher = {Cambridge University Press},
title = {{Cognition in Practice}},
year = {1988}
}
@book{dyson12,
author = {Dyson, George},
publisher = {Pantheon},
title = {{Turing's Cathedral: The Origins of the Digital Universe}},
year = {2012}
}
@inproceedings{ammar97,
author = {Ammar, H H and Nikzadeh, T and Dugan, J B},
booktitle = {Proceedings of the International Symposium on Software Metrics},
month = nov,
publisher = {IEEE Computer Society},
title = {{A Methodology for Risk Assessment of Functional Specification of Software Systems Using Colored Petri Nets}},
year = {1997}
}
@inproceedings{cheng92,
author = {Cheng, P C},
booktitle = {AAAI Spring Symposium on Reasoning with Diagrammatic Representations},
editor = {Narayanan, N H},
pages = {33--38},
title = {{Diagrammatic Reasoning in Scientific Discovery: Modelling Galileo's Kinematic Diagrams}},
year = {1992}
}
@article{Brickellc,
author = {Brickell, Justin and Shmatikov, Vitaly},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Brickell, Shmatikov - Unknown - The Cost of Privacy Destruction of Data-Mining Utility in Anonymized Data Publishing Categories and Sub.pdf:pdf},
journal = {ReCALL},
title = {{The Cost of Privacy : Destruction of Data-Mining Utility in Anonymized Data Publishing Categories and Subject Descriptors}}
}
@article{Williams2010,
author = {Williams, James},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Williams - 2010 - Social Networking Applications in Health Care Threats to the Privacy and Security of Health Information.pdf:pdf},
journal = {Health Care},
keywords = {0,[Electronic Manuscript],health information privacy,medicine 2,personal health record,social networks},
pages = {39--49},
title = {{Social Networking Applications in Health Care : Threats to the Privacy and Security of Health Information}},
year = {2010}
}
@inproceedings{lud88,
author = {Ludolph, F and Chow, Y and Ingalls, D and Wallace, S and Doyle, K},
booktitle = {IEEE Proceedings Workshop on Visual Languages},
pages = {222--230},
title = {{The Fabrik Programming Environment}},
year = {1988}
}
@inproceedings{me95a,
author = {Menzies, T J},
booktitle = {Australian Cognitive Science Society, 3rd Conference},
title = {{Situated \{S\}emantics is a \{S\}ide-\{E\}ffect of the \{C\}omputational \{C\}omplexity of \{A\}bduction}},
year = {1995}
}
@inproceedings{jiang07,
abstract = {The prediction of fault-prone modules in a software project has been the topic of many studies. In this paper, we investigate whether metrics available early in the development lifecycle can be used to identify fault-prone software modules. More precisely, we build predictive models using the metrics that characterize textual requirements. We compare the performance of requirements-based models against the performance of code-based models and models that combine requirement and code metrics. Using a range of modeling techniques and the data from three NASA projects, our study indicates that the early lifecycle metrics can play an important role in project management, either by pointing to the need for increased quality monitoring during the development or by using the models to assign verification and validation activities.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07issre.pdf\}},
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim},
booktitle = {The 18th IEEE International Symposium on Software Reliability (ISSRE '07)},
doi = {10.1109/ISSRE.2007.24},
isbn = {978-0-7695-3024-6},
issn = {1071-9458},
title = {{Fault Prediction using Early Lifecycle Data}},
year = {2007}
}
@inproceedings{jiang08,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08compare.pdf\}},
author = {Jiang, Y and Cukic, B and Menzies, T and Bartlow, N},
booktitle = { 4th International Workshop on Predictor Models in Software Engineering, PROMISE 2008},
isbn = {978-1-60558-036-4},
keywords = {Software Quality Measurement},
pages = {11--18},
title = {{Comparing Design and Code Metrics for Software Quality Prediction}},
year = {2008}
}
@inproceedings{gama06,
address = {New York, NY, USA},
annote = {Available from $\backslash$url\{http://www.liacc.up.pt/\~{}jgama/IWKDDS/Papers/p6.pdf \}},
author = {Gama, Joao and Pinto, Carlos},
booktitle = {SAC '06: Proceedings of the 2006 ACM symposium on Applied computing},
file = {:Users/timm/svns/doc/pinto05.pdf:pdf},
isbn = {1-59593-108-2},
pages = {662--667},
publisher = {ACM Press},
title = {{Discretization from data streams: applications to histograms and data mining}},
year = {2006}
}
@article{Hoigaard2011,
author = {Hoigaard, E},
file = {:Users/timm/svns/doc/coffeescriptSmooth.pdf:pdf},
pages = {214},
title = {{Smooth CoffeeScript}},
year = {2011}
}
@misc{woller96,
author = {Woller, J},
title = {{The Basics of Monte Carlo Simulations}},
year = {1996}
}
@inproceedings{oates97,
annote = {Available from $\backslash$url\{http://www.cs.umbc.edu/\~{}oates/publications.html\}},
author = {Oates, Tim and Jensen, David},
booktitle = {Proc. 14th International Conference on Machine Learning},
pages = {254--262},
publisher = {Morgan Kaufmann},
title = {{The effects of training set size on decision tree complexity}},
year = {1997}
}
@article{regan04,
author = {Regan, Patrick and Hamilton, Scott},
journal = {IEEEComputer},
number = {1},
pages = {59--68},
title = {{NASA's Mission Reliable}},
volume = {37},
year = {2004}
}
@inproceedings{hame93,
author = {Haynes, P and Menzies, T J},
booktitle = {Tools Pacific 1993},
organization = {Prentice Hall},
pages = {75--82},
title = {{C++ is \{B\}etter than \{S\}malltalk?}},
year = {1993}
}
@inproceedings{raffo05c,
author = {Raffo, D and Menzies, T},
booktitle = {Proceedings of the 6th International Workshop on Software Process Simulation Modeling (ProSim'05)},
title = {{Evaluating the Impact of a New Technology Using Simulation: The Case for Mining Software Repositories}},
year = {2005}
}
@inproceedings{lukose99,
author = {Lukose, Dickson and Nechab, Said and Pritchard, Simon and Lee, Ashley and Hussen, Sajid and Clawley, Jon and Jackson, Philip and Hare, Chris and Bayliss, Tony and Hawcutts, Mike and Bdar, Alex},
booktitle = {Proceedings of the Banff Knowledge Acquisition Workshop},
title = {{TAPS: Knowledge Management System}},
year = {1999}
}
@inproceedings{me08f,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ispa.pdf\}},
author = {Hihn, J and Menzies, T and Lum, K and Baker, D and Jalali, O},
booktitle = {ISPA'08: International Society of Parametric Analysis},
title = {{\{2CEE\}, A \{T\}WENTY \{F\}IRST \{C\}ENTURY \{E\}FFORT \{E\}STIMATION \{M\}ETHODOLOGY}},
year = {2008}
}
@inproceedings{mockus09,
annote = {Available from $\backslash$url\{http://sequoia.cs.byu.edu/files/reser2010/proceedings/Mockus\%20-\%20Experiences\%20from.pdf\}},
author = {{Audris Mockus Bente Anda} and Sjoberg, Dag I K},
booktitle = {First International Workshop on Replication in Empirical Software Engineering Research, ICSE'09},
title = {{Experiences from Replicating a Case Study to Investigate Reproducibility of Software Development}},
year = {2009}
}
@article{webb09,
author = {Novak, Petra Kralj and Lavra\v{c}, Nada and Webb, Geoffrey I},
journal = {J. Mach. Learn. Res.},
month = jun,
pages = {377--403},
title = {{Supervised Descriptive Rule Discovery: A Unifying Survey of Contrast Set, Emerging Pattern and Subgroup Mining}},
volume = {10},
year = {2009}
}
@inproceedings{bay99,
author = {Bay, S B and Pazzani, M J},
booktitle = {Proceedings of the Fifth International Conference on Knowledge Discovery and Data Mining},
title = {{Detecting Change in Categorical Data: Mining Contrast Sets}},
year = {1999}
}
@inproceedings{me97c,
author = {Menzies, T J and Cohen, R E},
booktitle = {European Symposium on the Validation and Verification of Knowledge Based Systems, Leuven, Belgium},
title = {{A Graph-Theoretic Optimisation of Temporal Abductive Validation}},
year = {1997}
}
@article{dmcdermott87,
author = {McDermott, D},
journal = {Computational Intelligence},
pages = {151--160},
title = {{A \{C\}ritique of \{P\}ure \{R\}eason}},
volume = {3},
year = {1987}
}
@article{macdonell10,
author = {MacDonell, Stephen G and Shepperd, Martin J and Kitchenham, Barbara A and Mendes, Emilia},
journal = {IEEE Trans. Software Eng.},
number = {5},
pages = {676--687},
title = {{How Reliable Are Systematic Reviews in Empirical Software Engineering?}},
volume = {36},
year = {2010}
}
@article{colomb99,
author = {Colomb, R M},
journal = {Artificial Intelligence},
number = {1-2},
pages = {187--209},
title = {{Representation of Propositional Expert Systems as Partial Functions}},
volume = {109},
year = {1999}
}
@inproceedings{me97o,
author = {Menzies, T and Cohen, Rf and Waugh, S},
booktitle = {11th Banff Knowledge Acquisition for \ldots},
title = {{Evaluating conceptual modeling languages}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.28.492\&rep=rep1\&type=pdf},
year = {1998}
}
@inproceedings{briand00,
author = {Briand, L C and Langley, T and Wieczorek, I},
booktitle = {Proceedings of the 22nd International Conference on Software Engineering, Limerick, Ireland},
pages = {377--386},
title = {{A replicated assessment and comparison of common software cost modeling techniques}},
year = {2000}
}
@article{searle82,
annote = {April 29},
author = {Searle, J R},
journal = {The New York Review of Books},
pages = {3--6},
title = {{The Myth of the Computer}},
year = {1982}
}
@inproceedings{goa06,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06compsac.pdf\}},
author = {Gao, J and Heimdahl, M and Owen, D and Menzies, T},
booktitle = {COMPSAC '06},
title = {{On the Distribution of Property Violations in Formal Models: An Initial Study}},
year = {2006}
}
@phdthesis{benj93,
author = {Benjamins, R},
school = {University of Amsterdam},
title = {{Problem Solving Methods for Diagnosis}},
year = {1993}
}
@article{mair00investigation,
author = {Mair, Carolyn and Kadoda, Gada and Lefley, Martin and Phalp, Keith and Ofield1, Chris Sch and Shepperd, Martin and Webster, Steve},
journal = {The Journal of Systems and Software},
number = {1},
pages = {23--29},
title = {{An investigation of machine learning based prediction systems}},
url = {citeseer.ist.psu.edu/mair99investigation.html},
volume = {53},
year = {2000}
}
@inproceedings{veerappa11,
address = {Washington, DC, USA},
author = {Veerappa, V and Letier, E},
booktitle = {Proceedings of the 2011 IEEE 19th International Requirements Engineering Conference},
doi = {10.1109/RE.2011.6051654},
file = {:Users/timm/svns/doc/11veerappa\_clustering.pdf:pdf},
isbn = {978-1-4577-0921-0},
keywords = {Pareto front,industrial problem,multiobjective decision problem,nondominated solution,requirements engineering,search-based technique},
pages = {89--98},
publisher = {IEEE Computer Society},
series = {RE '11},
title = {{Understanding Clusters of Optimal Solutions in Multi-objective Decision Problems}},
url = {http://dx.doi.org/10.1109/RE.2011.6051654},
year = {2011}
}
@article{dekleer86a,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {163--196},
title = {{An \{A\}ssumption-\{B\}ased \{TMS\}}},
volume = {28},
year = {1986}
}
@article{hailpern06,
author = {B. hailpern and P. tarr},
journal = {ibm systems journal},
number = {3},
pages = {451--461},
title = {model-driven develpment: the good, the bad, and the ugly},
volume = {45},
year = {2006}
}
@inproceedings{zelkowitz01,
address = {Washington, DC, USA},
author = {Zelkowitz, Marvin V and Rus, Ioana},
booktitle = {ICSE '01: Proceedings of the 23rd International Conference on Software Engineering},
isbn = {0-7695-1050-7},
pages = {349--357},
publisher = {IEEE Computer Society},
title = {{Understanding \{IV\&V\} in a safety critical and complex evolutionary environment: the NASA space shuttle program}},
year = {2001}
}
@inproceedings{me08g,
abstract = {In mission critical systems, such as those developed by NASA, it is very important that the test engineers properly recognize the severity of each issue they identify during testing. Proper severity assessment is essential for appropriate resource allocation and planning for fixing activities and additional testing. Severity assessment is strongly influenced by the experience of the test engineers and by the time they spend on each issue. The paper presents a new and automated method named SEVERIS (severity issue assessment), which assists the test engineer in assigning severity levels to defect reports. SEVERIS is based on standard text mining and machine learning techniques applied to existing sets of defect reports. A case study on using SEVERIS with data from NASApsilas Project and Issue Tracking System (PITS) is presented in the paper. The case study results indicate that SEVERIS is a good predictor for issue severity levels, while it is easy to use and efficient.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08severis.pdf\}},
author = {Menzies, Tim and Marcus, Andrian},
booktitle = {IEEE International Conference on Software Maintenance, ICSM},
doi = {10.1109/ICSM.2008.4658083},
isbn = {9781424426140},
issn = {1063-6773},
pages = {346--355},
title = {{Automated severity assessment of software defect reports}},
year = {2008}
}
@article{mckelvey05,
author = {McKelvey, Bill and Andriani, Pierpaolo},
journal = {Strategic Organization},
number = {2},
pages = {219--228},
publisher = {Edward Elgar},
title = {{Why Gaussian statistics are mostly wrong for strategic organization}},
volume = {3},
year = {2005}
}
@inproceedings{me08fh,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08antares.pdf\}},
author = {Gundy-Burlet, K and Schumann, J and Menzies, T and Barrett, T},
booktitle = {9th International Symposium on Artifical Intelligence, Robotics and Automation in Space},
title = {{Parametric Analysis of a Hover Test Vehicle Using Advanced Test Generation and Data Analysis}},
year = {2009}
}
@inproceedings{noda99,
author = {Noda, E and Freitas, A A and Lopes, H S},
booktitle = {Evolutionary Computation, 1999. CEC 99. Proceedings of the 1999 Congress on},
pages = {--1329 Vol. 2},
title = {{Discovering interesting prediction rules with a genetic algorithm}},
volume = {2},
year = {1999}
}
@inproceedings{me99f,
author = {Menzies, T and Cukic, B},
booktitle = {Proceedings, AAAI '99 workshop on Intelligent Software Engineering, Orlando, Florida},
month = jul,
title = {{Intelligent Testing can be Very Lazy}},
year = {1999}
}
@book{motwani95,
annote = {(reprinted 1997,2000)},
author = {Motwani, R and Raghavan, P},
isbn = {0521474655},
publisher = {Cambridge University Press},
title = {{Randomized Algorithms}},
year = {1995}
}
@article{darke96,
author = {Darke, P and Shanks, G},
journal = {Requirements Engineering},
number = {2},
pages = {88--105},
title = {{Stakeholder Viewpoints in Requirements Definition: A Framework for Understanding Viewpoint Development Approaches}},
volume = {1},
year = {1996}
}
@article{yann00,
author = {Kalfoglou, Y and Menzies, T and Althoff, K F and Motta, E},
journal = {The Knowledge Engineering Review},
month = dec,
number = {4},
title = {{Meta-Knowledges in systems design: panacea... or undelivered promise?}},
volume = {15},
year = {2000}
}
@inproceedings{deb95a,
author = {Debenham, J},
booktitle = {Proceedings Sixth International Conference on Database and Expert Systems Applications DEXA'95, London, September},
title = {{Understanding Expert Systems Maintenance}},
year = {1995}
}
@inproceedings{garre05,
author = {Garre, M and {J.J. Cuadrado-Gallego}, M Sicilia and Charro, M and Rodriguez, D},
booktitle = {27th International Conference on Information Technology Interfaces. ITI 2005, Dubrovnik, Croatia},
title = {{Segmented Parametric Software Estimation Models: Using the EM algorithm with the ISBSG 8 database}},
year = {2005}
}
@book{sterman00,
author = {Sterman, H},
publisher = {Irwin McGraw-Hill},
title = {{Business Dynamics: Systems Thinking and Modeling for a Complex World}},
year = {2000}
}
@article{leake91,
author = {Leake, D B},
journal = {Cognitive Science},
pages = {509--545},
title = {{Goal-Based Explanation Evaluation}},
volume = {15},
year = {1991}
}
@inproceedings{zuluaga13,
author = {Zuluaga, Marcela and Krause, Andreas and Sergent, Guillaume and P\"{u}schel, Markus},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Active Learning for Multi-Objective Optimization}},
year = {2013}
}
@inproceedings{LI08,
address = {New York, NY, USA},
author = {Li, Jingzhou and Ruhe, Guenther},
booktitle = {PROMISE '08: Proceedings of the 4th international workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1370788.1370803},
isbn = {978-1-60558-036-4},
pages = {55--62},
publisher = {ACM},
title = {{Multi-criteria decision analysis for customization of estimation by analogy method AQUA+}},
year = {2008}
}
@misc{powell99,
author = {Powell, J D},
title = {{A Graph Theoretic Approach to Assessing Tradeoffs on Memory Usage for Model Checking,}},
year = {1999}
}
@inproceedings{tracey98,
author = {Tracey, N and Clarke, J and Mander, K},
booktitle = {International Symposium on Software Testing and Analysis},
month = mar,
pages = {73--81},
publisher = {ACM/SIGSOFT},
title = {{Automated program flaw finding using simulated annealing}},
year = {1998}
}
@article{jones98az,
address = {Hingham, MA, USA},
author = {Jones, Donald R and Schonlau, Matthias and Welch, William J},
issn = {0925-5001},
journal = {J. of Global Optimization},
keywords = {Bayesian global optimization,Kriging,Random function,Response surface,Stochastic process,Visualization},
month = dec,
number = {4},
pages = {455--492},
publisher = {Kluwer Academic Publishers},
title = {{Efficient Global Optimization of Expensive Black-Box Functions}},
volume = {13},
year = {1998}
}
@article{Algorithm2000,
author = {Algorithm, The Metropolis and Method, Monte Carlo},
file = {:Users/timm/svns/doc/dataFarm/00metropolis.pdf:pdf},
pages = {65--69},
title = {{He etropolis lgorithm}},
year = {2000}
}
@inproceedings{meseguer91,
author = {Meseguer, P},
booktitle = {Proceedings of the Ninth National Conference on Artificial Intelligence},
pages = {323--328},
title = {{Verification of Multi-Level Rule-Based Expert Systems}},
year = {1991}
}
@inproceedings{me01f,
author = {Menzies, Tim and Hu, Y},
booktitle = {First International Workshop on Model-based Requirements Engineering},
title = {{Reusing models for requirements engineering}},
year = {2001}
}
@article{jorg11,
author = {J\o rgensen, Magne},
journal = {Information and Software Technology (in press)},
title = {{Contrasting Ideal and Realistic Conditions as a Means to Improve Judgment-based Software Development Effort Estimation}},
year = {2011}
}
@article{hart89,
author = {Hartson, H R and Hicks, D},
journal = {ACM Computing Surveys},
pages = {5--92},
title = {{Human-Computer Interface Development: Concepts and Systems for its Management.}},
volume = {21},
year = {1989}
}
@article{Dalvi2004,
address = {New York, New York, USA},
author = {Dalvi, Nilesh and Domingos, Pedro and Sanghai, Sumit and Verma, Deepak},
doi = {10.1145/1014052.1014066},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Domingos - 2004 - Adversarial Classification.pdf:pdf},
isbn = {1581138889},
journal = {Proceedings of the 2004 ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '04},
keywords = {cost-sensitive learning,game theory,naive bayes,spam de-},
pages = {99},
publisher = {ACM Press},
title = {{Adversarial classification}},
url = {http://portal.acm.org/citation.cfm?doid=1014052.1014066},
year = {2004}
}
@article{jones98,
author = {Jones, B and Eyres, D and Sthamer, H.-H.},
journal = {ï¿½Computer Journalï¿½},
number = {2},
pages = {98--107},
title = {{A strategy for using genetic algorithms to automate branch and fault-based testing}},
volume = {41},
year = {1998}
}
@inproceedings{pan08,
author = {Pan, H and Zheng, M and Han, X},
booktitle = {International Conference on Computer Science and Software Engineering},
pages = {78--81},
title = {{Particle Swarm-Simulated Annealing Fusion Algorithm and its Application in Function Optimization}},
year = {2008}
}
@inproceedings{pand97,
author = {Nayak, P Pandurang and Williams, Brian C},
booktitle = {Proceedings of AAAI-97},
title = {{Fast Context Switching in Real-time Propositional Reasoning}},
year = {1997}
}
@article{Diakonikolas,
author = {Diakonikolas, Ilias},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Diakonikolas - Unknown - Succinct Approximate Convex Pareto Curves ( Extended Abstract ).pdf:pdf},
keywords = {pareto},
mendeley-tags = {pareto},
pages = {74--83},
title = {{Succinct Approximate Convex Pareto Curves ( Extended Abstract )}}
}
@inproceedings{nielsen94,
author = {Nielsen, J},
booktitle = {Usability Inspection Methods},
editor = {Nielsen, J and Mack, R L},
publisher = {John Wiley \& Sons},
title = {{Heuristic Evaluation}},
year = {1994}
}
@incollection{hayes97,
author = {Hayes, C C},
booktitle = {Expertise in Context},
chapter = {14},
editor = {Feltovich, P J and Ford, K M and Hoffman, R R},
pages = {339--362},
publisher = {MIT PRess},
title = {{A Study in Solution Quality Human Expert and Knolwedge-Based System Reasoning}},
year = {1997}
}
@book{seni10,
author = {Seni, Giovanni and Elder, John},
publisher = {Morgan Claypool},
title = {{Ensemble Methods in Data Mining: Improving Accuracy Through Combining Predictions}},
year = {2010}
}
@article{Tavani1999a,
author = {Tavani, Herman T},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Tavani - 1999 - Informational privacy , data mining , and the Internet.pdf:pdf},
journal = {Computer},
number = {11},
pages = {137--145},
title = {{Informational privacy , data mining , and the Internet}},
volume = {39},
year = {1999}
}
@article{frank02,
author = {Franklin, D},
journal = {Time Magazine},
month = dec,
title = {{Data Miners: New software instantly connects key bits of data that once eluded teams of researchers}},
year = {2002}
}
@inproceedings{kal04,
author = {{M. Kalinowski}, G H Travassos},
booktitle = {IEEE ASE 2004},
pages = {46--55},
title = {{Computational Framework for Supporting Software Inspections}},
year = {2004}
}
@article{dejaeger12,
author = {Dejaeger, Karel and Verbeke, Wouter and Martens, David and Baesens, Bart},
file = {:Users/timm/svns/doc/11dejaeger.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
pages = {375--397},
title = {{Data Mining Techniques for Software Effort Estimation: A Comparative Study}},
volume = {38},
year = {2012}
}
@article{Du2003a,
address = {New York, New York, USA},
author = {Du, Wenliang and Zhan, Zhijun},
doi = {10.1145/956750.956810},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Du, Zhan, Science - 2003 - Using Randomized Response Techniques for Privacy-Preserving Data Mining.pdf:pdf},
isbn = {1581137370},
journal = {Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '03},
keywords = {data mining,decision tree,privacy,security},
pages = {505},
publisher = {ACM Press},
title = {{Using randomized response techniques for privacy-preserving data mining}},
url = {http://portal.acm.org/citation.cfm?doid=956750.956810},
year = {2003}
}
@article{stickel92,
author = {Stickel, M E},
journal = {Theoretical Computer Science},
pages = {109--128},
title = {{A Prolog technology theorem prover: a new exposition and implementation in Prolog}},
volume = {104},
year = {1992}
}
@inproceedings{compton93,
author = {Compton, P and Kang, B and Preston, P and Mulholland, M},
booktitle = {European Knowledge Acquisition Workshop},
title = {{Knowledge Acquisition Without Analysis}},
year = {1993}
}
@article{me89za,
author = {Menzies, T J},
journal = {AI Magazine},
title = {{An Investigation of the AI and Expert Systems Literature 1980-1984}},
year = {1989}
}
@inproceedings{coo04,
author = {Cooper, G and Dash, D and Levander, J and Wong, W-.K. and Hogan, W and {M. Wagner}, M},
booktitle = {Proceedings of the Twentieth Conference of Uncertainty in Artificial Intelligence (UAI-2004)},
pages = {94--103},
title = {{Bayesian biosurveillance of disease outbreaks}},
year = {2004}
}
@inproceedings{corbet00,
author = {Corbett, J and Dwyer, M B and Hatcliff, J and Laubach, S and Pasareanu, C S and Robby and Zheng, H},
booktitle = {Proceedings ICSE2000, Limerick, Ireland},
pages = {439--448},
title = {{Bandera: Extracting Finite-state Models from Java Source Code}},
year = {2000}
}
@book{Laird2006,
abstract = {An effective, quantitative approach for estimating and managing software projectsHow many people do I need? When will the quality be good enough for commercial sale? Can this really be done in two weeks? Rather than relying on instinct, the authors of Software Measurement and Estimation offer a new, tested approach that includes the quantitative tools, data, and knowledge needed to make sound estimations.The text begins with the foundations of measurement, identifies the appropriate metrics, and then focuses on techniques and tools for estimating the effort needed to reach a given level of quality and performance for a software project. All the factors that impact estimations are thoroughly examined, giving you the tools needed to regularly adjust and improve your estimations to complete a project on time, within budget, and at an expected level of quality.This text includes several features that have proven to be successful in making the material accessible and easy to master:* Simple, straightforward style and logical presentation and organization enables you to build a solid foundation of theory and techniques to tackle complex estimations* Examples, provided throughout the text, illustrate how to use theory to solve real-world problems* Projects, included in each chapter, enable you to apply your newfound knowledge and skills* Techniques for effective communication of quantitative data help you convey your findings and recommendations to peers and managementSoftware Measurement and Estimation: A Practical Approach allows practicing software engineers and managers to better estimate, manage, and effectively communicate the plans and progress of their software projects. With its classroom-tested features, this is an excellent textbook for advanced undergraduate-level and graduate students in computer science and software engineering.An Instructor Support FTP site is available from the Wiley editorial department.},
author = {Laird, Linda M. and Brennan, M. Carol},
file = {:Users/timm/svns/doc/06Software.Measurement.and.Estimation.A.Practical.Approach.Jun.2006.pdf:pdf},
isbn = {0471792527},
pages = {257},
title = {{Software Measurement and Estimation: A Practical Approach}},
url = {http://books.google.com/books?id=3g8wtcpFHZcC\&pgis=1$\backslash$nftp://pedidos.rafalim.com/Software.Measurement.and.Estimation.A.Practical.Approach.Jun.2006.pdf},
year = {2006}
}
@article{fagan86,
author = {Fagan, M},
journal = {IEEE Trans. on Software Engineering},
month = jul,
pages = {744--751},
title = {{Advances in software inspections}},
year = {1986}
}
@inproceedings{me04c,
author = {Menzies, Tim and Stefano, Justin S Di and Cunanan, Chris and Chapman, Robert Mike and Virginia, West},
booktitle = {IET Software},
doi = {10.1049/ic:20040480},
isbn = {0 86341 432 X},
title = {{Mining Repositories to Assist in Project Planning and Resource Allocation}},
year = {2004}
}
@inproceedings{CATAL2009,
address = {London, U.K.},
author = {Catal, C and Sevim, U and Diri, B},
booktitle = {Proceedings of the World Congress on Engineering 2009 Vol I},
title = {{Software Fault Prediction of Unlabeled Program Modules}},
year = {2009}
}
@book{glass88,
author = {Glass, L and Mackey, M C},
publisher = {Princeton University Press},
title = {{From Clocks to Chaos}},
year = {1988}
}
@article{towell93extracting,
author = {Towell, Geoffrey G and Shavlik, Jude W},
journal = {Machine Learning},
pages = {71--101},
title = {{Extracting Refined Rules from Knowledge-Based Neural Networks}},
url = {citeseer.ist.psu.edu/towell92extracting.html},
volume = {13},
year = {1993}
}
@article{zhang07,
author = {Zhang, H and Zhang, X},
journal = {IEEE Transactions on Software Engineering},
month = sep,
title = {{Comments on 'Data Mining Static Code Attributes to Learn Defect Predictors'}},
year = {2007}
}
@inproceedings{turhan10,
author = {Turhan, Burak and Bener, Ayse and Menzies, Tim},
booktitle = {Profes 2010},
title = {{Regularities in Learning Defect Predictors}},
year = {2010}
}
@article{me99c,
author = {Menzies, T},
journal = {Submitted to AAAI-99},
title = {{Simpler, Faster Abductive Validation}},
year = {1999}
}
@article{Schuffenhauer2006,
abstract = {Following the theoretical model by Hann et al. moderately complex structures are preferable lead compounds since they lead to specific binding events involving the complete ligand molecule. To make this concept usable in practice for library design, we studied several complexity measures on the biological activity of ligand molecules. We applied the historical IC50/EC50 summary data of 160 assays run at Novartis covering a diverse range of targets, among them kinases, proteases, GPCRs, and protein-protein interactions, and compared this to the background of "inactive" compounds which have been screened for 2 years but have never shown any activity in any primary screen. As complexity measures we used the number of structural features present in various molecular fingerprints and descriptors. We found generally that with increasing activity of the ligands, their average complexity also increased, and we could therefore establish a minimum number of structural features in each descriptor needed for biological activity. Especially well suited in this context were the Similog keys and circular substructure fingerprints. These are those descriptors, which also perform especially well in the identification of bioactive compounds by similarity search, suggesting that structural features encoded in these descriptors have a high relevance for bioactivity. Since the number of features correlates with the number of atoms present in the molecule, also the number of atoms serves as a reasonable complexity measure and larger molecules have, in general, higher activities. Due to the relationship between feature counts and densities on one hand and biological activity on the other, the size bias present in almost all similarity coefficients becomes especially important. Diversity selections using these coefficients can influence the overall complexity of the resulting set of molecules, which has an impact on the biological activity that they exhibit. Using sphere-exclusion based diversity selection methods, such as OptiSim together with the Tanimoto dissimilarity, the average feature count distribution of the resulting selections is shifted toward lower complexity than that of the original set, particularly when applying tight diversity constraints. This size bias reduces the fraction of molecules in the subsets having the complexity required for a high, submicromolar activity. None of the diversity selection methods studied, namely OptiSim, divisive K-means clustering, and self-organizing maps, yielded subsets covering the activity space of the IC50 summary data set better than subsets selected randomly.},
author = {Schuffenhauer, Ansgar and Brown, Nathan and Selzer, Paul and Ertl, Peter and Jacoby, Edgar},
doi = {10.1021/ci0503558},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Schuffenhauer-JCIM-46-525-2006.pdf:pdf},
issn = {15499596},
journal = {Journal of Chemical Information and Modeling},
number = {2},
pages = {525--535},
pmid = {16562980},
title = {{Relationships between molecular complexity, biological activity, and structural diversity}},
volume = {46},
year = {2006}
}
@inproceedings{levy96b,
author = {Levy, A Y and Rousset, M},
booktitle = {AAAI '96},
pages = {577--584},
title = {{The Limits on Combining Recursive Horn Rules with Description Logics}},
year = {1996}
}
@article{gar95,
author = {Garzotto, F and Mainetti, L and Paolini, P},
journal = {Communications of the ACM},
month = aug,
number = {8},
pages = {74--86},
title = {{Hypermedia Design Analysis and Evaluation Issues}},
volume = {38},
year = {1995}
}
@article{kim08,
author = {Kim, Sunghun and Whitehead, James and Zhang, Yi},
journal = {IEEE TSE},
pages = {181--196},
title = {{Classifying Software Changes: Clean or Buggy?}},
year = {2008}
}
@article{Nakanishi2006,
author = {Nakanishi, Kotaro and Washio, Takashi and Mitsunaga, Yuki and Fujimoto, Atsushi and Motoda, Hiroshi},
doi = {10.1527/tjsai.21.526},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/washio07.pdf:pdf},
issn = {1346-0714},
journal = {Transactions of the Japanese Society for Artificial Intelligence},
keywords = {classification,lsc-caep,quan-,quantitative class association rule,subspace clustering,titative frequent itemset},
pages = {526--536},
title = {{A Classification Method Based on Subspace Clustering and Association Rules}},
volume = {21},
year = {2006}
}
@misc{NORTH93,
author = {North, S C},
howpublished = {preprint},
title = {{Drawing ranked digraphs with recursive clusters}},
year = {1993}
}
@inproceedings{memaco92,
author = {Menzies, T and Mahidadia, A and Compton, P},
booktitle = {Proceedings of the 7th \{AAAI\}-Sponsored \{B\}anff Knowledge Acquisition for Knowledge-Based Systems Workshop \{B\}anff, \{C\}anada, October 11-16},
title = {{Using \{C\}ausality as a \{G\}eneric \{K\}nowledge \{R\}epresentation, or \{W\}hy and \{H\}ow \{C\}entralised \{K\}nowledge \{S\}ervers \{C\}an \{U\}se \{C\}ausality}},
year = {1992}
}
@article{Potok2005,
author = {Potok, Thomas E T.E. and Palathingal, Paul and Cui, Xiaohui},
doi = {10.1109/SIS.2005.1501621},
file = {:Users/timm/svns/doc/pso/01psoDocumentCluster.pdf:pdf},
isbn = {0-7803-8916-6},
journal = {Proceedings 2005 IEEE Swarm Intelligence Symposium, 2005. SIS 2005.},
pages = {185--191},
title = {{Document clustering using particle swarm optimization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1501621},
year = {2005}
}
@inproceedings{selman96,
address = {Providence RI},
author = {Selman, Bart and Kautz, Henry A and Cohen, Bram},
booktitle = {Proceedings of the Second \{DIMACS\} Challange on Cliques, Coloring, and Satisfiability},
editor = {Trick, Michael and Johnson, David Stifler},
title = {{Local Search Strategies for Satisfiability Testing}},
url = {citeseer.ist.psu.edu/selman95local.html},
year = {1993}
}
@article{Abbass1999,
author = {Abbass, H.a. and Sarker, R. and Newton, C.},
doi = {10.1109/CEC.2001.934295},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Abbass, Sarker, Newton - 1999 - PDE a Pareto-frontier differential evolution approach for multi-objective optimization problems.pdf:pdf},
isbn = {0-7803-6657-3},
journal = {Proceedings of the 2001 Congress on Evolutionary Computation (IEEE Cat. No.01TH8546)},
pages = {971--978},
publisher = {Ieee},
title = {{PDE: a Pareto-frontier differential evolution approach for multi-objective optimization problems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=934295},
year = {1999}
}
@inproceedings{ashoh09,
address = {New York, NY, USA},
author = {Ashok, B and Joy, Joseph and Liang, Hongkang and Rajamani, Sriram K and Srinivasa, Gopal and Vangala, Vipindeep},
booktitle = {ESEC/FSE '09: Proceedings of the the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering},
isbn = {978-1-60558-001-2},
pages = {373--382},
publisher = {ACM},
title = {{DebugAdvisor: a recommender system for debugging}},
year = {2009}
}
@article{stroulia00,
annote = {(to appear)},
author = {Stroulia, E and Goel, A K},
journal = {International Journal of Human Computer Studies},
title = {{Evaluating PSMs in Redesign: The AUTOGNOSTIC Experiments}},
year = {2000}
}
@article{me10a,
abstract = {Building quality software is expensive and software quality assurance (QA) budgets are limited. Data miners can learn defect predictors from static code features which can be used to control QA resources; e.g. to focus on the parts of the code predicted to be more defective. Recent results show that better data mining technology is not leading to better defect predictors. We hypothesize that we have reached the limits of the standard learning goal of maximizing area under the curve (AUC) of the probability of false alarms and probability of detection AUC(pd, pf) ; i.e. the area under the curve of a probability of false alarm versus probability of detection. Accordingly, we explore changing the standard goal. Learners that maximize AUC(effort, pd) find the smallest set of modules that contain the most errors. WHICH is a meta-learner framework that can be quickly customized to different goals. When customized to AUC(effort, pd), WHICH out-performs all the data mining methods studied here. More importantly, measured in terms of this new goal, certain widely used learners perform much worse than simple manual methods. Hence, we advise against the indiscriminate use of learners. Learners must be chosen and customized to the goal at hand. With the right architecture (e.g. WHICH), tuning a learner to specific local business goals can be a simple task.},
author = {Menzies, Tim and Milton, Zach and Turhan, Burak and Cukic, Bojan and Jiang, Yue and Bener, AyÅe},
doi = {10.1007/s10515-010-0069-5},
issn = {09288910},
journal = {Automated Software Engineering},
keywords = {Defect prediction,Static code features,Which},
number = {4},
pages = {375--407},
title = {{Defect prediction from static code features: Current results, limitations, new approaches}},
volume = {17},
year = {2010}
}
@misc{compton94,
annote = {regarding the status of the PIERS system},
author = {Compton, P},
title = {{Personal communication}},
year = {1994}
}
@inproceedings{me94z,
annote = {$\backslash$url\{http://menzies.us/pdf/banff94.pdf\}},
author = {Menzies, T J and Compton, P},
booktitle = {Proceedings of the 8th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge-Based Systems Workshop, Banff, Canada},
title = {{Knowledge Acquisition for Performance Systems; or: When can "tests" replace "tasks"?}},
year = {1994}
}
@inproceedings{me97q,
author = {Menzies, T J},
booktitle = {Banff KA '98 workshop.},
title = {{Evaluation Issues with Critical Success Metrics}},
year = {1998}
}
@article{briemann01,
author = {Breimann, L},
journal = {Machine Learning},
month = oct,
pages = {5--32},
title = {{Random Forests}},
year = {2001}
}
@inproceedings{cukic00,
author = {Cukic, B and Chakrawarthy, D},
booktitle = {Proceedings of the 5th International Symposium on High Assurance Systems Engineering, Albuquerque, NM, November},
title = {{Bayesian Framework for Reliability Assurance of a Deployed Safety Critical System}},
year = {2000}
}
@article{turing39,
author = {Turing, A},
journal = {Proc. London Math. Soc},
pages = {161--228},
title = {{Systems of Logic Based on Ordinals}},
volume = {45},
year = {1939}
}
@inproceedings{cohen95r,
annote = {Available on-line from $\backslash$url\{http://www.cs.cmu.edu/\~{}wcohen/postscript/ml-95-ripper.ps\}},
author = {Cohen, W W},
booktitle = {ICML'95},
pages = {115--123},
title = {{Fast effective rule induction}},
year = {1995}
}
@book{ocs-book-96,
editor = {Jampel, M and Freuder, E and Maher, M},
month = aug,
number = {1106},
publisher = {Springer},
series = {LNCS},
title = {{Over-Constrained Systems}},
year = {1996}
}
@inproceedings{Ginty2001,
author = {Ginty, L. and Smyth, Barry},
booktitle = {Case-Based Reasoning Research and Development},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Ginty, Smyth - 2001 - Collaborative case-based reasoning Applications in personalised route planning.pdf:pdf},
keywords = {case-based reasoning},
pages = {362--376},
publisher = {Springer},
title = {{Collaborative case-based reasoning: Applications in personalised route planning}},
url = {http://www.springerlink.com/index/NXL1KBB9MH73VTNX.pdf},
year = {2001}
}
@article{phillips84,
author = {Phillips, L D},
journal = {Acta Psychologica},
pages = {29--48},
title = {{A Theory of Requisite Decision Models}},
volume = {56},
year = {1984}
}
@inproceedings{barwise92,
author = {Barwise, J and Etchemendy, J},
booktitle = {AAAI Spring Symposium on Reasoning with Diagrammatic Representations},
pages = {80--84},
title = {{Hyperproof: Logical Reasoning with Diagrams}},
year = {1992}
}
@article{shtern12,
annote = {$\backslash$url\{http://dx.doi.org/10.1155/2012/792024\}},
author = {Shtern, M and Tzerpos, V},
doi = {10.1155/2012/792024},
journal = {Adv. Soft. Eng.},
month = jan,
title = {{Clustering Methodologies for Software Engineering}},
volume = {2012},
year = {2012}
}
@book{pad74,
author = {Paulo, L and Arbib, M A},
publisher = {W.B. Saunders},
title = {{System Theory}},
year = {1974}
}
@inproceedings{me06f,
annote = {Available from $\backslash$url\{http://menzies.us/06deviations.pdf\}},
author = {Menies, T and Lum, K and Hihn, J},
booktitle = {PROMISE, 2006},
title = {{The Deviance Problem in Effort Estimation}},
year = {2006}
}
@phdthesis{jalali07,
author = {Jalali, Omid},
school = {Lane Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{Evaluation Bias in Effort Estimation}},
year = {2007}
}
@inproceedings{Marcus2010a,
abstract = {Software systems are designed and engineered to process data. However, software is data too. The size and variety of today's software artifacts and the multitude of stakeholder activities result in so much data that individuals can no longer reason about all of it. Software evolution is no longer just about writing code, it is becoming an information management problem.
Analysis and management of the software data are activities that software engineers are not trained to do. We have to look for solutions outside software engineering, adopt them, and make them our own. These solutions can come from data mining, information retrieval, machine learning, statistical analysis, etc. This is not the first time software engineers are looking at such solutions. It has been going on for about two decades, in a form or another. The results so far indicate that software engineering is facing a paradigm shift, where more and more software engineering tasks are reinterpreted as optimization, search, retrieval, or classification problems. Despite this experience, applications of data analysis, data integration, and data mining in software engineering are in their infancy by comparison with other research fields. New research is needed to adapt existing algorithms and tools for software engineering data and processes, and new ones will have to be created. This research has to be supported by integration with software development processes and with education as well. More than that, in order for this type of research to succeed, it should be supported with new approaches to empirical work, where data and results are shared globally among researchers and practitioners.
The talk will focus on arguing for and mapping out (part of) this research agenda, while looking back at (some of) the existing work in the area.},
address = {Antwerp, Belgium},
annote = {Laura. Fixed on 10/01/2012},
author = {Marcus, Andrian},
booktitle = {ERCIM Workshop on Software Evolution and the International Workshop on Principles of Software Evolution (IWPSE-EVOL'10)},
keywords = {data\_mining software\_engineering information\_retri},
pages = {1},
title = {{Software is Data Too: How Should We Deal with It?}}
}
@book{modelchecking,
address = {\{C\}ambridge, \{MA\}},
author = {Clarke, Edmund A and Grumberg, Orna and Peled, Doron A},
publisher = {\{MIT\} \{P\}ress},
title = {{\{M\}odel \{C\}hecking}},
year = {1999}
}
@article{Hippocratic2007,
author = {Hippocratic, Leveraging and Technology, Database},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Hippocratic, Technology - 2007 - Privacy in eHealth Why Should I Worry About Privacy Compliance with Data Protection Laws.pdf:pdf},
journal = {Information Security},
title = {{Privacy in eHealth : Why Should I Worry About Privacy ? Compliance with Data Protection Laws}},
year = {2007}
}
@inproceedings{nohrer12,
author = {N\"{o}hrer, Alexander and Biere, Armin and Egyed, Alexander},
booktitle = {Proceedings of the 16th International Software Product Line Conference - Volume 1},
isbn = {978-1-4503-1094-9},
pages = {11--20},
series = {SPLC '12},
title = {{A comparison of strategies for tolerating inconsistencies during decision-making}},
year = {2012}
}
@inproceedings{me00s,
author = {Menzies, T and Cukic, B},
booktitle = {International Workshop on Empirical Studies of Software Maintenance (WESS 2000), October 14, San Jose CA},
title = {{Maintaining Maintainability = Recognizing Reachability}},
year = {2000}
}
@inproceedings{me90,
author = {Menzies, T J},
booktitle = {Proceedings \{AI\} '90},
title = {{Isa Object Part-of Knowledge Representation?}},
year = {1990}
}
@inproceedings{jalali08,
abstract = {Recent work with NASA's Jet Propulsion Laboratory has allowed for external access to five of JPL's real-world requirements models, anonymized to conceal proprietary information, but retaining their computational nature. Experimentation with these models, reported herein, demonstrates a dramatic speedup in the computations performed on them. These models have a well defined goal: select mitigations that retire risks which, in turn, increases the number of attainable requirements. Such a non-linear optimization is a well-studied problem. However identification of not only (a) the optimal solution(s) but also (b) the key factors leading to them is less well studied. Our technique, called KEYS, shows a rapid way of simultaneously identifying the solutions and their key factors. KEYS improves on prior work by several orders of magnitude. Prior experiments with simulated annealing or treatment learning took tens of minutes to hours to terminate. KEYS runs much faster than that; e.g for one model, KEYS ran 13,000 times faster than treatment learning (40 minutes versus 0.18 seconds). Processing these JPL models is a non-linear optimization problem: the fewest mitigations must be selected while achieving the most requirements. Non-linear optimization is a well studied problem. With this paper, we challenge other members of the PROMISE community to improve on our results with other techniques.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08keys.pdf\}},
author = {Jalali, Omid and Menzies, Tim and Feather, Martin},
booktitle = {Proceedings of the PROMISE 2008 Workshop (ICSE)},
doi = {10.1145/1370788.1370807},
isbn = {9781605580364},
issn = {02705257},
title = {{Optimizing Requirements Decisions with KEYS}},
year = {2008}
}
@book{Segaran2007,
abstract = {Want to tap the power behind search rankings, product recommendations, social bookmarking, and online matchmaking? This fascinating book demonstrates how you can build Web 2.0 applications to mine the enormous amount of data created by people on the Internet. With the sophisticated algorithms in this book, you can write smart programs to access interesting datasets from other web sites, collect data from users of your own applications, and analyze and understand the data once you've found it. Programming Collective Intelligence takes you into the world of machine learning and statistics, and explains how to draw conclusions about user experience, marketing, personal tastes, and human behavior in general-all from information that you and others collect every day. Each algorithm is described clearly and concisely with code that can immediately be used on your web site, blog, Wiki, or specialized application. This book explains: Collaborative filtering techniques that enable online retailers to recommend products or media Methods of clustering to detect groups of similar items in a large dataset Search engine features-crawlers, indexers, query engines, and the PageRank algorithm Optimization algorithms that search millions of possible solutions to a problem and choose the best one Bayesian filtering, used in spam filters for classifying documents based on word types and other features Using decision trees not only to make predictions, but to model the way decisions are made Predicting numerical values rather than classifications to build price models Support vector machines to match people in online dating sites Non-negative matrix factorization to find the independent features in adataset Evolving intelligence for problem solving-how a computer develops its skill by improving its own code the more it plays a game Each chapter includes exercises for extending the algorithms to make them more powerful. Go beyond simple database-backed applications and put the wealth of Internet data to work for you. "Bravo! I cannot think of a better way for a developer to first learn these algorithms and methods, nor can I think of a better way for me (an old AI dog) to reinvigorate my knowledge of the details." - Dan Russell, Google "Toby's book does a great job of breaking down the complex subject matter of machine-learning algorithms into practical, easy-to-understand examples that can be directly applied to analysis of social interaction across the Web today. If I had this book two years ago, it would have saved precious time going down some fruitless paths." - Tim Wolters, CTO, Collective Intellect},
author = {Segaran, Toby},
booktitle = {Book},
doi = {10.1016/j.jconhyd.2010.08.009},
file = {:Users/timm/svns/doc/collectiveInt.pdf:pdf},
isbn = {0596529325},
issn = {13613200},
pages = {334},
pmid = {20926156},
title = {{Programming Collective Intelligence: Building Smart Web 2.0 Applications}},
url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0596529325},
year = {2007}
}
@misc{kadoda00,
author = {Kadoda, G and Cartwright, M and Chen, L and Shepperd, M},
title = {{Experiences Using CaseBased Reasoning to Predict Software Project Effort}},
url = {citeseer.ist.psu.edu/kadoda00experiences.html},
year = {2000}
}
@inproceedings{door93,
author = {Doorenbos, R D},
booktitle = {AAAI '93},
pages = {290--296},
title = {{Matching 100,000 Learnt Rules}},
year = {1993}
}
@inproceedings{brle84,
author = {Brachman, R J and Levesque, H J},
booktitle = {\{AAAI\} '84},
pages = {34--37},
title = {{The Tractability of Subsumption in Frame-Based Description Languages}},
year = {1984}
}
@inproceedings{lum06,
author = {Lum, K and Hihn, J and Menzies, Tim},
booktitle = {ISPA Conference Proceedings},
title = {{Studies in Software Cost Model Behavior: Do we Really Understand Cost Model Performance?}},
year = {2006}
}
@inproceedings{myers92,
author = {Myers, K L and Konolige, K},
booktitle = {AAAI Spring Symposium on Reasoning with Diagrammatic Representations},
editor = {Narayanan, N H},
pages = {96--101},
title = {{Integrating Analogical and Sentential Resoning for Perception}},
year = {1992}
}
@inproceedings{Alm91,
author = {Almuallim, H and Dietterich, T G},
booktitle = {The Ninth National Conference on Artificial Intelligence},
pages = {pp. 547--552},
publisher = {AAAI Press},
title = {{Learning with Many Irrelevant Features}},
year = {1991}
}
@inproceedings{Bruegge1994,
author = {Bruegge, B and Coyne, R F},
booktitle = {Software Engineering Education, 7th SEI CSEE Conference, San Antonio, Texas, USA, J L Diaz-Herrera (Ed.), LNCS 750, Springer-Verlag},
month = jan,
pages = {411--428},
title = {{Teaching Iterative and Collaborative Design: Lessons and Directions}},
year = {1994}
}
@article{nelson11,
author = {{Adam Nelson Tim Menzies}, Gregory Gay},
journal = {Software- Practice and Experience (to appear)},
title = {{Sharing Experiments Using Open Source Software}},
year = {2011}
}
@inproceedings{griesel93,
author = {Griesel, A and Hihn, J and Bruno, K and Tausworthe, R},
booktitle = {Proceedings of the Eighteenth Annual Software Engineering Workshop, Goddard Space Flight Center},
title = {{\{S\}oftware \{F\}orecasting: As it is \{R\}eally \{D\}one: A \{S\}tudy of \{JPL\} \{S\}oftware \{E\}ngineers}},
year = {1993}
}
@inproceedings{bhar97,
author = {Bharadwaj, Ramesh and Heitmeyer, Constance},
booktitle = {Proc. First ACM SIGPLAN Workshop on Automatic Analysis of Software},
month = jan,
title = {{Verifying \{SCR\} Requirements Specifications Using State Exploration}},
year = {1997}
}
@book{jones07,
author = {Jones, C},
publisher = {McGraw-Hill},
title = {{Estimating Software Costs, 2nd Edition}},
year = {2007}
}
@misc{me96o,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/96ie.pdf\}},
author = {Menzies, T and Tucker, S},
title = {{Subject Handbook SFT3500/SYS3030: Industrial Experience Project}},
year = {1996}
}
@article{turhan07b,
address = {Los Alamitos, CA, USA},
author = {Turhan, B and Bener, A},
doi = {http://doi.ieeecomputersociety.org/10.1109/QSIC.2007.4},
issn = {1550-6002},
journal = {QSIC 2007: The Seventh International Conference on Quality Software},
pages = {231--237},
publisher = {IEEE Computer Society},
title = {{A Multivariate Analysis of Static Code Attributes for Defect Prediction}},
volume = {0},
year = {2007}
}
@inproceedings{me09l,
abstract = {Software fault prediction models play an important role in software quality assurance. They identify software subsystems (modules,components, classes, or files) which are likely to contain faults. These subsystems, in turn, receive additional resources for verification and validation activities. Fault prediction models are binary classifiers typically developed using one of the supervised learning techniques from either a subset of the fault data from the current project or from a similar past project. In practice, it is critical that such models provide a reliable prediction performance on the data not used in training. Variance is an important reliability indicator of software fault prediction models. However, variance is often ignored or barely mentioned in many published studies. In this paper, through the analysis of twelve data sets from a public software engineering repository from the perspective of variance, we explore the following five questions regarding fault prediction models: (1) Do different types ofclassification performance measures exhibit different variance? (2) Does the size of the data set imply a more (or less) accurate prediction performance? (3) Does the size of training subset impact model's stability? (4) Do different classifiers consistently exhibit different performance in terms of model's variance? (5) Are there differences between variance from 1000 runs and 10 runs of 10-fold cross validation experiments? Our results indicate that variance is a very important factor in understanding fault prediction models and we recommend the best practice for reporting variance in empirical software engineering studies.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09irrf.pdf\}},
author = {Jiang, Yue Jiang Yue and Lin, Jie Lin Jie and Cukic, B. and Menzies, T.},
booktitle = {2009 20th International Symposium on Software Reliability Engineering},
doi = {10.1109/ISSRE.2009.13},
isbn = {978-1-4244-5375-7},
issn = {1071-9458},
keywords = {fault prediction models,machine learning,variance},
title = {{Variance Analysis in Software Fault Prediction Models}},
year = {2009}
}
@misc{ithink94,
author = {Inc., High Performance Software},
title = {{iThink 3.0.5}},
year = {1994}
}
@inproceedings{koed92,
author = {Koedinger, K R},
booktitle = {Proceedings of the AAAI Symposium on Diagrammatic Reasoning Stanford University, March 25-27},
pages = {154--159},
title = {{Emergent Properties and Structural Constraints: Advantages of Diagrammatic Representations for Reasoning and Learning}},
year = {1992}
}
@book{clancey97b,
author = {Clancey, W J},
publisher = {Cambridge University Press},
title = {{Situated Cognition: On Human Knowledge and Computer Representations}},
year = {1997}
}
@inproceedings{rothermel98a,
author = {Rothermel, G and Lixin, L and DuPuis, C and Burnett, M},
booktitle = {International Conference on Software Engineering, Kyoto, Japan},
pages = {198--207},
title = {{What You See Is What You Test: A Methodology for Testing Form-Based Visual Programs}},
year = {1998}
}
@inproceedings{akhavi93,
author = {Akhavi, M and Wilson, W},
booktitle = {Proceedings of the 5th Software Engineering Process Group National Meeting (Held at Costa Mesa, California, April 26 - 29)},
publisher = {Software engineering Institute, Carnegie Mellon University},
title = {{Dynamic Simulation of Software Process Models}},
year = {1993}
}
@inproceedings{me04e,
author = {Menzies, T and Pecheur, C},
booktitle = {Advances in Computing},
editor = {Zelkowtiz, M},
publisher = {Elsevier},
title = {{Verification and \{V\}alidation and \{A\}rtificial \{I\}ntelligence}},
volume = {65},
year = {2005}
}
@article{newell82,
author = {Newell, A},
journal = {Artificial Intelligence},
pages = {87--127},
title = {{The \{K\}nowledge \{L\}evel}},
volume = {18},
year = {1982}
}
@article{boehm86,
author = {Boehm, B},
journal = {Software Engineering Notes},
number = {4},
pages = {22},
title = {{A Spiral Model of Software Development and Enhancement}},
volume = {11},
year = {1986}
}
@inproceedings{gil97,
author = {Gil, Y and Tallis, M},
booktitle = {Proceedings of the Fourteenth National Conference on Artificial Intelligence (AAAI-97)},
title = {{A Script-Based Approach to Modifying Knowledge Bases}},
year = {1997}
}
@article{me89zb,
author = {Menzies, T J},
journal = {AI Expert},
title = {{Domain-Specific Knowledge Representations}},
year = {1989}
}
@misc{spohrer84,
author = {Spohrer, J C and Riesbeck, C K},
institution = {Yale University},
number = {YALEU/DCS/RR-308},
title = {{Reasoning-driven Memory Modifications in the Economics Domain.}},
year = {1984}
}
@article{glass99,
author = {Glass, R L},
journal = {Communications of the ACM},
month = apr,
number = {2},
pages = {17--19},
title = {{Inspections Some Surprising Findings}},
volume = {42},
year = {1999}
}
@inproceedings{me97p,
author = {Menzies, T J},
booktitle = {The Second Australian Workshop on Requirements Engineering (AWRE'97)},
title = {{Qualitative Causal Diagrams for Requirements Engineering}},
year = {1997}
}
@misc{schw02,
author = {Schwaber, Ken},
title = {{No Title}},
year = {2002}
}
@article{vera93a,
author = {Vera, A H and Simon, H A},
journal = {Cognitive Science},
pages = {77--86},
title = {{Situated Action: A Response to Reviewers}},
volume = {17},
year = {1993}
}
@book{Zourob2010,
abstract = {Genetically engineered whole cells as biosensing systems in biosensors have been employed, in the past two decades, for the detection of a variety of analytes. In addition to being rapid, specific/selective, and sensitive, these whole-cell-based sensing systems provide information pertaining to the analyte bioavailability. This information is particularly important to study the effect of harmful/toxic chemicals on living systems. The whole cells used for designing and developing cell-based sensing systems can be either prokaryotic or eukaryotic in nature. These intact prokaryotic or eukaryotic cells can be genetically engineered to recognize the analytes of interest and respond with the production of a measurable signal in a dose-dependent manner. Generally, prokaryotic bacterial whole-cell sensing systems are developed by introducing a plasmid construct with a reporter gene fused to a promoter, which is induced by a target analyte through a regulatory protein. Similarly, a receptor, which is activated by a target analyte, is coupled with a reporter gene for the development of genetically modified eukaryotic cell-based biosensing systems. The most commonly used reporter proteins in whole-cell biosensing include luminescent proteins, such as bacterial and firefly luciferases; green fluorescent protein along with its variants; and $\beta$-galactosidase. The analytes that can be detected using genetically manipulated whole-cell sensing systems range from general toxicants and cell stress factors to specific analytes, such as metals, metalloids, organic pollutants, sugars, drugs, and bacterial signaling molecules. In order to develop self-contained sensing devices based on recombinant whole-cell sensing systems, preservation, miniaturization, and portability are important issues that need to be addressed.},
author = {Zourob, Mohammed},
booktitle = {Recognition Receptors in Biosensors},
doi = {10.1007/978-1-4419-0919-0},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Baldrich10.pdf:pdf},
isbn = {9781441909183},
keywords = {aptamer \'{a} aptasensor \'{a},development,reagentless detection \'{a} sensor},
pages = {1--863},
title = {{Recognition receptors in biosensors}},
year = {2010}
}
@article{me09d,
annote = {Avialable from $\backslash$url\{http://menzies.us/pdf/09ir4pc.pdf\}},
author = {Etzkorn, L and Menzies, T},
journal = {Empirical Software Engineering},
number = {1},
pages = {1--4},
title = {{Editorial, Special issue on information retrieval for program comprehension}},
volume = {14},
year = {2009}
}
@inproceedings{me02l,
abstract = { There are many machine learning algorithms currently available. In the 21st century, the problem no longer lies in writing the learner but in choosing which learners to run on a given data set. We argue that the final choice of learners should not be exclusive; in fact, there are distinct advantages in running data sets through multiple learners. To illustrate our point, we perform a case study on a reuse data set using three different styles of learners: association rule, decision tree induction, and treatment. Software reuse is a topic of avid debate in the professional and academic arena; it has proven that it can be both a blessing and a curse. Although there is much debate over where and when reuse should be instituted into a project, our learners found some procedures which should significantly improve the odds of a reuse program succeeding.},
author = {Stefano, J.S. Di and Menzies, T.},
booktitle = {14th IEEE International Conference on Tools with Artificial Intelligence, 2002. (ICTAI 2002). Proceedings.},
doi = {10.1109/TAI.2002.1180811},
isbn = {0-7695-1849-4},
issn = {1082-3409},
title = {{Machine learning for software engineering: case studies in software reuse}},
year = {2002}
}
@inproceedings{me91c,
author = {Menzies, T J},
booktitle = {Tools 3: Proceedings of the third International Technology of Object-Oriented Languages and; Systems conference},
publisher = {Prentice-Hall},
title = {{Beyond the MVC Triad: Quality Assurance via Interactive Specification Editors}},
year = {1991}
}
@inproceedings{tallis98,
author = {Tallis, M},
booktitle = {Banff KAW '98 workshop.},
title = {{A Script-Based Approach to Modifying Knowledge-Based Systems}},
year = {1998}
}
@inproceedings{me99h,
author = {Menzies, T and Cukic, B and Coiera, E},
booktitle = {AAAI'99 workshop on Conflicts and Identifying Opportunities.},
title = {{Smaller, Faster Dialogues via Conversational Probing}},
year = {1999}
}
@inproceedings{Kon94,
author = {Kononenko, I},
booktitle = {The Seventh European Conference on Machine Learning},
pages = {pp. 171--182},
publisher = {Springer-Verlag},
title = {{Estimating attributes: Analysis and extensions of relief}},
year = {1994}
}
@article{erik95,
author = {Eriksson, H and Shahar, Y and Tu, S W and Puerta, A R and Musen, M A},
journal = {Artificial Intelligence},
number = {2},
pages = {293--326},
title = {{Task Modeling with Reusable Problem-Solving Methods}},
volume = {79},
year = {1995}
}
@incollection{shadbolt97,
author = {Shadbolt, N and O'Hara, K},
booktitle = {Expertise in Context},
chapter = {13},
editor = {Feltovich, P J and Ford, K M and Hoffman, R R},
pages = {315--337},
publisher = {MIT PRess},
title = {{Model-based Expert Systems and the Explanations of Expertise}},
year = {1997}
}
@inproceedings{me98e,
author = {Menzies, T J and Waugh, S},
booktitle = {Proceedings Pacific Knowledge Acquisition Workshop, Singapore, November, 1998},
title = {{More Results on the Practical Lower Limits of Test Set Size}},
year = {1998}
}
@inproceedings{me02m,
abstract = {A range of agent implementation technologies are reviewed according to five user-based criteria and via a comparison with object-oriented programming. The comparison with OO shows that some parts of object technology are a candidate implementation technique for some parts of agent systems. However, many other non-object-based implementation techniques may be just as useful. Also, for agents with mentalistic attitudes, the high-level specification of agent behavior requires numerous concepts outside the object paradigm; e.g. plans, communication, intentions, roles, and teams.},
author = {Menzies, T and Pearce, a and {C Heinze} and Goss, S},
booktitle = {Formal Aspects of AgentBased Systems},
issn = {03029743},
pages = {1--14},
title = {{What is an agent and why should I care?}},
url = {http://www.springerlink.com/index/55EH2FB4AVC3HCE1.pdf},
year = {2002}
}
@article{Vaidya2004,
author = {Vaidya, J. and Clifton, C.},
doi = {10.1109/MSP.2004.108},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Mannila, Smyth - 2004 - Privacy-Preserving Data Mining Why, How, and When.pdf:pdf},
issn = {1540-7993},
journal = {IEEE Security and Privacy Magazine},
month = nov,
number = {6},
pages = {19--27},
title = {{Privacy-preserving data mining: why, how, and when}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1366115},
volume = {2},
year = {2004}
}
@inproceedings{me03d,
author = {Gunnalan, Rajesh and Us, T I M Menzies and Appukutty, Kalaivani},
title = {{Feature Subset Selection with TAR2less}},
year = {2003}
}
@misc{Chib1995,
abstract = {Abstract We provide a detailed, introductory exposition of the Metropolis-Hastings algorithm, a powerful Markov chain method to simulate multivariate distributions. A simple, intuitive derivation of this method is given along with guidance on implementation. Also discussed are two applications of the algorithm, one for implementing acceptance-rejection sampling when a blanketing function is not available and the other for implementing the algorithm with block-at-a-time scans. In the latter situation, many different algorithms, including the Gibbs sampler, are shown to be special cases of the Metropolis-Hastings algorithm. The methods are illustrated with examples.},
author = {Chib, Siddhartha and Greenberg, Edward},
booktitle = {Journal of the American Statistical Association},
doi = {10.2307/2684568},
file = {:Users/timm/svns/doc/dataFarm/95chibMetropolis.pdf:pdf},
isbn = {00031305},
issn = {00031305},
keywords = {Gibbs sampling,Markov chain Monte Carlo,Multivariate density simulation,Reversible Markov chains},
number = {4},
pages = {327--335},
pmid = {64},
title = {{Understanding the Metropolis-Hastings algorithm}},
url = {http://amstat.tandfonline.com/doi/abs/10.1080/00031305.1995.10476177\#.U5sEzXVdVcY},
volume = {49},
year = {1995}
}
@book{bergadano95,
author = {Bergadano, F and Gunetti, D},
publisher = {The MIT Press},
title = {{Inductive Logic Programming: From Machine Learning to Software Engineering}},
year = {1995}
}
@inproceedings{me95c,
author = {Menzies, T J},
booktitle = {Proceedings of AI '95, Australia},
publisher = {World-Scientific},
title = {{\{L\}imits to \{K\}nowledge \{L\}evel-\{B\} \{M\}odeling (and \{KADS\})}},
year = {1995}
}
@inproceedings{koc12m,
author = {Kocaguneli, Ekrem and Menzies, Tim and Hihn, Jairus and Kang, Byeong Ho},
booktitle = {Proceedings of the 8th International Conference on Predictive Models in Software Engineering (PROMISE '12)},
pages = {89--98},
title = {{Size doesn't matter?: on the value of size for effort estimation}},
year = {2012}
}
@inproceedings{kamei07,
author = {Kamei, Yasutaka and Monden, Akito and Matsumoto, Shinsuke and Kakimoto, Takeshi and Matsumoto, Ken-ichi},
booktitle = {Empirical Software Engineering and Measurement, 2007. ESEM 2007. First International Symposium on},
pages = {196--204},
title = {{The Effects of Over and Under Sampling on Fault-prone Module Detection}}
}
@article{swan90,
author = {Swanson, D R},
journal = {Bull Med Libr Assoc},
pages = {29--37},
title = {{Medical Knowledge as a Potential Source of New Knowledge}},
volume = {78},
year = {1990}
}
@inproceedings{BIRD2009,
address = {New York, NY, USA},
author = {Bird, Christian and Bachmann, Adrian and Aune, Eirik and Duffy, John and Bernstein, Abraham and Filkov, Vladimir and Devanbu, Premkumar},
booktitle = {ESEC/FSE '09: Proceedings of the the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering},
doi = {http://doi.acm.org/10.1145/1595696.1595716},
isbn = {978-1-60558-001-2},
pages = {121--130},
publisher = {ACM},
title = {{Fair and balanced?: bias in bug-fix datasets}},
year = {2009}
}
@article{poole93g,
author = {Poole, D},
journal = {Artificial Intelligence},
number = {1},
pages = {81--129},
title = {{Probabilistic \{Horn\} Abduction and \{Bayesian\} Networks}},
volume = {64},
year = {1993}
}
@article{me08e,
author = {Menzies, Tim and Milton, Z and Bener, a and Cukic, Bojan and Gay, G and Jiang, Y and Turhan, B},
journal = {Submitted to IEEE TSE},
title = {{Overcoming Ceiling Effects in Defect Prediction}},
year = {2008}
}
@inproceedings{Brickell08,
address = {New York, NY, USA},
author = {Brickell, Justin and Shmatikov, Vitaly},
booktitle = {Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining},
isbn = {978-1-60558-193-4},
keywords = {anonymity,data mining,privacy,utility},
pages = {70--78},
publisher = {ACM},
series = {KDD '08},
title = {{The cost of privacy: destruction of data-mining utility in anonymized data publishing}},
year = {2008}
}
@misc{seminal01,
annote = {ISSN:0163-5948},
month = nov,
publisher = {ACM SIGSOFT Software Engineering Notes},
title = {{The SEMINAL workshop: reformulating software engineering as a meta-heuristic search problem}},
volume = {26},
year = {2001}
}
@article{Wang2012,
abstract = {During the past decade, solving constrained opti- mization problems with evolutionary algorithms has received considerable attention among researchers and practitioners. Cai and Wangâs method (abbreviated as CW method) is a recent constrained optimization evolutionary algorithm proposed by the authors. However, its main shortcoming is that a trial-and- error process has to be used to choose suitable parameters. To overcome the above shortcoming, this paper proposes an improved version of the CW method, called CMODE, which combines multiobjective optimization with differential evolu- tion to deal with constrained optimization problems. Like its predecessor CW, the comparison of individuals in CMODE is also based on multiobjective optimization. In CMODE, however, differential evolution serves as the search engine. In addition, a novel infeasible solution replacement mechanism based on multiobjective optimization is proposed, with the purpose of guiding the population toward promising solutions and the feasible region simultaneously. The performance of CMODE is evaluated on 24 benchmark test functions. It is shown empirically that CMODE is capable of producing highly competitive results compared with some other state-of-the-art approaches in the community of constrained evolutionary optimization},
author = {Wang, Yong and Cai, Zixing},
doi = {10.1109/TEVC.2010.2093582},
file = {:Users/timm/svns/doc/12de.pdf:pdf},
isbn = {1089-778X},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Constrained optimization problems,constraint-handling technique,differential evolution,multiobjective optimization},
number = {1},
pages = {117--134},
title = {{Combining multiobjective optimization with differential evolution to solve constrained optimization problems}},
volume = {16},
year = {2012}
}
@inproceedings{me98f,
author = {Menzies, T J and Waugh, S},
booktitle = {Proceedings, Pacific Rim Conference on Artificial Intelligence, Singapore},
publisher = {Springer-Verlag},
title = {{On the Practicality of Viewpoint-based Requirements Engineering}},
year = {1998}
}
@inproceedings{frank03,
author = {Frank, Eibe and Hall, Mark and Pfahringer, Bernhard},
booktitle = {Proceedings of the Conference on Uncertainty in Artificial Intelligence},
pages = {249--256},
publisher = {Morgan Kaufmann},
title = {{Locally weighted naive Bayes}},
year = {2003}
}
@article{Boehm2000b,
author = {Boehm, Barry and Abts, Chris and Chulani, S},
file = {:Users/timm/svns/doc/cost/00Boehm.pdf:pdf},
journal = {Annals of Software Engineering},
pages = {177--205},
title = {{Software development cost estimation approachesâA survey}},
url = {http://www.springerlink.com/index/VV7W63752176772J.pdf},
volume = {10},
year = {2000}
}
@article{Walkerden1999,
address = {Hingham, MA, USA},
author = {Walkerden, Fiona and Jeffery, Ross},
doi = {http://dx.doi.org/10.1023/A:1009872202035},
issn = {1382-3256},
journal = {Empirical Softw. Engg.},
number = {2},
pages = {135--158},
publisher = {Kluwer Academic Publishers},
title = {{An Empirical Study of Analogy-based Software Effort Estimation}},
volume = {4},
year = {1999}
}
@inproceedings{lait02,
author = {Laitenberger, O},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{A Survey of Software inspection Techniques}},
year = {2002}
}
@misc{sessions09,
annote = {Available from $\backslash$url\{http://goo.gl/Q0Xhs\}},
author = {Sessions, Roger},
title = {{Cost of \{IT\} Failure}},
year = {2009}
}
@inproceedings{me08h,
abstract = {Prediction of fault prone software components is one of the most researched$\backslash$nproblems in software engineering. Many statistical techniques have$\backslash$nbeen proposed but there is no consensus on the methodology to select$\backslash$nthe ``best model" for the specific project. In this paper, we introduce$\backslash$nand discuss the merits of cost curve analysis of fault prediction$\backslash$nmodels. Cost curves allow software quality engineers to introduce$\backslash$nproject-specific cost of module misclassification into model evaluation.$\backslash$nClassifying a software module as fault-prone implies the application$\backslash$nof some verification activities, thus adding to the development cost.$\backslash$nMisclassifying a module as fault free carries the risk of system$\backslash$nfailure, also associated with cost implications. Through the analysis$\backslash$nof sixteen projects from public repositories, we observe that software$\backslash$nquality does not necessarily benefit from the prediction of fault$\backslash$nprone components. The inclusion of misclassification cost in model$\backslash$nevaluation may indicate that even the ``best" models achieve performance$\backslash$nno better than trivial classification. Our results support a recommendation$\backslash$nfavoring the use of cost curves in practice with the hope they will$\backslash$nbecome a standard tool for software quality model performance evaluation.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08costcurves.pdf\}},
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim},
booktitle = {ISSRE'08: Proceedings of the 19th International Symposium on Software Reliability Engineering},
pages = {197--206},
title = {{Costs Curve Evaluation of Fault Prediction Models}},
year = {2008}
}
@article{dekleer84,
author = {DeKleer, J and Brown, J S},
journal = {Artificial Intelligence},
pages = {7--83},
title = {{A Qualitative Physics Based on Confluences}},
volume = {25},
year = {1984}
}
@article{boehm01,
author = {Boehm, B and Basili, V R},
journal = {IEEE Software},
month = jan,
pages = {135--137},
title = {{Software Defect Reduction Top 10 list}},
year = {2001}
}
@article{glover86,
author = {Glover, Fred and McMillan, Claude},
issn = {0305-0548},
journal = {Computers \& Operations Research},
number = {5},
pages = {563--573},
title = {{The general employee scheduling problem. An integration of MS and AI}},
volume = {13},
year = {1986}
}
@inproceedings{boehm96,
author = {Boehm, B},
booktitle = {IEEE Software},
month = mar,
title = {{Aims for Indentifying Conflicts Among Quality Requirements}},
year = {1996}
}
@inproceedings{kabas90,
author = {Kakas, A C and Mancrella, P},
booktitle = {ECAI-90},
title = {{Generalized Stable Models: A Semantics for Abduction}},
year = {1990}
}
@inproceedings{me03b,
author = {Liu, Y and Menzies, T and Cukic, B},
title = {{Detecting Novelties by Mining Association Rules}},
year = {2003}
}
@article{wu08,
author = {Wu, Xindong and Kumar, Vipin and {Ross Quinlan}, J and Ghosh, Joydeep and Yang, Qiang and Motoda, Hiroshi and McLachlan, GeoffreyJ. and Ng, Angus and Liu, Bing and Yu, PhilipS. and Zhou, Zhi-Hua and Steinbach, Michael and Hand, DavidJ. and Steinberg, Dan},
file = {:Users/timm/svns/doc/07top10dataMiners.pdf:pdf},
journal = {Knowledge and Information Systems},
number = {1},
pages = {1--37},
title = {{Top 10 algorithms in data mining}},
volume = {14},
year = {2008}
}
@article{lutz04,
author = {Lutz, Robyn R and Mikulski, Ines Carmen},
journal = {IEEE Trans. Software Eng},
number = {3},
pages = {172--180},
title = {{Empirical Analysis of Safety-Critical Anomalies During Operations}},
url = {http://csdl.computer.org/comp/trans/ts/2004/03/e0172abs.htm},
volume = {30},
year = {2004}
}
@article{Handl2007,
abstract = {The framework of multiobjective optimization is used to tackle the unsupervised learning problem, data clustering, following a formulation first proposed in the statistics literature. The conceptual advantages of the multiobjective formulation are discussed and an evolutionary approach to the problem is developed. The resulting algorithm, multiobjective clustering with automatic k-determination, is compared with a number of well-established single-objective clustering algorithms, a modern ensemble technique, and two methods of model selection. The experiments demonstrate that the conceptual advantages of multiobjective clustering translate into practical and scalable performance benefits},
author = {Handl, Julia and Knowles, Joshua},
doi = {10.1109/TEVC.2006.877146},
file = {:Users/timm/svns/doc/07handl\_clustering.pdf:pdf},
isbn = {0791836223},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Clustering,Determination of the number of clusters,Evolutionary clustering,Model selection,Multiobjective clustering},
number = {1},
pages = {56--76},
title = {{An evolutionary approach to multiobjective clustering}},
volume = {11},
year = {2007}
}
@book{stutzke05,
author = {Strutzke, R},
publisher = {Addison Wesley},
title = {{Estimating Software-Intensive Systems: Products, Projects and Processes}},
year = {2005}
}
@article{bobrow85,
author = {Bobrow, D G},
journal = {IEEE Transactions on Software Engineering},
month = nov,
number = {11},
pages = {1401--1408},
title = {{If Prolog is the Answer, What is the Question? or What it Takes to Support AI Programming Paradigms}},
volume = {11},
year = {1985}
}
@inproceedings{me95zb,
author = {Menzies, Tim and Compton, Paul},
booktitle = {Proceedings of the 9th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge Based Systems,},
title = {{The Extensive Implications of Evaluation on the Development of Knowledge-Based System}},
year = {1989}
}
@inproceedings{smith00,
author = {Smtih, B and Feather, M and Muscettola, N},
booktitle = {Proceedings of the Fifth International Conference on Artificial Intelligence Planning Systems (AIPS-2000)},
title = {{Challenges and Methods in Validating the Remote Agent Planner}},
year = {2000}
}
@article{Hand2007,
abstract = {Data mining is the discovery of interesting, unexpected or valuable structures in large datasets. As such, it has two rather different aspects. One of these concerns large-scale, 'global' structures, and the aim is to model the shapes, or features of the shapes, of distributions. The other concerns small-scale, 'local' structures, and the aim is to detect these anomalies and decide if they are real or chance occurrences. In the context of signal detection in the pharmaceutical sector, most interest lies in the second of the above two aspects; however, signal detection occurs relative to an assumed background model, therefore, some discussion of the first aspect is also necessary. This paper gives a lightning overview of data mining and its relation to statistics, with particular emphasis on tools for the detection of adverse drug reactions.},
author = {Hand, David J},
file = {:Users/timm/svns/doc/hand01.pdf:pdf},
issn = {0114-5916},
journal = {Drug safety : an international journal of medical toxicology and drug experience},
keywords = {Adverse Drug Reaction Reporting Systems,Adverse Drug Reaction Reporting Systems: organizat,Databases, Factual,Drug Industry,Humans,Information Systems,Information Systems: organization \& administration,Product Surveillance, Postmarketing},
month = jan,
number = {7},
pages = {621--2},
pmid = {17604416},
title = {{Principles of data mining.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17604416},
volume = {30},
year = {2007}
}
@inproceedings{me99a,
abstract = {Multiple viewpoints are often used in requirements engineering to
facilitate traceability to stakeholders, to structure the requirements
process, and to provide richer modelling by incorporating multiple
conflicting descriptions. In the latter case, the need to reason with
inconsistent models introduces considerable extra complexity. We
describe an empirical study of the utility of multiple world reasoning
(using abduction) for domain modelling. In the study we used a range of
different models (ranging from correct to very incorrect), different
fanouts, different amounts of data available from the domain, and
different modelling primitives for representing time. In the experiments
there was no significant change in the expressive power of models that
incorporate multiple conflicting viewpoints. Whilst this does not negate
the advantages of viewpoints during requirements elicitation it does
suggest some limits to the utility of viewpoints during requirements
modelling},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/99re.pdf\}},
author = {Menzies, T. and Easterbrook, S. and Nuseibeh, B. and Waugh, S.},
booktitle = {Proceedings IEEE International Symposium on Requirements Engineering (Cat. No.PR00188)},
doi = {10.1109/ISRE.1999.777990},
isbn = {0-7695-0188-5},
issn = {1090-705X},
title = {{An empirical investigation of multiple viewpoint reasoning in
requirements engineering}},
year = {1999}
}
@inproceedings{bradley98scaling,
annote = {Available from $\backslash$url\{http://citeseer.ist.psu.edu/bradley98scaling.html\}},
author = {Bradley, Paul S and Fayyad, Usama M and Reina, Cory},
booktitle = {Knowledge Discovery and Data Mining},
pages = {9--15},
title = {{Scaling Clustering Algorithms to Large Databases}},
year = {1998}
}
@article{boehm76,
author = {Boehm, B W},
journal = {IEEE Trans. Comput.},
month = dec,
number = {12},
pages = {1226--1241},
title = {{Software Engineering}},
volume = {25},
year = {1976}
}
@inproceedings{me09m,
abstract = {The next challenge for the PROMISE community is scaling up and speeding up model generation to meet the size and time constraints of modern software development projects. There will always be a trade-off between completeness and runtime speed. Here we explore that trade-off in the context of using genetic algorithms to learn coverage models; i.e. biases in the control structures for randomized test generators. After applying feature subset selection to logs of the GA output, we find we can generate the coverage model and run the resulting test suite ten times faster while only losing 6\% of the test case coverage.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09fssga.pdf\}},
author = {Andrews, Jh and Menzies, Tim},
booktitle = {5th International Conference on Predictor Models in Software Engineering},
doi = {10.1145/1540438.1540456},
isbn = {9781605586342},
keywords = {feature subset selection,genetic algorithms,software testing},
pages = {13},
title = {{On the value of combining feature subset selection with genetic algorithms: faster learning of coverage models}},
url = {http://dl.acm.org/citation.cfm?id=1540456},
year = {2009}
}
@article{jorgensen07,
author = {Jrgensen, M and Shepperd, M},
journal = {IEEE Transactions on Software Engineering},
month = jan,
pages = {33--53},
title = {{A Systematic Review of Software Development Cost Estimation Studies}},
year = {2007}
}
@book{schank83,
address = {New York, NY, USA},
author = {Schank, Roger C},
isbn = {0521248582},
publisher = {Cambridge University Press},
title = {{Dynamic Memory: A Theory of Reminding and Learning in Computers and People}},
year = {1983}
}
@article{Xiong2009,
abstract = {This paper describes a new approach for clusteringâpattern preserving clusteringâwhich produces more easily interpretable and usable clusters. This approach is motivated by the following observation: while there are usually strong patterns in the dataâpatterns that may be key for the analysis and description of the dataâthese patterns are often split among different clusters by current clustering approaches. This is, perhaps, not surprising, since clustering algorithms have no built-in knowledge of these patterns and may often have goals that are in conflict with preserving patterns, e.g., minimize the distance of points to their nearest cluster centroids. In this paper, our focus is to characterize (1) the benefits of pattern preserving clustering and (2) the most effective way of performing pattern preserving clustering. To that end, we propose and evaluate two clustering algorithms, HIerarchical Clustering with pAttern Preservation (HICAP) and bisecting K-means Clustering with pAttern Preservation (K-CAP). Experimental results on document data show that HICAP can produce overlapping clusters that preserve useful patterns, but has relatively worse clustering performance than bisecting K-means with respect to the clustering evaluation criterion of entropy. By contrast, in terms of entropy, K-CAP can perform substantially better than the bisecting K-means algorithm when data sets contain clusters of widely different sizesâa common situation in the real-world. Most importantly, we also illustrate how patterns, if preserved, can aid cluster interpretation. [ABSTRACT FROM AUTHOR] Copyright of Knowledge \& Information Systems is the property of Springer Science \& Business Media B.V. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
author = {Xiong, Hui and Steinbach, Michael and Ruslim, Arifin and Kumar, Vipin},
doi = {10.1007/s10115-008-0148-0},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/xiong09.pdf:pdf},
isbn = {02191377},
issn = {02191377},
journal = {Knowledge and Information Systems},
keywords = {Hierarchical clustering,Hyperclique pattern,K-means clustering,Pattern preserving clustering},
number = {3},
pages = {311--336},
pmid = {40211436},
title = {{Characterizing pattern preserving clustering}},
volume = {19},
year = {2009}
}
@book{jones91,
author = {Jones, C},
publisher = {McGraw Hill},
title = {{Applied Software Measurement}},
year = {1991}
}
@inproceedings{gers87,
author = {Gerstendorfer, M and Rohr, G},
booktitle = {Human-Computer Interaction - \{INTERACT\} '87},
pages = {6 pages},
title = {{Which Task in Which Representation on What Kind of Interface}},
year = {1987}
}
@inproceedings{JIANG20082,
abstract = {Data preprocessing (transformation) plays an important role in data$\backslash$nmining and machine learning. In this study, we investigate the effect$\backslash$nof four different preprocessing methods to fault-proneness prediction$\backslash$nusing nine datasets from NASA Metrics Data Programs (MDP) and ten$\backslash$nclassification algorithms. Our experiments indicate that log transformation$\backslash$nrarely improves classification performance, but discretization affects$\backslash$nthe performance of many different algorithms. The impact of different$\backslash$ntransformations differs. Random forest algorithm, for example, performs$\backslash$nbetter with original and log transformed data set. Boosting and Naive$\backslash$nBayes perform significantly better with discretized data. We conclude$\backslash$nthat no general benefit can be expected from data transformations.$\backslash$nInstead, selected transformation techniques are recommended to boost$\backslash$nthe performance of specific classification algorithms.},
address = {New York, NY, USA},
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim},
booktitle = {Proceedings of the 2008 workshop on Defects in large software systems - DEFECTS '08},
doi = {10.1145/1390817.1390822},
isbn = {9781605580517},
pages = {16},
publisher = {ACM},
title = {{Can data transformation help in the detection of fault-prone modules?}},
url = {http://portal.acm.org/citation.cfm?doid=1390817.1390822},
year = {2008}
}
@article{codd:70,
author = {Codd, E F},
journal = {Communications of the ACM},
pages = {377--387},
title = {{A Relational Model of Data for Large Shared Data Banks}},
volume = {13},
year = {1970}
}
@inproceedings{waugh98,
author = {Waugh, S and Blogs, J and Menzies, T},
booktitle = {Proceedings of the Australain AI '98 conference},
title = {{The Temporal Qualitative Compartmental Modeling Language}},
year = {1998}
}
@article{Mylopoulos97,
author = {Mylopoulos, J and Borgida, A and Yu, E},
journal = {Automated Software Engineering},
pages = {291--317},
title = {{Representing Software Engineering Knowledge}},
volume = {4},
year = {1997}
}
@inproceedings{corn01,
author = {Cornford, S L and Feather, M S and Hicks, K A},
booktitle = {IEEE Aerospace Conference, Big Sky, Montana},
month = mar,
pages = {441--451},
title = {{\{DDP\} A tool for life-cycle risk management}},
year = {2001}
}
@misc{me97i,
author = {Menzies, T},
howpublished = {Asian-Pacific Workshop on Intelligent Software Engineering},
title = {{Applications of Abduction: A Unified Framework for Software and Knowledge Engineering}},
year = {1998}
}
@misc{12207,
isbn = {0-7381-0428-0, SS94581},
title = {{ISO/IEC 12207 Standard for Information Technology - Software Lifecycle Process}},
year = {1998}
}
@inproceedings{me99h,
author = {Menzies, T and Cukic, B and Coiera, E},
booktitle = {AAAI'99 workshop on Conflicts and Identifying Opportunities.},
title = {{Smaller, Faster Dialogues via Conversational Probing}},
year = {1999}
}
@article{Abbass1999a,
author = {Abbass, H.a. and Sarker, R. and Newton, C.},
doi = {10.1109/CEC.2001.934295},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Abbass, Sarker, Newton - 1999 - PDE a Pareto-frontier differential evolution approach for multi-objective optimization problems.pdf:pdf},
isbn = {0-7803-6657-3},
journal = {Proceedings of the 2001 Congress on Evolutionary Computation (IEEE Cat. No.01TH8546)},
pages = {971--978},
publisher = {Ieee},
title = {{PDE: a Pareto-frontier differential evolution approach for multi-objective optimization problems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=934295},
year = {1999}
}
@article{knowles06,
author = {Knowles, J},
issn = {1089-778X},
journal = {Evolutionary Computation, IEEE Transactions on},
number = {1},
pages = {50--66},
title = {{ParEGO: a hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems}},
volume = {10},
year = {2006}
}
@article{Baum2011,
abstract = {Methods to measure the sequence diversity of polymerase chain reaction (PCR)-amplified DNA lack standards for use as assay calibrators and controls. Here we present a general and economical method for developing customizable DNA standards of known sequence diversity. Standards ranging from 1 to 25,000 sequences were generated by directional ligation of oligonucleotide "words" of standard length and GC content and then amplified by PCR. The sequence accuracy and diversity of the library were validated using AmpliCot analysis (DNA hybridization kinetics) and Illumina sequencing. The library has the following features: (i) pools containing tens of thousands of sequences can be generated from the ligation of relatively few commercially synthesized short oligonucleotides; (ii) each sequence differs from all others in the library at a minimum of three nucleotide positions, permitting discrimination between different sequences by either sequencing or hybridization; (iii) all sequences have identical length, GC content, and melting temperature; (iv) the identity of each standard can be verified by restriction digestion; and (v) once made, the ends of the library may be cleaved and replaced with sequences to match any PCR primer pair. These standards should greatly improve the accuracy and reproducibility of sequence diversity measurements. ?? 2010 Elsevier Inc. All rights reserved.},
author = {Baum, Paul D. and Young, Jennifer J. and Zhang, Qianjun and Kasakow, Zeljka and McCune, Joseph M.},
doi = {10.1016/j.ab.2010.11.035},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Baum11.pdf:pdf},
issn = {00032697},
journal = {Analytical Biochemistry},
keywords = {AmpliCot,Diversity,Ligation,PCR,Sequence,Standards},
number = {1},
pages = {106--115},
pmid = {21111699},
publisher = {Elsevier Inc.},
title = {{Design, construction, and validation of a modular library of sequence diversity standards for polymerase chain reaction}},
url = {http://dx.doi.org/10.1016/j.ab.2010.11.035},
volume = {411},
year = {2011}
}
@article{frued92,
author = {Frueder, E C and Wallace, R J},
journal = {Artificial Intelligence},
pages = {21--70},
title = {{Partial Constraint Satisfaction}},
volume = {58},
year = {1992}
}
@misc{raffo95,
annote = {Ph.D. thesis, Manufacturing and Operations Systems},
author = {Raffo, D M},
institution = {Graduate School of Industrial Administration, Carnegie Mellon University, Pittsburgh, Pennsylvania},
month = may,
title = {{Modeling Software Processes Quantitatively and Assessing the Impact of Potential Process Changes of Process Performance}},
year = {1996}
}
@inproceedings{burk04,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/04lean.pdf\}},
author = {Burkleaux, T and Menzies, T and Owen, D},
booktitle = {Proceedings of WITSE 2005},
title = {{LEAN = (LURCH+TAR3) = Reusable Modeling Tools}},
year = {2004}
}
@misc{simon78,
author = {Simon, H},
title = {{Rational Decision-Making in Business Organiations- a Nobel Memorial Lecture, December 8}},
url = {http://goo.gl/E80Nyy},
year = {1978}
}
@article{duda85,
author = {Duda, R O and Hart, P E and Reboh, R},
journal = {Artificial Intelligence},
pages = {359--360},
title = {{Letter to the Editor}},
volume = {26},
year = {1985}
}
@article{preece92a,
author = {Preece, A D},
journal = {The Knowledge Engineering Review},
pages = {115--141},
title = {{Principles and Practice in Verifying Rule-based Systems}},
volume = {7},
year = {1992}
}
@inproceedings{me05e,
author = {Menzies, T and Richardson, J},
booktitle = {COCOMO forum, 2005},
title = {{XOMO: Understanding Development Options for Autonomy}},
year = {2005}
}
@inproceedings{MIZUNO2007,
address = {New York, NY, USA},
author = {Mizuno, Osamu and Kikuno, Tohru},
booktitle = {ESEC-FSE '07: Proceedings of the the 6th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering},
doi = {http://doi.acm.org/10.1145/1287624.1287683},
isbn = {978-1-59593-811-4},
pages = {405--414},
publisher = {ACM},
title = {{Training on errors experiment to detect fault-prone software modules by spam filter}},
year = {2007}
}
@inproceedings{rousset88,
author = {Rousset, M C},
booktitle = {Proceedings of the 8th European Conference on Artificial Intelligence (ECAI'88)},
pages = {79--84},
title = {{On the Consistency of Knowledge Bases: the Covadis System}},
year = {1988}
}
@inproceedings{me92k,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/ai92.pdf\}},
author = {Menzies, T J},
booktitle = {Proceedings of AI '92, Australia},
title = {{Maintaining Procedural Knowledge: Ripple-Down-Functions}},
year = {1992}
}
@inproceedings{kang95b,
author = {Kang, B H and Compton, P},
booktitle = {Advances in Case-Based Reasoning, Selected Papers from Second European Workshop, EWCBR-94},
editor = {M.Keane and Haton, J P and Manago, M},
pages = {226--239},
publisher = {Springer},
title = {{A Maintenance Approach to Case Based Reasoning}}
}
@book{alex77,
author = {Alexander, C and Ishikawa, S and Silverstein, S and Jacobsen, I and Fiksdahl-King, I and Angel, S},
publisher = {Oxford University Press},
title = {{A Pattern Language}},
year = {1977}
}
@article{Cha2007,
author = {Cha, Sung-hyuk},
file = {:Users/timm/svns/doc/distance07.pdf:pdf},
keywords = {distance,histogram,probability density function},
number = {4},
title = {{Comprehensive Survey on Distance / Similarity Measures between Probability Density Functions}},
volume = {1},
year = {2007}
}
@book{halstead77,
author = {Halstead, M H},
publisher = {Elsevier},
title = {{Elements of Software Science}},
year = {1977}
}
@article{Mining2009,
abstract = {During the past decade there has been an explosion in computation and information technology. With it has come a vast amount of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics.},
author = {Mining, Data},
doi = {10.1007/b94608},
file = {:Users/timm/svns/doc/elementsOfStatisticalLearning.pdf:pdf},
isbn = {9780387848570},
issn = {03436993},
journal = {The Mathematical Intelligencer},
number = {2},
pages = {83--85},
pmid = {15512507},
title = {{Springer Series in Statistics The Elements of}},
url = {http://www.springerlink.com/index/D7X7KX6772HQ2135.pdf},
volume = {27},
year = {2009}
}
@book{musa87,
author = {Musa, J and Iannino, A and Okumoto, K},
publisher = {McGraw Hill},
title = {{Software Reliability: Measurement, Prediction, Application}},
year = {1987}
}
@inproceedings{me02l,
author = {Stefano, J S Di and Menzies, T},
booktitle = {Proceedings, IEEE Tools with AI, 2002},
title = {{Machine Learning for Software Engineering: Case Studies in Software Reuse}},
year = {2002}
}
@inproceedings{nam13,
author = {Nam, Jaechang and Pan, Sinno Jialin and Kim, Sunghun},
booktitle = {the 2013 International Conference on Software Engineering},
organization = {IEEE Press Piscataway, NJ, USA},
pages = {802--811},
title = {{Transfer Defect Learning}},
year = {2013}
}
@inproceedings{keung2008a,
address = {New York, NY, USA},
author = {Keung, Jacky Wai},
booktitle = {ESEM '08: International Symposium on Empirical Software Engineering and Measurement},
doi = {http://doi.acm.org/10.1145/1414004.1414057},
isbn = {978-1-59593-971-5},
pages = {294--296},
publisher = {ACM},
title = {{Empirical evaluation of analogy-x for software cost estimation}},
year = {2008}
}
@article{holzmann97,
author = {Holzmann, G J},
journal = {IEEE Transactions on Software Engineering},
month = may,
number = {5},
pages = {279--295},
title = {{The Model Checker \{SPIN\}}},
volume = {23},
year = {1997}
}
@article{man95,
author = {Manley, R},
journal = {American Programmer},
pages = {17--18},
title = {{\{TAURUS\}: How I Lived to Tell the Tale}},
year = {1995}
}
@inproceedings{bark92,
author = {Barker-Plummer, D and Bailin, S C},
booktitle = {AAAI Spring Symposium on Reasoning with Diagrammatic Representations},
editor = {Narayanan, N H},
pages = {102--107},
title = {{Proofs and Pictures: Proving the Diamond Lemma with the GROVER Theorem Proving System}},
year = {1992}
}
@article{me06a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06qrre.pdf\}},
author = {Menzies, T and Richardson, J},
journal = {IEEE Computer},
month = oct,
title = {{Making Sense of Requirements, Sooner}},
year = {2006}
}
@incollection{lee96a,
author = {Lee, J and Lai, K},
booktitle = {Design Rationale: Concepts, Techniques, and Use},
editor = {Moran, T P and Carroll, J M},
pages = {21--52},
publisher = {Lawerence Erlbaum Associates},
title = {{What's in Design Rationale?}},
year = {1996}
}
@inproceedings{QWFENG95a,
author = {Feng, Q W and Cohen, R F and Eades, P},
booktitle = {Proc. of the Third European Symposium on Algorithms},
publisher = {Springer-Verlag},
series = {Lecture Notes in Computer Science},
title = {{Planarity for Clustered Graphs}},
year = {1995}
}
@article{Gray2012,
abstract = {Background: The NASA metrics data program (MDP) data sets have been heavily used in software defect prediction research. Aim: To highlight the data quality issues present in these data sets, and the problems that can arise when they are used in a binary classification context. Method: A thorough exploration of all 13 original NASA data sets, followed by various experiments demonstrating the potential impact of duplicate data points when data mining. Conclusions: Firstly researchers need to analyse the data that forms the basis of their findings in the context of how it will be used. Secondly, the bulk of defect prediction experiments based on the NASA MDP data sets may have led to erroneous findings. This is mainly because of repeated/duplicate data points potentially causing substantial amounts of training and testing data to be identical.},
author = {Gray, D. and Bowes, D. and Davey, N. and Sun, Y. and Christianson, B.},
doi = {10.1049/iet-sen.2011.0132},
file = {:Users/timm/svns/doc/12grayNoise.pdf:pdf},
issn = {17518806},
journal = {IET Software},
number = {6},
pages = {549},
title = {{Reflections on the NASA MDP data sets}},
volume = {6},
year = {2012}
}
@article{mcmonk94,
author = {McCarthy, J C and Monk, A F},
journal = {Collaborative Computing},
pages = {35--60},
title = {{Channels, conversation, co-operation and relevance: all you wanted to know about communication but were afraid to ask}},
volume = {1},
year = {1994}
}
@article{Jha,
author = {Jha, S and Kruger, L and Mcdaniel, P},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Jha, Kruger, Mcdaniel - Unknown - Privacy Preserving Clustering.pdf:pdf},
journal = {Work},
pages = {1--20},
title = {{Privacy Preserving Clustering}}
}
@misc{On,
abstract = {December 7, 2010},
author = {On, Focus},
booktitle = {University of Buffalo},
file = {:Users/timm/svns/doc/HowRareIsThat.pdf:pdf},
keywords = {forensics},
mendeley-tags = {forensics},
title = {{How Rare is that Fingerprint ? Computational Forensics Provides the First Clues}},
url = {http://www.buffalo.edu/news/12073}
}
@article{Abts1997,
author = {Abts, Christopher M},
file = {:Users/timm/svns/doc/cost/00USAFReport.pdf:pdf},
number = {June},
title = {{COTS Software Integration Cost Modeling Study Center for Software Engineering}},
year = {1997}
}
@article{laird86,
author = {Laird, P S and {J. E.}, Rosenbloom and Newell, A},
journal = {Machine Learning},
number = {1},
pages = {11--46},
title = {{Chunking in \{SOAR\}: The Anatomy of a General Learning Mechanism}},
volume = {1},
year = {1986}
}
@article{boetticher03,
author = {Boetticher, G},
journal = {IEEE Intelligent Systems},
month = jun,
title = {{When Will it Be Done? The 300 Billion Dollar Question, Machine Learner Answers}},
year = {2003}
}
@inproceedings{rahman12,
author = {Rahman, Foyzur and Posnett, Daryl and Devanbu, Premkumar T},
booktitle = {Foundations of Software Engineering (FSE-20)},
pages = {61},
title = {{Recalling the "imprecision" of cross-project defect prediction}},
year = {2012}
}
@inproceedings{PORT2008,
address = {New York, NY, USA},
author = {Port, Dan and Korte, Marcel},
booktitle = {ESEM '08: Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
doi = {http://doi.acm.org/10.1145/1414004.1414015},
isbn = {978-1-59593-971-5},
pages = {51--60},
publisher = {ACM},
title = {{Comparative studies of the model evaluation criterions mmre and pred in software cost estimation research}},
year = {2008}
}
@inproceedings{me05a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05safewhen.pdf\}},
author = {Menzies, Tim and Chen, Zhihao and Port, Dan and Hihn, Jairus},
booktitle = {Proceedings, PROMISE workshop, ICSE},
title = {{Simple software cost estimation: Safe or unsafe}},
volume = {2005},
year = {2005}
}
@misc{spear00,
title = {{No Title}}
}
@inproceedings{deb98a,
author = {Debenham, J},
booktitle = {Proceedings Seventh International Conference on Information Processing and Management of Uncertainty in Knowledge Based Systems IPMU '98, Paris, France, July},
title = {{Managing Knowledge Integrity}},
year = {1998}
}
@inproceedings{me08g,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08severis.pdf\}},
author = {Menzies, T and Marcus, A},
booktitle = {ICSM'08},
title = {{Automated Severity Assessment of Software Defect Reports}},
year = {2008}
}
@misc{nsf06,
author = {(U.S.)., National Science Board},
title = {{Science and engineering indicators}}
}
@article{foss05,
author = {Foss, T and Stensrud, E and Kitchenham, B and Myrtveit, I},
journal = {IEEE Transactions on Software Engineering},
month = nov,
number = {11},
pages = {985--995},
title = {{A simulation study of the model evaluation criterion MMRE}},
volume = {29},
year = {2003}
}
@inproceedings{nar92,
editor = {Narayanan, N H},
title = {{AAAI Spring Symposium on Reasoning with Diagrammatic Representations}},
year = {1992}
}
@book{buchanan84,
author = {Buchanan, B G and Shortliffe, E H},
publisher = {Addison-Wesley},
title = {{Rule-\{B\}ased \{E\}xpert \{S\}ystems: The \{MYCIN\} \{E\}xperiments of the \{S\}tanford \{H\}euristic \{P\}rogramming \{P\}roject}},
year = {1984}
}
@inproceedings{have00b,
author = {Havelund, Klaus},
booktitle = {SPIN Model Checking and Software Verification},
pages = {245--264},
publisher = {Springer-Verlag},
title = {{Using Runtime Analysis to Guide Model Checking of Java Programs}},
year = {2000}
}
@inproceedings{zhang07,
author = {Zhang, Y and Harman, M and Mansouri, S A},
booktitle = {In ACM Genetic and Evolutionary Computation Conference (GECCO 2007},
pages = {11},
title = {{The Multi-Objective Next Release Problem}},
year = {2007}
}
@article{Schutze2009,
abstract = {We have determined diversities exceeding 10(12) different sequences in an annealing and melting assay using synthetic randomized oligonucleotides as a standard. For such high diversities, the annealing kinetics differ from those observed for low diversities, favouring the remelting curve after annealing as the best indicator of complexity. Direct comparisons of nucleic acid pools obtained from an aptamer selection demonstrate that even highly complex populations can be evaluated by using DiStRO, without the need of complicated calculations.},
author = {Sch\"{u}tze, Tatjana and Arndt, Peter F. and Menger, Marcus and Wochner, Aniela and Vingron, Martin and Erdmann, Volker a. and Lehrach, Hans and Kaps, Christian and Gl\"{o}kler, J\"{o}rn},
doi = {10.1093/nar/gkp1108},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Schutze10.pdf:pdf},
isbn = {1362-4962 (Electronic)$\backslash$n0305-1048 (Linking)},
issn = {03051048},
journal = {Nucleic Acids Research},
number = {4},
pmid = {19965765},
title = {{A calibrated diversity assay for nucleic acid libraries using DiStRO-a Diversity Standard of Random Oligonucleotides}},
volume = {38},
year = {2009}
}
@inproceedings{me02n,
abstract = { Adaptive systems are systems whose function evolves while adapting to current environmental conditions, Due to the real-time adaptation, newly learned data have a significant impact on system behavior When online adaptation is included in system control, anomalies could cause abrupt loss of system functionality and possibly result in a failure. In this paper we present a framework for reasoning about the online adaptation problem. We describe a machine learning tool that sniffs data and detects anomalies before they are passed to the adaptive components for learning. Anomaly detection is based on distance computation. An algorithm for framework evaluation as well as sample implementation and empirical results are discussed. The method we propose is simple and reasonably effective, thus it can be easily adopted for testing.},
author = {Liu, Yan Liu Yan and Menzies, T. and Cukic, B.},
booktitle = {14th IEEE International Conference on Tools with Artificial Intelligence, 2002. (ICTAI 2002). Proceedings.},
doi = {10.1109/TAI.2002.1180783},
isbn = {0-7695-1849-4},
issn = {1082-3409},
title = {{Data sniffing - monitoring of machine learning for online adaptive systems}},
year = {2002}
}
@article{shepperd12,
author = {Shepperd, Martin J and Song, Qinbao and Sun, Zhongbin and Mair, Carolyn},
journal = {IEEE Trans. Software Eng.},
number = {9},
pages = {1208--1215},
title = {{Data Quality: Some Comments on the NASA Software Defect Datasets}},
volume = {39},
year = {2013}
}
@article{Zaki2007,
abstract = {We present a novel algorithm called Clicks, that finds clusters in categorical datasets based on a search for k-partite maximal cliques. Unlike previous methods, Clicks mines subspace clusters. It uses a selective vertical method to guarantee complete search. Clicks outperforms previous approaches by over an order of magnitude and scales better than any of the existing method for high-dimensional datasets. These results are demonstrated in a comprehensive performance study on real and synthetic datasets. Â© 2006 Elsevier B.V. All rights reserved.},
author = {Zaki, Mohammed J. and Peters, Markus and Assent, Ira and Seidl, Thomas},
doi = {10.1016/j.datak.2006.01.005},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/zaki06.pdf:pdf},
isbn = {159593135X},
issn = {0169023X},
journal = {Data and Knowledge Engineering},
keywords = {Categorical data,Clustering,Maximal cliques,k-Partite graph},
number = {1},
pages = {51--70},
title = {{Clicks: An effective algorithm for mining subspace clusters in categorical datasets}},
volume = {60},
year = {2007}
}
@misc{me01d,
author = {Menzies, T and Kiper, J D},
title = {{Machine Learning for Requirements Engineering}},
year = {2001}
}
@misc{shum97,
author = {Shum, S Buckingham and Sumner, T},
howpublished = {Knowledge Media Institute, The Open University, Milton Keynes, Technical report KMI-TR-57},
title = {{Publishing, Interpreting and Negotiating Scholarly Hypertexts: Evolution of an Approach and Toolkit}},
year = {1997}
}
@inproceedings{me08c,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08icsp.pdf\}},
author = {Menzies, T and Elrawas, O and Barry, B and Madachy, R and Hihn, J and Baker, D and Lum, K},
booktitle = {International Conference on Software Process},
title = {{Accurate Estimates without Calibration}},
year = {2008}
}
@inproceedings{agesen95,
author = {Agesen, O and Holzle, U},
booktitle = {OOPSLA '95},
pages = {91--107},
title = {{Type Feedback vs Concrete Type Inference: A Comparison of Optimisation Techniques for OO Languages}},
year = {1995}
}
@book{der96,
author = {Deransart, P and Ed-Dbali, A and Cervoni, L},
publisher = {Sprunger},
title = {{Prolog: The Standard}},
year = {1996}
}
@misc{gent97,
author = {Gent, I P and Grant, S A and MacIntyre, E and Prosser, P and P.Shar and Smith, B M and Walsh, T},
institution = {University of Leeds, School of Computer Studies},
number = {97.27},
title = {{How not to do it}},
year = {1997}
}
@article{chase73,
author = {Chase, W G and Simon, H A},
journal = {Cognitive Psychology},
pages = {55--81},
title = {{Perception in Chess}},
volume = {1},
year = {1973}
}
@inproceedings{me00y,
author = {Menzies, Tim and Cukic, Bojan},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
pages = {1--22},
title = {{How Many Tests are Enough ?}},
volume = {2},
year = {2000}
}
@incollection{gut90,
author = {Gutfreund, S H},
booktitle = {Visual Programming Environments: Applications and Issues},
editor = {Glinert, E P},
pages = {25--45},
publisher = {IEEE Computer Society Press Tutorial},
title = {{ManiplIcons in ThinkerToy}},
year = {1990}
}
@inproceedings{me10e,
author = {Huang, LiGuo and Port, Daniel and Wang, Liang and Xie, Tao and Menzies, Tim},
booktitle = {IEEE ASE'10},
pages = {163--166},
title = {{Text mining in supporting software systems risk assurance}},
year = {2010}
}
@book{bratko01,
author = {Bratko, I},
publisher = {Addison-Wesley},
title = {{Prolog Programming for Artificial Intelligence. (third edition)}},
year = {2001}
}
@phdthesis{easter91b,
author = {Easterbrook, S},
school = {Imperial College of Science Technology and Medicine, University of London},
title = {{Elicitation of Requirements from Multiple Perspectives}},
year = {1991}
}
@misc{dabney07,
author = {Dabney, J B},
title = {{Return on Investment for \{IV\&V\}}}
}
@inproceedings{me05a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05safewhen.pdf\}},
author = {Menzies, Tim and Chen, Zhihao and Port, Dan and Hihn, Jairus},
booktitle = {Proceedings, PROMISE workshop, ICSE 2005},
title = {{Simple Software Cost Estimation: Safe or Unsafe?}},
year = {2005}
}
@mastersthesis{papa13,
author = {Papakroni, Vasil},
school = {Lane Department of Computer Science and Electrical Engineering, West Virginia Unviersity},
title = {{Data Carving: Identifying and Removing Irrelevancies in the Data}},
year = {2013}
}
@book{uml13,
author = {Booch, G and Jacobsen, I and Rumbaugh, J},
publisher = {Addison Wesley},
title = {{The Unified Modeling Language User Guide}},
year = {1999}
}
@misc{jackson97,
author = {Jackson, B and Griggs, J and Costello, K and Solomon, D},
title = {{Systems level definition of IV\&V}},
year = {2006}
}
@inproceedings{me02c,
author = {Menzies, Tim and Chiang, Eliza and Feather, Martin and Hu, Ying and Kiper, James D},
booktitle = {Jet Propulsion},
editor = {Khoshgoftaar, Taghi M},
isbn = {1-4020-7427-1},
publisher = {Kluwer},
title = {{Condensing Uncertainty via Incremental Treatment Learning}},
year = {2002}
}
@inproceedings{laird83,
author = {Laird, J E and Newell, A},
booktitle = {IJCAI '83},
pages = {771--773},
title = {{A Universal Weak Method: Summary of Results}},
year = {1983}
}
@article{boning94,
author = {Boning, D S and Mozumder, P K},
journal = {IEEE Transactions on Semiconductor Manufacturing},
month = may,
number = {2},
pages = {233--244},
title = {{DOE/Opt: a system for design of experiments, response surface modeling, and optimization using process and device simulation}},
volume = {7},
year = {1994}
}
@book{Mills83,
author = {Mills, H},
publisher = {Little, Brown},
title = {{Software Productivity}},
year = {1983}
}
@article{Lin2005a,
author = {Lin, Xiaodong},
doi = {10.1007/s10115-004-0148-7},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Jha, Kruger, Mcdaniel - Unknown - Privacy Preserving Clustering.pdf:pdf},
journal = {Knowledge and Information Systems},
month = jul,
number = {1},
pages = {899--81},
title = {{Privacy-preserving clustering with distributed EM mixture modeling}},
volume = {86},
year = {2005}
}
@inproceedings{owen02a,
abstract = { This paper studies how details of a particular model can effect the efficacy of a search for detects. We find that if the test method is fixed, we can identity classes of software that are more or less testable. Using a combination of model mutators and machine learning, we find that we can isolate topological features that significantly change the effectiveness of a defect detection tool. More specifically, we show that for one defect detection tool (a stochastic search engine) applied to a certain representation (finite state machines), we can increase the average odds of finding a defect from 69\% to 91\%. The method used to change those odds is quite general and should apply to other defect detection tools being applied to other representations.},
author = {Owen, D. and Menzies, T. and Cukic, B.},
booktitle = {Proceedings 17th IEEE International Conference on Automated Software Engineering,},
doi = {10.1109/ASE.2002.1115019},
isbn = {0-7695-1736-6},
issn = {1527-1366},
title = {{What makes finite-state models more (or less) testable?}},
year = {2002}
}
@misc{Siekmann,
author = {Siekmann, J},
file = {:Users/timm/svns/doc/Engineering Knowledge in the Age of the Semantic Web 14th \ldots\_Suryanto\_2004.pdf:pdf},
isbn = {3540233407},
title = {{Engineering Knowledge in the Age of the Semantic Web}}
}
@inproceedings{me00t,
author = {Menzies, Tim and Singh, Harhsinder},
booktitle = {2nd International Workshop on Soft Computing applied to Software Engineering (Netherlands), February},
pages = {1--24},
title = {{Many Maybes Mean ( Mostly ) the Same Thing}},
year = {2001}
}
@article{marcus89,
author = {Marcus, S and McDermott, J},
journal = {Artificial Intelligence},
pages = {1--37},
title = {{\{SALT\}: A \{K\}nowledge \{A\}cquisition \{L\}anguage for \{P\}ropose-and-\{R\}evise \{S\}ystems}},
volume = {39},
year = {1989}
}
@misc{me97r,
author = {Menzies, T and Waugh, S and Goss, S and Cohen, Robert F},
howpublished = {Submitted to FOIS '97},
title = {{Evaluating a Temporal Causal Ontology}},
year = {1997}
}
@misc{standish95,
title = {{The \{S\}tandish \{G\}roup \{R\}eport: \{C\}haos}},
year = {1995}
}
@article{searle80,
author = {Searle, J R},
journal = {The Behavioral and Brain Sciences},
pages = {417--457},
title = {{Minds, \{B\}rain, and \{P\}rograms}},
volume = {3},
year = {1980}
}
@article{Barreno2010,
author = {Barreno, Marco and Nelson, Blaine and Joseph, Anthony D. and Tygar, J. D.},
doi = {10.1007/s10994-010-5188-5},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Barreno et al. - 2010 - The security of machine learning.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {adversarial environments,adversarial learning,security},
month = may,
number = {2},
pages = {121--148},
title = {{The security of machine learning}},
url = {http://www.springerlink.com/index/10.1007/s10994-010-5188-5},
volume = {81},
year = {2010}
}
@misc{kremer98,
annote = {To appear},
author = {Kremer, R},
howpublished = {KAW'98: Eleventh Workshop on Knowledge Acquisition, Modeling and Management, Voyager Inn, Banff, Alberta, Canada},
title = {{Visual Languages for Knowledge Representation}},
year = {1998}
}
@inproceedings{crawford96,
author = {Crawford, J and Dvorak, D L and Litman, D J and Mishra, A M and Patel-Schneider, P F},
booktitle = {Thirteenth National Conference on Artificial Intelligence (AAAI-96)},
title = {{Path-Based Rules in Object-Oriented Programming}},
year = {1996}
}
@inproceedings{hameph95,
author = {Haynes, P and Menzies, T and Phipps, G},
booktitle = {OOPSLA Workshop on OO Process and Metrics for Effort Estimation},
title = {{Using The Size of Classes and Methods as the Basis for Early Effort Prediction; Empirical Observations, Initial Application; A Practitioners Experience Report}},
year = {1995}
}
@article{Rhinehart2012,
abstract = {A novel optimization technique is introduced and demonstrated. Leapfrogging starts with a randomly located set of trial solutions (termed players) within the feasible decision variable (DV) space. At each iteration, the player with the worst objective function (OF) value is relocated to a random position within its DV-space reflection on the other side of the player with the best OF value. Test cases reveal that this simple algorithm has benefits over classic direct and gradient-based methods and particle swarm in speed of finding the optimum and in handling surface aberrations, including ridges, multi-optima, and stochastic objective functions. Potential limitations and analysis opportunities are discussed. ?? 2012 Elsevier Ltd.},
author = {Rhinehart, R. Russell and Su, Ming and Manimegalai-Sridhar, Upasana},
doi = {10.1016/j.compchemeng.2012.02.011},
file = {:Users/timm/svns/doc/12leapfrog.pdf:pdf},
issn = {00981354},
journal = {Computers and Chemical Engineering},
keywords = {Constraints,Direct search,Individuals,Nonlinear,Optimization,Stochastic},
pages = {67--81},
publisher = {Elsevier Ltd},
title = {{Leapfrogging and synoptic Leapfrogging: A new optimization approach}},
url = {http://dx.doi.org/10.1016/j.compchemeng.2012.02.011},
volume = {40},
year = {2012}
}
@article{Apte2010,
author = {Apte, Chid and Heights, Yorktown},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Apte, Heights - 2010 - Invited Applications Paper The Role of Machine Learning in Business Optimization.pdf:pdf},
journal = {Machine Learning},
title = {{Invited Applications Paper The Role of Machine Learning in Business Optimization}},
year = {2010}
}
@article{Heemstra1992,
abstract = {This paper reports the results of an empirical investigation of the relationships between effort expended, time scales, and project size for software project development. The observed relationships were compared with those predicted by Lawrence Putnam's Rayleigh curve model and Barry Boehm's COCOMO model. The results suggested that although the form of the basic empirical relationships were consistent with the cost models, the COCOMO model was a poor estimator of cost for the current data set and the data did not follow the Rayleigh curve suggested by Putnam. However, the results did suggest that it was possible to develop cost models tailored to a particular environment and to improve the precision of the models as they are used during the development cycle by including additional information such as the known effort for the early development phases. The paper finishes by discussing some of the problems involved in developing useful cost models.},
author = {Heemstra, F.J.},
doi = {10.1016/0950-5849(92)90068-Z},
file = {:Users/timm/svns/doc/cost/02Jplhandbook.pdf:pdf},
isbn = {0818620781},
issn = {09505849},
journal = {Information and Software Technology},
number = {10},
pages = {627--639},
title = {{Software cost estimation}},
volume = {34},
year = {1992}
}
@inproceedings{me00q,
abstract = {Early testing of requirements can decrease the cost of removing errors in software projects. However unless done carefully, that testing process can significantly add to the cost of requirements analysis. We show that requirements expressed as topoi diagrams can be built and tested cheaply <sup>s</sup>ing our SP2 algorithm, the formal temporal properties of a large class of topoi can be proven very quickly, in time nearly linear in the number of nodes and edges in the diagram. There are two limitations to our approach. Firstly, topoi diagrams cannot express certain complex concepts such as iteration and sub-routine calls. Hence, our approach is more useful for requirements engineering than for traditional model checking domains. Secondly, our approach is better for exploring the temporal occurrence of properties than the temporal ordering of properties. Within these restrictions, we can express a useful range of concepts currently seen in requirements engineering, and a wide range of interesting temporal properties.},
author = {Menzies, T and Powell, J and Houle, M E},
booktitle = {Software Engineering, 2001. ICSE 2001. Proceedings of the 23rd International Conference on},
doi = {10.1109/ICSE.2001.919112},
isbn = {0270-5257   VO  -},
issn = {02705257},
keywords = {SP2 algorithm,fast formal requirements analysis,formal specification,formal temporal properties,program verification,requirements engineering,software projects,testing process,topoi diagrams},
pages = {391--400},
title = {{Fast formal analysis of requirements via "topoi diagrams"}},
year = {2001}
}
@inproceedings{me06b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06hicss.pdf\}},
author = {Fisher, Marcus S. and Menzies, Tim},
booktitle = {Proceedings of the Annual Hawaii International Conference on System Sciences},
doi = {10.1109/HICSS.2006.251},
isbn = {0769525075},
issn = {15301605},
title = {{Learning IV\&V strategies}},
volume = {9},
year = {2006}
}
@misc{wu95a,
author = {Wu, X},
title = {{ARC application for initial support in 1996.}},
year = {1995}
}
@misc{bsc99,
author = {Page, Web},
title = {{No Title}}
}
@inproceedings{rod11,
author = {Rodr\'{\i}guez, Daniel and Carreira, Mercedes Ruiz and Riquelme, Jos\'{e} C and Harrison, Rachel},
booktitle = {GECCO},
pages = {1883--1890},
title = {{Multiobjective simulation optimisation in software project management}},
year = {2011}
}
@inproceedings{easterIWSSD96,
author = {Easterbrook, S M},
booktitle = {Eighth International Workshop on Software Specification and Design (IWSSD-8)},
month = mar,
title = {{Learning from Inconsistency}},
year = {1996}
}
@article{by91,
author = {Bylander, T and Allemang, D and Tanner, M C and Josephson, J R},
journal = {Artificial Intelligence},
pages = {25--60},
title = {{The \{C\}omputational \{C\}omplexity of \{A\}bduction}},
volume = {49},
year = {1991}
}
@inproceedings{ginsberg88a,
author = {Ginsberg, A},
booktitle = {Proceedings of the Seventh National Conference on Artificial Intelligence (AAAI'88),},
pages = {585--589},
title = {{Knowledge-Base Reduction: A New Approach to Checking Knowledge Bases for Inconsistency \& Redundancy}},
year = {1988}
}
@inproceedings{me09f,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09bfc.pdf\}},
author = {Menzies, T and El-Rawas, O and Hihn, J and Boehm, B},
booktitle = {PROMISE'09},
title = {{Can We Build Software Faster and Better and Cheaper?}},
year = {2009}
}
@article{compton05,
annote = {Available from $\backslash$url\{http://www.cse.unsw.edu.au/\~{}compton/\#Starter\_Papers\}},
author = {Compton, P and Peters, L and Edwards, G and Lavers, T G},
journal = {Knowledge-Based Systems},
month = sep,
number = {5},
pages = {356--362},
title = {{Experience with Ripple-Down Rules}},
volume = {19},
year = {2006}
}
@inproceedings{fecosm89b,
author = {Feldman, B and Compton, P and Smythe, G},
booktitle = {Proceedings of the Joint Australian Conference on Artificial Intelligence, \{AI\} '89},
pages = {319--331},
title = {{Towards \{H\}ypothesis \{T\}esting: JUSTIN, \{P\}rototype \{S\}ystem \{U\}sing \{J\}ustification in \{C\}ontext}},
year = {1989}
}
@book{Aboulnaga2002,
author = {Aboulnaga, Ashraf},
file = {:Users/timm/svns/doc/07mendes.pdf:pdf},
isbn = {9781599041353},
title = {{Cost Estimation Techniques for}},
year = {2002}
}
@misc{fen96,
author = {Fensel, D and Schonegge, A and Groenboom, R and Wielinga, B},
booktitle = {Proceedings of the 10th Knowledge Acquisition Workshop for Knowledge-Based Systems, Banff,Canada},
title = {{Specification and Verification of Knowledge-Based Systems}},
year = {1996}
}
@article{basili88,
author = {Basili, V R and Rombach, H D},
journal = {IEEE Transactions on Software Engineering},
month = jun,
number = {6},
pages = {758--773},
title = {{The TAME project: towards improvement-oriented software environments}},
volume = {14},
year = {1988}
}
@article{Liu2002,
author = {Liu, Huan and Motoda, Hiroshi},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Liu, Motoda - 2002 - On issues of instance selection.pdf:pdf},
issn = {1384-5810},
journal = {Data Mining and Knowledge Discovery},
keywords = {instance selection},
pages = {115--130},
publisher = {Springer},
title = {{On issues of instance selection}},
url = {http://www.springerlink.com/index/5W6J6PE15K7U8HRA.pdf},
volume = {6},
year = {2002}
}
@misc{swiprolog,
author = {Wielemaker, Jan},
title = {{SWI-Prolog}}
}
@article{Ahn1997,
author = {Ahn, H.K. and Mamoulis, Nikos and Wong, H.M.},
file = {:Users/timm/svns/doc/Ahn01.pdf:pdf},
journal = {Lecture COMP630c,âSpatial, Image and Multimedia Databasesâ, University of Science and Technology, Clearwater Bay, Hong Kong},
keywords = {Grid cluster},
publisher = {Citeseer},
title = {{A survey on multidimensional access methods}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.19.192\&amp;rep=rep1\&amp;type=pdf},
year = {1997}
}
@incollection{gas83,
author = {Gaschnig, J and Klahr, P and Pople, H and Shortliffe, E and Terry, A},
booktitle = {Building Expert Systems},
chapter = {8},
editor = {Hayes-Roth, F and Waterman, D A and Lenat, D B},
pages = {241--280},
publisher = {Addison-Wesley},
title = {{Evaluation of Expert Systems: Issues and Case Studies}},
year = {1983}
}
@article{gray97,
author = {Gray, A and MacDonnell, S},
journal = {Information and Software Technology},
title = {{A Comparison of Techniques for Developing Predictive Models of Software Metrics}},
volume = {39},
year = {1997}
}
@inproceedings{me01f,
author = {Menzies, Tim and Hu, Y},
booktitle = {First International Workshop on Model-based Requirements Engineering},
title = {{Reusing models for requirements engineering}},
year = {2001}
}
@misc{coker03,
annote = {Available from $\backslash$url\{http://www.jcrocket.com/altimeters.shtml\}},
author = {Coker, John},
title = {{John Coker's Rocket Pages: Altimeter Comparison}},
year = {2003}
}
@article{zave93,
address = {Los Alamitos, CA, USA},
author = {Zave, Pamela},
doi = {10.1109/2.223539},
issn = {0018-9162},
journal = {Computer},
month = aug,
number = {8},
pages = {20--29},
publisher = {IEEE Computer Society Press},
title = {{Feature Interactions and Formal Specifications in Telecommunications}},
url = {http://dx.doi.org/10.1109/2.223539},
volume = {26},
year = {1993}
}
@inproceedings{harr92,
author = {Harrison, W},
booktitle = {International Workshop on Experiment Software Engineering: Critical Assessment and Future Directions},
editor = {{H. Dieter Rombach V.R. Basili}, R W Selby},
pages = {107--111},
title = {{Towards Well-Defined, Shareable Product Data}},
year = {1992}
}
@misc{Zhou2007,
author = {Zhou, Hongfang and Zhou, Hongfang and Feng, Boqin and Feng, Boqin and Lv, Lintao and Lv, Lintao and Hui, Yue and Hui, Yue},
booktitle = {Information Technology Journal},
doi = {10.3923/itj.2007.255.258},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/zhou07.pdf:pdf},
issn = {18125638},
number = {2},
pages = {255--258},
title = {{A Robust Algorithm for Subspace Clustering of High-Dimensional Data}},
url = {http://www.scialert.net/abstract/?doi=itj.2007.255.258},
volume = {6},
year = {2007}
}
@book{fowler99,
address = {Boston, MA, USA},
author = {Fowler, Martin},
isbn = {0-201-48567-2},
keywords = {evolution refactoring software},
publisher = {Addison-Wesley},
title = {{Refactoring: Improving the Design of Existing Code}},
year = {1999}
}
@inproceedings{CMR92,
author = {Consens, M and Mendelzon, A and Ryman, A},
booktitle = {14th International Conference on Software Engineering (Melbourne)},
pages = {11--15},
title = {{Visualizing and Querying Software Structures}},
year = {1992}
}
@inproceedings{raffo05c,
author = {Raffo, D and Menzies, T},
booktitle = {Proceedings of the 6th International Workshop on Software Process Simulation Modeling (ProSim'05)},
title = {{Evaluating the Impact of a New Technology Using Simulation: The Case for Mining Software Repositories}},
year = {2005}
}
@article{lohse93,
author = {Lohse, G L},
journal = {Human-Computer Interaction},
pages = {353--388},
title = {{A Cognitive Model for Understanding Graphical Perception}},
volume = {8},
year = {1993}
}
@article{me08i,
annote = {Avialable from $\backslash$url\{http://menzies.us/pdf/08promised.pdf\}},
author = {Menzies, Tim},
doi = {10.1007/s10664-008-9087-3},
issn = {13823256},
journal = {Empirical Software Engineering},
month = oct,
number = {5},
pages = {469--471},
title = {{Editorial, special issue, repeatable experiments in software engineering}},
volume = {13},
year = {2008}
}
@article{Zhao2004a,
author = {Zhao, H.},
doi = {10.1109/TKDE.2004.3},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zhao - 2004 - Constrained cascade generalization of decision trees(2).pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = jun,
number = {6},
pages = {727--739},
title = {{Constrained cascade generalization of decision trees}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1294893},
volume = {16},
year = {2004}
}
@misc{me09g,
abstract = {Solutions to non-linear requirements engineering problems may be "brittle"; i.e. small changes may dramatically alter solution effectiveness. Hence, it is not enough to just generate solutions to requirements problems- we must also assess solution robustness. The KEYS2 algorithm can generate decision ordering diagrams. Once generated, these diagrams can assess solution robustness in linear time. In experiments with real-world requirements engineering models, we show that KEYS2 can generate decision ordering diagrams in O(N             2). When assessed in terms of terms of (a) reducing inference times, (b) increasing solution quality, and (c) decreasing the variance of the generated solution, KEYS2 out-performs other search algorithms (simulated annealing, ASTAR, MaxWalkSat).},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09keys2.pdf\}},
author = {Gay, Gregory and Menzies, Tim and Jalali, Omid and Mundy, Gregory and Gilkerson, Beau and Feather, Martin and Kiper, James},
booktitle = {Automated Software Engineering},
doi = {10.1007/s10515-009-0059-7},
isbn = {1051500900597},
issn = {09288910},
number = {1},
pages = {87--116},
title = {{Finding robust solutions in requirements models}},
volume = {17},
year = {2010}
}
@misc{schw02,
author = {Schwaber, Ken},
title = {{No Title}},
year = {2002}
}
@article{cour83,
author = {Courtney, R E and Gustafson, D A},
journal = {Software Engineering Journal},
month = jan,
pages = {5--11},
title = {{Shotgun Correlations in Software Measures}},
year = {1983}
}
@inproceedings{Guo2010,
annote = {Social metrics stuff.},
author = {Guo, PJ and Zimmermann, T and Nagappan, N},
booktitle = {Proceedings of the 32nd International Conference on Software Engineering},
file = {:Users/timm/svns/doc/guo10.pdf:pdf},
pages = {495--504},
title = {{Characterizing and predicting which bugs get fixed: An empirical study of microsoft windows}},
url = {http://portal.acm.org/citation.cfm?id=1806871},
year = {2010}
}
@inproceedings{carew05,
author = {Carew, D and Exton, C and Buckley, J},
booktitle = {Empirical Software Engineering, 2005. 2005 International Symposium on},
doi = {10.1109/ISESE.2005.1541834},
file = {:Users/timm/svns/doc/xplain/05carew.pdf:pdf},
month = nov,
pages = {10 pp.--},
title = {{An empirical investigation of the comprehensibility of requirements specifications}},
year = {2005}
}
@inproceedings{me91b,
author = {Menzies, T J},
booktitle = {IJCAI '91 Knowledge Acquisition Workshop},
title = {{Concerning the User of Procedural Construct as a Knowledge Acquisition Technique}},
year = {1991}
}
@article{hott90,
author = {Horty, J F and Thomson, R H and Touretzky, D S},
journal = {Artificial Intelligence},
number = {1},
pages = {311--348},
title = {{Skeptical \{T\}heory of \{I\}nheritance in \{N\}onmonotonic \{S\}emantic \{N\}etworks}},
volume = {42},
year = {1990}
}
@inproceedings{agrawal94,
author = {Agrawal, R and Srikant, R},
booktitle = {Proceedings of the 20th International Conference on Very Large Databases},
title = {{Fast Algorithms for Mining Association Rules}},
year = {1994}
}
@inproceedings{me02f,
author = {Menzies, Tim and Raffo, David and Setamanit, Siri-on and Hu, Ying and Tootoonian, Sina},
booktitle = {Proceedings of IEEE ASE 2002},
title = {{Model-based Tests of Truisms}},
year = {2002}
}
@article{harman13,
author = {Harman, M and Lakhotia, K and Singer, J and White, D and Yoo, S},
title = {{{Cloud Engineering is Search Based Software Engineering Too\}, journal=}}
}
@article{Dietterich2008a,
author = {Dietterich, Thomas G. and Domingos, Pedro and Getoor, Lise and Muggleton, Stephen and Tadepalli, Prasad},
doi = {10.1007/s10994-008-5079-1},
file = {:Users/timm/svns/doc/mlTheNext10years.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {dietterich,editors,g,hendrik blockeel,inductive logic programming,jude shavlik,learning,p,relational learning,statistical relational,structured machine learning,t,tadepalli},
month = aug,
number = {1},
pages = {3--23},
title = {{Structured machine learning: the next ten years}},
url = {http://www.springerlink.com/index/10.1007/s10994-008-5079-1},
volume = {73},
year = {2008}
}
@inproceedings{me09a,
abstract = {Before performing drastic changes to a project, it is worthwhile to thoroughly explore the available options within the current structure of a project. An alternative to drastic change are internal changes that adjust current options within a software project. In this paper, we show that the effects of numerous internal changes can out-weigh the effects of drastic changes. That is, the benefits of drastic change can often be achieved without disrupting a project. The key to our technique is SEESAW, a novel stochastic stability tool that (a) considers a very large set of minor changes using stochastic sampling; and (b) carefully selects the right combination of effective minor changes. Our results show, using SEESAW, project managers have more project improvement options than they currently realize. This result should be welcome news to managers struggling to maintain control and continuity over their project in the face of multiple demands for drastic change.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08drastic.pdf\}},
author = {Menzies, T. and Williams, S. and El-Rawas, O. and Boehm, B. and Hihn, J.},
booktitle = {2009 IEEE 31st International Conference on Software Engineering},
doi = {10.1109/ICSE.2009.5070552},
isbn = {978-1-4244-3453-4},
issn = {0270-5257},
title = {{How to avoid drastic software process change (using stochastic stability)}},
year = {2009}
}
@article{me97m,
author = {Menzies, T J and Cohen, R F and Waugh, S and Goss, S},
journal = {IEEE Transactions of Data and Knowledge Engineering},
pages = {1362--1375},
title = {{Applications of Abduction: Testing Very Long Qualitative Simulations}},
year = {2003}
}
@article{DH88,
author = {Harel, D},
journal = {Communications of the ACM},
number = {5},
pages = {514--530},
title = {{On visual formalisms}},
volume = {31},
year = {1988}
}
@article{mili95,
author = {{H. Mili F. Mili}, A Mili},
journal = {IEEE Transactions of Software Engineering},
month = jun,
number = {6},
pages = {528--562},
title = {{Reusing Software: Issues and Research Directions}},
volume = {21},
year = {1995}
}
@article{Mendes2007,
address = {Piscataway, NJ, USA},
annote = {Member-Kitchenham, Barbara A.},
author = {Kitchenham, Barbara and Mendes, Emilia and Travassos, Guilherme H},
doi = {http://dx.doi.org/10.1109/TSE.2007.1001},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Kitchenham, Mendes, Travassos - 2007 - Cross versus Within-Company Cost Estimation Studies A Systematic Review.pdf:pdf},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {5},
pages = {316--329},
publisher = {IEEE Press},
title = {{Cross versus Within-Company Cost Estimation Studies: A Systematic Review}},
volume = {33},
year = {2007}
}
@book{milne26,
author = {Milne, A A},
publisher = {Methuen Children's Book},
title = {{Winne-the-Pooh}},
year = {1926}
}
@misc{me95l,
author = {Menzies, Tim},
booktitle = {TR95-40, Software Development, Monash University},
institution = {Department of Software Development, Monash University},
number = {TR95-35},
title = {{Frameworks for assessing visual languages}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.1555\&rep=rep1\&type=pdf},
year = {1995}
}
@article{colomb98,
author = {Colomb, R M},
journal = {Artificial Intelligence},
number = {1-2},
pages = {187--209},
title = {{Representation of Propositional Expert Systems as Partial Functions}},
volume = {109},
year = {1999}
}
@misc{brown09,
annote = {$\backslash$url\{http://www.nasa.gov/mission\_pages/mars/news/msl-20081204.html\}},
author = {Brown, Dwayne},
title = {{Next NASA Mars Mission Rescheduled for 2011}},
year = {2009}
}
@inproceedings{waugh98,
author = {Waugh, S and Blogs, J and Menzies, T},
booktitle = {Proceedings of the Australain AI '98 conference},
title = {{The Temporal Qualitative Compartmental Modeling Language}},
year = {1998}
}
@misc{compton95,
author = {Compton, P and Preston, P and Kang, B},
booktitle = {Proceedings of the Banff KA workshop on Knowledge Acquisition for Knowledge-Based Systems},
title = {{The Use of Simulated Experts in Evaluating Knowledge Acquisition}},
year = {1995}
}
@article{Menzies2010,
author = {Menzies, Oussama El-rawas Tim},
doi = {10.1007/s11334-010-0137-9},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Menzies - 2010 - A second look at Faster , Better , Cheaper.pdf:pdf},
journal = {Star},
keywords = {cocomo,faster better cheaper,predictor models,simulated annealing,software engineering},
title = {{A second look at Faster , Better , Cheaper}},
year = {2010}
}
@article{Reidys2002,
abstract = {Fitness landscapes have proven to be a valuable concept in evolutionary biology, combinatorial optimization, and the physics of disordered systems. A fitness landscape is a mapping from a configuration space into the real numbers. The configuration space is equipped with some notion of adjacency, nearness, distance or accessibility. Landscape theory has emerged as an attempt to devise suitable mathematical structures for describing the âstaticâ properties of landscapes as well as their influence on the dynamics of adaptation. In this review we focus on the connections of landscape theory with algebraic combinatorics and random graph theory, where exact results are available.},
author = {Reidys, Christian M. and Stadler, Peter F.},
doi = {10.1137/S0036144501395952},
file = {:Users/timm/svns/doc/erin/references/AlgsForDNA/CombinatorialLandscapesReidys.pdf:pdf},
isbn = {0036-1445},
issn = {0036-1445},
journal = {SIAM Review},
keywords = {05c90,1,15-02,ams subject classifications,coherent algebras,combinatorial optimization,correlation functions,fitness landscape,fitness landscape originated in,genotype phenotype map,introduction,neutrality,random graphs,sequential dynamical systems,the 1930s in,the concept of a},
number = {1},
pages = {3--54},
pmid = {1054},
title = {{Combinatorial Landscapes}},
volume = {44},
year = {2002}
}
@article{SURE83,
author = {Supowit, K J and Reingold, E M},
journal = {Acta Informatica},
pages = {377--392},
title = {{The Complexity of Drawing Trees Nicely}},
volume = {18},
year = {1983}
}
@article{me11p,
author = {Menzies, Tim and Brady, Adam and Kocaguneli, Ekrem},
journal = {Software Quality Professional},
number = {4},
title = {{What is 'Enough' Quality for Data Repositories?}},
volume = {13},
year = {2011}
}
@misc{Coiera96,
annote = {Technical Report HPL-96-65, May, 1996},
author = {Coiera, E},
institution = {Hewlett-Packard Laboratories},
title = {{Communication in Organisations}},
year = {1996}
}
@article{Rashedi2009,
abstract = {In recent years, various heuristic optimization methods have been developed. Many of these methods are inspired by swarm behaviors in nature. In this paper, a new optimization algorithm based on the law of gravity and mass interactions is introduced. In the proposed algorithm, the searcher agents are a collection of masses which interact with each other based on the Newtonian gravity and the laws of motion. The proposed method has been compared with some well-known heuristic search methods. The obtained results confirm the high performance of the proposed method in solving various nonlinear functions. ?? 2009 Elsevier Inc. All rights reserved.},
author = {Rashedi, Esmat and Nezamabadi-pour, Hossein and Saryazdi, Saeid},
doi = {10.1016/j.ins.2009.03.004},
file = {:Users/timm/svns/doc/pso/00psoVSgsaCluster.pdf:pdf},
isbn = {0020-0255},
issn = {00200255},
journal = {Information Sciences},
keywords = {Gravitational Search Algorithm,Heuristic search algorithms,Law of gravity,Optimization},
number = {13},
pages = {2232--2248},
publisher = {Elsevier Inc.},
title = {{GSA: A Gravitational Search Algorithm}},
url = {http://dx.doi.org/10.1016/j.ins.2009.03.004},
volume = {179},
year = {2009}
}
@article{reiter80,
author = {Reiter, R},
journal = {Artificial Intelligence},
pages = {81--132},
title = {{A \{L\}ogic for \{D\}efault \{R\}easoning}},
volume = {13},
year = {1980}
}
@inproceedings{jeff88,
author = {Jeffery, D R and Basili, V R},
booktitle = {Proceedings of the 10th International Conference on Software Engineering},
pages = {187--201},
title = {{Validating the TAME Resource Data Model}},
year = {1988}
}
@inproceedings{clarkelong89,
author = {Clark, E and Long, D E},
booktitle = {Fourth Annual Symposium on Logic in Computer Science},
title = {{Compositional Model Checking}},
year = {1989}
}
@inproceedings{fen97,
author = {Fensel, D and Schoenegge, A},
booktitle = {Workshop on Problem-Solving Methods for Knowledge-based Systems, IJCAI '97, August 23.},
title = {{Hunting for Assumptions as Developing Method for Problem-Solving Methods}},
year = {1997}
}
@inproceedings{mus93,
author = {Musen, M A and Tu, S W},
booktitle = {Knowledge-Oriented Software Design},
editor = {Cuena, J},
publisher = {Elsevier, Amsterdam},
title = {{Probelm-Solving Models for Generation of Task-Specific Knowledge Acquisition Tools}},
year = {1993}
}
@misc{clancey96,
annote = {Personal communcaition},
author = {Clancey, W},
title = {{No Title}},
year = {1996}
}
@book{Arbenz2011,
author = {Arbenz, Markus},
file = {:Users/timm/svns/doc/12MachineLearningIAction.pdf:pdf},
isbn = {9781933988771},
number = {November 2010},
title = {{In Action}},
year = {2011}
}
@inproceedings{bin07,
author = {Bin, L and Zhi-Shu, L and Yan-Hong, C and Bao-Lin, L},
booktitle = {Workshop of Computational Intelligence and Security Workshops, 2007, CISW 2007},
pages = {183--186},
title = {{Automatic Test Data Generation Tool Based on Genetic Simulated Annealing Algorithm}},
year = {2007}
}
@article{Data2010,
author = {Data, Sharing Sensitive},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Data - 2010 - Preserving Privacy Based on Semantic Policy Tools.pdf:pdf},
journal = {Architecture},
number = {August},
pages = {25--30},
title = {{Preserving Privacy Based on Semantic Policy Tools}},
year = {2010}
}
@inproceedings{fecosm89a,
author = {Feldman, B and Compton, P and Smythe, G},
booktitle = {4th \{AAAI\}-Sponsored Knowledge Acquisition for Knowledge-based Systems Workshop \{B\}anff, \{C\}anada},
title = {{Hypothesis \{T\}esting: an \{A\}ppropriate \{T\}ask for \{K\}nowledge-\{B\}ased \{S\}ystems}},
year = {1989}
}
@article{sullivan03,
author = {(ed), Kevin Sullivan},
title = {{Preliminary Report, NSF Workshop on the Science of Design: Software and Software-Intensive Systems}},
year = {2003}
}
@article{dieng95,
author = {Dieng, R and Corby, O and Lapalut, S},
journal = {International Journal of Human-Computer Studies},
pages = {465--499},
title = {{Acquisition and Exploitation of Gradual Knowledge}},
volume = {42},
year = {1995}
}
@inproceedings{me02g,
author = {Menzies, Tim and Lutz, Robyn},
booktitle = {Seke03},
keywords = {anomaly,artificial intelligence,association,debugging,dent,learning,metrics,nasa mis-,reports on deep space,rule learning,software engineering,surprise,testing and,treatment learning},
pages = {0--5},
title = {{Better analysis of defect data at NASA}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.197.5917\&amp;rep=rep1\&amp;type=pdf},
year = {2003}
}
@article{turhan13,
author = {Turhan, Burak and MÄ±sÄ±rlÄ±, AyÅe Tosun and Bener, AyÅe},
file = {:Users/timm/svns/doc/13turhanMixed.pdf:pdf},
journal = {Information and Software Technology},
pages = {1101--1118},
title = {{Empirical evaluation of the effects of mixed project data on learning defect predictors}},
volume = {55},
year = {2013}
}
@article{console91a,
author = {Console, L and Dupre, D T and Torasso, P},
journal = {Journal of Logic Programming},
pages = {661--690},
title = {{On the Relationship Between Abduction and Deduction}},
volume = {1},
year = {1991}
}
@article{Vaidya2008,
author = {Vaidya, Jaideep and Clifton, Chris and Kantarcioglu, Murat and Patterson, a. Scott},
doi = {10.1145/1409620.1409624},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Vaidya, Clifton - Unknown - Privacy-Preserving Decision Trees over Vertically Partitioned Data.pdf:pdf},
issn = {15564681},
journal = {ACM Transactions on Knowledge Discovery from Data},
month = oct,
number = {3},
pages = {1--27},
title = {{Privacy-preserving decision trees over vertically partitioned data}},
url = {http://portal.acm.org/citation.cfm?doid=1409620.1409624},
volume = {2},
year = {2008}
}
@incollection{me10b,
author = {Menzies, Tim and Shull, Forrest},
booktitle = {Making Software: What Really Works and We We Believe it},
editor = {Oram, A and G.Wilson},
publisher = {O'Reilly Books},
title = {{The Quest for Convincing Evidence}},
year = {2010}
}
@inproceedings{poole90,
author = {Poole, D},
booktitle = {Working Notes of the 1990 Spring Symposium on Automated Abduction.},
editor = {O'Rourke, P},
organization = {UC Irvine},
pages = {106--110},
title = {{Hypo-\{D\}eductive \{R\}easoning for \{A\}bduction, \{D\}efault \{R\}easoning, and \{D\}esign}},
volume = {TR 90-32},
year = {1990}
}
@inproceedings{mizuno00,
author = {Mizuno, O and Kikuno, T and Takagi, Y and Sakamoto, K},
booktitle = {ICSE 2000},
title = {{Characterization of risky projects based on project managers evaluation}},
year = {2000}
}
@incollection{mockus08,
author = {Mockus, Audris},
booktitle = {Guide to Advanced Empirical Software Engineering},
editor = {Shull, Forrest and Singer, Janice and Sj\o berg, DagI.K.},
pages = {185--200},
publisher = {Springer London},
title = {{Missing Data in Software Engineering}},
year = {2008}
}
@article{Freund2007,
author = {Freund, Y. and Dasgupta, S. and Kabra, M. and Verma, N.},
file = {:Users/timm/svns/doc/07rptrees.pdf:pdf},
journal = {Neural Information Processing Systems},
pages = {1--8},
title = {{Learning the structure of manifolds using random projections}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Learning+the+structure+of+manifolds+using+random+projections\#0},
year = {2007}
}
@incollection{buch83,
author = {Buchanan, B and Barstow, D and Bechtel, R and Bennet, J and Clancey, W and Kulikowski, C and Mitchell, T M and Waterman, D A},
chapter = {Constructi},
pages = {127--168},
publisher = {Addison-Wesley},
title = {{Building Expert Systems, F. Hayes-Roth and D. Waterman and D. Lenat (eds)}},
year = {1983}
}
@article{vandebrug86,
author = {de Brug, A Van and Bachant, J and McDermott, J},
journal = {IEEE Expert},
pages = {33--39},
title = {{The \{T\}aming of \{R1\}}},
year = {1986}
}
@book{hof81,
author = {Hofstader, D R and Dennett, D C},
title = {{The Mind's I}},
year = {1981}
}
@article{Gayler2006,
archivePrefix = {arXiv},
arxivId = {arXiv:math/0606452v1},
author = {Gayler, Ross W.},
doi = {10.1214/088342306000000051},
eprint = {0606452v1},
file = {:Users/timm/svns/doc/gaylor06.pdf:pdf},
issn = {0883-4237},
journal = {Statistical Science},
month = feb,
number = {1},
pages = {19--23},
primaryClass = {arXiv:math},
title = {{Comment: Classifier Technology and the Illusion of ProgressâCredit Scoring}},
url = {http://projecteuclid.org/Dienst/getRecord?id=euclid.ss/1149600841/},
volume = {21},
year = {2006}
}
@inproceedings{mul93,
author = {Mulholland, M and Preston, P and Hibbert, B and Compton, P},
booktitle = {Proceedings of the Sixth International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems, Edinburgh},
title = {{An expert system for ion chromatography developed using machine learning and knowledge in context}},
year = {1996}
}
@inproceedings{hame94,
author = {Haynes, P and Menzies, T J},
booktitle = {Tools '94},
pages = {121--129},
publisher = {Prentice Hall},
title = {{The \{E\}ffects of \{C\}lass \{C\}oupling on \{C\}lass \{S\}ize in \{S\}malltalk \{S\}ystems}},
year = {1994}
}
@misc{fowl02,
author = {Fowler, Martin},
title = {{The New Methodology}},
year = {2002}
}
@incollection{me95g,
author = {Menzies, T J},
booktitle = {Proceedings of the Melbourne Workshop on Intelligent Decision Support},
publisher = {Department of Information Systems, Monash University, Melbourne},
title = {{Applications of Abduction: Intelligent Decision Support Systems}},
year = {1996}
}
@inproceedings{alvarez-data,
author = {Alvarez, J L and Mata, J and Riquelme, Jose C and Ramos, I},
booktitle = {ICEIS'2003: Fifth International Conference on Enterprise Information Systems},
title = {{A Data Mining Method to Support Decision Making in Software Development Projects}},
url = {citeseer.ist.psu.edu/alvarez03data.html},
year = {2003}
}
@inproceedings{zannier06,
author = {{C. Zannier G. Melnik} and Maurer, F},
booktitle = {ICSE'06},
title = {{On the Success of Empirical Studies in the International Conference on Software Engineering}},
year = {2006}
}
@article{Kitchenham2009c,
author = {Kitchenham, B and Pearlbrereton, O and Budgen, D and Turner, M and Bailey, J and Linkman, S},
doi = {10.1016/j.infsof.2008.09.009},
file = {:Users/timm/svns/doc/Kitchenham\_2009.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {evidence-based software engineering,systematic literature review},
month = jan,
number = {1},
pages = {7--15},
title = {{Systematic literature reviews in software engineering â A systematic literature review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950584908001390},
volume = {51},
year = {2009}
}
@inproceedings{me95zb,
author = {Menzies, T J and Compton, P},
booktitle = {Proceedings of the 9th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge Based Systems,},
title = {{The (Extensive) Implications of Evaluation on the Development of Knowledge-Based Systems}},
year = {1995}
}
@misc{smythe92,
annote = {Personal communication},
author = {Smythe, G A},
title = {{Concerning errors in the Smythe '87 model.}},
year = {1992}
}
@inproceedings{basili94,
author = {Basili, V R and Caldiera, G and Rombach, H D},
booktitle = {Encyclopedia of Software Engineering, volume 1},
editor = {Marciniak, J J},
pages = {469Â476},
publisher = {John Wiley \& Sons},
title = {{Experience Factory}},
year = {1994}
}
@article{jorg04,
author = {J\o rgensen, M},
journal = {Journal of Systems and Software},
number = {1-2},
pages = {37--60},
title = {{A Review of Studies on Expert Estimation of Software Development Effort}},
volume = {70},
year = {2004}
}
@article{Krink2005,
abstract = {In recent years, many partitional clustering algorithms based on genetic algorithms (GA) have been proposed to tackle the problem of finding the optimal partition of a data set. Surprisingly, very few studies considered alternative stochastic search heuristics other than GAs or simulated annealing. Two promising algorithms for numerical optimization, which are hardly known outside the heuristic search field, are particle swarm optimisation (PSO) and differential evolution (DE). In this study, we compared the performance of GAs with PSO and DE for a medoid evolution approach to clustering. Moreover, we compared these results with the nominal classification, k-means and random search (RS) as a lower bound. Our results show that DE is clearly and consistently superior compared to GAs and PSO for hard clustering problems, both in respect to precision as well as robustness (reproducibility) of the results. Only for trivial problems all algorithms can obtain comparable results. Apart from superior performance, DE is very easy to implement and requires hardly any parameter tuning compared to substantial tuning for GAs and PSOs. Our study shows that DE rather than GAs should receive primary attention in partitional cluster algorithms.},
author = {Krink, Thiermo},
file = {:Users/timm/svns/doc/pso/06psoVSdeClustering.pdf:pdf},
pages = {1--27},
title = {{Differential Evolution and Particle Swarm Optimization in Partitional Clustering}},
url = {http://videolectures.net/solomon\_krink\_depso/},
year = {2005}
}
@inproceedings{TOSUN2008,
address = {New York, NY, USA},
author = {Tosun, Ayse and Turhan, Burak and Bener, Ayse},
booktitle = {ESEM '08: Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
doi = {http://doi.acm.org/10.1145/1414004.1414066},
isbn = {978-1-59593-971-5},
pages = {318--320},
publisher = {ACM},
title = {{Ensemble of software defect predictors: a case study}},
year = {2008}
}
@article{birnbaum91,
author = {Birnbaum, L},
journal = {Artificial Intelligence},
pages = {57--77},
title = {{Rigor \{M\}ortis: A \{R\}esponse to \{N\}ilsson's '\{L\}ogic and \{A\}rtificial \{I\}ntelligence'}},
volume = {47},
year = {1991}
}
@article{shepperd97,
annote = {Available from $\backslash$url\{http://www.utdallas.edu/\~{}rbanker/SE\_XII.pdf\}},
author = {Shepperd, M and Schofield, C},
journal = {IEEE Transactions on Software Engineering},
month = nov,
number = {12},
title = {{Estimating Software Project Effort Using Analogies}},
volume = {23},
year = {1997}
}
@article{Merugu2003,
author = {Merugu, Srujana and Ghosh, Joydeep},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Merugu, Ghosh - 2003 - Privacy-preserving Distributed Clustering using Generative Models.pdf:pdf},
pages = {0--7},
title = {{Privacy-preserving Distributed Clustering using Generative Models}},
year = {2003}
}
@inproceedings{basili92,
annote = {LNCS 706, Springer-Verlag},
author = {Basili, V R},
booktitle = {Experimental Software Engineering Issues: Critical Assessment and Future Directions, International Workshop, Germany},
editor = {Rombach, H D and Basili, V R and Selby, R W},
pages = {3--12},
title = {{The Experimental Paradigm in Software Engineering}},
year = {1992}
}
@article{stark93,
author = {Stark, M},
journal = {J. Systems Software},
pages = {163--169},
title = {{Impacts of \{O\}bject-\{O\}riented \{T\}echnologies: Seven Years of \{S\}oftware \{E\}ngineering}},
volume = {23},
year = {1993}
}
@inproceedings{me11e,
abstract = {The practices of industrial and academic data mining are very different. These differences have significant implications for (a) how we manage industrial data mining projects; (b) the direction of academic studies in data mining; and (c) training programs for engineers who seek to use data miners in an industrial setting.},
address = {New York, NY, USA},
author = {Menzies, Tim and Bird, Christian and Zimmermann, Thomas and Schulte, Wolfram and Kocaganeli, Ekrem},
booktitle = {Proceedings of the International Workshop on Machine Learning Technologies in Software Engineering SE - MALETS '11},
doi = {10.1145/2070821.2070824},
isbn = {978-1-4503-1022-2},
keywords = {inductive engineering,industry},
pages = {19--26},
publisher = {ACM},
series = {MALETS '11},
title = {{The inductive software engineering manifesto: principles for industrial data mining}},
url = {citeulike-article-id:10194816$\backslash$nhttp://dx.doi.org/10.1145/2070821.2070824$\backslash$nhttp://portal.acm.org/citation.cfm?id=2070824},
year = {2011}
}
@inproceedings{curtis00,
author = {Curtis, S A and Mica, J and Nuth, J and Marr, G and Rilee, M and Bhat, M},
booktitle = {International Astronautical Federation, 51st Congress},
month = oct,
title = {{ANTS (Autonomous Nano-Technology Swarm): An Artificial Intelligence Approach to Asteroid Belt Resource Exploration}},
year = {2000}
}
@article{Berezovski2006,
abstract = {Aptamers are typically selected from libraries of random DNA (or RNA) sequences through systematic evolution of ligands by exponential enrichment (SELEX), which involves several rounds of alternating steps of partitioning of candidate oligonucleotides and their PCR amplification. Here we describe a protocol for non-SELEX selection of aptamers--a process that involves repetitive steps of partitioning with no amplification between them. Non-equilibrium capillary electrophoresis of equilibrium mixtures (NECEEM), which is a highly efficient affinity method, is used for partitioning. NECEEM also facilitates monitoring of bulk affinity of enriched libraries at every step of partitioning and screening of individual clones for their affinity to the target. NECEEM allows all clones to be screened prior to sequencing, so that only clones with suitable binding parameters are sequenced. The entire protocol can be completed in 1 wk, whereas conventional SELEX protocols take several weeks even in a specialized industrial facility.},
author = {Berezovski, Maxim and Musheev, Michael and Drabovich, Andrei and Krylov, Sergey N.},
doi = {10.1021/ja056943j},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Berezovski05.pdf:pdf},
isbn = {1750-2799 (Electronic)},
issn = {00027863},
journal = {Journal of the American Chemical Society},
number = {5},
pages = {1410--1411},
pmid = {17406423},
title = {{Non-SELEX selection of aptamers}},
volume = {128},
year = {2006}
}
@inproceedings{me91c,
author = {Menzies, T J},
booktitle = {Tools 3: Proceedings of the third International Technology of Object-Oriented Languages and; Systems conference},
publisher = {Prentice-Hall},
title = {{Beyond the MVC Triad: Quality Assurance via Interactive Specification Editors}},
year = {1991}
}
@book{leven95,
author = {Leveson, N},
publisher = {Addison-Wesley},
title = {{Safeware System Safety And Computers}},
year = {1995}
}
@article{selby88,
author = {Selby, R W and Porter, A A},
journal = {IEEE Trans. Software Eng.},
month = dec,
pages = {1,741--743,757},
title = {{Learning from Examples: Generation and Evalaution of Decision Trees for Software Resource Analysis}},
year = {1988}
}
@book{deb98e,
author = {Debenham, J},
publisher = {Springer-Verlag},
title = {{Knowledge Engineering: Unifying Knowledge Base and Database Design}},
year = {1998}
}
@article{me97j,
author = {Menzies, T J},
journal = {Software Practice and Experience},
month = dec,
number = {12},
pages = {1457--1478},
title = {{\{O\}\{O\} Patterns: Lessons from Expert Systems}},
volume = {27},
year = {1997}
}
@article{me03f,
author = {Menzies, T},
journal = {Requirements Engineering},
title = {{Editorial, Requirements Engineering Journal, Special Issue on Model-based Requirements Engineering}},
year = {2003}
}
@article{lessmann09,
author = {Lessmann, S and Baesens, B and Mues, C and Pietsch, S},
journal = {IEEE Transactions on Software Engineering},
title = {{Benchmarking classification models for software defect prediction: A proposed framework and novel findings}},
year = {2008}
}
@misc{spear00,
annote = {www.nasawatch.com/congress/2000/03.22.00.spear.pdf},
author = {Spear, Tony},
month = mar,
title = {{Testimony on NASA FBC Task before the Subcommittee on Science, Technology, and Space}},
year = {2000}
}
@inproceedings{ambler87,
author = {Ambler, A L},
booktitle = {Proceedings Workshop on Visual Languages, Tryck-Center, Linkoping, Sweden},
pages = {105--117},
title = {{Forms: Expanding the Visualness of Sheet Languages}},
year = {1987}
}
@inproceedings{mkaouer14,
address = {New York, NY, USA},
author = {Mkaouer, Mohamed Wiem and Kessentini, Marouane and Bechikh, Slim and Deb, Kalyanmoy and {\'{O} Cinn\'{e}ide}, Mel},
booktitle = {Proceedings of the 2014 Conference on Genetic and Evolutionary Computation},
doi = {10.1145/2576768.2598366},
isbn = {978-1-4503-2662-9},
keywords = {code-smells,refactroing,search-based software engineering},
pages = {1263--1270},
publisher = {ACM},
series = {GECCO '14},
title = {{High Dimensional Search-based Software Engineering: Finding Tradeoffs Among 15 Objectives for Automating Software Refactoring Using NSGA-III}},
url = {http://doi.acm.org/10.1145/2576768.2598366},
year = {2014}
}
@inproceedings{CHEN2005,
address = {New York, NY, USA},
author = {Chen, Zhihao and Menzies, Tim and Port, Dan and Boehm, Barry},
booktitle = {ACM SIGSOFT Software Engineering Notes},
doi = {10.1145/1082983.1083171},
isbn = {-159593-125-2},
issn = {01635948},
number = {4},
pages = {1},
publisher = {ACM},
title = {{Feature subset selection can improve software cost estimation accuracy}},
volume = {30},
year = {2005}
}
@article{Lu2006a,
author = {Lu, Jingli and Yang, Ying and Webb, G.},
file = {:Users/timm/svns/doc/webb08.pdf:pdf},
journal = {Advanced Data Mining and Applications},
pages = {223--238},
publisher = {Springer},
title = {{Incremental discretization for naive-bayes classifier}},
url = {http://www.springerlink.com/index/e3471527150p1n66.pdf},
year = {2006}
}
@inproceedings{levy96,
author = {Levy, A Y and Rousset, M},
booktitle = {AAAI '96},
title = {{Verification of knowledge bases using containnment checking}},
year = {1996}
}
@article{reel99,
author = {Reel, J S},
journal = {IEEE Computer},
pages = {18--23},
title = {{Critical Success Factors in Software Projects}},
year = {1999}
}
@article{albrecht83,
author = {Albrecht, A J and Gaffney, J E},
file = {:Users/timm/svns/doc/83albrecht.pdf:pdf},
journal = {IEEE Trans. Softw. Eng.},
month = nov,
number = {6},
pages = {639--648},
title = {{Software Function, Source Lines of Code, and Development Effort Prediction: A Software Science Validation}},
volume = {9},
year = {1983}
}
@inproceedings{raffo99a,
author = {Raffo, D and Kellner, M},
booktitle = {Elements of Software Process Assessment and Improvement},
editor = {Emam, K El and Madhavji, N},
publisher = {IEEE Computer Society},
title = {{Impact of Potential Process Changes: A Quantitative Approach to Process Modeling}},
year = {199}
}
@inproceedings{me97d,
author = {Postema, M and Menzies, T J and Wu, X},
booktitle = {The Joint Pacific Asia Conference on Expert Systems/Singapore International Conference on Intelligent Systems. (PACES/SPICIS '97)},
title = {{A Decision Support Tool for Tuning Parameters in a Machine Leraning Algorithm}},
year = {1997}
}
@inproceedings{ram94,
author = {Ramakrishnan, S},
booktitle = {Proceedings of the \{F\}irst \{I\}nternational \{C\}onference on \{S\}oftware \{T\}esting, \{R\}eliability and \{Q\}uality \{A\}ssurance (STRQA 1994)},
title = {{Quality \{F\}actors for \{R\}esource \{A\}llocations \{P\}roblems - \{L\}inking \{D\}omain \{A\}nalysis and \{O\}bject-\{O\}riented \{S\}oftware \{E\}ngineering}},
year = {1994}
}
@inproceedings{sayyad13d,
author = {Sayyad, A and Ammar, H},
booktitle = {International Workshop on Realizing Synergies between Artificial Intelligence and Software Engineering (RAISEâ13)},
title = {{Pareto-Optimal Search-Based Software Engineering: A Literature Survey}},
year = {2013}
}
@article{dekleer87,
author = {DeKleer, J and Williams, B C},
journal = {Artificial Intelligence},
pages = {97--130},
title = {{Diagnosing \{M\}ultiple \{F\}aults}},
volume = {32},
year = {1987}
}
@article{rich07,
author = {Richardson, I and Wangenheim, C},
journal = {IEEE Software},
title = {{Guest Editors' Introduction: Why are Small Software Organizations Different?}},
year = {2007}
}
@article{Kiernana,
author = {Kiernan, Jerry and Road, Harry and Jose, San},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Kiernan, Road, Jose - Unknown - Implementing P3P Using Database Technology.pdf:pdf},
journal = {Population (English Edition)},
pages = {1--12},
title = {{Implementing P3P Using Database Technology}}
}
@article{cohen98,
author = {Cohen, Paul and Schrag, Robert and Jones, Eric and Pease, Adam and Lin, Albert and Starr, Barbara and Gunning, David and Burke, Murray},
journal = {AI Magazine},
number = {4},
pages = {25--49},
title = {{The DARPA High-Performance Knowledge Bases Project}},
volume = {19},
year = {1998}
}
@inproceedings{posnet11,
author = {Posnett, D and Filkov, V and Devanbu, P},
booktitle = {Proceedings of ASE'11},
title = {{Ecological Inference in Empirical Software Engineering}},
year = {2011}
}
@article{Lecture2010,
author = {Lecture, Stochastics and Prof, Notes and Schmidt, Volker},
file = {:Users/timm/svns/doc/12markovChainsMonteCarlo.pdf:pdf},
number = {July},
title = {{Markov Chains and Monte â Carlo Simulation}},
year = {2010}
}
@inproceedings{grove95,
author = {Grove, D and Dean, J and Garnett, C and Chambers, C},
booktitle = {OOPSLA '95},
pages = {108--123},
title = {{Profile Guided Reciever Class Prediction}},
year = {1995}
}
@inproceedings{BRAGA08,
address = {New York, NY, USA},
author = {Braga, Petr\^{o}nio L and Oliveira, Adriano L I and Meira, Silvio R L},
booktitle = {SAC '08: Proceedings of the 2008 ACM symposium on Applied computing},
doi = {http://doi.acm.org/10.1145/1363686.1364116},
isbn = {978-1-59593-753-7},
pages = {1788--1792},
publisher = {ACM},
title = {{A GA-based feature selection and parameters optimization for support vector regression applied to software effort estimation}},
year = {2008}
}
@article{davis93,
author = {Davis, R and Shrobe, H and Szolovits, P},
journal = {\{AI\} Magazine},
pages = {17--33},
title = {{What is a \{K\}nowledge \{R\}epresentation?}},
year = {1993}
}
@article{saud89,
author = {Sanderson, P M and Verhapge, A G and Fuld, R B},
journal = {Ergonomics},
number = {11},
pages = {1343--1372},
title = {{State-space and Verbal Protocol Methods for Studying the Human Operator in Process Control}},
volume = {32},
year = {1989}
}
@inproceedings{me04a,
author = {Menzies, T and Setamanit, S and Raffo, D},
booktitle = {Prosim 2004},
title = {{Data Mining from Process Models}},
year = {2004}
}
@book{Walden1995,
annote = {unread},
author = {Walden, K and Nerson, J-M},
publisher = {Prentice-Hall, Englewood Cliffs, New Jersey},
title = {{Seamless Object-Oriented Software Architecture}},
year = {1995}
}
@inproceedings{brady10b,
author = {Brady, Adam and Menzies, Tim},
booktitle = {PROMISE'10},
title = {{Case-Based Reasoning vs Parametric Models for Software Quality optimization}},
year = {2010}
}
@article{mack92,
author = {Mackworth, A},
journal = {Artificial Intelligence},
pages = {3--20},
title = {{The Logic of Constraint Satisfaction}},
volume = {58},
year = {1992}
}
@article{pargas99,
author = {Pargas, R P and Harrold, M J and Peck, R R},
journal = {ï¿½Journal of Software Testing, Verification and Reliabilityï¿½},
pages = {263--282},
title = {{Test-data generation using genetic algorithms}},
volume = {9},
year = {1999}
}
@book{winston84,
author = {Winston, P},
publisher = {Addison-Wesley},
title = {{Artificial Intelligence}},
year = {1984}
}
@inproceedings{me02c,
author = {Menzies, T and Chiang, E and Feather, M and Hu, Y and Kiper, J D},
booktitle = {Software Engineering with Computational Intelligence},
editor = {Khoshgoftaar, Taghi M},
isbn = {1-4020-7427-1},
publisher = {Kluwer},
title = {{Condensing uncertainty via Incremental Treatment Learning}},
year = {2003}
}
@inproceedings{falk90,
author = {Falkenhainer, B},
booktitle = {Working Notes of the 1990 Spring Symposium on Automated Abduction},
editor = {O'Rourke, P},
pages = {135--139},
title = {{Abduction as \{S\}imilarity-\{D\}riven \{E\}xplanation}},
year = {1990}
}
@inproceedings{cooper01,
author = {{Kendra Cooper Tim Menzies}, Mabo Ito},
booktitle = {UBC ECE tech report},
title = {{Assessment of a Lightweight Formal Method for Specifying and Analyzing Requirements}},
year = {2001}
}
@book{silver12,
author = {Silver, Nate},
publisher = {Penguin},
title = {{The Signal and the Noise: Why Most Predictions Fail â But Some Don't.}},
year = {2012}
}
@article{Noman2008,
author = {Noman, Nasimul and Iba, Hitoshi},
file = {:Users/timm/svns/doc/08-de-localSearch.pdf:pdf},
number = {1},
pages = {107--125},
title = {{Using an Adaptive Local Search}},
volume = {12},
year = {2008}
}
@article{feather08,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ddp.pdf\}},
author = {Feather, M and Cornford, S and Hicks, K and Kiper, J and Menzies, T},
journal = {IEEE Software},
title = {{Application of a broad-spectrum quantitative requirements model to early-lifecycle decision making}},
year = {2008}
}
@article{mintz75,
author = {Mintzberg, H},
journal = {Harvard Business Review},
pages = {29--61},
title = {{The \{M\}anager's \{J\}ob: \{F\}olklore and \{F\}act}},
year = {1975}
}
@article{ruhe09,
author = {Ngo-The, An and Ruhe, G},
journal = {Software Engineering, IEEE Transactions on},
number = {1},
pages = {109--123},
title = {{Optimized Resource Allocation for Software Release Planning}},
volume = {35},
year = {2009}
}
@misc{me97i,
author = {Menzies, T},
howpublished = {Asian-Pacific Workshop on Intelligent Software Engineering},
title = {{Applications of Abduction: A Unified Framework for Software and Knowledge Engineering}},
year = {1998}
}
@article{lee98,
author = {Lee, J and Gruninger, M and Jin, Y and Malone, T and Tate, A and Yost, G and other members of the PIF working group},
journal = {Knowledge Engineering Review},
month = feb,
number = {1},
pages = {91--120},
title = {{The PIF Process Interchange Format and framework}},
volume = {13},
year = {1998}
}
@article{Schutze2011,
abstract = {BACKGROUND: SELEX is an iterative process in which highly diverse synthetic nucleic acid libraries are selected over many rounds to finally identify aptamers with desired properties. However, little is understood as how binders are enriched during the selection course. Next-generation sequencing offers the opportunity to open the black box and observe a large part of the population dynamics during the selection process.$\backslash$n$\backslash$nMETHODOLOGY: We have performed a semi-automated SELEX procedure on the model target streptavidin starting with a synthetic DNA oligonucleotide library and compared results obtained by the conventional analysis via cloning and Sanger sequencing with next-generation sequencing. In order to follow the population dynamics during the selection, pools from all selection rounds were barcoded and sequenced in parallel.$\backslash$n$\backslash$nCONCLUSIONS: High affinity aptamers can be readily identified simply by copy number enrichment in the first selection rounds. Based on our results, we suggest a new selection scheme that avoids a high number of iterative selection rounds while reducing time, PCR bias, and artifacts.},
author = {Sch\"{u}tze, Tatjana and Wilhelm, Barbara and Greiner, Nicole and Braun, Hannsj\"{o}rg and Peter, Franziska and M\"{o}rl, Mario and Erdmann, Volker a. and Lehrach, Hans and Konthur, Zolt\'{a}n and Menger, Marcus and Arndt, Peter F. and Gl\"{o}kler, J\"{o}rn},
doi = {10.1371/journal.pone.0029604},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Schutze11.pdf:pdf},
isbn = {1932-6203 (Electronic)$\backslash$n1932-6203 (Linking)},
issn = {19326203},
journal = {PLoS ONE},
number = {12},
pages = {1--11},
pmid = {22242135},
title = {{Probing the SELEX process with next-generation sequencing}},
volume = {6},
year = {2011}
}
@article{DeMil78,
author = {DeMillo, R and Lipton, R and Sayad, F},
journal = {IEEE Computer},
month = apr,
number = {4},
pages = {34--41},
title = {{Hints on Test Data Selection: Help for the Practising Programmer}},
volume = {11},
year = {1987}
}
@article{pasquini96,
author = {Pasquini, A and A, N Crespo and Matrella, P},
journal = {IEEE Transactions on Reliability},
number = {4},
pages = {531--540},
title = {{Sensitivity of Reliability-Growth Models to Pperational Profile Errors vs Testing Accuracy}},
volume = {45},
year = {1996}
}
@article{Speil2002,
author = {Speil, Christopher},
file = {:Users/timm/svns/doc/texinfo.pdf:pdf},
journal = {Linux Gazette},
title = {{Writing Documentation , Part IV : Texinfo}},
year = {2002}
}
@article{Arif2009a,
abstract = {Current systems for similarity-based virtual screening use similarity measures in which all the fragments in a fingerprint contribute equally to the calculation of structural similarity. This paper discusses the weighting of fragments on the basis of their frequencies of occurrence in molecules. Extensive experiments with sets of active molecules from the MDL Drug Data Report and the World of Molecular Bioactivity databases, using fingerprints encoding Tripos holograms, Pipeline Pilot ECFC\_4 circular substructures and Sunset Molecular keys, demonstrate clearly that frequency-based screening is generally more effective than conventional, unweighted screening. The results suggest that standardising the raw occurrence frequencies by taking the square root of the frequencies will maximise the effectiveness of virtual screening. An upper-bound analysis shows the complex interactions that can take place between representations, weighting schemes and similarity coefficients when similarity measures are computed, and provides a rationalisation of the relative performance of the various weighting schemes.},
author = {Arif, Shereena M. and Holliday, John D. and Willett, Peter},
doi = {10.1007/s10822-009-9285-0},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Arif2009.pdf:pdf},
issn = {0920654X},
journal = {Journal of Computer-Aided Molecular Design},
keywords = {Fingerprint,Fragment occurrences,Ligand-based virtual screening,Similarity searching,Substructural fragment,Tanimoto coefficient,Virtual screening,Weighting scheme},
number = {9},
pages = {655--668},
pmid = {19536456},
title = {{Analysis and use of fragment-occurrence data in similarity-based virtual screening}},
volume = {23},
year = {2009}
}
@article{agre90,
author = {Agre, P H},
journal = {Artificial Intelligence},
pages = {369--384},
title = {{Book Review: Lcy A. Scuhman, Plans and Situated Actions: The Problems of Human-Machine Communication}},
volume = {43},
year = {1990}
}
@article{me08a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07ivv.pdf\}},
author = {Menzies, T and Benson, M and Costello, K and Moats, C and Northey, M and Richarson, J},
journal = {Innovations in Systems and Software Engineering},
month = mar,
title = {{Learning Better \{IV\&V\} Practices}},
year = {2008}
}
@inproceedings{me99l,
author = {Menzies, T},
booktitle = {11th Annual International Conference on Software Engineering and Knowledge Engineering, Kaiserslautern, Germany, June 17 - 19, 1999},
title = {{Knowledge Maintenance Heresies: Meta-Knowledge Complicates KM}},
year = {1999}
}
@article{Kaariainen2006,
author = {K\"{a}\"{a}ri\"{a}inen, M},
journal = {Algorithmic Learning Theory},
title = {{Active learning in the non-realizable case}},
url = {http://www.springerlink.com/index/PKU3430515658M85.pdf},
year = {2006}
}
@inproceedings{yol96,
author = {Gil, Y and Melz, E},
booktitle = {Proceedings AAAI' 96},
title = {{Explicit Representations of Problem-Soving Strategies to Support Knowledge Acquisition}},
year = {1996}
}
@article{Das2005,
abstract = {Differential evolution (DE) is well known as a simple and efficient scheme for global optimization over continuous spaces. In this paper we present two new, improved variants of DE. Performance comparisons of the two proposed methods are provided against (a) the original DE, (b) the canonical particle swarm optimization (PSO), and (c) two PSO-variants. The new DE-variants are shown to be statistically significantly better on a seven-function test bed for the following performance measures: solution quality, time to find the solution, frequency of finding the solution, and scalability.},
author = {Das, Swagatam and Konar, Amit and Chakraborty, Uday K.},
doi = {10.1145/1068009.1068177},
file = {:Users/timm/svns/doc/pso/07aDEvariantBeatsOthers.pdf:pdf},
isbn = {1595930108},
journal = {Proceedings of the 2005 conference on Genetic and evolutionary computation - GECCO '05},
keywords = {differential evolution,evolutionary,particle swarm optimization},
pages = {991},
title = {{Two improved differential evolution schemes for faster global search}},
url = {http://portal.acm.org/citation.cfm?doid=1068009.1068177},
year = {2005}
}
@article{Mcfee2010,
author = {Mcfee, Brian and Lanckriet, Gert},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - 504.pdf.pdf:pdf},
journal = {Source},
title = {{Metric Learning to Rank}},
year = {2010}
}
@incollection{nus97,
author = {Nuseibeh, B},
booktitle = {Proceedings of 8th International Workshop on Software Specification and Design (IWSSD-8)},
pages = {164--169},
publisher = {IEEE CS Press.},
title = {{To Be \{$\backslash$em and\} Not to Be: On Managing Inconsistency in Software Development}},
year = {1997}
}
@inproceedings{rothermel98,
author = {Rothermel, G and Harrold, M J and Ostrin, J and Hong, Christie},
booktitle = {Proceedings of International Conference on Software Maintenance '98},
month = nov,
pages = {34--43},
title = {{An Empirical Study of the Effects of Minimizaton on the Fault-Detection Capabilities of Test Suites}},
year = {1998}
}
@article{me97a,
author = {Menzies, T J and Compton, P},
journal = {Artificial Intelligence in Medicine},
pages = {145--175},
title = {{Applications of Abduction: Hypothesis Testing of Neuroendocrinological Qualitative Compartmental Models}},
volume = {10},
year = {1997}
}
@article{uschold96,
author = {Uschold, M and Gruninger, M},
journal = {The Knowledge Engineering Review},
number = {2},
pages = {93--136},
title = {{Ontologies: Principles, Methods, and Applications}},
volume = {11},
year = {1996}
}
@article{ichikawa90,
author = {Ichikawa, T and Chang, S K},
journal = {IEEE Transactions on Software Engineering},
number = {10},
pages = {1105--1197},
title = {{Special Issue on Visual Programming}},
volume = {16},
year = {1990}
}
@article{Ling2007,
abstract = {We propose EMD-L1: a fast and exact algorithm for computing the Earth Mover's Distance (EMD) between a pair of histograms. The efficiency of the new algorithm enables its application to problems that were previously prohibitive due to high time complexities. The proposed EMD-L1 significantly simplifies the original linear programming formulation of EMD. Exploiting the L1 metric structure, the number of unknown variables in EMD-L1 is reduced to O(N) from O(N2) of the original EMD for a histogram with N bins. In addition, the number of constraints is reduced by half and the objective function of the linear program is simplified. Formally, without any approximation, we prove that the EMD-L1 formulation is equivalent to the original EMD with a L1 ground distance. To perform the EMD-L1 computation, we propose an efficient tree-based algorithm, Tree-EMD. Tree-EMD exploits the fact that a basic feasible solution of the simplex algorithm-based solver forms a spanning tree when we interpret EMD-L1 as a network flow optimization problem. We empirically show that this new algorithm has an average time complexity of O(N2), which significantly improves the best reported supercubic complexity of the original EMD. The accuracy of the proposed methods is evaluated by experiments for two computation-intensive problems: shape recognition and interest point matching using multidimensional histogram-based local features. For shape recognition, EMD-L1 is applied to compare shape contexts on the widely tested MPEG7 shape data set, as well as an articulated shape data set. For interest point matching, SIFT, shape context and spin image are tested on both synthetic and real image pairs with large geometrical deformation, illumination change, and heavy intensity noise. The results demonstrate that our EMD-L1-based solutions outperform previously reported state-of-the-art features and distance measures in solving the two tasks.},
author = {Ling, Haibin and Okada, Kazunori},
doi = {10.1109/TPAMI.2007.1058},
file = {:Users/timm/svns/doc/earthMoverDistance07.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Computer Simulation,Data Interpretation, Statistical,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Models, Statistical,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reproducibility of Results,Sensitivity and Specificity,Subtraction Technique},
month = may,
number = {5},
pages = {840--53},
pmid = {17356203},
title = {{An efficient Earth Mover's Distance algorithm for robust histogram comparison.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17356203},
volume = {29},
year = {2007}
}
@inproceedings{chen05,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05/fsscocomo.pdf\}},
author = {Chen, Zhihoa and Menzies, Tim and Port, Dan},
booktitle = {PROMISE'05},
title = {{Feature Subset Selection Can Improve Software Cost Estimation}},
year = {2005}
}
@incollection{shalin97,
author = {Shalin, V L and Geddes, N D and Bertram, D and Szczepkowski, M A and Dubois, D},
booktitle = {Expertise in Context},
chapter = {9},
editor = {Feltovich, P J and Ford, K M and Hoffman, R R},
pages = {195--217},
publisher = {MIT PRess},
title = {{Expertise in Dynamic, Physical Task Domains}},
year = {1997}
}
@inproceedings{cruz93,
author = {Cruz-Neira, C and Sandin, D and DeFanti, T},
booktitle = {Proceedings of SIGGRAPH '93, ACM SIGGRAPH},
month = aug,
pages = {135--142},
title = {{Surround-Screen Projection-Based Virtual Reality: The Design and Implementation of the CAVE}},
year = {1993}
}
@article{neches91,
author = {Neches, R and Fikes, R and Finin, T and Gruber, T and Patil, R and Senator, T and Swartout., W R},
journal = {AI Magazine},
number = {3},
pages = {16--36},
title = {{Enabling technology for knowledge sharing}},
volume = {12},
year = {1991}
}
@incollection{hoff97,
author = {Hoffman, R R and Feltovich, P J and Ford, K M},
booktitle = {Expertise in Context},
chapter = {24},
editor = {Feltovich, P J and Ford, K M and Hoffman, R R},
pages = {543--580},
publisher = {MIT PRess},
title = {{A General Framework for Conceiving of Expertise in Expert Systems in Context}},
year = {1997}
}
@article{clarke03,
author = {Clarke, J and Dolado, J J and Harman, M and Hierons, R and Jones, B and Lumkin, M and Mitchell, B and Mancoridis, S and Rees, K and Roper, M and Shepperd, M},
journal = {ï¿½IEE Proceedings-Softwareï¿½},
number = {3},
pages = {161--175},
title = {{Reformulating software engineering as a search problem}},
volume = {150},
year = {2003}
}
@article{for93a,
author = {Forbus, K},
journal = {Artifical Intelligence},
pages = {115--123},
title = {{Qualitative Process Theory: Twelve Years After.}},
volume = {59},
year = {1993}
}
@article{Barrett2008a,
address = {New York, New York, USA},
author = {Barrett, Leon and Narayanan, Srini},
doi = {10.1145/1390156.1390162},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Barrett, Narayanan - 2008 - Learning all optimal policies with multiple criteria.pdf:pdf},
isbn = {9781605582054},
journal = {Proceedings of the 25th international conference on Machine learning - ICML '08},
pages = {41--47},
publisher = {ACM Press},
title = {{Learning all optimal policies with multiple criteria}},
url = {http://portal.acm.org/citation.cfm?doid=1390156.1390162},
year = {2008}
}
@article{gaddam07,
author = {Gaddam, S R and Phoha, V V and Balagani, K S},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = mar,
number = {3},
title = {{K-Means+ID3: A Novel Method for Supervised Anomaly Detection by Cascading K-Means Clustering and ID3 Decision Tree Learning Methods}},
volume = {19},
year = {2007}
}
@article{chang90,
author = {Chang, C L and Combs, J B and Stachowitz, R A},
journal = {Expert Systems with Applications},
number = {3},
pages = {217--230},
title = {{Report on the Expert Systems Validation Associate (EVA)}},
volume = {1},
year = {1990}
}
@article{Dai2008,
abstract = {BACKGROUND: Many proposed statistical measures can efficiently compare protein sequence to further infer protein structure, function and evolutionary information. They share the same idea of using k-word frequencies of protein sequences. Given a protein sequence, the information on its related protein sequences hasn't been used for protein sequence comparison until now. This paper proposed a scheme to construct protein 'sequence space' which was associated with protein sequences related to the given protein, and the performances of statistical measures were compared when they explored the information on protein 'sequence space' or not. This paper also presented two statistical measures for protein: gre.k (generalized relative entropy) and gsm.k (gapped similarity measure). RESULTS: We tested statistical measures based on protein 'sequence space' or not with three data sets. This not only offers the systematic and quantitative experimental assessment of these statistical measures, but also naturally complements the available comparison of statistical measures based on protein sequence. Moreover, we compared our statistical measures with alignment-based measures and the existing statistical measures. The experiments were grouped into two sets. The first one, performed via ROC (Receiver Operating Curve) analysis, aims at assessing the intrinsic ability of the statistical measures to discriminate and classify protein sequences. The second set of the experiments aims at assessing how well our measure does in phylogenetic analysis. Based on the experiments, several conclusions can be drawn and, from them, novel valuable guidelines for the use of protein 'sequence space' and statistical measures were obtained. CONCLUSION: Alignment-based measures have a clear advantage when the data is high redundant. The more efficient statistical measure is the novel gsm.k introduced by this article, the cos.k followed. When the data becomes less redundant, gre.k proposed by us achieves a better performance, but all the other measures perform poorly on classification tasks. Almost all the statistical measures achieve improvement by exploring the information on 'sequence space' as word's length increases, especially for less redundant data. The reasonable results of phylogenetic analysis confirm that Gdis.k based on 'sequence space' is a reliable measure for phylogenetic analysis. In summary, our quantitative analysis verifies that exploring the information on 'sequence space' is a promising way to improve the abilities of statistical measures for protein comparison.},
author = {Dai, Qi and Wang, Tianming},
doi = {10.1186/1471-2105-9-394},
file = {:Users/timm/svns/doc/erin/references/AlgsForDNA/ComparisonK-wordStatMeasuresDai2008.pdf:pdf},
issn = {1471-2105},
journal = {BMC bioinformatics},
pages = {394},
pmid = {18811946},
title = {{Comparison study on k-word statistical measures for protein: from sequence to 'sequence space'.}},
volume = {9},
year = {2008}
}
@article{okeefe87,
author = {R.M., R M O'Keefe and Balci, O and Smith, E P},
journal = {IEEE Expert},
pages = {81--89},
title = {{Validating Expert System Performance}},
volume = {87},
year = {1987}
}
@incollection{fea03b,
author = {Feather, M S and Menzies, T and Connelly, J R},
booktitle = {Proceedings of the 2003 IEEE International Engineering Management Conference (IEMC-2003) on Managing Technologically Driven Organizations; Albany, NY,},
month = nov,
pages = {451--455},
title = {{Identifying Fruitful Connections Between and Among Researchers and Practitioners}},
year = {2003}
}
@book{tcp,
author = {Stevens, W Richard},
publisher = {\{A\}ddison-\{W\}esley},
title = {{\{TCP/IP\} \{I\}llustrated, \{V\}olume 1: \{T\}he \{P\}rotocols}},
year = {1994}
}
@article{peters12a,
author = {Peters, Fayola and Menzies, Tim and Gong, Liang and Zhang, Hongyu},
journal = {IEEE Transactions on Software Engineering},
month = aug,
number = {8},
pages = {1054--1068},
title = {{Balancing Privacy and Utility in Cross-Company Defect Prediction}},
volume = {39},
year = {2013}
}
@article{Ierusalimschy,
author = {Ierusalimschy, Roberto},
file = {:Users/timm/svns/doc/lua.pdf:pdf},
title = {{Programming in Lua Programming in Lua}}
}
@inproceedings{cohen99,
author = {Cohen, P and Chaudhri, V and Pease, A and Schrag, R},
booktitle = {AAAI'99},
title = {{Does Prior Knowledge Facilitate the Development of Knowledge-based Systems?}},
year = {1999}
}
@article{devedzic99,
author = {Devedzic, V},
journal = {Intelligence (formerly, SIGART)},
pages = {14--24},
title = {{Ontologies: Borrowing from Software Patterns}},
year = {1999}
}
@article{me06d,
abstract = {Effort estimation often requires generalizing from a small number of historical projects. Generalization from such limited experience is an inherently underconstrained problem. Hence, the learned effort models can exhibit large deviations that prevent standard statistical methods (e.g., t-tests) from distinguishing the performance of alternative effort-estimation methods. The COSEEKMO effort-modeling workbench applies a set of heuristic rejection rules to comparatively assess results from alternative models. Using these rules, and despite the presence of large deviations, COSEEKMO can rank alternative methods for generating effort models. Based on our experiments with COSEEKMO, we advise a new view on supposed "best practices" in model-based effort estimation: 1) Each such practice should be viewed as a candidate technique which may or may not be useful in a particular domain, and 2) tools like COSEEKMO should be used to help analysts explore and select the best method for a particular domain},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06coseekmo.pdf\}},
author = {Menzies, T. and Chen, Zhihao Chen Zhihao and Hihn, J. and Lum, K.},
doi = {10.1109/TSE.2006.114},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Menzies et al. - 2006 - Selecting Best Practices for Effort Estimation.pdf:pdf},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {COCOMO,Model-based effort estimation,data mining.,deviation},
month = nov,
number = {11},
title = {{Selecting Best Practices for Effort Estimation}},
volume = {32},
year = {2006}
}
@article{Fung2007,
author = {Fung, Benjamin C M and Wang, Ke and Yu, Philip S},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Fung, Wang, Yu - 2007 - Anonymizing Classification Data for Privacy Preservation.pdf:pdf},
journal = {IEEE Transactions on Knowledge and Data Engineering},
pages = {1--14},
title = {{Anonymizing Classification Data for Privacy Preservation}},
year = {2007}
}
@inproceedings{hoos98,
author = {Hoos, H H and Stutzle, T},
booktitle = {Proc. of UAI-98},
title = {{Evaluating Las Vegas Algorithms - Pitfalls and Remedies}},
year = {1998}
}
@article{dennett82,
annote = {8 June 24},
author = {Dennett, D C},
journal = {The New York Review of Books},
pages = {56--57},
title = {{Letter to the Editor}},
year = {1982}
}
@article{Garcia2012,
abstract = {The nearest neighbor classifier is one of the most used and well-known techniques for performing recognition tasks. It has also demonstrated itself to be one of the most useful algorithms in data mining in spite of its simplicity. However, the nearest neighbor classifier suffers from several drawbacks such as high storage requirements, low efficiency in classification response, and low noise tolerance. These weaknesses have been the subject of study for many researchers and many solutions have been proposed. Among them, one of the most promising solutions consists of reducing the data used for establishing a classification rule (training data) by means of selecting relevant prototypes. Many prototype selection methods exist in the literature and the research in this area is still advancing. Different properties could be observed in the definition of them, but no formal categorization has been established yet. This paper provides a survey of the prototype selection methods proposed in the literature from a theoretical and empirical point of view. Considering a theoretical point of view, we propose a taxonomy based on the main characteristics presented in prototype selection and we analyze their advantages and drawbacks. Empirically, we conduct an experimental study involving different sizes of data sets for measuring their performance in terms of accuracy, reduction capabilities, and runtime. The results obtained by all the methods studied have been verified by nonparametric statistical tests. Several remarks, guidelines, and recommendations are made for the use of prototype selection for nearest neighbor classification.},
author = {Garc\'{\i}a, Salvador and Derrac, Joaqu\'{\i}n and Cano, Jos\'{e} Ram\'{o}n and Herrera, Francisco},
doi = {10.1109/TPAMI.2011.142},
file = {:Users/timm/svns/doc/12prototype.pdf:pdf},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Prototype selection,classification,condensation,edition,nearest neighbor,taxonomy},
number = {3},
pages = {417--435},
pmid = {21768651},
title = {{Prototype selection for nearest neighbor classification: Taxonomy and empirical study}},
volume = {34},
year = {2012}
}
@article{Mannila2004,
author = {Mannila, Heikki and Smyth, Padhraic},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Mannila, Smyth - 2004 - Privacy-Preserving Data Mining Why, How, and When.pdf:pdf},
journal = {Security},
pages = {19--27},
title = {{Privacy-Preserving Data Mining: Why, How, and When}},
year = {2004}
}
@article{coiera92,
author = {Coiera, E},
journal = {The Knowledge Engineering Review},
pages = {1--23},
title = {{The \{Q\}ualitative \{R\}epresentation of \{P\}hysical \{S\}ystems}},
volume = {7},
year = {1992}
}
@inproceedings{me99b,
author = {Menzies, T J and Cukic, B},
booktitle = {Submitted to ISSRE-99},
title = {{When You Don't Need to Re-Test the System}},
year = {1999}
}
@article{Of,
author = {Of, Transmission and Thick, Through and Targets, Silicon},
file = {:Users/timm/svns/doc/cost/02Nasahandbook.pdf:pdf},
title = {{N a s a}}
}
@article{brieman96,
author = {Brieman, L},
journal = {Machine Learning},
number = {2},
pages = {123--140},
title = {{Bagging predictors}},
volume = {24},
year = {1996}
}
@inproceedings{Guerrieri99,
author = {Guerrieri, E},
booktitle = {Proceedings of WISR9: The 9th annual workshop on Institutionalizing Software Reuse},
title = {{Reuse success - when and how?}},
year = {1999}
}
@article{uschold98c,
author = {Uschold, M and King, M and Moralee, S and Zorgios, Y},
journal = {The Knowledge Engineering Review},
month = feb,
number = {1},
title = {{The enterprise ontology}},
volume = {13},
year = {1998}
}
@article{hand06,
author = {Hand, D J},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Hand - 2006 - Classifier Technology and the Illusion of Progress.pdf:pdf},
journal = {Stastical Science},
number = {1},
pages = {1--15},
title = {{Classifier Technology and the Illusion of Progress}},
volume = {21},
year = {2006}
}
@article{Fung2007a,
author = {Fung, Benjamin C.M. and Wang, Ke and Yu, Philip S.},
doi = {10.1109/TKDE.2007.1015},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Fung, Wang, Yu - 2007 - Anonymizing Classification Data for Privacy Preservation.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = may,
number = {5},
pages = {711--725},
title = {{Anonymizing Classification Data for Privacy Preservation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4138206},
volume = {19},
year = {2007}
}
@book{morari86,
author = {Morari, M and McAvoy, T J},
publisher = {A Cache Publication},
title = {{Chemical Process Control: CPC III}},
year = {1986}
}
@inproceedings{me03i,
author = {Comford, Steven L. and Feather, Martin S. and Dunphy, Julia R. and Salcedo, Jose and Menzies, Tim},
booktitle = {IEEE Aerospace Conference Proceedings},
doi = {10.1109/AERO.2003.1235551},
isbn = {078037651X},
issn = {1095323X},
pages = {3681--3690},
title = {{Optimizing spacecraft design optimization engine development: Progress and plans}},
volume = {8},
year = {2003}
}
@inproceedings{me03l,
author = {Menzies, T and Singh, H},
booktitle = {Soft Computing in Software Engineering},
editor = {Madravio, M},
publisher = {Springer-Verlag},
title = {{Many Maybes Mean (Mostly) the Same Thing}},
year = {2003}
}
@article{giger96,
author = {Gigerenzer, G and Goldstein, D G},
journal = {Psychological Review},
number = {103},
pages = {650--669},
title = {{Reasoning the Fast and Frugal Way: Models of Bounded Rationality}},
year = {1996}
}
@article{kirsopp03,
author = {Kirsopp, C and Shepperd, M and Premraj, R},
journal = {Proc. 22nd SGAI Intï¿½l Conf. Knowledge-Based Systems and Applied Artificial Intelligence},
pages = {61},
publisher = {Springer-Verlag New York Inc},
title = {{Case and feature subset selection in case-based software project effort prediction}},
year = {2003}
}
@article{Das2008,
abstract = {Differential evolution (DE) has emerged as one of the fast, robust, and efficient global search heuristics of current interest. This paper describes an application of DE to the automatic clustering of large unlabeled data sets. In contrast to most of the existing clustering techniques, the proposed algorithm requires no prior knowledge of the data to be classified. Rather, it determines the optimal number of partitions of the data "on the run." Superiority of the new method is demonstrated by comparing it with two recently developed partitional clustering techniques and one popular hierarchical clustering algorithm. The partitional clustering algorithms are based on two powerful well-known optimization algorithms, namely the genetic algorithm and the particle swarm optimization. An interesting real-world application of the proposed method to automatic segmentation of images is also reported.},
author = {Das, S. and Abraham, a. and Konar, a.},
doi = {10.1109/TSMCA.2007.909595},
file = {:Users/timm/svns/doc/08clusterDE.pdf:pdf},
isbn = {9780470404614},
issn = {1083-4427},
journal = {IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},
keywords = {Differential evolution (DE),genetic algorithms (GAs),particle swarm optimization (PSO),partitional clustering},
number = {1},
pages = {218--237},
title = {{Automatic Clustering Using an Improved Differential Evolution Algorithm}},
volume = {38},
year = {2008}
}
@incollection{kit91,
author = {Kitchenham, B and Mellor, P},
booktitle = {Software Metrics},
chapter = {6},
editor = {Fenton, N E},
publisher = {Chapman and Hall, London},
title = {{Data Collection and Analysis}},
year = {1991}
}
@book{boehm00b,
author = {Boehm, Barry and Horowitz, Ellis and Madachy, Ray and Reifer, Donald and Clark, Bradford K and Steece, Bert and Brown, A Winsor and Chulani, Sunita and Abts, Chris},
publisher = {Prentice Hall},
title = {{Software Cost Estimation with Cocomo II}},
year = {2000}
}
@inproceedings{kind92,
author = {Kindfield, A C H},
booktitle = {Proceedings of the AAAI Symposium on Diagrammatic Reasoning Stanford University, March 25-27},
pages = {41--46},
title = {{Expert Diagrammatic Reasoning in Biology}},
year = {1992}
}
@article{miller83,
author = {Miller, P L},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = sep,
number = {5},
pages = {449--461},
title = {{ATTENDING: critiquing a physcian's management plan}},
year = {1983}
}
@inproceedings{keung08z,
author = {Keung, Jacky},
booktitle = {Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
pages = {294--296},
series = {ESEM '08},
title = {{Empirical evaluation of analogy-x for software cost estimation}},
year = {2008}
}
@misc{me00c,
author = {Menzies, Tim and Cukic, Bojan and Coiera, Enrico},
month = apr,
number = {April},
pages = {7--10},
title = {{Agents Talking Faster Â¤Â£}},
year = {2000}
}
@article{Stoltenburg2005,
abstract = {Aptamers are ssDNA or RNA oligonucleotides with very high affinity for their target. They bind to the target with high selectivity and specificity because of their specific three-dimensional shape. They are developed by the so-called Systematic Evolution of Ligands by Exponential Enrichment (SELEX) process. We have modified this method in two steps-use of fluorescent labels for DNA quantification and use of magnetic beads for target immobilization. Thus, radioactive labelling is avoided. Immobilization on magnetic beads enables easy handling, use of very small amounts of target for the aptamer selection, rapid and efficient separation of bound and unbound molecules, and stringent washing steps. We have called this modified SELEX technology FluMag-SELEX. With FluMag-SELEX we have provided a methodological background for our objective of being able to select DNA aptamers for targets with very different properties and size. These aptamers will be applied as new biosensor receptors. In this work selection of streptavidin-specific aptamers by FluMag-SELEX is described. The streptavidin-specific aptamers will be used to check the surface occupancy of streptavidin-coated magnetic beads with biotinylated molecules after immobilization procedures.},
author = {Stoltenburg, R. and Reinemann, C. and Strehlitz, B.},
doi = {10.1007/s00216-005-3388-9},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Stoltenberg05.pdf:pdf},
isbn = {4934123520},
issn = {16182642},
journal = {Analytical and Bioanalytical Chemistry},
keywords = {Aptamer,Magnetic beads,SELEX,Streptavidin},
number = {1},
pages = {83--91},
pmid = {16052344},
title = {{FluMag-SELEX as an advantageous method for DNA aptamer selection}},
volume = {383},
year = {2005}
}
@inproceedings{me09i,
abstract = {When AI search methods are applied to software process models, then appropriate technologies can be discovered for a software project. We show that those recommendations are greatly affected by the business context of its use. For example, the automatic defect reduction tools explored by the ASE community are only relevant to a subset of software projects, and only according to certain value criteria. Therefore, when arguing for the value of a particular technology, that argument should include a description of the value function of the target user community.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09value.pdf\}},
author = {Green, Phillip and Menzies, Tim and Williams, Steven and El-Rawas, Oussama},
booktitle = {ASE2009 - 24th IEEE/ACM International Conference on Automated Software Engineering},
doi = {10.1109/ASE.2009.93},
isbn = {9780769538914},
issn = {1527-1366},
keywords = {Artificial intelligence,Software economics},
pages = {52--61},
title = {{Understanding the value of software engineering technologies}},
year = {2009}
}
@book{anderson85,
author = {Anderson, J R},
publisher = {W.H. Freeman and Company},
title = {{Cognitive Psychology and its Implications}},
year = {1985}
}
@inproceedings{wilson1992,
author = {Wilson, P R},
booktitle = {Proceedings of the 1992 International Workshop on Memory Management},
publisher = {Springer-Verlag},
title = {{Uniprocessor Garbage Collection Techniques}},
year = {1992}
}
@inproceedings{Child2005,
author = {Child, Christopher and Stathis, Kostas},
booktitle = {Computational Logic in Multi-Agent Systems},
file = {:Users/timm/svns/doc/child04.pdf:pdf},
pages = {105--113},
publisher = {Springer},
title = {{The Apriori Stochastic Dependency Detection (ASDD) Algorithm for Learning Stochastic Logic Rules}},
url = {http://www.springerlink.com/index/CBJHWJPRCF60HPQ0.pdf},
year = {2005}
}
@article{Arif2009,
abstract = {Binary fingerprints encoding the presence of 2D fragment substructures in molecules are extensively used for similarity-based virtual screening in the agrochemical and pharmaceutical industries. This paper describes two techniques for enhancing the effectiveness of screening: the use of a second-level search based on the nearest neighbours of the initial reference structure; and the use of weighted fingerprints encoding the frequency of occurrence, rather than just the mere presence, of substructures. Experiments using several databases for which both structural and bioactivity data are available demonstrate the effectiveness of these two approaches.},
author = {Arif, Shereena M. and Hert, J\'{e}r\^{o}me and Holliday, John D. and Malim, Nurul and Willett, Peter},
doi = {10.1007/978-3-642-04031-3\_35},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Arif22009.pdf:pdf},
isbn = {3642040306},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Chemoinformatics,Fingerprint,Fragment substructure,Similarity measure,Similarity searching,Turbo similarity searching,Virtual screening,Weighting scheme},
pages = {404--414},
title = {{Enhancing the effectiveness of fingerprint-based virtual screening: Use of turbo similarity searching and of fragment frequencies of occurrence}},
volume = {5780 LNBI},
year = {2009}
}
@article{hayes97a,
author = {Hayes, C C and Parzen, M I},
journal = {IEEE Transactions of Knowledge and Data Engineering},
number = {6},
pages = {838--847},
title = {{QUEN: An Achivement Test for Knowledge-Based Systems}},
volume = {9},
year = {1997}
}
@inproceedings{waugh97,
annote = {$\backslash$url\{http://www.cse.unsw.edu.au/\~{}timm/pub/docs\}},
author = {Waugh, S and Menzies, T J and Goss, S},
booktitle = {Advanced Topics in Artificial Intelligence: 10th Australian Joint Conference on AI},
editor = {Sattar, Abdul},
isbn = {3-540-63797-4},
publisher = {Springer-Verlag},
title = {{Evaluating a Qualitative Reasoner}},
year = {1997}
}
@incollection{fenton00,
author = {Fenton, N E and Neil, M},
booktitle = {Software metrics: A roadmap},
editor = {Finkelstein, A},
publisher = {ACM Press, New York},
title = {{Software Metrics: A Roadmap}},
year = {2000}
}
@article{jorg04uncertainty,
address = {Piscataway, NJ, USA},
author = {J\o rgensen, Magne},
doi = {http://dx.doi.org/10.1109/TSE.2004.1274041},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {4},
pages = {209--217},
publisher = {IEEE Press},
title = {{Realism in Assessment of Effort Estimation Uncertainty: It Matters How You Ask}},
volume = {30},
year = {2004}
}
@misc{murph95a,
author = {Murphy, G C and Notkin, D and Lan, E S C},
institution = {Department of Computer Science \& Engineering, University of Washington},
number = {TR95-8-01},
title = {{An Empirical Study of Static Call Graph Extractors}},
year = {1995}
}
@article{bobrow85,
author = {Bobrow, D G},
journal = {IEEE Transactions on Software Engineering},
month = nov,
number = {11},
pages = {1401--1408},
title = {{If Prolog is the Answer, What is the Question? or What it Takes to Support AI Programming Paradigms}},
volume = {11},
year = {1985}
}
@misc{beohm06a,
annote = {Keynote address, CSEET'06},
author = {Boehm, B},
title = {{Educating Students in Value-Based Design and Development}},
year = {2006}
}
@book{garey79,
author = {Garey, M R and Johnson, D S},
publisher = {Freeman},
title = {{Computers and Intractability: A Guide to the Theory of NP-Completeness}},
year = {1979}
}
@article{dion83,
author = {Dion, R},
journal = {IEEE Software},
month = jul,
pages = {28--35},
title = {{Process Improvement and the Corporate Balance Sheet}},
year = {1993}
}
@article{me09e,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09nodata.pdf\}},
author = {Menzies, T and Williams, S and Elrawas, O and Baker, D and Boehm, B and Hihn, J and Lum, K and Madachy, R},
journal = {Software Process Improvement and Practice},
month = jul,
number = {4},
pages = {213--225},
title = {{Accurate Estimates Without Local Data?}},
volume = {14},
year = {2009}
}
@misc{coker03,
annote = {Available from $\backslash$url\{http://www.jcrocket.com/altimeters.shtml\}},
author = {Coker, John},
title = {{John Coker's Rocket Pages: Altimeter Comparison}},
year = {2003}
}
@inproceedings{goseva07,
author = {Goseva-Popstojanova, K and Hamill, M},
booktitle = {Computer Software and Applications Conference, 2007},
pages = {423--430},
title = {{Architecture-Based Software Reliability: Why Only a Few Parameters Matter?}},
year = {2007}
}
@misc{me96c,
author = {Menzies, T and Haynes, P},
title = {{Empirical Observations of Class-level Encapsulation and Inheritance}},
year = {1996}
}
@article{Menzies2006,
abstract = {Effort estimation often requires generalizing from a small number of historical projects. Generalization from such limited experience is an inherently underconstrained problem. Hence, the learned effort models can exhibit large deviations that prevent standard statistical methods (e.g., t-tests) from distinguishing the performance of alternative effort-estimation methods. The COSEEKMO effort-modeling workbench applies a set of heuristic rejection rules to comparatively assess results from alternative models. Using these rules, and despite the presence of large deviations, COSEEKMO can rank alternative methods for generating effort models. Based on our experiments with COSEEKMO, we advise a new view on supposed "best practices" in model-based effort estimation: 1) Each such practice should be viewed as a candidate technique which may or may not be useful in a particular domain, and 2) tools like COSEEKMO should be used to help analysts explore and select the best method for a particular domain},
author = {Menzies, Tim and Chen, Zhihao and Hihn, Jairus and Lum, Karen},
doi = {10.1109/TSE.2006.114},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Menzies et al. - 2006 - Selecting Best Practices for Effort Estimation.pdf:pdf},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {COCOMO,Data mining,Deviation,Model-based effort estimation},
number = {11},
pages = {883--895},
title = {{Selecting best practices for effort estimation}},
volume = {32},
year = {2006}
}
@article{tosun2010,
author = {Tosun, A and Bener, A and Turhan, B and Menzies, T},
title = {{No Title}}
}
@article{voas95,
author = {Voas, J M and Miller, K W},
journal = {IEEE Software},
month = may,
pages = {17--28},
title = {{Software Testability: The New Verification}},
year = {1995}
}
@article{hoppe93,
author = {{T. Hoppe}, P Meseguer},
journal = {IEEE Expert},
number = {3},
pages = {48--55},
title = {{VVT Terminology: A Proposal}},
volume = {8},
year = {1993}
}
@inproceedings{joseph98,
author = {Josephson, J R and Chandrasekaran, B and Carroll, M and Iyer, N and Wasacz, B and Rizzoni, G},
booktitle = {AAAI '98},
title = {{Exploration Of Large Design Spaces: an Architecture and Preliminary Results}},
year = {1998}
}
@inproceedings{me00p,
abstract = {Machine learning is practical for software engineering problems, even in data- starved domains. When data is scarce, knowledge can be farmed from seeds; i.e. minimal and partial descriptions of a domain. These seeds can be grown into large datasets via Monte Carlo simulations. The datasets can then be harvested using machine learning techniques. Examples of this knowledge farming approach, and the associated technique of data-mining, is given from numerous software engineering domains.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/00ml.pdf\}},
author = {Menzies, Tim},
booktitle = {Handbook of Software Engineering and Knowledge Engineering690 (2001).},
isbn = {981-02-4973-X},
month = dec,
number = {690},
pages = {690},
publisher = {World-Scientific},
title = {{Practical Machine Learning for Software Engineering and Knowledge Engineering}},
url = {http://menzies.us/pdf/00ml.pdf},
volume = {1},
year = {2001}
}
@article{Larsen1999d,
address = {New York, New York, USA},
author = {Larsen, Bjornar and Aone, Chinatsu},
doi = {10.1145/312129.312186},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Larsen, Aone - 1999 - Fast and effective text mining using linear-time document clustering(2).pdf:pdf},
isbn = {1581131437},
journal = {Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '99},
keywords = {clustering,multi-document summarization,text mining},
pages = {16--22},
publisher = {ACM Press},
title = {{Fast and effective text mining using linear-time document clustering}},
url = {http://portal.acm.org/citation.cfm?doid=312129.312186},
year = {1999}
}
@inproceedings{hamscher90,
author = {Hamscher, W},
booktitle = {\{AAAI\} Spring Symposium on Automated Abduction},
editor = {O'Rourke, P},
pages = {96--100},
title = {{Explaining \{U\}nexpected \{F\}inancial \{R\}esults}},
year = {1990}
}
@article{jorgensen04,
author = {J\o rgensen, M and Molokken-Ostvold, K},
journal = {IEEE Transactions on Software Engineering},
month = dec,
number = {12},
title = {{Reasons for Software Effort Estimation Error: Impact of Respondent Error, Information Collection Approach, and Data Analysis Method}},
volume = {30},
year = {2004}
}
@inproceedings{me00u,
author = {Menzies, T and Singh, H},
booktitle = {Advances in Artificial Intelligence, 14th Biennial Conference of the Canadian Society for Computational Studies of Intelligence, AI 2001, Ottawa, Canada, June 7-9, 2001, Proceedings},
pages = {100--110},
title = {{How AI Can Help SE; or: Randomized Search Not Considered Harmful}},
year = {2001}
}
@journal{voinea07,
booktitle = {Computers and Graphics},
number = {3},
pages = {410--428},
title = {{S.L. Voinea and A.C. Telea}},
volume = {31},
year = {2007}
}
@book{norman89,
author = {Norman, D A},
pages = {257},
publisher = {DoubleDay Currency},
title = {{The Design of Everyday Things}},
year = {1989}
}
@article{srinivasan95,
author = {Srinivasan, K and Fisher, D},
journal = {IEEE Trans. Soft. Eng.},
month = feb,
pages = {126--137},
title = {{Machine Learning Approaches to Estimating Software Development Effort}},
year = {1995}
}
@inproceedings{me92zb,
author = {Menzies, T J and Compton, P},
booktitle = {ECAI '92 Workshop on Improving the Use of Knowledge-Based Systems with Explanations, Vienna},
title = {{Causal Explanations as a Tool for Refining Qualitative Models}},
year = {1992}
}
@inproceedings{WAGNER2009,
address = {New York, NY, USA},
author = {Wagner, Stefan},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540447},
isbn = {978-1-60558-634-2},
pages = {1--9},
publisher = {ACM},
title = {{A Bayesian network approach to assess and predict software quality using activity-based quality models}},
year = {2009}
}
@article{Middleton2009a,
author = {Middleton, Grant and Peyton, Liam and Kuziemsky, Craig and Eze, Ben},
doi = {10.1109/CONGRESS.2009.9},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Middleton et al. - 2009 - A Framework for Continuous Compliance Monitoring of eHealth Processes.pdf:pdf},
isbn = {978-1-4244-5344-3},
journal = {2009 World Congress on Privacy, Security, Trust and the Management of e-Business},
month = aug,
pages = {152--160},
publisher = {Ieee},
title = {{A Framework for Continuous Compliance Monitoring of eHealth Processes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5341705},
year = {2009}
}
@book{tour86,
author = {Touretzky, J},
publisher = {Morgan Kaufmann},
title = {{The Mathematics of Inheritance}},
year = {1986}
}
@article{Miklau2004a,
author = {Miklau, Gerome and Suciu, Dan},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Miklau, Suciu - 2004 - A Formal Analysis of Information Disclosure in Data Exchange.pdf:pdf},
title = {{A Formal Analysis of Information Disclosure in Data Exchange}},
year = {2004}
}
@article{kotonya92,
author = {Kotonya, G and Sommerville, I},
journal = {IEE Software Engineering Journal},
pages = {375--387},
title = {{Viewpoints for Requirements Definition}},
volume = {7},
year = {1992}
}
@article{Lum2006,
author = {Lum, Karen and Menzies, Tim and Hihn, Jairus},
file = {:Users/timm/svns/doc/cost/06Lum.pdf:pdf},
title = {{Studies in Software Cost Model Behavior: Do We Really Understand Cost Model Performance?}},
url = {http://trs-new.jpl.nasa.gov/dspace/handle/2014/41450},
year = {2006}
}
@article{such87,
author = {Suchman, L},
journal = {Artificial Intelligence},
pages = {227--232},
title = {{Book Review of Winograd \& Flores, Understanding Computers and Cognition: A New Foundation for Design}},
volume = {31},
year = {1987}
}
@inproceedings{cunn95,
author = {Cunningham, W},
booktitle = {Pattern Languages of Program Design},
editor = {Coplien, J and Schmidt, D},
publisher = {Addison-Wesley},
title = {{The CHECKS Pattern Language of Information Integrity}},
year = {1995}
}
@inproceedings{khoshgoftaar99,
author = {Khoshgoftaar, T M and Allen, E B},
booktitle = {Recent Advances in Reliability and Quality Engineering},
chapter = {15},
editor = {Pham, H},
pages = {247--270},
publisher = {World Scientific},
title = {{Model Software Quality with Classification Trees}},
year = {2001}
}
@misc{predict,
title = {{Predict\^{}\{$\backslash$mbox $\backslash$textregistered\}}},
url = {$\backslash$url\{http://www.ismwv.com/products.asp\}},
year = {2005}
}
@article{me96a,
author = {Menzies, T J},
journal = {International Journal of Human Computer Studies},
pages = {305--355},
title = {{Applications of Abduction: Knowledge Level Modeling}},
volume = {45},
year = {1996}
}
@article{forbus84,
author = {Forbus, K},
journal = {Artificial Intelligence},
pages = {85--168},
title = {{Qualitative Process Theory}},
volume = {24},
year = {1984}
}
@article{lenat90,
author = {Lenat, D B and Gutha, R V},
journal = {AI Magazine},
pages = {32--59},
title = {{CYC: A Midterm Report}},
year = {1990}
}
@inproceedings{wise00,
author = {Wise, A and Cass, A G and Lerner, B Staudt and McCall, E K and Osterweil, L J and {S.M. Sutton}, Jr.},
booktitle = {Proceedings of the Automated Software Engineering Conference (ASE 2000) Grenoble, France.},
month = sep,
title = {{Using Little-JIL to Coordinate Agents in Software Engineering}},
year = {2000}
}
@article{Athitsos2008,
abstract = {This paper describes BoostMap, a method for efficient nearest neighbor retrieval under computationally expensive distance measures. Database and query objects are embedded into a vector space, in which distances can be measured efficiently. Each embedding is treated as a classifier that predicts for any three objects X, A, B whether X is closer to A or to B. It is shown that a linear combination of such embeddingbased classifiers naturally corresponds to an embedding and a distance measure. Based on this property, the BoostMap method reduces the problem of embedding construction to the classical boosting problem of combining many weak classifiers into an optimized strong classifier. The classification accuracy of the resulting strong classifier is a direct measure of the amount of nearest neighbor structure preserved by the embedding. An important property of BoostMap is that the embedding optimization criterion is equally valid in both metric and non-metric spaces. Performance is evaluated in databases of hand images, handwritten digits, and time series. In all cases, BoostMap significantly improves retrieval efficiency with small losses in accuracy compared to brute-force search. Moreover, BoostMap significantly outperforms existing nearest neighbor retrieval methods, such as Lipschitz embeddings, FastMap, and VP-trees.},
author = {Athitsos, Vassilis and Alon, Jonathan and Sclaroff, Stan and Kollios, George},
doi = {10.1109/TPAMI.2007.1140},
file = {:Users/timm/svns/doc/08boostmap.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Imaging, Three-Dimensional,Imaging, Three-Dimensional: methods,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reproducibility of Results,Sensitivity and Specificity,Subtraction Technique},
month = jan,
number = {1},
pages = {89--104},
pmid = {18000327},
title = {{BoostMap: an embedding method for efficient nearest neighbor retrieval.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18000327},
volume = {30},
year = {2008}
}
@inproceedings{steels94,
author = {Steels, L},
booktitle = {Proceedings of the Third Japanese Knowledge Acquisition for Knowledge-Based Systems Workshop, JKAW '94},
editor = {Mizoguchi, R and Motoda, H and Boose, J and Gaines, B and Compton, P},
pages = {65--71},
title = {{How \{C\}an we \{M\}ake \{F\}urther \{P\}rogress in \{K\}nowledge \{A\}cquisition?}},
year = {1994}
}
@incollection{maimon05,
title = {{No Title}}
}
@article{kah82,
author = {Kahneman, D and Tversky, A},
journal = {Scientific American},
pages = {136--142},
title = {{The Psychology of Preferences}},
volume = {246},
year = {1982}
}
@article{Stoltenburg2007,
abstract = {SELEX stands for systematic evolution of ligands by exponential enrichment. This method, described primarily in 1990 [Ellington, A.D., Szostak, J.W., 1990. In vitro selection of RNA molecules that bind specific ligands. Nature 346, 818-822; Tuerk, C., Gold, L., 1990. Systematic evolution of ligands by exponential enrichment: RNA ligands to bacteriophage T4 DNA polymerase. Science 249, 505-510] aims at the development of aptamers, which are oligonucleotides (RNA or ssDNA) binding to their target with high selectivity and sensitivity because of their three-dimensional shape. Aptamers are all new ligands with a high affinity for considerably differing molecules ranging from large targets as proteins over peptides, complex molecules to drugs and organic small molecules or even metal ions. Aptamers are widely used, including medical and pharmaceutical basic research, drug development, diagnosis, and therapy. Analytical and separation tools bearing aptamers as molecular recognition and binding elements are another big field of application. Moreover, aptamers are used for the investigation of binding phenomena in proteomics. The SELEX method was modified over the years in different ways to become more efficient and less time consuming, to reach higher affinities of the aptamers selected and for automation of the process. This review is focused on the development of aptamers by use of SELEX and gives an overview about technologies, advantages, limitations, and applications of aptamers. ?? 2007 Elsevier B.V. All rights reserved.},
author = {Stoltenburg, Regina and Reinemann, Christine and Strehlitz, Beate},
doi = {10.1016/j.bioeng.2007.06.001},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Stoltenberg07.pdf:pdf},
isbn = {1389-0344},
issn = {13890344},
journal = {Biomolecular Engineering},
keywords = {Aptamer,Random oligonucleotide library,SELEX,Target},
number = {4},
pages = {381--403},
pmid = {17627883},
title = {{SELEX-A (r)evolutionary method to generate high-affinity nucleic acid ligands}},
volume = {24},
year = {2007}
}
@article{paulk93,
author = {Paulk, M C and Curtis, B and Chrissis, M B and Weber, C V},
journal = {IEEE Software},
month = jul,
number = {4},
pages = {18--27},
title = {{Capability Maturity Model, Version 1.1}},
volume = {10},
year = {1993}
}
@inproceedings{rish01,
author = {Rish, E},
booktitle = {IJCAI-01 workshop on Empirical Methods in AI},
title = {{An empirical study of the naive Bayes classifier}},
year = {2001}
}
@article{Paslay2010,
abstract = {High throughput screening (HTS) has become the cornerstone of lead identification for small molecules in drug discovery during the last quarter century. The evolution of the sciences and technologies that have evolved as the foundation of modern HTS campaigns are complex and require multidisciplinary interactions. Innovations in integrated automated systems, reagent systems enabled by molecular biology, computational capabilities, and visualization tools have converged to provide sophisticated tools to HTS practitioners. The success of HTS in an organi- zation does not rest solely with those performing HTS but is critically dependent on the interactions of biology and chemistry members of the multidisciplinary teams throughout the early discovery process. Thus a basic knowledge and understanding of the components and processes of HTS is a necessary requirement for effective communication in planning, executing, and analyzing an HTS campaign. This chapter addresses the key components of HTS campaigns, common approaches, and related issues that should be understood by those engaged in small molecule drug discovery.},
author = {Paslay, Jw and Morin, Je and Harrison, Rk},
doi = {10.1007/7355},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Bikker2009.pdf:pdf},
journal = {Topics in Medicinal Chemistry},
keywords = {assay development,automation,data management,high throughput,screening,statistics},
pages = {25--83},
title = {{High Throughput Screening in the Twenty-First Century}},
url = {http://link.springer.com/chapter/10.1007/7355\_2009\_6},
volume = {5},
year = {2010}
}
@misc{persist97,
address = {http://www.persistence.com/},
institution = {Persistence Software Inc.},
title = {{Persistence: A Relational Mapping and Caching Tool}}
}
@inproceedings{me06c,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06bad.pdf\}},
author = {Menzies, T and Allen, D and Orrego, A},
booktitle = {Proceedings of the Machine Learning Algorithms for Surveillance and Event Detection Workshop, ICML'06},
title = {{Bayesian Anomaly Detection (BAD v1.0)}},
year = {2006}
}
@misc{boxing,
annote = {$\backslash$url\{http://en.wikipedia.org/wiki/List\_of\_Heavyweight\_Champions\}},
title = {{List of Heavyweight Champions}}
}
@inproceedings{deb98b,
author = {Debenham, J},
booktitle = {Proceedings Tenth International Conference on Software Engineering and Knowledge Engineering SEKE'98, San Francisco, US, June},
title = {{Representing Knowledge Normalisation}},
year = {1998}
}
@article{bert96,
author = {{A. Bertolino}, L Strigini},
journal = {IEEE Transactions on Software Engineering},
number = {2},
pages = {97--108},
title = {{On the Use of Testability Measures for Dependability Assessment}},
volume = {22},
year = {1996}
}
@article{fenton02,
address = {Los Alamitos, CA, USA},
author = {Fenton, Norman and Krause, Paul and Neil, Martin},
doi = {http://doi.ieeecomputersociety.org/10.1109/MS.2002.1020298},
issn = {0740-7459},
journal = {IEEE Software},
number = {4},
pages = {116--122},
publisher = {IEEE Computer Society},
title = {{Software Measurement: Uncertainty and Causal Modeling}},
volume = {19},
year = {2002}
}
@article{Miklau2004,
address = {New York, New York, USA},
author = {Miklau, Gerome and Suciu, Dan},
doi = {10.1145/1007568.1007633},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Miklau, Suciu - 2004 - A Formal Analysis of Information Disclosure in Data Exchange.pdf:pdf},
isbn = {1581138598},
journal = {Proceedings of the 2004 ACM SIGMOD international conference on Management of data - SIGMOD '04},
pages = {575},
publisher = {ACM Press},
title = {{A formal analysis of information disclosure in data exchange}},
url = {http://portal.acm.org/citation.cfm?doid=1007568.1007633},
year = {2004}
}
@article{korf85,
author = {Korf, R E},
journal = {Artificial Intelligence},
pages = {97--109},
title = {{Depth-First Iterative Deepening: an Optimal Admissible Tree Search}},
volume = {27},
year = {1985}
}
@article{Brody2000,
abstract = {Aptamers are oligonucleotides derived from an in vitro evolution process called SELEX. Aptamers have been evolved to bind proteins which are associated with a number of disease states. Using this method, many powerful antagonists of such proteins have been found. In order for these antagonists to work in animal models of disease and in humans, it is necessary to modify the aptamers. First of all, sugar modifications of nucleoside triphosphates are necessary to render the resulting aptamers resistant to nucleases found in serum. Changing the 2'OH groups of ribose to 2'F or 2'NH2 groups yields aptamers which are long lived in blood. The relatively low molecular weight of aptamers (8000-12000) leads to rapid clearance from the blood. Aptamers can be kept in the circulation from hours to days by conjugating them to higher molecular weight vehicles. When modified, conjugated aptamers are injected into animals, they inhibit physiological functions known to be associated with their target proteins. A new approach to diagnostics is also described. Aptamer arrays on solid surfaces will become available rapidly because the SELEX protocol has been successfully automated. The use of photo-cross-linkable aptamers will allow the covalent attachment of aptamers to their cognate proteins, with very low backgrounds from other proteins in body fluids. Finally, protein staining with any reagent which distinguishes functional groups of amino acids from those of nucleic acids (and the solid support) will give a direct readout of proteins on the solid support.},
author = {Brody, E N and Gold, L},
doi = {10.1016/S1389-0352(99)00004-5},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Brody00.pdf:pdf},
isbn = {1389-0352},
issn = {13890352},
journal = {Journal of biotechnology},
keywords = {brody,clearance,com \v{z} e,compuserve,corresponding author,e-mail address,edwardnbrody,fax,n,oligonucleotide,pharmaceuticals,photo-selex,q 1-303-499-6846,q 1-303-499-8327,selex,tel,universal protein stain},
number = {1},
pages = {5--13},
pmid = {10943568},
title = {{Aptamers as therapeutic and diagnostic agents.}},
volume = {74},
year = {2000}
}
@misc{me09c,
author = {Gundy-Burlet, K and Schumann, J and Menzies, T and Barrett, T},
booktitle = {AIAA Aerospace, 2009},
title = {{Parametric Analysis of a Hover Test Vehicle Using Advanced Test Generation and Data Analysis}},
year = {2009}
}
@article{smith97,
author = {Smith, A and Mason, A},
journal = {The Engineering Economist},
number = {2},
pages = {137--161},
title = {{Cost estimation predictive modeling: Regression versus neural network}},
volume = {42},
year = {1997}
}
@inproceedings{pecheur00,
author = {Pecheur, Charles and Simmons, Reid},
booktitle = {Proceedings of First Goddard Workshop on Formal Approaches to Agent-Based Systems},
month = apr,
pages = {5--7},
title = {{From Livingstone to SMV: Formal Verification for Autonomous Spacecrafts}},
year = {2000}
}
@inproceedings{me99g,
author = {Menzies, T and Michael, C C},
booktitle = {SEKE '99, June 17-19, Kaiserslautern, Germany.},
title = {{Fewer Slices of PIE: Optimising Mutation Testing via Abduction}},
year = {1999}
}
@inproceedings{delucia06,
author = {{De Lucia}, A and Oliveto, R and Zurolo, F and {Di Penta}, M},
booktitle = {Program Comprehension, 2006. ICPC 2006. 14th IEEE International Conference on},
doi = {10.1109/ICPC.2006.28},
issn = {1092-8138},
pages = {317--326},
title = {{Improving Comprehensibility of Source Code via Traceability Information: a Controlled Experiment}},
year = {2006}
}
@inproceedings{yann01,
author = {Kalgoglou, Y},
booktitle = {Handbook of Software and Knowledge Engineering (volume 1)},
editor = {Chung, S K},
title = {{Ontologies in Software Design}},
year = {2001}
}
@book{brooks95,
author = {Brooks, F P},
publisher = {Addison-Wesley},
title = {{The Mythical Man-Month, Anniversary edition}},
year = {1995}
}
@inproceedings{hame93,
author = {Haynes, P and Menzies, T J},
booktitle = {Tools Pacific 1993},
organization = {Prentice Hall},
pages = {75--82},
title = {{C++ is \{B\}etter than \{S\}malltalk?}},
year = {1993}
}
@inproceedings{TOSUN2009,
address = {New York, NY, USA},
author = {Tosun, Ayse and Turhan, Burak and Bener, Ayse},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540446},
isbn = {978-1-60558-634-2},
pages = {1--9},
publisher = {ACM},
title = {{Validation of network measures as indicators of defective modules in software systems}},
year = {2009}
}
@incollection{patel97,
author = {Patel, V L and Ramoni, M F},
booktitle = {Expertise in Context},
chapter = {3},
editor = {Feltovich, P J and Ford, K M and Hoffman, R R},
pages = {67--99},
publisher = {MIT PRess},
title = {{Cognitive Models of Directional Inference in Expert Medical Reasoning}},
year = {1997}
}
@book{walpole72,
author = {Walpole, R E and Myers, R H},
edition = {2},
publisher = {Collier Macmillion},
title = {{Probability and Statistics for Engineers ad Scientists}},
year = {1972}
}
@inproceedings{cook71,
author = {Cook, S},
booktitle = {Proceedings of the 3rd ACM Symposium on the Theory of Computing},
pages = {151--158},
title = {{The complexity of theorem-proving procedures}},
year = {1971}
}
@inproceedings{preston93,
author = {Preston, P and Edwards, G and Compton, P},
booktitle = {Second World Congress on Expert Systems},
editor = {Leibowitz, J},
title = {{A 1600 \{R\}ule \{E\}xpert \{S\}ystem \{W\}ithout \{K\}nowledge \{E\}ngineers.}},
year = {1993}
}
@inproceedings{Milic2004,
author = {Milic, Drazen and Wohlin, Claes},
booktitle = {Euromicro},
keywords = {control,effort estimation,estimation process,software project,software project management},
title = {{Distribution Patterns of Effort Estimations}},
year = {2004}
}
@misc{har98,
author = {Hawryszkiewycz, I T},
booktitle = {In preperation},
title = {{Evolving Workspace Networks for Cooperative Work}},
year = {1998}
}
@phdthesis{baker07,
author = {Baker, Dan},
file = {:Users/timm/svns/doc/cost/07Baker.pdf:pdf},
school = {Lane Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{A Hybrid Approach to Expert and Model-based Effort Estimation}},
year = {2007}
}
@article{brooks91,
author = {Brooks, R A},
journal = {Artificial Intelligence},
pages = {139--159},
title = {{Intelligence Without Representation}},
volume = {47},
year = {1991}
}
@misc{me99d,
annote = {In preperation},
author = {Menzies, T and Cukic, B},
howpublished = {NASA/WVU IVV tech report.},
month = mar,
title = {{An Average-Case Model of Reachability}},
year = {1999}
}
@article{VanDerMerwe2003a,
author = {{Van Der Merwe}, Dw and Engelbrecht, Ap},
file = {:Users/timm/svns/doc/pso/01psoKmeansCluster.pdf:pdf},
isbn = {0780378040},
journal = {2003 Ieee},
pages = {215--220},
title = {{Data Clustering using Particle Swarm Optimization}},
year = {2003}
}
@article{boehm00a,
author = {Boehm, B},
journal = {IEEE Software},
pages = {14--17},
title = {{Safe and Simple Software Cost Analysis}},
year = {2000}
}
@book{laguna04,
author = {Laguna, M and Marklund, J},
publisher = {Pearson Prenctice Hall},
title = {{Business Process Modeling, Simulation, and Design}},
year = {2004}
}
@article{mitchell06,
author = {Mitchell, B S and Mancoridis, S},
journal = {IEEE Transactions on Software Engineering},
month = mar,
number = {3},
pages = {193--208},
title = {{On the Automatic Modularization of Software Systems Using the Bunch Tool}},
volume = {32},
year = {2006}
}
@inproceedings{horgan96,
address = {McGraw-Hill},
author = {Horgan, J and Mathur, A},
booktitle = {The Handbook of Software Reliability Engineering},
editor = {Lyu, M R},
pages = {531--565},
title = {{Software Testing and Reliability}},
year = {1996}
}
@inproceedings{poole89,
author = {Poole, D},
booktitle = {IJCAI '89},
pages = {1304--1310},
title = {{Normality and \{F\}aults in \{L\}ogic-\{B\}ased \{D\}iagnosis}},
year = {1989}
}
@article{Wen2012,
abstract = {Context: Software development effort estimation (SDEE) is the process of predicting the effort required to develop a software system. In order to improve estimation accuracy, many researchers have proposed machine learning (ML) based SDEE models (ML models) since 1990s. However, there has been no attempt to analyze the empirical evidence on ML models in a systematic way. Objective: This research aims to systematically analyze ML models from four aspects: type of ML technique, estimation accuracy, model comparison, and estimation context. Method: We performed a systematic literature review of empirical studies on ML model published in the last two decades (1991-2010). Results: We have identified 84 primary studies relevant to the objective of this research. After investigating these studies, we found that eight types of ML techniques have been employed in SDEE models. Overall speaking, the estimation accuracy of these ML models is close to the acceptable level and is better than that of non-ML models. Furthermore, different ML models have different strengths and weaknesses and thus favor different estimation contexts. Conclusion: ML models are promising in the field of SDEE. However, the application of ML models in industry is still limited, so that more effort and incentives are needed to facilitate the application of ML models. To this end, based on the findings of this review, we provide recommendations for researchers as well as guidelines for practitioners. Â© 2011 Elsevier B.V. All rights reserved.},
author = {Wen, Jianfeng and Li, Shixian and Lin, Zhiyong and Hu, Yong and Huang, Changqin},
doi = {10.1016/j.infsof.2011.09.002},
file = {:Users/timm/svns/doc/12wenEffortEstimationReview.pdf:pdf},
isbn = {0950-5849},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Machine learning,Software effort estimation,Systematic literature review},
number = {1},
pages = {41--59},
title = {{Systematic literature review of machine learning based software development effort estimation models}},
volume = {54},
year = {2012}
}
@article{Lindell,
author = {Lindell, Yehuda},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Lindell - Unknown - Privacy Preserving Data Mining â.pdf:pdf},
journal = {Organization},
keywords = {11,an earlier version of,and,data mining,decision trees,most of this work,oblivious polynomial evaluation,oblivious transfer,science and the hebrew,secure two-party computation,the weizmann institute of,this work appeared in,university of jerusalem,was done while at},
title = {{Privacy Preserving Data Mining â}}
}
@article{Quickstart2011,
author = {Quickstart, A Beamer},
doi = {10.1002/ajmg.a.33931},
issn = {1552-4833},
journal = {American journal of medical genetics. Part A},
month = feb,
number = {2},
pages = {fmi--fmiv},
pmid = {21271636},
title = {{Table of contents, volume 155, number 2, february 2011.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21271636},
volume = {155},
year = {2011}
}
@article{TecoloteResearch2005,
author = {{Tecolote Research}},
file = {:Users/timm/svns/doc/cost/07Airforcehandbook.pdf:pdf},
pages = {204},
title = {{U.S. Air Force Cost Risk and Uncertainty Analysis Handbook}},
year = {2005}
}
@inproceedings{funt92,
author = {Funt, B V},
booktitle = {AAAI Spring Symposium on Reasoning with Diagrammatic Representations},
editor = {Narayanan, N H},
pages = {181},
title = {{Experiential Reasoning}},
year = {1992}
}
@article{such93,
author = {Suchman, L},
journal = {Cognitive Science},
pages = {71--75},
title = {{Response to Vera and Simon's Situated Action: A Symbolic Interpretation}},
volume = {17},
year = {1993}
}
@inproceedings{Scanniello2011,
abstract = {One of the most common comprehension activities undertaken by developers is concept location in source code. In the context of software change, concept location means finding locations in source code where changes are to be made in response to a modification request. Static techniques for concept location usually rely on searching the source code using textual information or on navigating the dependencies among software elements. In this paper we propose a novel static concept location technique, which leverages both the textual information present in the code and the structural dependencies between source code elements. The technique employs a textual search in that source code, which is clustered using the Border Flow algorithm, based on combining both structural and textual data. We evaluated the technique against a text search based baseline approach using data on almost 200 changes from five software systems. The results indicate that the new approach outperforms the baseline and that improvements are still possible.},
address = {Kingston, ON},
annote = {Laura. Fixed on 09/24/2012},
author = {Scanniello, Giuseppe and Marcus, Andrian},
booktitle = {19th IEEE International Conference on Program Comprehension (ICPC'11)},
keywords = {concept\_feature\_concern\_location semantic\_informat},
pages = {1--10},
title = {{Clustering Support for Static Concept Location in Source Code}},
year = {2011}
}
@inproceedings{fen97b,
author = {Fensel, D and Schonegge, A},
booktitle = {Proceedings of the 12th IEEE International Conference on Automated Software Engineering (ASEC-97), Incline Village, Nevada, Nov 3-5},
title = {{Using KIV to Specify and Verify Architecture of Knowledge-Based Systems}},
year = {1997}
}
@article{me13e,
author = {Menzies, Tim},
journal = {Information and Software Technology},
number = {8},
pages = {1477--1478},
title = {{Guest editorial for the Special Section on \{BEST\} \{PAPERS\} from the 2011 conference on Predictive Models in Software Engineering (PROMISE)}},
volume = {55},
year = {2013}
}
@article{me98b,
abstract = {Situated cognition is not a mere philosophical concern: it has pragmatic implications for current practice in knowledge acquisition. Tools must move from being design-focused to being maintenance-focused. Reuse-based approaches (e.g. using problem-solving methods) will fail unless the reused descriptions can be extensively modified to suit the new situation. Knowledge engineers must model not only descriptions of expert knowledge, but also the environment in which a knowledge base will perform. Descriptions of knowledge must be constantly re-evaluated. This re-evaluation process has implications for assessing representations},
author = {Menzies, T I M},
doi = {10.1006/ijhc.1998.0230},
isbn = {1071-5819},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
number = {6},
pages = {867--893},
title = {{Towards situated knowledge acquisition}},
url = {http://www.sciencedirect.com/science/article/B6WGR-45J548X-6/2/d7a982a694598b232b8c2e7ec4c0263f},
volume = {49},
year = {1998}
}
@misc{john96,
annote = {(personal communication)},
author = {Johnson, R},
title = {{No Title}}
}
@inproceedings{roth94,
author = {Rothenfluh, T E and Gennari, J H and Erikson, H and Puetra, A R and Tu, W and Musen, M A},
booktitle = {Proceedings of the 8th \{AAAI\}-Sponsored \{B\}anff Knowledge Acquisition for Knowledge-Based Systems Workshop},
editor = {Gaines, B R and Musen, M},
pages = {43.1--43.30},
title = {{Reusable Ontologies, Knowledge-Acquisition Tools and Performance Systems: PROTEGE-\{II\} Solutions to Sisyphus-2}},
year = {1994}
}
@article{grog92,
author = {Grogono, P and Batarekh, A and Preece, A and Shinghal, R and Suen, C},
journal = {Expert Systems},
pages = {227--239},
title = {{Expert System Evaluation Techniques: A Selected Bibliography.}},
year = {1992}
}
@inproceedings{me04h,
author = {Menzies, T and Port, D and Chen, Z and Hihn, J and Stukes, S},
booktitle = {Proceedings, ICSE},
title = {{Validation Methods for Calibrating Software Effort Models}},
year = {2005}
}
@article{Durillo2011,
author = {Durillo, Juan J and Nebro, Antonio J},
doi = {DOI: 10.1016/j.advengsoft.2011.05.014},
issn = {0965-9978},
journal = {Advances in Engineering Software},
keywords = {Experimentation,Metaheuristics,Multi-objective optimization,Object-oriented architecture,Performance assessment support,Software tool},
pages = {760--771},
title = {{jMetal: A Java framework for multi-objective optimization}},
url = {http://www.sciencedirect.com/science/article/pii/S0965997811001219},
volume = {42},
year = {2011}
}
@article{Fang2008,
abstract = {A method is presented to partition a given set of data entries embedded in Euclidean space by recursively bisecting clusters into smaller ones. The initial set is subdivided into two subsets whose centroids are farthest from each other, and the process is repeated recursively on each subset. An approximate algorithm is proposed to solve the original integer programming problem which is NP-hard. Experimental evidence shows that the clustering method often outperforms a standard spectral clustering method, albeit at a slightly higher computational cost. The paper also discusses improvements of the standard K-means algorithm. Specifically, the clustering quality resulting from the K-means technique can be significantly enhanced by using the proposed algorithm for its initialization.},
author = {Fang, Haw Ren and Saad, Yousef},
doi = {10.1109/ICMLA.2008.141},
file = {:Users/timm/svns/doc/08farthestCentroidsDivisiveClustering.pdf:pdf},
isbn = {9780769534954},
journal = {Proceedings - 7th International Conference on Machine Learning and Applications, ICMLA 2008},
keywords = {graph partitioning,k-means algorithm,lanczos method,spectral bisection,unsupervised clustering},
pages = {232--238},
title = {{Farthest centroids divisive clustering}},
year = {2008}
}
@article{codd:81,
author = {Codd, E F},
journal = {Communications of the ACM},
pages = {109--117},
title = {{Relational Database: A Practical Foundation for Productivity}},
volume = {25},
year = {1981}
}
@article{Barreno2010a,
author = {Barreno, Marco and Nelson, Blaine and Joseph, Anthony D. and Tygar, J. D.},
doi = {10.1007/s10994-010-5188-5},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Barreno et al. - 2010 - The security of machine learning.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {adversarial environments,adversarial learning,security},
month = may,
number = {2},
pages = {121--148},
title = {{The security of machine learning}},
url = {http://www.springerlink.com/index/10.1007/s10994-010-5188-5},
volume = {81},
year = {2010}
}
@inproceedings{ohara93,
author = {O'Hara, K and Shadbolt, N},
booktitle = {\{IJCAI\} '93},
pages = {188--193},
title = {{\{AI\} \{M\}odels as a \{V\}ariety of \{P\}sychological \{E\}xplanation}},
volume = {1},
year = {1993}
}
@article{basili84,
author = {Basili, V R and Weiss, D M},
journal = {Software Engineering, IEEE Transactions on},
month = nov,
number = {6},
pages = {728--738},
title = {{A Methodology for Collecting Valid Software Engineering Data}},
volume = {10},
year = {1984}
}
@inproceedings{feather08b,
author = {Feather, M S and Uckun, S and Hicks, K A},
booktitle = {Space Technology and Applications International Forum (STAIF-2008) Albuquerque, USA},
month = feb,
title = {{Technology Maturation of Integrated System Health Management}},
year = {2008}
}
@inproceedings{nag06,
author = {Nagappan, Nachiappan and Ball, Thomas and Zeller, Andreas},
booktitle = {Proceedings of the 28th international conference on Software engineering},
pages = {452--461},
series = {ICSE '06},
title = {{Mining metrics to predict component failures}},
year = {2006}
}
@phdthesis{acree80,
author = {Acree, A T},
school = {School of Information and Computer Science, Georgia Institute of Technology},
title = {{On Mutations}},
year = {1980}
}
@article{Altshuler2013,
author = {Altshuler, Bruce},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/IntroCheminformatics-VirtualScreening2007.pdf:pdf},
journal = {Biennials and Beyond},
title = {{Chapter 8}},
year = {2013}
}
@misc{me02b,
author = {Houle, M and Menzies, T and Powell, J},
booktitle = {IEEE Trans. Sofw. Eng. (submitted)},
title = {{A Fast Search for Temporal Properties of Requirements}},
year = {2002}
}
@misc{Sayyad-Shirabad+Menzies:2005,
author = {{Sayyad Shirabad}, J and Menzies, T J},
howpublished = {School of Information Technology and Engineering, University of Ottawa, Canada},
title = {{The \{PROMISE\} Repository of Software Engineering Databases.}},
year = {2005}
}
@inproceedings{SARCIA2009-2,
address = {New York, NY, USA},
author = {Sarcia', Salvatore Alessandro and Basili, Victor Robert and Cantone, Giovanni},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540464},
isbn = {978-1-60558-634-2},
pages = {1--9},
publisher = {ACM},
title = {{Using uncertainty as a model selection and comparison criterion}},
year = {2009}
}
@inproceedings{tosun10,
author = {Tosun, A and Bener, A and Kale, R},
booktitle = {Twenty-Second IAAI Conference on Artificial Intelligence},
title = {{AI-Based Software Defect Predictors: Applications and Benefits in a Case Study}},
year = {2010}
}
@misc{ithink94,
author = {Inc., High Performance Software},
title = {{iThink 3.0.5}},
year = {1994}
}
@article{Zadeh1973a,
author = {Zadeh, L A},
journal = {IEEE Transactions on Systems, Man and Cybernetics},
month = jan,
number = {1},
pages = {28--44},
title = {{Outline of a New Approach to the Analysis of Complex Systems and Decision Processes}},
volume = {SMC-3},
year = {1973}
}
@incollection{ohara97,
author = {O'Hara, K and Shadbolt, N},
booktitle = {Expertise in Context},
chapter = {19},
editor = {Feltovich, P J and Ford, K M and Hoffman, R R},
pages = {449--472},
publisher = {MIT PRess},
title = {{Inerpreting Generic Structures: Expert Systems, Expertise, and Context}},
year = {1997}
}
@article{Bayardoa,
author = {Bayardo, R.J. and Agrawal, R.},
doi = {10.1109/ICDE.2005.42},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Bayardo - Unknown - Data Privacy Through Optimal k-Anonymization.pdf:pdf},
isbn = {0-7695-2285-8},
journal = {21st International Conference on Data Engineering (ICDE'05)},
pages = {217--228},
publisher = {Ieee},
title = {{Data Privacy through Optimal k-Anonymization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1410124}
}
@book{hamscher92,
author = {Hamscher, W and Console, L and DeKleer, J},
publisher = {Morgan Kaufmann},
title = {{Readings in Model-Based Diagnosis}},
year = {1992}
}
@article{me11o,
author = {Nandeshwar, Ashutosh and Menzies, Tim and Nelson, Adam},
journal = {Expert Systems with Applications},
number = {12},
pages = {14984--14996},
title = {{Learning patterns of university student retention}},
volume = {38},
year = {2011}
}
@inproceedings{chai02bayesian,
annote = {Available from $\backslash$url\{citeseer.ist.psu.edu/chai02bayesian.html\}},
author = {Chai, K and Ng, H and Chieu, H},
booktitle = {Proceedings of SIGIR-02, 25th ACM International Conference on Research and Development in Information Retrieval},
editor = {Beaulieu, M and BaezaYates, R and Myaeng, S H and Jarvelin, K},
pages = {97--104},
title = {{Bayesian online classifiers for text classification and filtering}},
year = {2002}
}
@article{kahn85,
author = {Kahn, G and Nowlan, S and McDermott, J},
journal = {IEEE Trsansactions on Pattern Analysis and Machine Intelligence},
pages = {511--522},
title = {{Strategies for Knowledge Acquisition}},
volume = {Vol. PAMI-},
year = {1985}
}
@inproceedings{owen01,
author = {Owen, D and Menzies, T},
booktitle = {Proceedings of the First International Workshop on Model-based Requirements Engineering},
title = {{Random Search of AND-OR Graphs Representing Finite-State Models}},
year = {2001}
}
@book{gleick87,
author = {Gleick, J},
pages = {352},
publisher = {Cardinal},
title = {{Chaos}},
year = {1987}
}
@book{breuker94a,
author = {Breuker, J and {de Velde (eds)}, W Van},
publisher = {IOS Press, Netherlands},
title = {{The CommonKADS Library for Expertise Modelling}},
year = {1994}
}
@inproceedings{lutz93,
address = {San Diego, CA},
author = {Lutz, R R},
booktitle = {\{IEEE\} International Symposium on Requirements Engineering},
pages = {126--133},
publisher = {IEEE Computer Society Press},
title = {{Analyzing Software Requirements Errors in Safety-Critical, Embedded Systems}},
year = {1993}
}
@article{zlatereva94,
author = {Zlatereva, N and Preece, A},
journal = {Expert Systems with Applications},
pages = {151--167},
title = {{State of the Art in Automated Validation of Knowledge-Based Systems}},
volume = {7},
year = {1994}
}
@misc{owl09,
author = {Ciccarese, Paolo},
title = {{Scientific Discourse Relationships Ontology Specification}},
year = {2009}
}
@inproceedings{Dougherty1995,
author = {Dougherty, J. and Kohavi, R. and Sahami, M.},
booktitle = {MACHINE LEARNING-INTERNATIONAL WORKSHOP THEN CONFERENCE-},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Dougherty, Kohavi, Sahami - 1995 - Supervised and unsupervised discretization of continuous features.pdf:pdf},
pages = {194--202},
publisher = {MORGAN KAUFMANN PUBLISHERS, INC.},
title = {{Supervised and Unsupervised Discretization of Continuous Features}},
url = {http://robotics.stanford.edu/users/sahami/papers-dir/disc.pdf},
year = {1995}
}
@article{habib98,
author = {Habib-agahi, H and Malhotra, S and Quirk, J},
journal = {Journal of Parametrics},
month = nov,
pages = {59--71},
title = {{Estimating Software Productivity and Cost for \{NASA\} Projects}},
year = {1998}
}
@article{Dai2012,
abstract = {There are two crucial problems with statistical measures for sequence comparison: overlapping structures and background information of words in biological sequences. Word normalization in improved composition vector method took into account these problems and achieved better performance in evolutionary analysis. The word normalization is desirable, but not sufficient, because it assumes that the four bases A, C, T, and G occur randomly with equal chance. This paper proposed an improved word normalization which uses Markov model to estimate exact k-word distribution according to observed biological sequence and thus has the ability to adjust the background information of the k-word frequencies in biological sequences. The improved word normalization was tested with three experiments and compared with the existing word normalization. The experiment results confirm that the improved word normalization using Markov model to estimate the exact k-word distribution in biological sequences is more efficient.},
author = {Dai, Qi and Liu, Xiaoqing and Yao, Yuhua and Zhao, Fukun},
doi = {10.1007/s00726-011-0906-2},
file = {:Users/timm/svns/doc/erin/references/AlgsForDNA/MarkovWordNormAlgSequence2Dai2011.pdf:pdf},
isbn = {0072601109062},
issn = {09394451},
journal = {Amino Acids},
keywords = {Classification,Markov model,Phylogenetic analysis,Sequence comparison,Word normalization},
number = {5},
pages = {1867--1877},
pmid = {21505825},
title = {{Using Markov model to improve word normalization algorithm for biological sequence comparison}},
volume = {42},
year = {2012}
}
@article{klein93,
author = {Klein, M},
journal = {IEEE Computer},
number = {1},
pages = {39--47},
title = {{Capturing Design Rationale in Concurrent Engineering Teams}},
volume = {26},
year = {1993}
}
@article{me98d,
author = {Menzies, T J and Clancey, B},
journal = {International Journal of Human-Computer Studies},
title = {{Editorial, Special Issue on Situated Cognition}},
volume = {49},
year = {1998}
}
@inproceedings{kohavi96,
author = {Kohavi, R},
booktitle = {Proceedings of the Second International Conference on Knowledge Discovery and Data Mining},
pages = {202--207},
title = {{Scaling up the accuracy of naive-bayes classifiers: A decision-tree hybrid.}},
year = {1996}
}
@inproceedings{dejong00,
author = {DeJong, K A and Spears, W M},
booktitle = {Proc. First Workshop Parallel Problem Solving from Nature},
publisher = {Springer-Verlag},
title = {{An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms}},
year = {1990}
}
@article{VanDerMerwe2003,
author = {{Van Der Merwe}, Dw and Engelbrecht, Ap},
file = {:Users/timm/svns/doc/pso/03clusterPSO.pdf:pdf},
isbn = {0780378040},
journal = {2003 Ieee},
pages = {215--220},
title = {{Data Clustering using Particle Swarm Optimization}},
year = {2003}
}
@article{fink94,
author = {Finkelstein, A and Gabbay, D and Hunter, A and Kramer, J and Nuseibeh, B},
journal = {IEEE Transactions on Software Engineering},
number = {8},
pages = {569--578},
title = {{Inconsistency Handling In Multi-Perspective Specification}},
volume = {20},
year = {1994}
}
@article{sjoeberg05,
author = {Sjoeberg, D I K and Hannay, J E and Hansen, O and Kampenes, V B and Karahasanovic, A and Liborg, N.-K. and Rekdal, A C},
journal = {IEEE Transactions on Software Engineering},
number = {9},
pages = {733--753},
title = {{A survey of controlled experiments in software engineering}},
volume = {31},
year = {2005}
}
@inproceedings{yang02,
annote = {Available from $\backslash$url\{http://www.csse.monash.edu/\~{}webb/Files/YangWebb03.pdf\}},
author = {Yang, Y and Webb, G},
booktitle = {Proceedings of the 7th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2003)},
title = {{Weighted Proportional k-Interval Discretization for Naive-Bayes Classifiers}},
year = {2003}
}
@article{leveson91,
author = {Leveson, N and Cha, S and Shimall, T},
journal = {IEEE Software},
month = jul,
number = {7},
pages = {48--59},
title = {{Safety Verification of \{ADA\} Programs using software fault trees}},
volume = {8},
year = {1991}
}
@article{console91,
author = {Console, L and Torasso, P},
journal = {Computational Intelligence},
pages = {133--141},
title = {{A \{S\}pectrum of \{D\}efinitions of \{M\}odel-\{B\}ased \{D\}iagnosis}},
volume = {7},
year = {1991}
}
@incollection{fea03b,
abstract = { Many organizations look to research to yield new and improved products and practices. Connecting practitioners who have the need for research results to the researchers producing those results is important to guiding research and utilizing its results. Likewise, connecting researchers working on related topics to one another, and connecting practitioners with related needs to one another, is important to establishing communities of shared interests. We present an approach that helps identify fruitful such connections.},
author = {Feather, M.S. and Menzies, T. and Connelly, J.R.},
booktitle = {IEMC '03 Proceedings. Managing Technologically Driven Organizations: The Human Side of Innovation and Change},
doi = {10.1109/IEMC.2003.1252313},
isbn = {0-7803-8150-5},
month = nov,
pages = {451--455},
title = {{Identifying fruitful connections between and among researchers and practitioners}},
year = {2003}
}
@article{Seo2013,
abstract = {Context Along with expert judgment, analogy-based estimation, and algorithmic methods (such as Function point analysis and COCOMO), Least Squares Regression (LSR) has been one of the most commonly studied software effort estimation methods. However, an effort estimation model using LSR, a single LSR model, is highly affected by the data distribution. Specifically, if the data set is scattered and the data do not sit closely on the single LSR model line (do not closely map to a linear structure) then the model usually shows poor performance. In order to overcome this drawback of the LSR model, a data partitioning-based approach can be considered as one of the solutions to alleviate the effect of data distribution. Even though clustering-based approaches have been introduced, they still have potential problems to provide accurate and stable effort estimates. Objective In this paper, we propose a new data partitioning-based approach to achieve more accurate and stable effort estimates via LSR. This approach also provides an effort prediction interval that is useful to describe the uncertainty of the estimates. Method Empirical experiments are performed to evaluate the performance of the proposed approach by comparing with the basic LSR approach and clustering-based approaches, based on industrial data sets (two subsets of the ISBSG (Release 9) data set and one industrial data set collected from a banking institution). Results The experimental results show that the proposed approach not only improves the accuracy of effort estimation more significantly than that of other approaches, but it also achieves robust and stable results according to the degree of data partitioning. Conclusion Compared with the other considered approaches, the proposed approach shows a superior performance by alleviating the effect of data distribution that is a major practical issue in software effort estimation. ?? 2013 Elsevier B.V. All rights reserved.},
author = {Seo, Yeong Seok and Bae, Doo Hwan and Jeffery, Ross},
doi = {10.1016/j.infsof.2013.03.007},
file = {:Users/timm/svns/doc/13effortPartition.pdf:pdf},
isbn = {0950-5849},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Adaptive recursive data partitioning,Data distribution,Least squares regression,Software cost estimation,Software effort estimation,Software project management},
number = {10},
pages = {1710--1725},
publisher = {Elsevier B.V.},
title = {{AREION: Software effort estimation based on multiple regressions with adaptive recursive data partitioning}},
url = {http://dx.doi.org/10.1016/j.infsof.2013.03.007},
volume = {55},
year = {2013}
}
@inproceedings{jahnke97,
author = {Jahnke, J and Zundorf, A},
booktitle = {Proc. of ESEC:FSE '97 Workshop on Object-Oriented Reengineering},
title = {{Rewriting poor Design Patterns by good Design Patterns}},
year = {1997}
}
@article{Brickella,
author = {Brickell, Justin and Shmatikov, Vitaly},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Brickell, Shmatikov - Unknown - The Cost of Privacy Destruction of Data-Mining Utility in Anonymized Data Publishing Categories and Sub.pdf:pdf},
journal = {ReCALL},
title = {{The Cost of Privacy : Destruction of Data-Mining Utility in Anonymized Data Publishing Categories and Subject Descriptors}}
}
@article{schreiber96,
author = {Schreiber, A Th. and Birmingham, W P},
journal = {International Journal of Human-Computer Studies},
number = {3/4},
title = {{The Sisyphus-VT initiative}},
volume = {44},
year = {1996}
}
@article{vera93,
author = {Vera, A H and Simon, H A},
journal = {Cognitive Science},
pages = {7--48},
title = {{Situated \{A\}ction: A \{S\}ymbolic \{I\}nterpretation}},
volume = {17},
year = {1993}
}
@article{Vargha00,
abstract = {McGraw and Wong (1992) described an appealing index of effect size, called CL, which measures the difference between two populations in terms of the probability that a score sampled at random from the first population will be greater than a score sampled at random from the second. McGraw and Wong introduced this "common language effect size statistic" for normal distributions and then proposed an approximate estimation for any continuous distribution. In addition, they generalized CL to the n-group case, the correlated samples case, and the discrete values case.In the current paper a different generalization of CL, called the A measure of stochastic superiority, is proposed, which may be directly applied for any discrete or continuous variable that is at least ordinally scaled. Exact methods for point and interval estimation as well as the significance tests of the A = .5 hypothesis are provided. New generalizations ofCL are provided for the multi-group and correlated samples cases.},
author = {Vargha, Andr\'{a}s and Delaney, Harold D},
doi = {10.3102/10769986025002101},
file = {:Users/timm/svns/doc/00varghaEffectSize.pdf:pdf},
journal = {Journal of Educational and Behavioral Statistics},
number = {2},
pages = {101--132},
title = {{A Critique and Improvement of the CL Common Language Effect Size Statistics of McGraw and Wong}},
url = {http://jeb.sagepub.com/content/25/2/101.abstract},
volume = {25},
year = {2000}
}
@incollection{me10e,
author = {Menzies, Tim and Shull, Forrest},
booktitle = {Making Software: What really works, and why we believe it},
editor = {Oram, A and Wilson, G},
pages = {3--11},
publisher = {O'Reilly},
title = {{The Quest for Convincing Evidence}},
year = {2010}
}
@misc{marick97,
author = {Marick, B},
title = {{The Testing Tools Supplier List $\backslash$url\{http://www.stlabs.com/marick/faqs/tools.htm\}}},
year = {1997}
}
@article{koc13a,
author = {Kocaguneli, E and Menzies, T},
journal = {Journal of Systems and Software},
title = {{Software Effort Models Should be Assessed Via Leave-One-Out Validation}}
}
@article{voas92,
author = {Voas, J M},
journal = {IEEE Transactions of Software Engineering},
month = aug,
number = {2},
pages = {717--727},
title = {{PIE: A Dynamic Failure-Based Technique}},
volume = {18},
year = {1992}
}
@article{kitch08,
author = {Kitchenham, Barbara},
journal = {Empirical Software Engineering},
pages = {219--221},
title = {{The role of replications in empirical software engineering: a word of warning}},
volume = {13}
}
@inproceedings{me09a,
author = {Menzies, Tim and Williams, S and El-Rawas, Oussama and Boehm, B and Hihn, J},
booktitle = {ICSE'09},
title = {{How to Avoid Drastic Software Process Change (using Stochastic Stability)}},
year = {2009}
}
@article{mack85,
author = {Mackworth, A K and Frueder, E C},
journal = {Artificial Intelligence},
pages = {65--74},
title = {{The Complexity of Some Polynomial Network Consistency Algorithms for Constraint Satisfaction Problems}},
volume = {25},
year = {1985}
}
@book{popper63,
author = {Popper, K R},
publisher = {Routledge and Kegan Paul},
title = {{Conjectures and Refutations,}},
year = {1963}
}
@misc{boehm09,
author = {Boehm, B},
title = {{Future Challenges for Software Data Collection and Analysis}},
year = {2009}
}
@article{Kim2001a,
author = {Kim, Yang Sok and Kang, Sung Won and Kang, Byeong Ho and Compton, Paul},
file = {:Users/timm/svns/doc/kang09.pdf:pdf},
journal = {Knowledge Creation Diffusion Utilization},
keywords = {mcrdr,scheduling,web monitoring},
pages = {169--180},
title = {{Using Knowledge Base for Event-Driven Scheduling of Web Monitoring Systems}},
year = {2001}
}
@article{pazzani00,
author = {Pazzani, M J},
journal = {IEEE Intelligent Systems},
pages = {10--13},
title = {{Knowledge discovery from data?}},
year = {2000}
}
@article{demillo78,
author = {DeMillo, R A and Lipton, R J and Sayward, F G},
journal = {Computer},
keywords = {mutation,testing},
number = {4},
pages = {34--41},
title = {{Hints on Test Data Selection: Help for the Practicing Programmer}},
volume = {11},
year = {1978}
}
@misc{swiprolog,
author = {Wielemaker, Jan},
title = {{SWI-Prolog}}
}
@article{tosun10a,
author = {Tosun, Ayse and Bener, Ayse Basar and Turhan, Burak and Menzies, Tim},
journal = {Information \& Software Technology},
pages = {1242--1257},
title = {{Practical considerations in deploying statistical methods for defect prediction: A case study within the Turkish telecommunications industry.}},
year = {2010}
}
@book{puccia85,
author = {Levins, R and Puccia, C J},
pages = {259},
publisher = {Harvard University Press, Cambridge, Mass.},
title = {{Qualitative Modeling of Complex Systems: An Introduction to Loop Analysis and Time Averaging}},
year = {1985}
}
@article{Tanaka2009,
abstract = {By generating a large diversity of molecules, the immune system selects antibodies that bind antigens. Sharing the same approach, combinatorial biotechnologies use a large library of compounds to screen for molecules of high affinity to a given target. Understanding the properties of the best binders in the pool aids the design of the library. In particular, how does the maximum affinity increase with the size of the library or repertoire? We consider two alternative models to examine the properties of extreme affinities. In the first model, affinities are distributed lognormally, while in the second, affinities are determined by the number of matches to a target sequence. The second model more explicitly models nucleic acids (DNA or RNA) and proteins such as antibodies. Using extreme value theory we show that the logarithm of the mean of the highest affinity in a combinatorial library grows linearly with the square root of the log of the library size. When there is an upper bound to affinity, this "absolute maximum" is also approached approximately linearly with root log library size, reaching the upper limit abruptly. The design of libraries may benefit from considering how this plateau is reached as the library size is increased. Â© 2009 Elsevier Ltd. All rights reserved.},
author = {Tanaka, Mark M. and Sisson, Scott a. and King, Garry C.},
doi = {10.1016/j.jtbi.2009.07.041},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Tanaka09.pdf:pdf},
issn = {00225193},
journal = {Journal of Theoretical Biology},
keywords = {Affinity distribution,Combinatorial chemistry,Extreme value theory,Immune repertoire,Library size},
number = {2},
pages = {260--265},
pmid = {19665466},
publisher = {Elsevier},
title = {{High affinity extremes in combinatorial libraries and repertoires}},
url = {http://dx.doi.org/10.1016/j.jtbi.2009.07.041},
volume = {261},
year = {2009}
}
@misc{haaga08,
author = {Haaga, John},
title = {{Demographic and socioeconomic change in Appalachia}},
year = {2008}
}
@article{koru08,
author = {Koru, A G and Emam, K El and Zhang, D and Liu, H and Mathew, D},
journal = {Empirical Software Engineering},
month = oct,
pages = {473--498},
title = {{Theory of relative defect proneness: Replicated Studies on the Functional Form of the Size-Defect Relationship}},
year = {2008}
}
@inproceedings{Thompson99:nimbus-proto,
author = {Thompson, Jeffrey M and Heimdahl, Mats Per Erik},
booktitle = {\{IEEE\} International Workshop on Rapid System Prototyping},
pages = {172--177},
title = {{An Integrated Development Environment for Prototyping Safety Critical Systems}},
url = {citeseer.nj.nec.com/thompson99integrated.html},
year = {1999}
}
@inproceedings{park88,
author = {Park, R},
booktitle = {4th COCOMO Users\~{O} Group Meeting},
month = nov,
title = {{The Central Equations of the PRICE Software Cost Model}},
year = {1988}
}
@inproceedings{cooper01,
author = {{Kendra Cooper Tim Menzies}, Mabo Ito},
booktitle = {UBC ECE tech report},
title = {{Assessment of a Lightweight Formal Method for Specifying and Analyzing Requirements}},
year = {2001}
}
@article{musc98,
author = {Muscettola, N and Nayak, P Pandurang and Pell, B and Williams, B},
journal = {Artificial Intelligence},
month = aug,
number = {1-2},
pages = {5--48},
title = {{Remote Agent: To Boldly Go Where No AI System Has Gone Before}},
volume = {103},
year = {1998}
}
@inproceedings{me04g,
author = {Menzies, Tim and DiStefano, J and Orrego, Andres S and Chapman, Robert},
booktitle = {Proceedings of the Workshop on Predictive Software Models},
title = {{Assessing predictors of software defects}},
year = {2004}
}
@article{hori00,
annote = {(to appear)},
author = {Hori, M},
journal = {International Journal of Human Computer Studies},
title = {{Stability of a Domain-Oriented Component Library: An Explanatory Case Study}},
year = {2000}
}
@book{demarco87,
address = {New York, NY, USA},
author = {DeMarco, Tom and Lister, Timothy},
isbn = {0-932633-05-6},
publisher = {Dorset House Publishing Co., Inc.},
title = {{Peopleware: productive projects and teams}},
year = {1987}
}
@article{even75,
author = {Even, S and Tarjan, S E},
journal = {\{SIAM\} \{J\}. \{C\}omputing},
pages = {507--518},
title = {{Network \{F\}low and \{T\}esting \{G\}raph \{C\}onnectivity}},
volume = {4},
year = {1975}
}
@inproceedings{sayyad12,
author = {Sayyad, Abdel Salem and Ammar, Hany and Menzies, Tim},
booktitle = {Recommendation Systems for Software Engineering (RSSE), 2012 Third International Workshop on},
pages = {47--51},
title = {{Software Feature Model recommendations using data mining}},
year = {2012}
}
@inproceedings{men87,
author = {Menzies, T J and Worral, C},
booktitle = {Proceedings of AI '87},
title = {{Worlds in Prolog}},
year = {1987}
}
@article{Chen2007a,
abstract = {Systematic evolution of ligands by exponential enrichment (SELEX) is an in vitro combinatorial engineering approach to enrich aptamers from a library of nucleic acids ligands by iterative extraction and amplification of receptor-bound ligands. Aptamers are the selected nucleic acid ligands with high receptor-binding affinity. Typically, they are obtained in single-receptor SELEX experiments where the ligand library is incubated with receptor molecules of a single identity, e.g., a purified protein. For years, aptamers have been shown to be valuable for biomedical applications and research. To further explore the power of SELEX technology, the idea of complex SELEX was proposed to obtain multiple aptamers by incubating the ligand library with multiple species of receptors. However, the reports on complex SELEX have been few, possible due to the ignorance of the effects of experimental variables. To address this problem, computer simulations should be useful. A major task of simulating complex SELEX is to solve interdependent binding equilibrium equations for binding events among heterogeneous ligands and receptors. Although a detailed subpooling model was developed, that model could be useful to simulate complex SELEX against at most four species of receptors, because the demand of computer memory grew exponentially with the number of receptor species. Here we develop a novel, condensed subpooling model where ligands of similar characteristic affinity are first pooled together regardless of receptor-specificity, and then divided into partial subpools receptor-specifically. With this model, the need of computer memory grows only linearly with receptor number. In the simulation of SELEX against four receptors, our results are the same or very similar to earlier work. We have further simulated SELEX against 100 heterogeneous receptors. We suggest that our computation method can be applied to other research fields where binding events between heterogeneous ligands and receptors are involved. ?? 2006 Elsevier Ltd. All rights reserved.},
author = {Chen, Chi Kan and Kuo, Tai Chih},
doi = {10.1016/j.compchemeng.2006.08.015},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Chen06.pdf:pdf},
issn = {00981354},
journal = {Computers and Chemical Engineering},
keywords = {Aptamers,Computer model,Computer simulation,SELEX},
number = {9},
pages = {1007--1019},
title = {{Simulations of SELEX against complex receptors with a condensed statistical model}},
volume = {31},
year = {2007}
}
@article{me99m,
author = {Menzies, T and van Harmelen, Frank},
doi = {10.1006/ijhc.1999.0336},
issn = {1071-5819},
journal = {International Journal of HumanComputer Studies special issue on evaluation of Knowledge Engineering Techniques},
month = oct,
number = {4},
pages = {717--727},
title = {{Editorial: Evaluating Knowledge Engineering Techniques}},
volume = {51},
year = {1999}
}
@book{gardner00,
author = {Gardner, Karen M and Rush, Alexander R and Crist, Michael and Konitzer, Rober and Odell, James J and Teegarden, Bobbin and Konitzer, Robert},
isbn = {0521649986},
month = jun,
publisher = {Cambridge University Press},
title = {{Cognitive Patterns: Problem-Solving Frameworks for Object Technology}},
year = {1998}
}
@inproceedings{shi10,
author = {Shi, X and Liu, Q and Yi, P S and Zhu, R},
booktitle = {IEEE International Conference on Data Mining},
file = {:Users/timm/svns/doc/10ShiTransfer.pdf:pdf},
title = {{Transfer Learning on Heterogenous Feature Spaces via Spectral Transformation}},
year = {2010}
}
@misc{ss1,
title = {{SpaceShipOne: Soaring Toward Tomorrow, A Space.com special report}},
year = {2004}
}
@article{me99p,
abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article. ACM has opted to expose the complete List rather than only correct and linked references.},
author = {Menzies, Tim},
doi = {10.1145/318964.318969},
isbn = {1523-8822},
issn = {15238822},
journal = {Intelligence},
number = {3},
pages = {26--32},
title = {{Cost benefits of ontologies}},
volume = {10},
year = {1999}
}
@article{me07d,
annote = {$\backslash$url\{http://menzies.us/pdf/07strange.pdf\}},
author = {Menzies, T and D.Owen and Richardson, J},
journal = {IEEE Computer},
title = {{The Strangest Thing About Software}},
year = {2007}
}
@inproceedings{martin05,
address = {Washington, DC, USA},
author = {Martin, Cuauhtemoc Lopez and Pasquier, Jerome Leboeuf and Yanez, Cornelio M and Gutierrez, Agustin T},
booktitle = {ENC '05: Proceedings of the Sixth Mexican International Conference on Computer Science},
doi = {http://dx.doi.org/10.1109/ENC.2005.47},
isbn = {0-7695-2454-0},
pages = {113--120},
publisher = {IEEE Computer Society},
title = {{Software Development Effort Estimation Using Fuzzy Logic: A Case Study}},
year = {2005}
}
@book{glass97,
author = {Glass, R L},
isbn = {013673443X},
publisher = {Pearson Education},
title = {{Software Runaways: Lessons Learned from Massive Software Project Failures}},
year = {1997}
}
@article{olender92,
author = {Olender, K M and Osterweil, L J},
journal = {TOSEM},
number = {2},
pages = {21--52},
title = {{Interprocedural Static Analysis of Sequencing Constraints}},
volume = {1},
year = {1992}
}
@incollection{john92,
author = {Johnson, R},
booktitle = {Proceedings of OOPSLA'92},
publisher = {ACM SIGPLAN},
title = {{Documenting Frameworks using Patterns}},
year = {1992}
}
@article{rosen92,
author = {Rosenblum, L J and Brown, B E},
journal = {IEEE Computer Graphics and Applications},
number = {4},
pages = {18--71},
title = {{Special Issue on Visualization}},
volume = {12}
}
@misc{Blake+Merz:1998,
author = {Blake, C L and Merz, C J},
institution = {University of California, Irvine, Dept. of Information and Computer Sciences},
title = {{\{UCI\} Repository of machine learning databases}},
year = {1998}
}
@article{Tavani1999,
author = {Tavani, Herman T},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Tavani - 1999 - Informational privacy , data mining , and the Internet.pdf:pdf},
journal = {Computer},
number = {11},
pages = {137--145},
title = {{Informational privacy , data mining , and the Internet}},
volume = {39},
year = {1999}
}
@article{Watson2007,
author = {Watson, H.J. and Wixom, B.H.},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Watson, Wixom - Unknown - Intelligence.pdf:pdf;:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Watson, Wixom - 2007 - The Current State of Business Intelligence.pdf:pdf},
issn = {0018-9162},
journal = {Computer},
keywords = {businessintelligence},
mendeley-tags = {businessintelligence},
number = {9},
pages = {96--99},
publisher = {IEEE},
title = {{The current state of business intelligence}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4302625},
volume = {40},
year = {2007}
}
@article{Dai2011,
abstract = {Word-based models have achieved promising results in sequence comparison. However, as the important statistical properties of words in biological sequence, how to use the overlapping structures and background information of the words to improve sequence comparison is still a problem. This paper proposed a new statistical method that integrates the overlapping structures and the background information of the words in biological sequences. To assess the effectiveness of this integration for sequence comparison, two sets of evaluation experiments were taken to test the proposed model. The first one, performed via receiver operating curve analysis, is the application of proposed method in discrimination between functionally related regulatory sequences and unrelated sequences, intron and exon. The second experiment is to evaluate the performance of the proposed method with f-measure for clustering Hepatitis E virus genotypes. It was demonstrated that the proposed method integrating the overlapping structures and the background information of words significantly improves biological sequence comparison and outperforms the existing models.},
author = {Dai, Qi and Li, Lihua and Liu, Xiaoqing and Yao, Yuhua and Zhao, Fukun and Zhang, Michael},
doi = {10.1371/journal.pone.0026779},
file = {:Users/timm/svns/doc/erin/references/AlgsForDNA/OverlappingStructuresWordsDai2011.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {11},
pmid = {22102867},
title = {{Integrating overlapping structures and background information of words significantly improves biological sequence comparison}},
volume = {6},
year = {2011}
}
@inproceedings{drummond03,
author = {Drummond, C and Holte, R C},
booktitle = {Workshop on Learning from Imbalanced Datasets II},
title = {{C4.5, class imbalance, and cost sensitivity: why under-sampling beats over-sampling}},
year = {2003}
}
@article{yost93,
author = {Yost, G R},
journal = {IEEE Expert},
month = jun,
pages = {26--34},
title = {{Acquiring Knowledge in Soar}},
year = {1993}
}
@inproceedings{me97o,
author = {Menzies, T J and Cohen, R F and Waugh, S},
booktitle = {Banff KAW '98 workshop.},
title = {{Evaluating Conceptual Qualitative Modeling Languages}},
year = {1998}
}
@inproceedings{white09,
address = {Pittsburgh, PA, USA},
author = {White, Jules and Dougherty, Brian and Schmidt, Doulas C and Benavides, David},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {11--20},
publisher = {Carnegie Mellon University},
series = {SPLC '09},
title = {{Automated Reasoning for Multi-step Feature Model Configuration Problems}},
url = {http://dl.acm.org/citation.cfm?id=1753235.1753238},
year = {2009}
}
@inproceedings{Grechanik10,
author = {Grechanik, Mark and Csallner, Christoph and Fu, Chen and Xie, Qing},
booktitle = {ISSRE},
pages = {368--377},
title = {{Is Data Privacy Always Good for Software Testing?}},
year = {2010}
}
@article{bobrow86,
author = {Bobrow, D G and Mittal, S and Stefik, M J},
journal = {Communications of the ACM},
pages = {880--894},
title = {{Expert Systems: Perils and Promise}},
volume = {29},
year = {1986}
}
@article{Cui2005,
author = {Cui, X and Potok, Te and Palathingal, P},
file = {:Users/timm/svns/doc/pso/05clusterPSO.pdf:pdf},
journal = {\ldots  Intelligence Symposium, 2005. \ldots},
title = {{Document clustering using particle swarm optimization}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1501621},
year = {2005}
}
@article{boehm00,
author = {Boehm, B and Abts, C and Chulani, S},
journal = {Annals of Software Engineering},
pages = {177--205},
title = {{Software Development Cost Estimation Approaches - A Survey}},
volume = {10},
year = {2000}
}
@article{harel90,
author = {Harel, D},
journal = {IEEE Transactions on Software Engineering},
month = apr,
number = {4},
pages = {403--414},
title = {{STATEMATE: A Working Environment for the Development of Complex Reactive Systems}},
volume = {16},
year = {1990}
}
@article{cover67,
author = {Cover, T M and Hart, P E},
journal = {IEEE Transactions on Information Theory},
month = jan,
pages = {21--27},
title = {{Nearest neighbour pattern classification}},
year = {1967}
}
@article{Xiao2009,
author = {Xiao, Liang and Hu, Bo and Hederman, Lucy and Lewis, Paul and Dimitrov, Borislav D and Fahey, Tom},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Xiao et al. - 2009 - Towards Knowledge Sharing and Patient Privacy in a Clinical Decision Support System.pdf:pdf},
journal = {Technology},
pages = {99--104},
title = {{Towards Knowledge Sharing and Patient Privacy in a Clinical Decision Support System}},
year = {2009}
}
@inproceedings{mendes07,
annote = {Available from $\backslash$url\{http://www2007.org/paper326.php\}},
author = {E, Mendes and Dinakaran, G and Mosley, N},
booktitle = {16th International World Wide Web Conference, Banff, Canada, May 8-12},
title = {{How Valuable is it for a Web company to Use a Cross-company Cost Model, Compared to Using Its Own Single-company Model?}},
year = {2007}
}
@misc{pearce00,
author = {Pearce, A and Heinz, C and Goss, S},
booktitle = {AOD technical report, Australian DSTO},
title = {{Meeting plan recognition requirements for real-time air-mission simulations}},
year = {2000}
}
@article{dennett95,
author = {Dennett, D C},
journal = {The New York Review of Books},
month = dec,
pages = {83},
title = {{'The Mystery of Consciousness': An Exchange}},
year = {1995}
}
@article{Pareek2013,
abstract = {Humans may be exceptional learners but they have biological limitations and more- over, inductive biases similar to machine learning algorithms. This puts limits on human learning ability and on the kinds of learning tasks humans can easily han- dle. In this paper, we consider the prob- lem of âboostingâ human learners to extend the learning ability of human learners and achieve improved performance on tasks which individual humans find difficult. We consider classification (category learning) tasks, pro- pose a boosting algorithm for human learn- ers and give theoretical justifications. We conduct experiments using Amazonâs Me- chanical Turk on two synthetic datasets â a crosshair task with a nonlinear decision boundary and a gabor patch task with a lin- ear boundary but which is inaccessible to hu- man learners â and one real world dataset â the Opinion Spam detection task introduced in (Ott et al., 2011). Our results show that boosting human learners produces gains in accuracy and can overcome some fundamen- tal limitations of human learners.},
author = {Pareek, Harsh and Ravikumar, Pradeep},
file = {:Users/timm/svns/doc/13humanBoost.pdf:pdf},
journal = {Proceedings of the 30th International Conference on Machine Learning},
pages = {338--346},
title = {{Human Boosting}},
year = {2013}
}
@article{Mendes2003,
author = {Mendes, Emilia and Watson, Ian D and Triggs, Chris and Mosley, Nile and Counsell, Steve},
journal = {Empirical Software Engineering},
number = {2},
pages = {163--196},
title = {{A Comparative Study of Cost Estimation Models for Web Hypermedia Applications}},
volume = {8},
year = {2003}
}
@article{Vinterbo2004,
author = {Vinterbo, S.a.},
doi = {10.1109/TKDE.2004.31},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Vinterbo - 2004 - Privacy a machine learning view.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {approx-,combinatorial optimization,complexity,disclosure control,imation properties,machine learning,privacy},
month = aug,
number = {8},
pages = {939--948},
title = {{Privacy: a machine learning view}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1318579},
volume = {16},
year = {2004}
}
@article{Kitchenham2007,
abstract = {The objective of this paper is to determine under what circumstances$\backslash$nindividual organisations would be able to rely on cross-company based$\backslash$nestimation models. We performed a systematic review of studies that$\backslash$ncompared predictions from crosscompany models with predictions from$\backslash$nwithin-company models based on analysis of project data. Ten papers$\backslash$ncompared cross-company and within-company estimation models, however,$\backslash$nonly seven of the papers presented independent results. Of those$\backslash$nseven, three found that crosscompany models were as good as within-company$\backslash$nmodels, four found cross-company models were significantly worse$\backslash$nthan within-company models. Experimental procedures used by the studies$\backslash$nd iffered making it impossible to undertake formal meta-analysis$\backslash$nof the results. The main trend distinguishing study results was that$\backslash$nstudies with small single company data sets (i.e. <20 projects) that$\backslash$nused leaveone-out cross-validation all found that the within-company$\backslash$nmodel was significantly more accurate than$\backslash$n$\backslash$nthe cross-company model. The results of this review are inconclusive.$\backslash$nIt is clear that some organisations would be ill-served by cross-company$\backslash$nmodels whereas others would benefit. Further studies are needed,$\backslash$nbut they must be independent (i.e. based on different data bases$\backslash$nor at least different single comp any data sets). In addition, experimenters$\backslash$nneed to standardise their experimental procedures to enable formal$\backslash$nmeta-analysis.},
author = {Kitchenham, B a and Mendes, E and Travassos, G H},
doi = {http://dx.doi.org/10.1109/TSE.2007.1001},
file = {:Users/timm/svns/doc/cost/07Barbara.pdf:pdf},
isbn = {9781450324762},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
number = {5},
pages = {316--329},
title = {{Cross- vs. Within-Company Cost Estimation Studies: A Systematic Review}},
volume = {33},
year = {2007}
}
@inproceedings{edwards95,
author = {Edwards, G},
booktitle = {Poster, Australian AI '95},
title = {{New Paradigms in Expert Systems in Health Care}},
year = {1995}
}
@inproceedings{meha94,
author = {Menzies, T J and Haynes, P},
booktitle = {Tools Pacific '94},
pages = {83--92},
publisher = {Prentice-Hall},
title = {{The \{M\}ethodologies of \{M\}ethodologies; or, \{E\}valuating \{C\}urrent \{M\}ethodologies: \{W\}hy and \{H\}ow}},
year = {1994}
}
@inproceedings{Freitas98onobjective,
author = {Freitas, Alex A},
booktitle = {Proceedings of the Second European Conference on the Principles of Data Mining and Knowledge Discovery (PKDD'98},
pages = {1--9},
publisher = {Springer-Verlag},
title = {{On Objective Measures of Rule Surprisingness.}},
year = {1998}
}
@inproceedings{me10c,
author = {Kocaguneli, Ekrem and Gay, Gregory and Menzies, Tim and Yang, Ye and Keung, Jacky W.},
booktitle = {Proceedings of the IEEE/ACM international conference on Automated software engineering - ASE '10},
doi = {10.1145/1858996.1859061},
isbn = {9781450301169},
pages = {321},
title = {{When to use data from other projects for effort estimation}},
url = {http://portal.acm.org/citation.cfm?doid=1858996.1859061},
year = {2010}
}
@article{Bentley1975a,
annote = {Classic paper on k-d trees},
author = {Bentley, Jon Louis},
doi = {10.1145/361002.361007},
file = {:Users/timm/svns/doc/bentleyKDtree75.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = sep,
number = {9},
pages = {509--517},
title = {{Multidimensional binary search trees used for associative searching}},
url = {http://portal.acm.org/citation.cfm?doid=361002.361007},
volume = {18},
year = {1975}
}
@inproceedings{luqi96b,
author = {Luqi},
booktitle = {Proceedings of SEKE '96},
pages = {189--197},
title = {{Specifications in Software Prototyping}},
year = {1996}
}
@inproceedings{me99k,
abstract = {Knowledge-based engineering and computational intelligence are
expected to become core technologies in the design and manufacturing for
the next generation of space exploration missions. Yet, if one is
concerned with the reliability of knowledge based systems, studies
indicate significant disagreement regarding the amount of testing needed
for system assessment. The sizes of standard black-box test suites are
impracticably large since the black-box approach neglects the internal
structure of knowledge-based systems. On the contrary, practical results
repeatedly indicate that only a few tests are needed to sample the range
of behaviors of a knowledge-based program. In this paper, we model
testing as a search process over the internal state space of the
knowledge-based system. When comparing different test suites, the test
suite that examines larger portion of the state space is considered more
complete. Our goal is to investigate the trade-off between the
completeness criterion and the size of test suites. The results of
testing experiment on tens of thousands of mutants of real-world
knowledge based systems indicate that a very limited gain in
completeness can be achieved through prolonged testing. The use of
simple (or random) search strategies for testing appears to be as
powerful as testing by more thorough search algorithms},
author = {Menzies, T. and Cukic, B.},
booktitle = {Proceedings 11th International Conference on Tools with Artificial Intelligence},
doi = {10.1109/TAI.1999.809838},
isbn = {0-7695-0456-6},
issn = {1082-3409},
title = {{On the sufficiency of limited testing for knowledge based systems}},
year = {1999}
}
@article{denne95,
author = {Dennebouy, Y and Andersson, M and Auddino, A and Dupont, Y and Fontana, E and Gentile, M and Spaccapietra, S},
journal = {Journal of Visual Languages and Computing},
pages = {73--99},
title = {{Super: Visual Interfaces for Object and Relationship Data Models}},
year = {1995}
}
@article{Langer1969,
author = {Langer, J},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Langer - 1969 - No Title Avail.pdf:pdf},
journal = {Annals of Physics},
number = {1},
title = {{No Title Avail}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:No+Title\#0},
year = {1969}
}
@article{hall11,
author = {Hall, Tracy and Beecham, Sarah and Bowes, David and Gray, David and Counsell, Steve},
journal = {IEEE Transactions on Software Engineering},
number = {PrePrints},
title = {{A Systematic Review of Fault Prediction Performance in Software Engineering}},
year = {2011}
}
@misc{boehm09,
author = {Boehm, B},
title = {{Keynote address, PROMISE'09}},
year = {2009}
}
@article{Chen2008a,
abstract = {Structure learning of Bayesian networks is a well-researched but computationally hard task. We present an algorithm that integrates an information-theory-based approach and a scoring-function-based approach for learning structures of Bayesian networks. Our algorithm also makes use of basic Bayesian network concepts like d-separation and condition independence. We show that the proposed algorithm is capable of handling networks with a large number of variables. We present the applicability of the proposed algorithm on four standard network data sets and also compare its performance and computational efficiency with other standard structure-learning methods. The experimental results show that our method can efficiently and accurately identify complex network structures from data.},
author = {Chen, Xue Wen and Anantha, Gopalakrishna and Lin, Xiaotong},
doi = {10.1109/TKDE.2007.190732},
file = {:Users/timm/svns/doc/08k2.pdf:pdf},
isbn = {1041-4347},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Classification,Data mining,Machine learning},
number = {5},
pages = {628--640},
title = {{Improving bayesian network structure learning with mutual information-based node ordering in the K2 algorithm}},
volume = {20},
year = {2008}
}
@book{pol85,
author = {Politakis, P},
publisher = {Pitman},
title = {{Empirical Analsis for Expert Systems}},
year = {1985}
}
@misc{me09g,
abstract = {Solutions to non-linear requirements engineering problems may be "brittle"; i.e. small changes may dramatically alter solution effectiveness. Hence, it is not enough to just generate solutions to requirements problems- we must also assess solution robustness. The KEYS2 algorithm can generate decision ordering diagrams. Once generated, these diagrams can assess solution robustness in linear time. In experiments with real-world requirements engineering models, we show that KEYS2 can generate decision ordering diagrams in O(N             2). When assessed in terms of terms of (a) reducing inference times, (b) increasing solution quality, and (c) decreasing the variance of the generated solution, KEYS2 out-performs other search algorithms (simulated annealing, ASTAR, MaxWalkSat).},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09keys2.pdf\}},
author = {Gay, Gregory and Menzies, Tim and Jalali, Omid and Mundy, Gregory and Gilkerson, Beau and Feather, Martin and Kiper, James},
booktitle = {Automated Software Engineering},
doi = {10.1007/s10515-009-0059-7},
isbn = {1051500900597},
issn = {09288910},
number = {1},
pages = {87--116},
title = {{Finding robust solutions in requirements models}},
volume = {17},
year = {2010}
}
@article{Holte2006,
author = {Holte, Robert C.},
doi = {10.1214/088342306000000033},
file = {:Users/timm/svns/doc/holte06.pdf:pdf},
issn = {0883-4237},
journal = {Statistical Science},
month = feb,
number = {1},
pages = {24--26},
title = {{Elaboration on Two Points Raised in âClassifier Technology and the Illusion of Progressâ}},
url = {http://projecteuclid.org/Dienst/getRecord?id=euclid.ss/1149600842/},
volume = {21},
year = {2006}
}
@inproceedings{rao95,
author = {Roa, A and Georgeff, M},
booktitle = {Proceedings of the First International Conference on Multi-Agent Systems, San Francisco, CA, June},
title = {{BDI agents: From theory to practice}},
year = {1995}
}
@misc{heeger98,
author = {Heeger, D},
title = {{Signal Detection Theory}},
year = {1998}
}
@article{5601760,
author = {Das, S and Suganthan, P N},
doi = {10.1109/TEVC.2010.2059031},
file = {:Users/timm/svns/doc/11de-state-of-the-art.pdf:pdf},
issn = {1089-778X},
journal = {Evolutionary Computation, IEEE Transactions on},
month = feb,
number = {1},
pages = {4--31},
title = {{Differential Evolution: A Survey of the State-of-the-Art}},
volume = {15},
year = {2011}
}
@misc{bsc99,
author = {Page, Web},
title = {{No Title}}
}
@article{Yangyuoru2012,
abstract = {Aptamers that bind small molecules can serve as basic biosensing platforms. Evaluation of the binding constant between an aptamer and a small molecule helps to determine the effectiveness of the aptamer-based sensors. Binding constants are often measured by a series of experiments with varying ligand or aptamer concentrations. Such experiments are time-consuming, material nonprudent, and prone to low reproducibility. Here, we use laser tweezers to determine the dissociation constant for aptamer-ligand interactions at the single-molecule level from only one ligand concentration. Using an adenosine 5'-triphosphate disodium salt (ATP) binding aptamer as an example, we have observed that the mechanical stabilities of aptamers bound with ATP are higher than those without a ligand. Comparison of the change in free energy of unfolding ($\Delta$G(unfold)) between these two aptamers yields a $\Delta$G of 33 Â± 4 kJ/mol for the binding. By applying a Hess-like cycle at room temperature, we obtained a dissociation constant (K(d)) of 2.0 Â± 0.2 $\mu$M, a value consistent with the K(d) obtained from our equilibrated capillary electrophoresis (CE) (2.4 Â± 0.4 $\mu$M) and close to that determined by affinity chromatography in the literature (6 Â± 3 $\mu$M). We anticipate that our laser tweezers and CE methodologies may be used to more conveniently evaluate the binding between receptors and ligands and also serve as analytical tools for force-based biosensing.},
author = {Yangyuoru, Philip M. and Dhakal, Soma and Yu, Zhongbo and Koirala, Deepak and Mwongela, Simon M. and Mao, Hanbin},
doi = {10.1021/ac300427d},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Yangyuoru12.pdf:pdf},
isbn = {0003-2700},
issn = {00032700},
journal = {Analytical Chemistry},
number = {12},
pages = {5298--5303},
pmid = {22702719},
title = {{Single-molecule measurements of the binding between small molecules and DNA aptamers}},
volume = {84},
year = {2012}
}
@book{sha83,
address = {Cambridge, Massachusetts},
author = {Shapiro, E Y},
pages = {232},
publisher = {MIT Press},
title = {{Algorithmic program debugging}},
year = {1983}
}
@inproceedings{rymon94an,
author = {Rymon, R},
booktitle = {Annals of Math. and A.I., special issue on Model-Based Diagnosis},
title = {{An SE-tree-based Prime Implicant Generation Algorithm}},
volume = {11},
year = {1994}
}
@misc{Norvig2011,
author = {Norvig, Peter},
booktitle = {New York Post},
title = {{The machine age}},
url = {http://www.getcited.org/pub/102527552},
year = {2011}
}
@article{Lisurek2010,
abstract = {Success in small molecule screening relies heavily on the preselection of compounds. Here, we present a strategy for the enrichment of chemical libraries with potentially bioactive compounds integrating the collected knowledge of medicinal chemistry. Employing a genetic algorithm, substructures typically occurring in bioactive compounds were identified using the World Drug Index. Availability of compounds containing the selected substructures was analysed in vendor libraries, and the substructure-specific sublibraries were assembled. Compounds containing reactive, undesired functional groups were omitted. Using a diversity filter for both physico-chemical properties and the substructure composition, the compounds of all the sublibraries were ranked. Accordingly, a screening collection of 16,671 compounds was selected. Diversity and chemical space coverage of the collection indicate that it is highly diverse and well-placed in the chemical space spanned by bioactive compounds. Furthermore, secondary assay-validated hits presented in this study show the practical relevance of our library design strategy.},
author = {Lisurek, Michael and Rupp, Bernd and Wichard, J\"{o}rg and Neuenschwander, Martin and {Von Kries}, J. P. and Frank, Ronald and Rademann, J\"{o}rg and K\"{u}hne, Ronald},
doi = {10.1007/s11030-009-9187-z},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Lisurek2009.pdf:pdf},
isbn = {1381-1991},
issn = {13811991},
journal = {Molecular Diversity},
keywords = {Bio informatics,Drug design,High throughput screening,Library design,Molecular diversity},
number = {2},
pages = {401--408},
pmid = {19685275},
title = {{Design of chemical libraries with potentially bioactive molecules applying a maximum common substructure concept}},
volume = {14},
year = {2010}
}
@incollection{porter80,
author = {Porter, M F},
booktitle = {Readings in Information Retrieval, San Francisco: Morgan Kaufmann},
editor = {Jones, K Sparck and Willet, P},
isbn = {1-55860-454-4},
title = {{An algorithm for suffix stripping}},
year = {1997}
}
@article{box51,
journal = {Journal of the Royal Statistical Society Series},
number = {1},
pages = {1--45},
title = {{On the Experimental Attainment of Optimum Conditions (with discussion)}},
volume = {B13},
year = {1951}
}
@inproceedings{shaw92,
author = {Shaw, M L G and Gaines, B R},
booktitle = {7th Banff Knowledge Acquisition for Knowledge-Based Systems Workshop, Banff, Canada},
pages = {24.1--24.18},
title = {{Repgrid-net: Combining Conceptual Modeling with Electronic Mail to Provide Decision Support}},
year = {1992}
}
@inproceedings{fea00,
author = {Feather, M S and Cornford, S L and Larson, T W},
booktitle = {15th IEEE International Conference on Automated Software Engineering, Grenoble, France},
month = sep,
pages = {309--312},
title = {{Combining the Best Attributes of Qualitative and Quantitative Risk Management Tool Support}},
year = {2000}
}
@article{jorg04,
author = {Jorgensen, M},
journal = {Journal of Systems and Software},
number = {1-2},
pages = {37--60},
title = {{A Review of Studies on Expert Estimation of Software Development Effort}},
volume = {70},
year = {2004}
}
@article{Clifton2004a,
address = {New York, New York, USA},
author = {Clifton, Chris and KantarcioÇ§lu, Murat and Doan, AnHai and Schadow, Gunther and Vaidya, Jaideep and Elmagarmid, Ahmed and Suciu, Dan},
doi = {10.1145/1008694.1008698},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Clifton et al. - 2004 - Privacy-Preserving Data Integration and Sharing.pdf:pdf},
isbn = {158113908X},
journal = {Proceedings of the 9th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery - DMKD '04},
pages = {19},
publisher = {ACM Press},
title = {{Privacy-preserving data integration and sharing}},
url = {http://portal.acm.org/citation.cfm?doid=1008694.1008698},
year = {2004}
}
@book{davi91,
author = {Davison, A},
publisher = {The PARLOG Group, Dept. of Computing, Imperial College, London},
title = {{Design Issues for Logic-Programming-based Object-Oriented Languages}},
year = {1991}
}
@incollection{gordon2001,
author = {Gordon, Diana F},
booktitle = {Formal Approaches to Agent-Based Systems},
pages = {278--293},
publisher = {Springer},
title = {{APT Agents: Agents that are adaptive predictable and timely}},
year = {2001}
}
@article{Chen2007,
abstract = {Systematic evolution of ligands by exponential enrichment (SELEX) is an important technology in combinatorial chemistry and molecular biology of developing high affinity target-binding molecules (aptamers) from highly complex nucleic acid ligand libraries. Schematically, the SELEX is a series of iterative rounds of operations where in each operational round ligands are incubated with the target (e.g., a purified protein), and target-binding ligands are extracted and amplified. In the recent development of biological study and drug discovery, by incubating ligand libraries with complex target mixtures (e.g., cell fragments), the SELEX experiments have been explored to simultaneously develop aptamers for targets embedded in target mixtures: the complex SELEX. While holding the considerable advantages of saving experimental resources, practicing the complex SELEX has often accompanied with unstable experimental performances. It is therefore important to understand the behaviors of the new application. In this paper, we develop stochastic computer model, and customized computational algorithm to numerically mimic the complex SELEX. We model the ligand selection through the probability of ligand binding to complex targets at the binding equilibrium, and efficiency of separating target-binders for amplification. The customized computational algorithm allows us to simulate real experiments that operate on huge ligand libraries. We evaluate the ligand evolution, and aptamer enrichment of complex SELEX under various experimental conditions by stochastic simulations, and theorize the simulated results. We argue that the stochastic effects, which were not previously captured in the studies of complex SELEX, may significantly affect the results of experiments. ?? 2007 Elsevier Ireland Ltd. All rights reserved.},
author = {Chen, Chi K.},
doi = {10.1016/j.cmpb.2007.05.008},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Chen07.pdf:pdf},
isbn = {0169-2607},
issn = {01692607},
journal = {Computer Methods and Programs in Biomedicine},
keywords = {Aptamer,Complex SELEX,Simulations,Stochastic computer model},
number = {3},
pages = {189--200},
pmid = {17624471},
title = {{Complex SELEX against target mixture: Stochastic computer model, simulation, and analysis}},
volume = {87},
year = {2007}
}
@incollection{bucsmi89,
author = {Buchanan, B G and Smith, R G},
booktitle = {The Handbook of Artificial Intelligence, Volume 4},
editor = {{A. Barr}, P R Cohen and Feigenbaum, E A},
pages = {149--192},
publisher = {Addison-Wesley},
title = {{Fundamentals of \{E\}xpert \{S\}ystems}},
volume = {4},
year = {1989}
}
@inproceedings{garm95,
author = {Gardin, F and Meltzer, B},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and {N.H. Narayanan}, B Chandrasekaran},
pages = {669--688},
publisher = {The AAAI Press},
title = {{Analogical Representations of Naive Physics}},
year = {1995}
}
@article{me05c,
author = {Chen, Zhihao and Menzies, Tim and Port, Dan and Boehm, Barry},
journal = {IEEE Software},
month = nov,
title = {{Finding the Right Data for Software Cost Modeling}},
year = {2005}
}
@misc{addy99,
author = {Addy, E A},
institution = {Software Research Lab, NASA IV\&V Facility, Fairmont, West Virginia},
title = {{A White Paper on Software Risk Assessment}},
year = {1999}
}
@inproceedings{vanlamsweerde98integrating,
author = {van Lamsweerde, Axel and Letier, Emmanuel},
booktitle = {Proceedings of the\~{}20th\~{}International Conference on Software Engineering},
pages = {53--62},
publisher = {IEEE Computer Society Press},
title = {{Integrating Obstacles in Goal-Driven Requirements Engineering}},
year = {1998}
}
@article{hamlet90,
author = {Hamlet, D and Taylor, R},
journal = {IEEE Transactions on Software Engineering},
month = dec,
number = {12},
pages = {1402--1411},
title = {{Partition Testing Does Not Inspire Confidence}},
volume = {16},
year = {1990}
}
@article{lark87,
author = {Larkin, J H and Simon, H A},
journal = {Cognitive Science},
pages = {65--99},
title = {{Why a Diagram is (Sometimes) Worth Ten Thousand Words}},
year = {1987}
}
@online{promise12,
author = {Menzies, Tim and Caglayan, Bora and He, Zhimin and Kocaguneli, Ekrem and Krall, Joe and Peters, Fayola and Turhan, Burak},
month = jun,
title = {{The PROMISE Repository of empirical software engineering data}},
url = {http://promisedata.googlecode.com},
year = {2012}
}
@article{martin01,
author = {Martin, R H and {D. M}, Raffo},
journal = {Journal of Systems and Software},
number = {3},
title = {{Application of a Hybrid Process Simulation Model to a Software Development Project}},
volume = {59},
year = {2001}
}
@article{shn08,
author = {Shneiderman, B},
journal = {Science},
month = mar,
number = {7},
pages = {1349--1350},
title = {{Science 2.0}},
volume = {319},
year = {2008}
}
@article{Middleton2009,
author = {Middleton, Grant and Peyton, Liam and Kuziemsky, Craig and Eze, Ben},
doi = {10.1109/CONGRESS.2009.9},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Middleton et al. - 2009 - A Framework for Continuous Compliance Monitoring of eHealth Processes.pdf:pdf},
isbn = {978-1-4244-5344-3},
journal = {2009 World Congress on Privacy, Security, Trust and the Management of e-Business},
month = aug,
pages = {152--160},
publisher = {Ieee},
title = {{A Framework for Continuous Compliance Monitoring of eHealth Processes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5341705},
year = {2009}
}
@inproceedings{nusmv,
author = {Cimatti, A and Clarke, E and Giunchiglia, E and Giunchiglia, F and Pistore, M and Roveri, M and Sebastiani, R and Tacchella, A},
booktitle = {\{P\}roc. \{I\}nternational \{C\}onference on \{C\}omputer-\{A\}ided \{V\}erification},
title = {{\{N\}u\{SMV\} \{V\}ersion 2: \{A\}n \{O\}pen\{S\}ource \{T\}ool for \{S\}ymbolic \{M\}odel \{C\}hecking}},
year = {2002}
}
@article{slaughter98,
author = {{S. Slaughter}, D Harter and Krishnan, M},
journal = {Communications of the ACM},
month = aug,
pages = {67--73},
title = {{Evaluating the Cost of Software Quality}},
year = {1998}
}
@inproceedings{Haiduc2010a,
abstract = {One of the main challenges faced by today's developers is keeping up with the staggering amount of source code that needs to be read and understood. In order to help developers with this problem and reduce the costs associated with it, one solution is to use simple textual descriptions of source code entities that developers can grasp easily, while capturing the code semantics precisely. We propose an approach to automatically determine such descriptions, based on automated text summarization technology.},
address = {Cape Town, South Africa},
annote = {Laura. Fixed on 10/04/2012},
author = {{Haiduc Sonia}, Aponte Jairo and Marcus, Andrian},
booktitle = {32nd ACM/IEEE International Conference on Software Engineering (ICSE'10), NIER track},
keywords = {summarization indexing SEVERE},
pages = {223--226},
title = {{Supporting Program Comprehension with Source Code Summarization}},
volume = {2}
}
@article{Leung2009,
abstract = {BACKGROUND: Recognizing regulatory sequences in genomes is a continuing challenge, despite a wealth of available genomic data and a growing number of experimentally validated examples. METHODOLOGY/PRINCIPAL FINDINGS: We discuss here a simple approach to search for regulatory sequences based on the compositional similarity of genomic regions and known cis-regulatory sequences. This method, which is not limited to searching for predefined motifs, recovers sequences known to be under similar regulatory control. The words shared by the recovered sequences often correspond to known binding sites. Furthermore, we show that although local word profile clustering is predictive for the regulatory sequences involved in blastoderm segmentation, local dissimilarity is a more universal feature of known regulatory sequences in Drosophila. CONCLUSIONS/SIGNIFICANCE: Our method leverages sequence motifs within a known regulatory sequence to identify co-regulated sequences without explicitly defining binding sites. We also show that regulatory sequences can be distinguished from surrounding sequences by local sequence dissimilarity, a novel feature in identifying regulatory sequences across a genome. Source code for WPH-finder is available for download at http://rana.lbl.gov/downloads/wph.tar.gz.},
author = {Leung, Garmay and Eisen, Michael B.},
doi = {10.1371/journal.pone.0006901},
file = {:Users/timm/svns/doc/erin/references/AlgsForDNA/WordProfileSimilarityLeung2009.pdf:pdf},
isbn = {1932-6203 (Electronic)$\backslash$n1932-6203 (Linking)},
issn = {19326203},
journal = {PLoS ONE},
number = {9},
pmid = {19730735},
title = {{Identifying cis-regulatory sequences by word profile similarity}},
volume = {4},
year = {2009}
}
@incollection{carrol96,
author = {Carrol, J M and Rosson, M B},
booktitle = {Design Rationale: Concepts, Techniques, and Use},
editor = {Moran, T P and Carroll, J M},
pages = {351--372},
publisher = {Lawerence Erlbaum Associates},
title = {{Deliberated Evolution: Stalking the View Matcher in Design Space}},
year = {1996}
}
@book{coles74,
author = {Coles, H S},
publisher = {Sussex University Press},
title = {{Thinking About the Future: A Critique of the Limits to Growth}},
year = {1974}
}
@book{booch91,
author = {Booch, G},
publisher = {Benjamin/ Cummings},
title = {{Object-Oriented Design with Applications}},
year = {1991}
}
@article{Aha1991,
author = {Aha, D.W. and Kibler, Dennis and Albert, M.K.},
doi = {10.1007/BF00153759},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Aha, Kibler, Albert - 1991 - Instance-based learning algorithms.pdf:pdf},
issn = {0885-6125},
journal = {Machine learning},
keywords = {incremental learning,instance-based concept descriptions,learning theory,supervised concept learning},
month = jan,
number = {1},
pages = {37--66},
publisher = {Springer},
title = {{Instance-based learning algorithms}},
url = {http://www.springerlink.com/index/G4QV6511520X3041.pdf},
volume = {6},
year = {1991}
}
@article{TURHAN2009,
address = {Tarrytown, NY, USA},
author = {Turhan, Burak and Kocak, Gozde and Bener, Ayse},
doi = {http://dx.doi.org/10.1016/j.eswa.2008.12.028},
issn = {0957-4174},
journal = {Expert Syst. Appl.},
number = {6},
pages = {9986--9990},
publisher = {Pergamon Press, Inc.},
title = {{Data mining source code for locating software bugs: A case study in telecommunication industry}},
volume = {36},
year = {2009}
}
@inproceedings{lutz99,
author = {Lutz, R and Woodhouse, R},
booktitle = {1st International Software Assurance Certification Conference (ISACC'99)},
title = {{Bi-directional Analysis for Certification of Safety-Critical Software}},
year = {1999}
}
@article{Garson2008,
author = {Garson, Kathryn and Kn, Canada and Adams, Carlisle},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Garson, Kn, Adams - 2008 - Security and Privacy System Architecture for an e-Hospital Environment.pdf:pdf},
journal = {Network},
keywords = {authentication,health care,policy-based encryption,privacy},
pages = {122--130},
title = {{Security and Privacy System Architecture for an e-Hospital Environment}},
year = {2008}
}
@article{Dishaw19999,
author = {Dishaw, Mark T and Strong, Diane M},
journal = {Information \& Management},
number = {1},
pages = {9--21},
title = {{Extending the technology acceptance model with task-technology fit constructs}},
volume = {36},
year = {1999}
}
@article{yildiz06,
author = {Yildiz, O T and Alpaydin, E},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {3},
pages = {392--402},
title = {{Ordering and Finding the Best of K>2 Supervised Learning Algorithms}},
volume = {28},
year = {2006}
}
@article{deb00a,
author = {Deb, Kalyanmoy and Pratap, Amrit and Agarwal, Sameer and Meyarivan, T},
journal = {IEEE Transactions on Evolutionary Computation},
pages = {182--197},
title = {{A Fast Elitist Multi-Objective Genetic Algorithm: NSGA-II}},
volume = {6},
year = {2002}
}
@article{wittig97,
author = {Wittig, G and Finnie, G},
journal = {Information and Software Technology},
number = {7},
pages = {469--476},
title = {{Estimating Software Development Effort with Connectionist Models}},
volume = {39},
year = {1997}
}
@article{ren07,
author = {Ren, J and Taylor, R N},
journal = {Communications of the ACM},
month = jun,
pages = {81--85},
title = {{Automatic and Versatile Publications Ranking for Research Instituions and Scholars}},
year = {2007}
}
@book{Society2008,
author = {Society, International},
file = {:Users/timm/svns/doc/cost/07Ispahandbook.pdf:pdf},
isbn = {0972020470},
keywords = {Cost Estimating$\backslash$r$\backslash$nParametrics$\backslash$r$\backslash$nCost Analysis},
number = {April},
title = {{Parametric Estimating}},
year = {2008}
}
@article{kitch07,
author = {Kitchenham, B A and Mendes, E and Travassos, G H},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Kitchenham, Mendes, Travassos - 2007 - Cross versus Within-Company Cost Estimation Studies A Systematic Review.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
month = may,
pages = {316--329},
title = {{Cross- vs. Within-Company Cost Estimation Studies: A Systematic Review}},
year = {2007}
}
@book{jacobson92,
author = {Jacobson, I and Christerson, M and Jonsson, P and Overgaard, G},
pages = {520},
publisher = {Addison-Wesley},
title = {{Object-Oriented Software Engineering: A Use Case Driven Approach}},
year = {1992}
}
@inproceedings{maxwelldata,
address = {Englewood Cliffs, NJ},
author = {Maxwell, K D},
publisher = {Prentice-Hall},
title = {{Applied Statistics for Software Managers}},
year = {2002}
}
@inproceedings{votta93,
author = {Votta, L G},
booktitle = {Proceedings of ACM SIGSOFT Symp. Foundations of Software Engineering, Assoc. for Computing Machinery},
month = dec,
title = {{Does Every Inspection Need a Meeting?}},
year = {1993}
}
@book{date95,
author = {Date, C J},
publisher = {Addison-Wesley},
title = {{An Introduction to Database Systems}},
volume = {6},
year = {1995}
}
@article{jorgensen05a,
author = {J\o rgensen, M},
journal = {IEEE Software},
number = {3},
title = {{Practical Guidelines for Expert Judgment Based-Software-Effort Estimation}},
volume = {22},
year = {2005}
}
@article{seidewitz03,
author = {Seidewitz, Ed},
journal = {IEEE Software},
number = {5},
pages = {26--32},
title = {{What Models Mean}},
volume = {20},
year = {2003}
}
@inproceedings{baile74,
author = {Baile, C A},
booktitle = {Control of Feeding and the Regulation of Energy Balance, FederatedProceedings},
pages = {1166--1175},
title = {{Putative neurotransmitters in the hypothalmus and feeding}},
volume = {33},
year = {1974}
}
@incollection{zeitz97,
author = {Zeitz, C M},
booktitle = {Expertise in Context},
chapter = {2},
editor = {Feltovich, P J and Ford, K M and Hoffman, R R},
pages = {43--65},
publisher = {MIT PRess},
title = {{Some Concrete Advantages of Abstraction: How Experts' representations Facilitate Reasoning}},
year = {1997}
}
@article{Lin2013,
abstract = {The Internet has provided IS researchers with the opportunity to conduct studies with extremely large sam- ples, frequently well over 10,000 observations. There are many advantages to large samples, but researchers using statistical inference must be aware of the p-value problem associated with them. In very large samples, p-values go quickly to zero, and solely relying on p-values can lead the researcher to claim support for results of no practical significance. In a survey of large sample IS research, we found that a significant number of papers rely on a low p-value and the sign of a regression coefficient alone to support their hypotheses. This research commentary recommends a series of actions the researcher can take to mitigate the p-value problem in large samples and illustrates them with an example of over 300,000 camera sales on eBay. We believe that addressing the p-value problem will increase the credibility of large sample IS research as well as provide more insights for readers.},
author = {Lin, Mingfeng and Lucas, Henry C},
doi = {http://dx.doi.org/10.1287/isre.2013.0480},
file = {:Users/timm/svns/doc/13problemsWithPValues.pdf:pdf},
issn = {1047-7047},
journal = {Information Systems Research},
keywords = {2 weeks for 1,2012,alok gupta,and was with the,authors,effect size,empirical modeling,history,in advance,inference,on august 15,p -value,practical significance,published online in articles,revision,senior editor,statistical significance,this paper was received},
pages = {1--12},
title = {{Too Big to Fail : Large Samples and the p -Value Problem}},
volume = {7047},
year = {2013}
}
@inproceedings{soloway87,
author = {Soloway, E and Bachant, J and Jensen, K},
booktitle = {\{AAAI\} '87},
pages = {824--829},
title = {{Assessing the Maintainability of XCON-in-RIME: Coping with the Problems of a VERY Large Rule-Base}},
year = {1987}
}
@book{putnam92,
author = {Putnam, L and Myers, W},
publisher = {Yourdon Press Computing Series},
title = {{Measures for Excellence}},
year = {1992}
}
@inproceedings{keung2008c,
address = {Washington, DC, USA},
author = {Keung, Jacky Wai and Kitchenham, Barbara},
booktitle = {ASWEC '08: Proceedings of the 19th Australian Conference on Software Engineering},
isbn = {978-0-7695-3100-7},
pages = {229--238},
publisher = {IEEE Computer Society},
title = {{Experiments with Analogy-X for Software Cost Estimation}},
year = {2008}
}
@inproceedings{burch90,
author = {Burch, J R and Clark, E M},
booktitle = {Fifth Annual IEEE Symposium on Logic in Computer Science},
title = {{Symbolic Model Checking: 10\^{}\{20\} States and Beyond}},
year = {1990}
}
@article{me89za,
author = {Me, Tim},
journal = {AI Magazine},
number = {2},
pages = {53--61},
title = {{An Investigation of AI and Expert Systems Literature : 1 980-l 984}},
volume = {10},
year = {1989}
}
@article{raffo05b,
abstract = {In this paper, we present a 'forward-looking' decision support framework that integrates up-to-date metrics data with simulation models of the software development process in order to support the software project management control function. This forward-looking approach (called the PROMPT method) provides predictions of project performance and the impact of various management decisions. Tradeoffs among performance measures are accomplished using outcome based control limits (OBCLs) and are augmented using multi-criteria utility functions and financial measures of performance to evaluate various process alternatives. The decision support framework enables the program manager to plan, manage and track current software development activities in the short term and to take corrective action as necessary to bring the project back on track. The model provides insight on potential performance impacts of the proposed corrective actions. A real world example utilizing a software process simulation model is presented. ?? 2005 Elsevier B.V. All rights reserved.},
author = {Raffo, David M.},
doi = {10.1016/j.infsof.2005.09.004},
isbn = {0950-5849},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Control limits,Multi-criteria decision making,Project management,Simulation,Software measurement repositories,Software process modeling},
month = dec,
number = {15},
pages = {1009--1017},
title = {{Software project management using PROMPT: A hybrid metrics, modeling and utility framework}},
volume = {47},
year = {2005}
}
@article{Manegold2010a,
author = {Manegold, S. and Laurent, D. and Lupu, M. and Onose, N. and R\'{e}, C. and Sans, V. and Senellart, P. and Wu, T. and Shasha, D. and Manolescu, I. and Afanasiev, L. and Feng, J. and Gou, G. and Hadjieleftheriou, M. and Harizopoulos, S. and Kalnis, P. and Karanasos, K.},
doi = {10.1145/1815933.1815944},
file = {:Users/timm/svns/doc/manegold09.pdf:pdf;:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Manegold et al. - 2010 - Repeatability \& workability evaluation of SIGMOD 2009(2).pdf:pdf},
issn = {01635808},
journal = {ACM SIGMOD Record},
month = dec,
number = {3},
pages = {40},
title = {{Repeatability \& workability evaluation of SIGMOD 2009}},
url = {http://portal.acm.org/citation.cfm?doid=1815933.1815944},
volume = {38},
year = {2010}
}
@article{ferens98,
author = {Ferens, D and Christensen, D},
journal = {Journal of Parametrics},
month = nov,
number = {1},
pages = {55--74},
title = {{Calibrating Software Cost Models to \{D\}epartment of \{D\}efense \{D\}atabase: A Review of Ten Studies}},
volume = {18},
year = {1998}
}
@inproceedings{me02m,
author = {Menzies, T and Pearce, A and {C. Heinze} and Goss, S},
booktitle = {Formal Aspects of Agent-Based Systems},
title = {{What is an agent and why should I care?}},
year = {2002}
}
@article{me99q,
abstract = {Small-scale software projects usually can't afford to implement
time-consuming and expensive tests. However, the authors show that, in a
surprisingly large number of cases, a small number of randomly selected
tests will adequately probe the software},
author = {Menzies, T. and Gukic, B.},
doi = {10.1109/52.877876},
issn = {0740-7459},
journal = {IEEE Software},
number = {5},
pages = {107--112},
title = {{When to test less [software testing]}},
volume = {17},
year = {2000}
}
@misc{BET93,
author = {Di\~{}Battista, G and Eades, P and Tamassia, R and Tollis, I},
institution = {Department of Computer Science, Brown University},
title = {{Algorithms for Drawing Graphs: An Annotated Bibliography}},
year = {1993}
}
@inproceedings{Haiduc2012b,
abstract = {Text retrieval approaches have been used to address many software engineering tasks. In most cases, their use involves issuing a textual query to retrieve a set of relevant software artifacts from the system. The performance of all these approaches depends on the quality of the given query (i.e., its ability to describe the information need in such a way that the relevant software artifacts are retrieved during the search). Currently, the only way to tell that a query failed to lead to the expected software artifacts is by investing time and effort in analyzing the search results. In addition, it is often very difficult to ascertain what part of the query leads to poor results. We propose a novel pre-retrieval metric, which reflects the quality of a query by measuring the specificity of its terms. We exemplify the use of the new specificity metric on the task of concept location in source code. A preliminary empirical study shows that our metric is a good effort predictor for text retrieval-based concept location, outperforming existing techniques from the field of natural language document retrieval.},
address = {Zurich, Switzerland},
annote = {Laura. Fixed on 09/24/2012},
author = {{Haiduc Sonia}, Bavota Gabriele Oliveto Rocco Marcus Andrian and {De Lucia}, Andrea},
booktitle = {34th IEEE/ACM International Conference on Software Engineering (ICSE'12)},
keywords = {searching queries concept\_feature\_concern\_location},
pages = {1273--1276},
publisher = {IEEE},
title = {{Evaluating the Specificity of Text Retrieval Queries to Support Software Engineering Tasks}}
}
@inproceedings{me96b,
annote = {Available from $\backslash$url\{http:/menzies.us/pdf/96ok.pdf\}},
author = {Menzies, T J},
booktitle = {Ecai '96},
title = {{On the Practicality of Abductive Validation}},
year = {1996}
}
@article{Dv2007,
author = {Dv, Vroxwlrqv and Lqlwldo, D Q and Dqg, Srlqw and Rwkhuv, W K H and Jxlglqj, D V and Lpsohphqwdwlrq, Vrsklvwlfdwhg and Wkh, R I and Lq, Dssurdfk and Wkh, Idfw and Lq, Ryhudoo and Dqg, Klvwru and Qrw, Grhv and Wudfn, Nhhs and Wr, Hvvhqwldo and Wkh, Hqulfklqj and Lqwhooljhqfh, Vzdup and Gr, R Z},
file = {:Users/timm/svns/doc/pso/07psoScatter.pdf:pdf},
isbn = {1424413400},
journal = {Evolutionary Computation},
pages = {2289--2296},
title = {{6Fdwwhu 362 Â± \$ 0Ruh (Iihfwlyh )Rup Ri 3Duwlfoh 6Zdup 2Swlpl]Dwlrq}},
year = {2007}
}
@inproceedings{HAYES2005-2,
address = {New York, NY, USA},
author = {Hayes, Jane Huffman and Dekhtyar, Alex},
booktitle = {TEFSE '05: Proceedings of the 3rd international workshop on Traceability in emerging forms of software engineering},
doi = {http://doi.acm.org/10.1145/1107656.1107661},
isbn = {1-59593-243-7},
pages = {20--23},
publisher = {ACM},
title = {{Humans in the traceability loop: can't live with 'em, can't live without 'em}},
year = {2005}
}
@article{me09d,
annote = {Avialable from $\backslash$url\{http://menzies.us/pdf/09ir4pc.pdf\}},
author = {Etzkorn, L and Menzies, T},
journal = {Empirical Software Engineering},
number = {1},
pages = {1--4},
title = {{Editorial, Special issue on information retrieval for program comprehension}},
volume = {14},
year = {2009}
}
@inproceedings{dekhtyar04,
abstract = {Software compiles and therefore is characterized by a parseable grammar. Natural language text rarely conforms to prescriptive grammars and therefore is much harder to parse. Mining parseable structures is easier than mining less structured entities. Therefore, most work on mining repositories focuses on software, not natural language text. Here, we report experiments with mining natural language text (requirements documents) suggesting that: (a) mining natural language is not too difficult, so (b) software repositories should routinely be augmented with all the natural language text used to develop that software.},
author = {Dekhtyar, a.},
booktitle = {"International Workshop on Mining Software Repositories (MSR 2004)" W17S Workshop - 26th International Conference on Software Engineering},
doi = {10.1049/ic:20040470},
isbn = {0 86341 432 X},
number = {917},
pages = {22--26},
title = {{Text is software tool}},
url = {http://www.mendeley.com/research/text-is-software-too/},
volume = {2004},
year = {2004}
}
@book{hansen97,
author = {Hansen, G A},
publisher = {Prentice Hall},
title = {{Automating Business Process Reengineering}},
year = {1997}
}
@inproceedings{petke14,
author = {Petke, Justyna and Harman, Mark and Langdon, William and Weimer, Westley},
booktitle = {European Conference on Genetic Programming (EuroGP)},
title = {{Using Genetic Improvement \& Code Transplants to Specialise a C++ Program to a Problem Class}},
year = {2014}
}
@misc{yost92,
annote = { Digital Equipment Co., Marlboro, Massachusetts},
author = {Yost, G R},
title = {{Configuring \{E\}levator \{S\}ystems}},
year = {1992}
}
@misc{schmann07,
author = {Schumann, J and Gundy-Burlet, K and Menzies, T},
institution = {Computer Science, West Virginia University},
title = {{Learning Predictors \& Controllers for Software Functional Requirements}},
year = {2007}
}
@book{brownston92,
author = {Brownston, L and Farell, R and Kant, E and Martin, N},
publisher = {Addison-Wesley},
title = {{Programming Expert Systems in OPS5: An Introduction to Rule-Based Programming}},
year = {1985}
}
@inproceedings{me92n,
author = {Menzies, T J and Compton, P and Mahidadia, A},
booktitle = {Communicating Scientific and Technical Knowledge, an AAAI '92 workshop},
title = {{Communicating Research Models of Human Physiology using Qualitative Compartmental Modeling}},
year = {1992}
}
@inproceedings{me03r,
abstract = { Model-based software has become quite popular in recent years, making its way into a broad range of areas, including the aerospace industry. The models provide an easy graphical interface to develop systems, which can generate the sometimes tedious code that follows. While there are many tools available to assess standard procedural code, there are limits to the testing of model-based systems. A major problem with the models are that their internals often contain gray areas of unknown system behavior. These possible behaviors form what is known as a data cloud, which is an overwhelming range of possibilities of a system that can overload analysts (Menzies et al., 2003). With large data clouds, it is hard to demonstrate which particular decision leads to a particular outcome. Even if definite decisions can't be made, it is possible to reduce the variance of and condense the clouds (Menzies et al., 2003). This paper presents two case studies; one with a simple illustrative model and another with a more complex application. The TAR3 treatment learning tool summarizes the particular attribute ranges that selects for particular behaviors of interest, reducing the data clouds.},
author = {Geletko, D. and Menzies, T.},
booktitle = {28th Annual NASA Goddard Software Engineering Workshop, 2003. Proceedings.},
doi = {10.1109/SEW.2003.1270729},
isbn = {0-7695-2064-2},
month = dec,
title = {{Model-based software testing via incremental treatment learning}},
year = {2003}
}
@book{boehm81,
author = {Boehm, B},
publisher = {Prentice Hall},
title = {{Software Engineering Economics}},
year = {1981}
}
@inproceedings{laird00,
author = {Laird, J and van Lent, M},
booktitle = {AAAI},
title = {{Interactive Computer Games: Human-level AI's Killer Application}},
year = {2000}
}
@misc{moberg92,
author = {Moberg, D},
title = {{Personal comminication}},
year = {1992}
}
@inproceedings{rod12,
author = {{D. Rodriguez}, I Herraiz and Harrison, R},
booktitle = {Proceedings RAISE'12},
title = {{On Software Engineering Repositories and Their Open Problems}},
year = {2012}
}
@misc{me99e,
annote = {in preperation},
author = {Menzies, T and Cukic, B},
howpublished = {NASA/WVU IVV tech report},
month = mar,
title = {{An Average-Case Model of Reachability}},
year = {1999}
}
@article{krauskopf90,
author = {Krauskopgf, R and Rash, F},
journal = {IEEE Potentials},
pages = {12--14},
title = {{Independent Verification and Validation}},
year = {1990}
}
@article{doyle79,
author = {Doyle, J},
journal = {Artificial Intelligence},
pages = {231--272},
title = {{A Truth Maintenance System}},
volume = {12},
year = {1979}
}
@misc{pricing05,
annote = {Available from $\backslash$url\{http://fast.faa.gov/pricing/c1919-5.htm\}},
author = {System, U S Government Federal Aviation Administration Acquisition},
title = {{Software Cost Estimating Methdologies}},
year = {2005}
}
@article{Taouji2012,
abstract = {Aptamers represent an important class of synthetic protein binders useful for proteome-wide applications. The identification and characterisation of such molecules have been greatly facilitated by the development of Systematic Evolution of Ligands by Exponential Amplification (SELEX). Since then numerous advances and alternatives to improve efficient aptamer discovery have been reported. In the present manuscript we discuss the recent advances performed around the SELEX approach that may help to expand the availability of new aptamers and the subsequent applications that may be developed. Â© 2011 Elsevier B.V.},
author = {Taouji, Sa\"{\i}d and Dausse, Eric and Evad\'{e}, Laetitia and {Di Primo}, Carmelo and Toulm\'{e}, Jean Jacques and Chevet, Eric},
doi = {10.1016/j.nbt.2011.11.017},
file = {:Users/timm/svns/doc/erin/references/Aptamer/Taouji2012.pdf:pdf},
isbn = {1871-6784},
issn = {18716784},
journal = {New Biotechnology},
number = {5},
pages = {550--554},
pmid = {22178698},
title = {{Advances in binder identification and characterisation: The case of oligonucleotide aptamers}},
volume = {29},
year = {2012}
}
@book{glas95,
author = {Glasgow, J and Narayanan, H and (eds), B Chandrasekaran},
publisher = {MIT Press},
title = {{Diagrammatic Reasoning : Cognitive and Computational Perspectives}},
year = {1995}
}
@inproceedings{me96i,
author = {Menzies, T J},
booktitle = {Proceedings of the Eighth International Conference on Software Engineering and Knowledge Engineering},
isbn = {0-9641699-3-2},
publisher = {Knowledge Systems Institute, Skokie, Illinois, USA},
title = {{Visual Programming, Knowledge Engineering, and Visual Programming}},
year = {1996}
}
@article{Fenton99,
address = {New York, NY, USA},
author = {Fenton, Norman E and Neil, Martin},
doi = {10.1016/S0164-1212(99)00035-7},
issn = {0164-1212},
journal = {J. Syst. Softw.},
month = jul,
number = {2-3},
pages = {149--157},
publisher = {Elsevier Science Inc.},
title = {{Software Metrics: Success, Failures and New Directions}},
url = {http://dx.doi.org/10.1016/S0164-1212(99)00035-7},
volume = {47},
year = {1999}
}
@article{yu79,
author = {Yu, V L and Fagan, L M and Wraith, S M and Clancey, W J and Scott, A C and Hanigan, J F and Blum, R L and Buchanan, B G and Cohen, S N},
journal = {Journal of American Medical Association},
pages = {1279--1282},
title = {{Antimicrobial \{S\}election by a \{C\}omputer: a \{B\}linded \{E\}valuation by \{I\}nfectious \{D\}isease \{E\}xperts}},
volume = {242},
year = {1979}
}
@article{stout97,
author = {Stout, Bryan},
journal = {Game Developer Magazine},
number = {7},
title = {{Smart Moves: Intelligent Pathfinding}},
url = {http://www.gamasutra.com/features/19970801/pathfinding.htm},
year = {1997}
}
@article{Bhumiratana,
author = {Bhumiratana, Bhume and Bishop, Matt},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Bhumiratana, Bishop - Unknown - Privacy Aware Data Sharing Balancing the Usability and Privacy of Datasets.pdf:pdf},
journal = {Policy},
keywords = {data anonymization,data shar-,information security,ing,ontology,privacy,security policy},
title = {{Privacy Aware Data Sharing : Balancing the Usability and Privacy of Datasets}}
}
@inproceedings{PS91,
author = {Palsberg, J and Schwartzbach, M},
booktitle = {Proc. OOPSLA'91, ACM SIGPLAN Sixth Annual Conference on Object-Oriented Programming Systems, Languages and Applications},
pages = {146--161},
title = {{Object-Oriented Type Inference}},
year = {1991}
}
@article{ma12,
author = {Ma, Ying and Luo, Guangchun and Zeng, Xue and Chen, Aiguo},
file = {:Users/timm/svns/doc/transfer/12ma.pdf:pdf},
journal = {Inf. Softw. Technol.},
month = mar,
number = {3},
pages = {248--256},
title = {{Transfer learning for cross-company software defect prediction}},
volume = {54},
year = {2012}
}
@article{Meda2010b,
abstract = {When designing a business workflow, it is customary practice to create the control flow structure first and to ensure its correctness. Information about the flow of data is introduced subsequently into the workflow and its correctness is independently verified. Improper specification of data requirements of tasks and XOR splits can cause problems such as wrong branching at XOR splits and the failure of tasks to execute. Here we present a graph traversal algorithm called GTforDF for detecting data flow errors in both nested and unstructured workflows, and illustrate its operation on realistic examples. Two of these have interconnected loops and are free of control flow errors, and the third one is an unstructured loop-free workflow. Our approach extends and generalizes data flow verification methods that have been recently proposed. It also makes use of the concept of corresponding pairs lately introduced in control flow verification. It thus has the potential for development into a unified algorithmic procedure for the concurrent detection of control flow and data flow errors. The correctness of the algorithm has been proved theoretically. It has also been tested experimentally on many examples.},
author = {Meda, Hema S. and Sen, Anup Kumar and Bagchi, Amitava},
issn = {1936-1955},
journal = {Journal of Data and Information Quality (JDIQ)},
keywords = {Corresponding pair,Data flow errors,Workflow management,pareto},
mendeley-tags = {pareto},
number = {1},
title = {{On Detecting Data Flow Errors in Workflows}},
url = {http://portal.acm.org/citation.cfm?id=1805286.1805290},
volume = {2},
year = {2010}
}
@misc{beed01,
annote = {Available from $\backslash$url\{http://www.agilemanifesto.org/\}},
author = {Et. al., M Beedle},
title = {{Manifesto for Agile Software Development}},
year = {2001}
}
@inproceedings{MAIR2005,
address = {New York, NY, USA},
author = {Mair, Carolyn and Shepperd, Martin and J\o rgensen, Magne},
booktitle = {PROMISE '05: Proceedings of the 2005 workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1083165.1083166},
isbn = {-159593-125-2},
pages = {1--6},
publisher = {ACM},
title = {{An analysis of data sets used to train and validate cost prediction systems}},
year = {2005}
}
@misc{blazy99,
author = {Blazy, L B},
month = mar,
title = {{\{O\}\{S\}\{M\}\{A\} Software Assurance Program Level 1 Technical Program Plan, Ames Research Center - Code \{I\}\{T\} Software Independent Verification \& Validation Facility \{F\}airmont, \{W\}est \{V\}irginia}},
year = {1999}
}
@article{me06a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06qrre.pdf\}},
author = {Menzies, T and Richardson, J},
journal = {IEEE Computer},
month = oct,
title = {{Making Sense of Requirements, Sooner}},
year = {2006}
}
@article{dekleer93,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {63--67},
title = {{A perspective on assumption-based truth maintenance}},
volume = {59},
year = {1993}
}
@book{hof80,
author = {Hofstadter, D R},
pages = {777},
publisher = {Penguin Books},
title = {{G\"{o}del, Escher, Bach: An Eternal Golden Braid}},
year = {1980}
}
@inproceedings{ag98,
author = {Askira-Gelman, Irit},
booktitle = {Hawaii International Conference on System Sciences},
title = {{Knowledge Discovery: Comprehensibility of the Results}},
year = {1998}
}
@inproceedings{pos97,
author = {Pos, A and Akkermans, H and Straatman, R and Wijngaards, N},
booktitle = {Workshop on Problem-Solving Methods for Knowledge-based Systems, IJCAI '97, August 23.},
title = {{Redesign Problem Solving}},
year = {1997}
}
@article{Bhatti2006a,
address = {New York, New York, USA},
author = {Bhatti, Rafae and Moidu, Khalid and Ghafoor, Arif},
doi = {10.1145/1183568.1183577},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Bhatti - 2006 - Policy-Based Security Management for Federated Healthcare Databases ( or RHIOs ).pdf:pdf},
isbn = {1595935282},
journal = {Proceedings of the international workshop on Healthcare information and knowledge management - HIKM '06},
keywords = {federated healthcare architecture,privacy and disclosure policy,role based access control},
pages = {41},
publisher = {ACM Press},
title = {{Policy-based security management for federated healthcare databases (or RHIOs)}},
url = {http://portal.acm.org/citation.cfm?doid=1183568.1183577},
year = {2006}
}
@article{Thomas1994,
author = {Thomas, M and McGarry, F},
journal = {IEEE Software},
month = jul,
number = {4},
pages = {2},
title = {{Top-down vs. Bottom-up Process Improvement}},
volume = {11},
year = {1994}
}
@inproceedings{lam00,
author = {van Lamsweerde, A},
booktitle = {Proceedings ICSE2000, Limmerick, Ireland},
pages = {5--19},
title = {{Requirements Engineering in the Year 00: A Research Perspective}},
year = {2000}
}
@article{Lin2004,
author = {Lin, Xiaodong and Clifton, Chris and Zhu, Michael},
doi = {10.1007/s10115-004-0148-7},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Lin, Clifton, Zhu - 2004 - Privacy-preserving clustering with distributed EM mixture modeling.pdf:pdf},
issn = {0219-1377},
journal = {Knowledge and Information Systems},
keywords = {clustering,privacy,security},
month = dec,
number = {1},
pages = {68--81},
title = {{Privacy-preserving clustering with distributed EM mixture modeling}},
url = {http://www.springerlink.com/index/10.1007/s10115-004-0148-7},
volume = {8},
year = {2004}
}
@article{frakes95,
author = {Frakes, W B and Fox, C J},
journal = {Communications of the ACM},
month = jun,
number = {6},
pages = {75--87},
title = {{Sixteen Questions About Software Reuse}},
volume = {38},
year = {1995}
}
@book{ebb85,
author = {Ebbinghaus, H},
publisher = {New York: Dover},
title = {{Memory: A contribution to experimental psychology.}}
}
@book{tufte86,
address = {Cheshire, CT, USA},
author = {Tufte, Edward R},
publisher = {Graphics Press},
title = {{The Visual Display of Quantitative Information}},
year = {1986}
}
@article{Boutsidis2008,
abstract = {Principal Components Analysis (PCA) is the predominant linear dimensionality reduction technique, and has been widely applied on datasets in all scientific domains. We consider, both theoretically and empirically, the topic of unsupervised feature selection for PCA, by leveraging algorithms for the so-called Column Subset Selection Problem (CSSP). In words, the CSSP seeks the "best" subset of exactly k columns from an m x n data matrix A, and has been extensively studied in the Numerical Linear Algebra community. We present a novel two-stage algorithm for the CSSP. From a theoretical perspective, for small to moderate values of k, this algorithm significantly improves upon the best previously-existing results 24, 12 for the CSSP. From an empirical perspective, we evaluate this algorithm as an unsupervised feature selection strategy in three application domains of modern statistical data analysis: finance, document-term data, and genetics. We pay particular attention to how this algorithm may be used to select representative or landmark features from an object-feature matrix in an unsupervised manner. In all three application domains, we are able to identify k landmark features, i.e., columns of the data matrix, that capture nearly the same amount of information as does the subspace that is spanned by the top k "eigenfeatures."},
author = {Boutsidis, Christos and Mahoney, Michael W. and Drineas, Petros},
doi = {10.1145/1401890.1401903},
file = {:Users/timm/svns/doc/08pca4fss.pdf:pdf},
isbn = {9781605581934},
journal = {Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '08},
keywords = {pca,random sampling,subset selection},
pages = {61},
title = {{Unsupervised feature selection for principal components analysis}},
url = {http://portal.acm.org/citation.cfm?doid=1401890.1401903},
year = {2008}
}
@inproceedings{me09j,
abstract = {This paper augments Boehm-Turner's model of agile and plan-based software development augmented with an AI search algorithm. The AI search finds the key factors that predict for the success of agile or traditional plan-based software developments. According to our simulations and AI search algorithm: (1) in no case did agile methods perform worse than plan-based approaches; (2) in some cases, agile performed best. Hence, we recommend that the default development practice for organizations be an agile method. The simplicity of this style of analysis begs the question: why is so much time wasted on evidence-less debates on software process when a simple combination of simulation plus automatic search can mature the dialog much faster?},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09pom2.pdf\}},
author = {Lemon, Bryan and Riesbeck, Aaron and Menzies, Tim and Price, Justin and D\&apos;Alessandro, Joseph and Carlsson, Rikard and Prifiti, Tomi and Peters, Fayola and Lu, Hiuhua and Port, Dan},
booktitle = {ASE2009 - 24th IEEE/ACM International Conference on Automated Software Engineering},
doi = {10.1109/ASE.2009.42},
isbn = {9780769538914},
issn = {1527-1366},
pages = {580--584},
title = {{Applications of simulation and AI search: Assessing the relative merits of agile vs traditional software development}},
year = {2009}
}
@article{silver92b,
author = {Silverman, B G and Mezher, T M},
journal = {AI Magazine},
pages = {45--62},
title = {{Expert critics in engineering design: lessons learned and research needs}},
year = {1992}
}
@inproceedings{MENDE2009,
address = {New York, NY, USA},
author = {Mende, Thilo and Koschke, Rainer},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540448},
isbn = {978-1-60558-634-2},
pages = {1--10},
publisher = {ACM},
title = {{Revisiting the evaluation of defect prediction models}},
year = {2009}
}
@book{Witten2005,
author = {Witten, Ian and Frank, Eibe},
edition = {2nd},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Witten, Frank - 2005 - Data Mining Practical machine learning tools and techniques.pdf:pdf},
isbn = {0120884070},
publisher = {Morgan Kaufmann Pub},
title = {{Data Mining: Practical machine learning tools and techniques}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=QTnOcZJzlUoC\&amp;oi=fnd\&amp;pg=PA3\&amp;dq=Data+Mining,+Practical+Machine+Learning+Tools+and+Techniques\&amp;ots=3ggzbtYjPh\&amp;sig=DEHWQVS0TZMOzl5d2hjBu5WoHQg},
year = {2005}
}
@article{Haiduc2013,
abstract = {There are more than twenty distinct software engineering tasks addressed with text retrieval (TR) techniques, such as, traceability link recovery, feature location, refactoring, reuse, etc. A common issue with all TR applications is that the results of the retrieval depend largely on the quality of the query. When a query performs poorly, it has to be reformulated and this is a difficult task for someone who had trouble writing a good query in the first place. We propose a recommender (called Refoqus) based on machine learning, which is trained with a sample of queries and relevant results. Then, for a given query, it automatically recommends a reformulation strategy that should improve its performance, based on the properties of the query. We evaluated Refoqus empirically against four baseline approaches that are used in natural language document retrieval. The data used for the evaluation corresponds to changes from five open source systems in Java and C++ and it is used in the context of TR-based concept location in source code. Refoqus outperformed the baselines and its recommendations lead to query performance improvement or preservation in 84\% of the cases (in average).},
author = {Haiduc, Sonia and Bavota, Gabriele and Marcus, Andrian and Oliveto, Rocco and {De Lucia}, Andrea and Menzies, Tim},
doi = {10.1109/ICSE.2013.6606630},
file = {:Users/timm/svns/doc/13query.pdf:pdf},
isbn = {9781467330763},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
keywords = {Query Reformulation,Text Retrieval},
pages = {842--851},
title = {{Automatic query reformulations for text retrieval in software engineering}},
year = {2013}
}
@article{yann00,
abstract = {In this study we present a review of the emerging field of meta-knowledge components as practised over the past decade among a variety of practitioners. We use the artificially-defined term `meta-knowledge' to encompass all those different but overlapping notions used by the Artificial Intelligence and Software Engineering communities to represent reusable modelling frameworks: ontologies, problem-solving methods, experience factories and experience bases, patterns, to name a few. We then elaborate on how meta-knowledge is deployed in the context of system's design to improve its reliability by consistency checking, enhance its reuse potential, and manage its knowledge sharing. We speculate on its usefulness and explore technologies for supporting deployment of meta-knowledge. We argue that, despite the different approaches being followed in systems design by divergent communities, meta-knowledge is present in all cases, in a tacit or explicit form, and its utilisation depends on pragmatic aspects which we try to identify and critically review on criteria of effectiveness.},
author = {Kalfoglou, Yannis and Menzies, Tim and Althoff, Klaus-Dieter and Motta, Enrico},
doi = {10.1017/S0269888900004033},
issn = {0269-8889},
journal = {The Knowledge Engineering Review},
month = dec,
number = {4},
title = {{Meta-Knowledge in systems design: panacea ...or undelivered promise?}},
url = {http://eprints.soton.ac.uk/260533/},
volume = {15},
year = {2000}
}
@inproceedings{rittel72,
author = {Rittel, H W J},
booktitle = {Design Methods Group 5th Anniversary Report: DMG Occasional Paper, 1, 5-10.},
title = {{Second generation design methods}},
year = {1972}
}
@article{rubin92,
author = {Rubin, K S and Goldberg, A},
journal = {Communications of the ACM},
number = {9},
title = {{Object Behavior Analysis}},
volume = {35},
year = {1992}
}
@misc{prevue,
author = {$\backslash$urlhttp://www.pacorp.com, Performance Awareness Corporation},
title = {{preVue-C/S}},
year = {1998}
}
@book{paulk95,
author = {Paulk, M C and Weber, C V and Curtis, B and Chriss, M B},
publisher = {Addison-Wesley},
title = {{The Capability Maturity Model: Guidelines for Improving the Software Process}},
year = {1995}
}
@article{Maldonado2006,
abstract = {This review is dedicated to a survey on molecular similarity and diversity. Key findings reported in recent investigations are selectively highlighted and summarized. Even if this overview is mainly centered in chemoinformatics, applications in other areas (pharmaceutical and medical chemistry, combinatorial chemistry, chemical databases management, etc.) are also introduced. The approaches used to define and describe the concepts of molecular similarity and diversity in the context of chemoinformatics are discussed in the first part of this review. We introduce, in the second and third parts, the descriptions and analyses of different methods and techniques. Finally, current applications and problems are enumerated and discussed in the last part.},
author = {Maldonado, Ana G. and Doucet, J. P. and Petitjean, Michel and Fan, Bo T.},
doi = {10.1007/s11030-006-8697-1},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Maldonado2004.pdf:pdf},
isbn = {1381-1991},
issn = {13811991},
journal = {Molecular Diversity},
keywords = {Chemoinformatics,Classification methods,Clustering methods,Combinatorial chemistry,Compound selection,Descriptors,Drug design,High throughput screening,Library design,Molecular diversity,Molecular similarity,Partitioning,Selection methods},
number = {1},
pages = {39--79},
pmid = {16404528},
title = {{Molecular similarity and diversity in chemoinformatics: From theory to applications}},
volume = {10},
year = {2006}
}
@inproceedings{me03h,
author = {Chiang, E and Menzies, T},
booktitle = {Prosim '03},
title = {{Position Paper: Summary of simulations for Very Early Lifecycle Quality Evaluations}},
year = {2003}
}
@inproceedings{cold94,
author = {Coldwell, J M and Wrightson, G},
booktitle = {Artificial Intelligence: Sowing the Seeds for the Future; Proceedings of AI '94},
editor = {Zhang, C and Debenham, J and Lukose, D},
pages = {275--282},
publisher = {World Scientific},
title = {{Lemmas and Links in Analystic Tableau}},
year = {1994}
}
@article{K.Beck2005,
abstract = {JUnit is a simple Java testing framework to write tests for you Java application. This tutorial gives you an overview of the features of JUnit and shows a little example how you can write tests for your Java application.},
archivePrefix = {arXiv},
arxivId = {0201616416},
author = {K.Beck, C.Andres},
eprint = {0201616416},
file = {:Users/timm/svns/doc/00beck.pdf:pdf},
isbn = {0201616416},
issn = {20161641},
journal = {Writing},
pages = {85--110},
pmid = {17337672},
title = {{Extreme Programming Explained}},
url = {http://www.laliluna.de/assets/tutorials/junit-testing-en.pdf},
year = {2005}
}
@article{silver93,
author = {Silverman, B G and Wenig, R G},
journal = {The Knowledge Engineering Review},
number = {4},
pages = {309--328},
title = {{Engineering Expert Critics for Cooperative Systems}},
volume = {8},
year = {1993}
}
@book{davi91,
author = {Davison, A},
publisher = {The PARLOG Group, Dept. of Computing, Imperial College, London},
title = {{Design Issues for Logic-Programming-based Object-Oriented Languages}},
year = {1991}
}
@book{mead72,
author = {Meadows, D H and Meadows, D L and Randers, J and Behrens, W W},
publisher = {Potomac Associates},
title = {{The Limits to Growth}},
year = {1972}
}
@article{gick80,
author = {Gick, M L and Holyoak, K J},
journal = {Cognitive Psychology},
pages = {306--355},
title = {{Analogic Problem Solving}},
volume = {12},
year = {1980}
}
@article{minku13,
author = {Minku, Leandro L and Yao, Xin},
journal = {Information \{\&\} Software Technology},
number = {8},
pages = {1512--1528},
title = {{Ensembles and locality: Insight on improving software effort estimation}},
volume = {55},
year = {2013}
}
@misc{bobntim2,
author = {Cohen, R F and Menzies, T},
number = {TR95-20},
title = {{Reverse Engineering a Software Engineering Curriculum}},
year = {1995}
}
@article{Debnath2005,
abstract = {A rapid development in diverse areas of molecular biology and genetic engineering resulted in emergence of variety of tools. These tools are not only applicable to basic researches being carried out world over, but also exploited for precise detection of abnormal conditions in plants, animals and human body. Although a basic researcher is well versed with few techniques used by him/her in the laboratory, they may not be well acquainted with methodologies, which can be used to work out some of their own research problems.The picture is more blurred when the molecular diagnostic tools are to be used by physicians, scientists and technicians working in diagnostic laboratories in hospitals, industry and academic institutions. Since many of them are not trained in basics of these methods, they come across several gray areas in understanding of these tools. The accurate application of molecular diagnostic tools demands in depth understanding of the methodology for precise detection of the abnormal condition of living body.To meet the requirements of a good book on molecular diagnostics of students, physicians, scientists working in agricultural, veterinary, medical and pharmaceutical sciences, it needs to expose the reader lucidly to:Give basic science behind commonly used tools in diagnosticsExpose the readers to detailed applications of these tools andMake them aware the availability of such diagnostic toolsThe book will attract additional audience of pathologists, medical microbiologists, pharmaceutical sciences, agricultural scientists and veterinary doctors if the following topics are incorporated at appropriate places in Unit II or separately as a part of Unit-III in the book.Molecular diagnosis of diseases in agricultural cropsMolecular diagnosis of veterinary diseases.Molecular epidemiology, which helps to differentiate various epidemic strains and sources of disease outbreaks. Even in different units of the same hospital, the infections could be by different strains of the same species and the information becomes valuable for infection control strategies.Drug resistance is a growing problem for bacterial, fungal and parasitic microbes and the molecular biology tools can help to detect the drug resistance genes without the cultivation and in vitro sensitivity testing. Molecular diagnostics offers faster help in the selection of the proper antibiotic for the treatment of tuberculosis, which is a major problem of the in the developing world. The conventional culture and drug sensitivity testing of tuberculosis bacilli is laborious and time consuming, whereas molecular diagnosis offers rapid drug resistant gene detection even from direct clinical samples. The same approach for HIV, malaria and many more diseases needs to be considered.Molecular diagnostics in the detection of diseases during foetal life is an upcoming area in the foetal medicine in case of genetic abnormalities and infectious like TORCH complex etc.The book will be equally useful to students, scientists and professionals working in the field of molecular diagnostics.},
author = {Debnath, Mousumi and Prasad, Godavarthi B K S and Bisen, Prakash S.},
doi = {10.1007/978-90-481-3261-4},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Debnath10.pdf:pdf},
isbn = {9781588293565},
journal = {Molecular Diagnostics: Promises and Possibilities},
keywords = {amplification,aptamers,combinatorial library,dna aptamers,dna selection,monolex,oligomers,oligonucleotide library,pathogens,rna aptamers,selex,therapeutics},
pages = {1--520},
title = {{Molecular diagnostics: Promises and possibilities}},
year = {2005}
}
@inproceedings{decu95,
author = {DeCuyper, J and Keymeulen, D and Steels, L},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and {N.H. Narayanan}, B Chandrasekaran},
pages = {731--752},
publisher = {The AAAI Press},
title = {{A Hybrid Architecture for Modeling Liquid Behavior}},
year = {1995}
}
@misc{me02b,
author = {Houle, M and Menzies, T and Powell, J},
booktitle = {IEEE Transactions on Software Engineering (submitted)},
title = {{A Fast Search for Temporal Properties of Requirements}},
year = {2002}
}
@inproceedings{kautz97,
annote = {Available on-line at $\backslash$url\{http://citeseer.ist.psu.edu/168907.html\}},
author = {Kautz, H and Selman, B and Jiang, Y},
booktitle = {The Satisfiability Problem: Theory and Applications, New York, NY},
editor = {Gu, D and Du, J and Pardalos, P},
pages = {573--586},
title = {{A general stochastic approach to solving problems with hard and soft constraints}},
year = {1997}
}
@inproceedings{newell72,
author = {Newell, A},
booktitle = {Visual Information Processing},
editor = {Chase, W G},
pages = {283--308},
publisher = {New York: Academic Press},
title = {{You can't play 20 Questions with Nature, and Win}},
year = {1972}
}
@inproceedings{me96l,
author = {Ramakrishnan, S and Menzies, T and Hasslinger, M and Bok, P and Mccarthy, H and Devakadadcham, B and Moulder, D},
booktitle = {Proceedings of Tools-Pacific, Melbourne},
publisher = {Prentice-Hall},
title = {{On Building an Effective Measurement System for OO Software Process}},
year = {1996}
}
@book{rubinstein04,
author = {Rubinstein, R Y and Kroese, D P},
publisher = {Springer-Verlag},
title = {{The Cross-Entropy Method: A Unified Approach to Combinatorial Optimization, Monte-Carlo Simulation, and Machine Learning}},
year = {2004}
}
@article{michie68,
author = {Michie, D},
journal = {Nature},
pages = {19--22},
title = {{Memo Functions and Machine Learning}},
volume = {218},
year = {1968}
}
@article{adams92,
author = {{Dennis A. Adams}, R Ryan Nelson and Todd, Peter A},
journal = {MIS Quarterly},
number = {2},
pages = {227--247},
title = {{Perceived Usefulness, Ease of Use, and Usage of Information Technology: A Replication}},
volume = {16},
year = {1992}
}
@misc{cocomoII,
annote = {$\backslash$url\{http://sunset.usc.edu/COCOMOII/cocomox.html\#downloads\}},
author = {Abts, C and Clark, B and Devnani-Chulani, S and Horowitz, E and Madachy, R and Reifer, D and Selby, R and Steece, B},
institution = {Center for Software Engineering, USC,},
title = {{\{COCOMO II\} Model Definition Manual}},
year = {1998}
}
@misc{raffo05,
author = {Raffo, D},
title = {{Personnel communication}},
year = {2005}
}
@book{BERGE89,
author = {Berge, Claude},
publisher = {North-Holland},
title = {{Hypergraphs}},
year = {1989}
}
@article{jorgensen06,
author = {J\o rgensen, Magne and Mol\o kken-\O stvold, Kjetil},
journal = {Information \{\&\} Software Technology},
number = {4},
pages = {297--301},
title = {{How large are software cost overruns? A review of the 1994 CHAOS report}},
volume = {48},
year = {2006}
}
@inproceedings{me03k,
author = {Menzies, T and Stefano, J S Di and Chapman, M},
booktitle = {IEEE Metrics '03},
title = {{Learning Early Lifecycle \{IVV\} Quality Indicators}},
year = {2003}
}
@inproceedings{me07g,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07fix.pdf\}},
author = {Menzies, T and Elrawas, O and Baker, D and Hihn, J and Lum, K},
booktitle = {International Workshop on Living with Uncertainty (an ASE'07 co-located event)},
title = {{On the Value of Stochastic Abduction (if you fix everything, you lose fixes for everything else)}},
year = {2007}
}
@book{capers98,
author = {Jones, T C},
publisher = {McGraw-Hill},
title = {{Estimating Software Costs}},
year = {1998}
}
@article{ElEmam2001,
author = {{El Emam}, K. and Benlarbi, S. and Goel, N. and Rai, S.N.},
doi = {10.1109/32.935855},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/El Emam et al. - 2001 - The confounding effect of class size on the validity of object-oriented metrics.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
month = jul,
number = {7},
pages = {630--650},
title = {{The confounding effect of class size on the validity of object-oriented metrics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=935855},
volume = {27},
year = {2001}
}
@book{jacob97,
author = {{I. Jacobson M. Griss}, P Jonsson},
publisher = {Addison-Wesley},
title = {{Software Reuse: Architecture Process and Organiation for Business Success}},
year = {1997}
}
@article{tambe90,
author = {Tambe, M and Newell, A and Rosenbloom, P S},
journal = {Machine Learning},
number = {3},
pages = {299--348},
title = {{The Problem of Expensive Chunks and its Solution by Restricting Expressiveness}},
volume = {5},
year = {1990}
}
@article{Ritchie2010,
abstract = {OBJECTIVES: The goal was to determine the sensitivity and specificity of family history in identifying children with severe or genetic hyperlipidemias in a rural, predominantly white population. METHODS: A total of 20,266 fifth-grade children in West Virginia, from the Coronary Artery Risk Detection in Appalachian Communities (CARDIAC) Project, who completed a family history and fasting lipid profile were used in analyses. The relationship between hyperlipidemia and family history was determined, and the use of family history to predict the need for pharmacologic treatment among children with dyslipidemia was evaluated. RESULTS: A total of 71.4\% of children met the National Cholesterol Education Program (NCEP) guidelines for cholesterol screening on the basis of positive family history. Of those, 1204 (8.3\%) were considered to have dyslipidemia (low-density lipoprotein > or =130 mg/dL), and 1.2\% of these children with dyslipidemia warranted possible pharmacologic treatment (low-density lipoprotein > or =160 mg/dL). Of the 28.6\% who did not have a positive family history (did not meet NCEP guidelines), 548 (9.5\%) had dyslipidemia, 1.7\% of whom warranted pharmacologic treatment. Sensitivity and specificity data demonstrated that family history does not provide a strong indication as to whether pharmacologic treatment may be warranted. CONCLUSIONS: Results indicate that the use of family history to determine the need for cholesterol screening in children would have (1) missed many with moderate dyslipidemia and (2) failed to detect a substantial number with likely genetic dyslipidemias that would require pharmacologic treatment. The use of universal cholesterol screening would identify all children with severe dyslipidemia, allowing for proper intervention and follow-up and leading to the prevention of future atherosclerotic disease.},
author = {Ritchie, Susan K and Murphy, Emily C-S and Ice, Christa and Cottrell, Lesley a and Minor, Valerie and Elliott, Eloise and Neal, William},
doi = {10.1542/peds.2009-2546},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Ritchie et al. - 2010 - Universal versus targeted blood cholesterol screening among youth The CARDIAC project.pdf:pdf},
issn = {1098-4275},
journal = {Pediatrics},
keywords = {cardiovascular disease,children,genetics,lipids},
month = aug,
number = {2},
pages = {260--5},
pmid = {20624798},
title = {{Universal versus targeted blood cholesterol screening among youth: The CARDIAC project.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20624798},
volume = {126},
year = {2010}
}
@inproceedings{breuker94,
author = {Breuker, J},
booktitle = {8th European Knowledge Acquisition Workshop, EKAW '94},
pages = {118--136},
title = {{Components of \{P\}roblem \{S\}olving and \{T\}ypes of \{P\}roblems}},
year = {1994}
}
@book{holz90,
author = {Holzmann, Gerard J},
publisher = {\{P\}rentice \{H\}all},
title = {{\{D\}esign and \{V\}alidation of \{C\}omputer \{P\}rotocols}},
year = {1990}
}
@misc{bobntim2,
author = {Cohen, R F and Menzies, T},
number = {TR95-20},
title = {{Reverse Engineering a Software Engineering Curriculum}},
year = {1995}
}
@inproceedings{Mohamed1993,
annote = {unread},
author = {Mohamed, W E and Sadler, C J and Law, D},
booktitle = {Proceedings of Software Quality Management, Elsevier Science and CMP, Southampton},
pages = {417--430},
title = {{Experimentation in Software Engineering: A New Framework}},
year = {1993}
}
@book{glinert90b,
editor = {Glinert, E P},
publisher = {IEEE Computer Society Press},
title = {{Visual Programming Environments: Applications and Issues}},
year = {1990}
}
@misc{mccabe,
title = {{McCabe QA\^{}\{$\backslash$mbox $\backslash$textregistered\}}},
url = {$\backslash$url\{http://www.mccabe.com\}},
year = {2005}
}
@article{huber09,
author = {Huberman, Bernardo and Romero, Daniel and Wu, Fang},
journal = {Journal of Information Science},
month = dec,
number = {6},
pages = {758--765},
title = {{Crowdsourcing, attention and productivity}},
volume = {35},
year = {2009}
}
@article{jorg04uncertainty,
address = {Piscataway, NJ, USA},
author = {Jorgensen, Magne},
doi = {http://dx.doi.org/10.1109/TSE.2004.1274041},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {4},
pages = {209--217},
publisher = {IEEE Press},
title = {{Realism in Assessment of Effort Estimation Uncertainty: It Matters How You Ask}},
volume = {30},
year = {2004}
}
@article{Framework2010,
author = {Framework, A Proposed Data-sharing},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Framework - 2010 - Dialing Privacy and Utility.pdf:pdf},
number = {August},
pages = {31--39},
title = {{Dialing Privacy and Utility}},
year = {2010}
}
@article{dieng95,
author = {Dieng, R and Corby, O and Lapalut, S},
journal = {International Journal of Human-Computer Studies},
pages = {465--499},
title = {{Acquisition and Exploitation of Gradual Knowledge}},
volume = {42},
year = {1995}
}
@inproceedings{me92l,
author = {Menzies, T and Mahidadia, a and Compton, P},
booktitle = {Proceedings of the 7th \{AAAI\}-Sponsored \{B\}anff Knowledge Acquisition for Knowledge-Based Systems Workshop \{B\}anff, \{C\}anada, October 11-16},
title = {{Using \{C\}ausality as a \{G\}eneric \{K\}nowledge \{R\}epresentation, or \{W\}hy and \{H\}ow \{C\}entralised \{K\}nowledge \{S\}ervers \{C\}an \{U\}se \{C\}ausality}},
year = {1992}
}
@inproceedings{toth91,
author = {Touretzky, J and Thomson, R H and Horty, J F},
booktitle = {\{IJCAI\} '91},
pages = {478--483},
title = {{Skeptic's Menagerie: Conflictor's, Preemptors. Reinstaters, and Zombies in Nonmonotonic Inheritance}},
year = {1991}
}
@article{Larsen1999a,
address = {New York, New York, USA},
author = {Larsen, Bjornar and Aone, Chinatsu},
doi = {10.1145/312129.312186},
file = {:Users/timm/svns/doc/larsen99.pdf:pdf},
isbn = {1581131437},
journal = {Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '99},
keywords = {clustering,multi-document summarization,text mining},
pages = {16--22},
publisher = {ACM Press},
title = {{Fast and effective text mining using linear-time document clustering}},
url = {http://portal.acm.org/citation.cfm?doid=312129.312186},
year = {1999}
}
@inproceedings{li07,
author = {Li, J and Ruhe, G},
booktitle = {Proceedings, PROMISE'07 workshop on Repeatable Experiments in Software Engineering},
title = {{Decision Support Analysis for Software Effort Estimation by Analogy}},
year = {2007}
}
@misc{gay07,
author = {Gay, G and Menzies, T},
institution = {Lane Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{Under- vs Over- Sampling for C4.5 and Naive Bayes Defect Predictors}},
year = {2007}
}
@article{Song2014,
abstract = {Modern software systems are increasingly configurable. While this has many benefits, it also makes some software engineering tasks,such as software testing, much harder. This is because, in theory,unique errors could be hiding in any configuration, and, therefore,every configuration may need to undergo expensive testing. As this is generally infeasible, developers need cost-effective technique for selecting which specific configurations they will test. One popular selection approach is combinatorial interaction testing (CIT), where the developer selects a strength t and then computes a covering array (a set of configurations) in which all t-way combinations of configuration option settings appear at least once. In prior work, we demonstrated several limitations of the CIT approach. In particular, we found that a given system's effective configuration space - the minimal set of configurations needed to achieve a specific goal - could comprise only a tiny subset of the system's full configuration space. We also found that effective configuration space may not be well approximated by t-way covering arrays. Based on these insights we have developed an algorithm called interaction tree discovery (iTree). iTree is an iterative learning algorithm that efficiently searches for a small set of configurations that closely approximates a system's effective configuration space. On each iteration iTree tests the system on a small sample of carefully chosen configurations, monitors the system's behaviors, and then applies machine learning techniques to discover which combinations of option settings are potentially responsible for any newly observed behaviors. This information is used in the next iteration to pick a new sample of configurations that are likely to reveal further new behaviors. In prior work, we presented an initial version of iTree and performed an initial evaluation with promising results. This paper presents an improved iTree algorithm in greater detail. The - ey improvements are based on our use of composite proto-interactions - a construct that improves iTree's ability to correctly learn key configuration option combinations, which in turn significantly improves iTree's running time, without sacrificing effectiveness. Finally, the paper presents a detailed evaluation of the improved iTree algorithm by comparing the coverage it achieves versus that of covering arrays and randomly generated configuration sets, including a significantly expanded scalability evaluation with the \~{} 1M-LOC MySQL. Our results strongly suggest that the improved iTree algorithm is highly scalable and can identify a high-coverage test set of configurations more effectively than existing methods.},
author = {Song, Charles and Porter, Adam and Foster, Jeffrey S.},
doi = {10.1109/TSE.2013.55},
file = {:Users/timm/svns/doc/14itree.pdf:pdf},
isbn = {9781467310673},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Empirical software engineering,software configurations,software testing and analysis},
number = {3},
pages = {251--265},
title = {{ITree: Efficiently discovering high-coverage configurations using interaction trees}},
volume = {40},
year = {2014}
}
@inproceedings{edelamp01,
author = {Edelkamp, S and Lafuente, L and Leue, S},
booktitle = {Proc. AAAI Stanford Spring Symposium},
title = {{Protocol Verification with Heuristic Search}},
year = {2001}
}
@phdthesis{pande96,
author = {Pande, H D},
school = {Gradaute School- New Brunswick. Rutgers, The State University of New Jersey},
title = {{Compile Time Analysis of C and C++ Systems}},
year = {1996}
}
@inproceedings{asano00,
author = {Asano, T and Williamson, D P},
booktitle = {SODA '00: 11th Annual ACM Symposium of Discrete Algorithms},
pages = {96--115},
title = {{Improved approximation algorithms for MAX SAT}},
year = {2000}
}
@article{me02k,
abstract = { For original paper see ibid., p. 474. This is a clear example of how research in software engineering can progress when empirical methods are applied. Menzies and Di Stefano apply a number of data mining tools to the data set. While, inmost cases, their results are in agreement with ours, in some cases they are not. Our first and main observation is that our interpretation of the data set is based not only on the data set itself but also on the knowledge gathered during the interviews with project members. The main problem with the data set is its size: 23 data points. Although this data set is the largest one available about reuse projects, it is too limited to base analysis only on data mining techniques; data mining is usually applied to data sets with thousands if not millions of data points.},
author = {Morisio, Maurizio and Ezran, Michel and Tully, Colin},
doi = {10.1109/TSE.2003.1199077},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
month = may,
number = {5},
pages = {478},
title = {{Comments on "more success and failure factors in software reuse"}},
volume = {29},
year = {2003}
}
@article{scott99,
author = {Scott, P D and Wilkins, E},
journal = {Information and Software Technology},
number = {9},
pages = {579--587},
title = {{Evaluating data mining procedures: techniques for generating artificial data sets}},
volume = {41},
year = {1999}
}
@book{beck00,
author = {Beck, Kent},
isbn = {0-201-61641-6},
publisher = {Addison Wesley},
title = {{Extreme Programming Explained: Embrace Change}},
year = {2000}
}
@book{darden91,
author = {Darden, L},
isbn = {0-19-506797-5},
publisher = {Oxford University Press},
title = {{Theory Change in Science: Strategies from Mendelian Genetics}},
year = {1991}
}
@article{me08e,
author = {Menzies, T and Milton, Z and Bener, A and Cukic, B and Gay, G and Jiang, Y and Turhan, B},
journal = {Submitted to IEEE TSE},
title = {{Overcoming Ceiling Effects in Defect Prediction}},
year = {2008}
}
@article{purv83,
author = {Purvey, R and Farrell, J and Klose, P},
journal = {ACM Tans Office Inf. Syst.},
number = {1},
pages = {3--34},
title = {{The Design of Star's Records Processing: Data processing for the noncomputer professional}},
volume = {1},
year = {1983}
}
@misc{atanacio01,
author = {Atanacio, B},
booktitle = {SEI, Carnegie Mellon University},
title = {{Modeling the Space Shuttle Liquid Hydrogen Subsystem}},
year = {2001}
}
@inproceedings{crawford96,
author = {Crawford, J and Dvorak, D L and Litman, D J and Mishra, A M and Patel-Schneider, P F},
booktitle = {Thirteenth National Conference on Artificial Intelligence (AAAI-96)},
title = {{Path-Based Rules in Object-Oriented Programming}},
year = {1996}
}
@article{El-halym2009,
author = {El-halym, Howida a Abd and Mahmoud, Imbaby I and Abdeltawab, a},
file = {:Users/timm/svns/doc/pso/09psoParticleFiltering.pdf:pdf},
journal = {Electronics and Communications},
keywords = {object tracking,particle filter,particle swarm optimization},
pages = {1--12},
title = {{Particle Filter versus Particle Swarm Optimization for Object}},
year = {2009}
}
@inproceedings{motta96,
author = {Motta, E and Zdrahal, Z},
booktitle = {Proceedings of the 10th Banff Knowledge Acquisition for Knowledge-Based System Workshop},
title = {{Parametric Design Problem Solving}},
year = {1996}
}
@article{Diakonikolasa,
author = {Diakonikolas, Ilias and Yannakakis, M},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Diakonikolas - Unknown - Succinct Approximate Convex Pareto Curves ( Extended Abstract ).pdf:pdf},
pages = {74--83},
title = {{Succinct Approximate Convex Pareto Curves (Extended Abstract)}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Succinct+Approximate+Convex+Pareto+Curves+(+Extended+Abstract+)\#1}
}
@inproceedings{betta12,
author = {Bettenburg, Nicolas and Nagappan, Meiyappan and Hassan, Ahmed E},
booktitle = {MSR'12},
file = {:Users/timm/svns/doc/12betternburg.pdf:pdf},
title = {{Think Locally, Act Globally: Improving Defect and Effort Prediction Models}},
year = {2012}
}
@article{glinert84,
author = {Glinert, E P and Tanimoto, S T},
journal = {IEEE Computer},
month = nov,
pages = {7--25},
title = {{Pict: An Interactive Graphical Programming Environment}},
year = {1984}
}
@article{Djordjevic2006,
abstract = {SELEX (systematic evolution of ligands by exponential enrichment) is an experimental procedure that allows the extraction, from an initially random pool of DNA, of those oligomers with high affinity for a given DNA-binding protein. We address what is a suitable experimental and computational procedure to infer parameters of transcription factor-DNA interaction from SELEX experiments. To answer this, we use a biophysical model of transcription factor-DNA interactions to quantitatively model SELEX. We show that a standard procedure is unsuitable for obtaining accurate interaction parameters. However, we theoretically show that a modified experiment in which chemical potential is fixed through different rounds of the experiment allows robust generation of an appropriate dataset. Based on our quantitative model, we propose a novel bioinformatic method of data analysis for such a modified experiment and apply it to extract the interaction parameters for a mammalian transcription factor CTF/NFI. From a practical point of view, our method results in a significantly improved false positive/false negative trade-off, as compared to both the standard information theory based method and a widely used empirically formulated procedure.},
archivePrefix = {arXiv},
arxivId = {arXiv:q-bio/0512001v1},
author = {Djordjevic, Marko and Sengupta, Anirvan M},
doi = {10.1088/1478-3975/3/1/002},
eprint = {0512001v1},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Djordjevic05.pdf:pdf},
issn = {1478-3975},
journal = {Physical biology},
keywords = {protein-dna interactions,selex,transcription factor binding sites,weight ma-},
number = {1},
pages = {13--28},
pmid = {16582458},
primaryClass = {arXiv:q-bio},
title = {{Quantitative modeling and data analysis of SELEX experiments.}},
volume = {3},
year = {2006}
}
@inproceedings{kanovich91,
author = {Kanovich, M I},
booktitle = {Theoretical Aspects of Comptuer Software, September, 1991, Sendai, Japan},
title = {{Effecient Program Synthesis: Semantics, Logic, Complexity}},
year = {1991}
}
@inproceedings{me99b,
author = {Menzies, T J and Cukic, B},
booktitle = {Submitted to ISSRE-99},
title = {{When You Don't Need to Re-Test the System}},
year = {1999}
}
@book{kaplan96,
author = {Kaplan, R S and Norton, D P},
publisher = {Harvard Business School Press. Boston},
title = {{The Balanced Scorecard: Translating Strategy into Action}},
year = {1996}
}
@misc{penix13,
author = {Penix, John},
title = {{No Title}},
year = {2013}
}
@article{Zimmermann2010,
abstract = {Genomic SELEX is a discovery tool for genomic aptamers, which are genomically encoded functional domains in nucleic acid molecules that recognize and bind specific ligands. When combined with genomic libraries and using RNA-binding proteins as baits, Genomic SELEX used with high-throughput sequencing enables the discovery of genomic RNA aptamers and the identification of RNA-protein interaction networks. Here we describe how to construct and analyze genomic libraries, how to choose baits for selections, how to perform the selection procedure and finally how to analyze the enriched sequences derived from deep sequencing. As a control procedure, we recommend performing a " Neutral" SELEX experiment in parallel to the selection, omitting the selection step. This control experiment provides a background signal for comparison with the positively selected pool. We also recommend deep sequencing the initial library in order to facilitate the final in silico analysis of enrichment with respect to the initial levels. Counter selection procedures, using modified or inactive baits, allow strengthening the binding specificity of the winning selected sequences. Â© 2010.},
author = {Zimmermann, Bob and Bilusic, Ivana and Lorenz, Christina and Schroeder, Ren\'{e}e},
doi = {10.1016/j.ymeth.2010.06.004},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Zimmermann10.pdf:pdf},
isbn = {1095-9130 (Electronic)$\backslash$r1046-2023 (Linking)},
issn = {10462023},
journal = {Methods},
number = {2},
pages = {125--132},
pmid = {20541015},
publisher = {Elsevier Inc.},
title = {{Genomic SELEX: A discovery tool for genomic aptamers}},
url = {http://dx.doi.org/10.1016/j.ymeth.2010.06.004},
volume = {52},
year = {2010}
}
@article{me07e,
annote = {$\backslash$url\{http://menzies.us/pdf/07precision.pdf\}},
author = {Menzies, Tim and Dekhtyar, Alex and Distefano, Justin and Greenwald, Jeremy},
journal = {IEEE Transactions on Software Engineering},
month = sep,
title = {{Problems with Precision}},
year = {2007}
}
@article{miller56,
annote = {Available from $\backslash$url\{http://www.well.com/\~{}smalin/miller.html\}},
author = {Miller, G A},
journal = {The Psychological Review},
pages = {81--97},
title = {{The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information}},
volume = {63},
year = {1956}
}
@article{me02k,
abstract = { For original paper see ibid., p. 474. This is a clear example of how research in software engineering can progress when empirical methods are applied. Menzies and Di Stefano apply a number of data mining tools to the data set. While, inmost cases, their results are in agreement with ours, in some cases they are not. Our first and main observation is that our interpretation of the data set is based not only on the data set itself but also on the knowledge gathered during the interviews with project members. The main problem with the data set is its size: 23 data points. Although this data set is the largest one available about reuse projects, it is too limited to base analysis only on data mining techniques; data mining is usually applied to data sets with thousands if not millions of data points.},
author = {Morisio, Maurizio and Ezran, Michel and Tully, Colin},
doi = {10.1109/TSE.2003.1199077},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
month = may,
number = {5},
pages = {478},
title = {{Comments on "more success and failure factors in software reuse"}},
volume = {29},
year = {2003}
}
@article{musilek00,
address = {New York, NY, USA},
author = {Mus\'{\i}lek, Petr and Pedrycz, Witold and Succi, Giancarlo and Reformat, Marek},
doi = {http://doi.acm.org/10.1145/373975.373984},
issn = {1559-6915},
journal = {SIGAPP Appl. Comput. Rev.},
number = {2},
pages = {24--29},
publisher = {ACM Press},
title = {{Software cost estimation with fuzzy models}},
volume = {8},
year = {2000}
}
@inproceedings{kalfoglou99,
author = {{Kalfoglou,Y. and Robertson,D.}},
booktitle = {Proceedings of the 11th International Conference on Software Engineering and Knowledge Engineering, SEKE'99, Kaiserslauten, Germany},
month = jun,
pages = {64--71},
title = {{A Case Study in Applying Ontologies to Augment and Reason about the Correctness of Specifications}},
year = {1999}
}
@article{shull00a,
author = {Shull, F and Rus, I and Basili, V R},
journal = {IEEE Computer},
number = {7},
pages = {73--79},
title = {{How Perspective-Based Reading Can Improve Requirements Inspections}},
volume = {33},
year = {2000}
}
@article{reich95,
author = {Reich, Y},
journal = {International Journal of Human-Computer Studies},
number = {1},
pages = {3--30},
title = {{Measuring the Value of Knowledge}},
volume = {42},
year = {1995}
}
@book{Bache1994,
annote = {unread},
author = {Bache, R and Bazzana, G},
publisher = {McGraw-Hill},
title = {{Software Metrics for Product Assessment}},
year = {1994}
}
@article{Ali2006a,
author = {Ali, S and Smith, K},
doi = {10.1016/j.asoc.2004.12.002},
file = {:Users/timm/svns/doc/On learning algorithm selection for classification (1).pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing},
keywords = {algorithm selection,classification,no free lunch theorem},
month = jan,
number = {2},
pages = {119--138},
title = {{On learning algorithm selection for classification}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1568494605000049},
volume = {6},
year = {2006}
}
@article{Kirsopp2002,
author = {Kirsopp, C and Shepperd, M},
doi = {10.1049/ip-sen},
journal = {IEEE Proc.},
number = {5},
title = {{Making inferences with small numbers of training sets}},
volume = {149},
year = {2002}
}
@article{Aggarwal1998,
abstract = {The problem of finding association rules in a large data- base of sales transactions has been widely studied in the literature, We discuss some of the weaknesses of the large itemset method for association rule generation. A differ- ent method for evaluating and finding itemsets referred to as otrongIyl collective itemsets is proposed. The concepts of âsupportâ of an itemset and correlation of the items within an itemset are related, though not quite the same. This cri- terion stresses the importance of the actual correlation of the items with one another rather than the absolute sup- port, Previously proposed methods to provide correlated itemsets are not necessarily applicable to very large data- bases, We provide an algorithm which provides very good computational efficiency, while maintaining statistical ro- buetneas, The fact that this algorithm relies on relative measures rather than absolute measures such as support also implies that the method can be applied to find association rules in datasets in which items may appear in a sizeable percentage of the transactions (dense datasets), datasets in which the items have varying density, or even negative as- sociation rules,},
author = {Aggarwal, Charu C. and Yu, Philip S.},
doi = {10.1145/275487.275490},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/aggarwal98.pdf:pdf},
isbn = {0897919963},
journal = {Proceedings of the seventeenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems - PODS '98},
pages = {18--24},
title = {{A new framework for itemset generation}},
url = {http://portal.acm.org/citation.cfm?doid=275487.275490},
year = {1998}
}
@inproceedings{har97,
author = {Hawryszkiewycz, I T},
booktitle = {Proceedings of the Inaugural Conference of Informatics in Multinational Enterprises, Washington, D.C, OCtober 12-13, 1997},
title = {{A Framework for Strategic Planning for Communications Support}},
year = {1997}
}
@inproceedings{meha94,
author = {Menzies, T J and Haynes, P},
booktitle = {Tools Pacific '94},
pages = {83--92},
publisher = {Prentice-Hall},
title = {{The \{M\}ethodologies of \{M\}ethodologies; or, \{E\}valuating \{C\}urrent \{M\}ethodologies: \{W\}hy and \{H\}ow}},
year = {1994}
}
@book{simon69,
author = {Simon, H},
publisher = {MIT Press},
title = {{The Science of the Artificial}},
year = {1969}
}
@article{Tusar2007,
author = {Tu\v{s}ar, T and Filipi\v{c}, B},
doi = {10.1007/978-3-540-70928-2\_22},
file = {:Users/timm/svns/doc/pso/07deBetterThanOthers.pdf:pdf},
isbn = {978-3-540-70927-5},
issn = {03029743},
journal = {Evolutionary Multi-Criterion Optimization},
pages = {257--271},
title = {{Differential evolution versus genetic algorithms in multiobjective optimization}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-70928-2\_22},
year = {2007}
}
@misc{clancey96,
annote = {Personal communcaition},
author = {Clancey, W},
title = {{No Title}},
year = {1996}
}
@article{aamod94,
author = {Aamodt, A and Plaza, E},
journal = {Artificial Intellegence Communications},
pages = {39--59},
title = {{Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches}},
volume = {7},
year = {1994}
}
@article{ambler89,
author = {Ambler, A L and Burnett, M M},
journal = {IEEE Computer},
number = {10},
pages = {9--22},
title = {{Influence of Visual Technology on the Evolution of Language Environments}},
volume = {22}
}
@inproceedings{me00v,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/00vp.pdf\}},
author = {Menzies, T J},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{Evaluation Issues for Problem Visual Programming Languages}},
year = {1998}
}
@inproceedings{phipps95,
author = {Phipps, G},
booktitle = {Tools Pacific 18},
pages = {253--264},
title = {{The Structure of Large C++ Programs}},
year = {1995}
}
@inproceedings{me02o,
author = {Menzies, T and Mason, L},
booktitle = {Third ACM SIGPLAN Workshop on Rule-Based Programming (RULE02) Pittsburgh, PA, October 5},
title = {{Some Prolog Macros for Rule-Based Programming: Why? How?}},
year = {2002}
}
@book{mcintosh80,
author = {McIntosh, J E A and McIntosh, R P},
publisher = {Springer-Verlag},
title = {{Mathematical Modeling and Computers in Endocrinology}},
year = {1980}
}
@inproceedings{norman86,
author = {Norman, D A},
booktitle = {User Centered System Design},
editor = {Norman, D A and Draper, S W},
publisher = {Hillsdale, NJ: Lawrence Erlbaum Associates},
title = {{Cognitive Engineering}},
year = {1986}
}
@misc{lee04,
author = {Lee, S C and Santo, A G},
title = {{Tradeoffs in functional allocation between spacecraft autonomy and ground operations: the \{NEAR\} (\{N\}ear \{E\}arth \{A\}steroid \{R\}endezvous) \{E\}xperience, \{J\}ohn \{H\}opkins \{APL\}, \{A\}ugust 9-12, \{U\}tah \{S\}tate \{U\}niversity , \{E\}ccles \{C\}onference \{C\}enter, \{L}}},
year = {2004}
}
@inproceedings{patil81,
author = {Patil, R S and Szolovitis, P and Schwartz, W B},
booktitle = {\{IJCAI\} '81},
pages = {893--899},
title = {{Causal \{U\}nderstanding of \{P\}atient \{I\}llness in \{M\}edical \{D\}iagnosis}},
year = {1981}
}
@inproceedings{bricc00,
author = {{G. Bricconi E. Di Nitto}, E Tracanella},
booktitle = {Proceedings of the 10th International Workshop on Software Specification and Design (IWSSD-10), San Diego, USA},
month = nov,
title = {{Issues in analyzing the behavior of event dispatching systems}},
year = {2000}
}
@inproceedings{CAGLAYAN2009,
address = {Washington, DC, USA},
author = {Caglayan, Bora and Bener, Ayse and Koch, Stefan},
booktitle = {FLOSS '09: Proceedings of the 2009 ICSE Workshop on Emerging Trends in Free/Libre/Open Source Software Research and Development},
doi = {http://dx.doi.org/10.1109/FLOSS.2009.5071357},
isbn = {978-1-4244-3720-7},
pages = {31--36},
publisher = {IEEE Computer Society},
title = {{Merits of using repository metrics in defect prediction for open source projects}},
year = {2009}
}
@inproceedings{me95za,
author = {Menzies, Tim},
booktitle = {Proceedings of the Melbourne Workshop on Intelligent Decision Support Department of Information Systems Monash University, Caulfield Campus, Melbourne Monday, March 20, 1995},
pages = {1--13},
title = {{Applications of Abduction \# 1 : Intelligent Decision Support Systems 1 Introduction}},
year = {1995}
}
@inproceedings{will96,
author = {Williams, B C and Nayak, P P},
booktitle = {Proceedings, AAAI '96},
pages = {971--978},
title = {{A Model-Based Approach to Reactive Self-Configuring Systems}},
year = {1996}
}
@inproceedings{me03l,
author = {Menzies, Tim},
booktitle = {Soft Computing in Software Engineering},
editor = {Madravio, M},
publisher = {Springer-Verlag},
title = {{Chapter 99 Maybes Mean ( Mostly ) the Same Thing}},
year = {2003}
}
@article{Kiernan2002a,
author = {Kiernan, Jerry},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Kiernan - 2002 - Hippocratic Databases.pdf:pdf},
journal = {Harvard Law Review},
number = {1890},
title = {{Hippocratic Databases}},
volume = {4},
year = {2002}
}
@inproceedings{koc11c,
author = {Kocaguneli, E and Menzies, T},
booktitle = {Proceedings ESEM'11},
title = {{How to Find Relevant Data for Effort Estimation?}},
year = {2011}
}
@inproceedings{have01,
author = {Havelund, K and Rosu, G},
booktitle = {The 6th International Symposium on AI, Robotics and Automation in Space},
month = may,
title = {{Java PathExplorer - A Runtime Verification Tool}},
year = {2001}
}
@article{Dasgupta2008a,
abstract = {Estrogen-related receptors (ERR), ERR alpha (ERR$\alpha$) and ERR gamma (ERR$\gamma$), are orphan nuclear receptors implicated in breast cancer that function similarly in the regulation of oxidative metabolism genes. Paradoxically, in clinical studies, high levels of ERR$\alpha$ are associated with poor outcomes whereas high levels of ERR$\gamma$ are associated with a favorable course. Recent studies suggest that ERR$\alpha$ may indeed promote breast tumor growth. The roles of ERR$\gamma$ in breast cancer progression and how ERR$\alpha$ and ERR$\gamma$ may differentially affect cancer growth are unclear. In mammary carcinoma cells that do not express endogenous ERR$\gamma$, we found that ectopic expression of ERR$\gamma$ enhanced oxidative metabolism in vitro and inhibited the growth of tumor xenografts in vivo. In contrast, ectopic expression of the ERR$\alpha$ coactivator PGC-1$\alpha$ enhanced oxidative metabolism but did not affect tumor growth. Notably, ERR$\gamma$ activated expression of a genetic program characteristic of mesenchymal-to-epithelial transition (MET). This program was apparent by changes in cellular morphology, upregulation of epithelial cell markers, downregulation of mesenchymal markers, and decreased cellular invasiveness. We determined that this program was also associated with upregulation of E-cadherin, which is activated directly by ERR$\gamma$. In contrast, PGC-1$\alpha$ activated only a subset of genes characteristic of the MET program and, unlike ERR$\gamma$, did not upregulate E-cadherin. In conclusion, these results show that ERR$\gamma$ induces E-cadherin, promotes MET, and suppresses breast cancer growth. Our findings suggest that ERR$\gamma$ agonists may have applications in the treatment of breast cancer.},
author = {Dasgupta, Sanjoy and Freund, Yoav},
doi = {10.1145/1374376.1374452},
file = {:Users/timm/svns/doc/08rptrees.pdf:pdf},
isbn = {9781605580470},
issn = {15387445},
journal = {Proceedings of the fourtieth annual ACM symposium on Theory of computing STOC 08},
number = {1},
pages = {537},
pmid = {21339306},
title = {{Random projection trees and low dimensional manifolds}},
url = {http://portal.acm.org/citation.cfm?doid=1374376.1374452},
volume = {6},
year = {2008}
}
@incollection{reeves94,
author = {Reeves, T C},
booktitle = {Computer education: New Perspectives},
editor = {Wild, M and Kirkpatrick, D},
pages = {219--246},
publisher = {MASTEC},
title = {{Evaluating what really matters in computer-based education}},
year = {1994}
}
@inproceedings{me02e,
abstract = { Within NASA, there is an increasing awareness that software is of growing importance to the success of missions. Much data has been collected, and many theories have been advanced on how to reduce or eliminate errors in code. However, learning requires experience. We document a new NASA initiative to build a centralized repository of software defect data; in particular, we document one specific case study on software metrics. Software metrics are used as a basis for prediction of errors in code modules, but there are many different metrics available. McCabe is one of the more popular tools used to produce metrics, but, other metrics can be more significant.},
author = {Menzies, T. and Stefano, J.S. Di and Chapman, M. and McGill, K.},
booktitle = {27th Annual NASA Goddard/IEEE Software Engineering Workshop, 2002. Proceedings.},
doi = {10.1109/SEW.2002.1199449},
isbn = {0-7695-1855-9},
issn = {0021-8499},
title = {{Metrics that matter}},
year = {2002}
}
@article{smith94,
author = {Smith, T and Setliff, D},
journal = {Automated Software Engineering},
pages = {155--176},
title = {{Using simulated annealing to synthesize resource-bounded software}},
year = {1994}
}
@article{weiss78,
author = {Weiss, S M and Kulikowski, C A and Amarel, S},
journal = {Artificial Intelligence},
title = {{A \{M\}odel-\{B\}ased \{M\}ethod for \{C\}omputer-\{A\}ided \{M\}edical \{D\}ecision-\{M\}aking}},
volume = {11},
year = {1978}
}
@incollection{forbus92,
author = {Forbus, K},
booktitle = {Recent Advances in Qualitative Physics},
editor = {Faltings, B and Struss, P},
pages = {245--261},
publisher = {The MIT Press},
title = {{Pushing the Edge of the (QP) Envelope}},
year = {1992}
}
@article{dekleer93,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {63--67},
title = {{A perspective on assumption-based truth maintenance}},
volume = {59},
year = {1993}
}
@misc{bobntim2,
author = {Cohen, R F and Menzies, T},
number = {TR95-20},
title = {{Reverse Engineering a Software Engineering Curriculum}},
year = {1995}
}
@article{aguilarevolutionary,
author = {Aguilar-Ruiz, Jesus S and Ramos, Isabel and Riquelme, Jose and Toro, Miguel},
journal = {Information and Software Technology},
number = {14},
pages = {875--882},
title = {{An evolutionary approach to estimating software development projects}},
url = {citeseer.ist.psu.edu/aguilar-ruiz01evolutionary.html},
volume = {43},
year = {2001}
}
@inproceedings{ocinneide12,
author = {{\'{O} Cinn\'{e}ide}, Mel and Tratt, Laurence and Harman, Mark and Counsell, Steve and {Hemati Moghadam}, Iman},
booktitle = {Proceedings of the ACM-IEEE International Symposium on Empirical Software Engineering and Measurement},
series = {ESEM '12},
title = {{Experimental Assessment of Software Metrics Using Automated Refactoring}},
year = {2012}
}
@misc{uml,
annote = {$\backslash$url\{http://www.rational.com/ot/uml/1.0/index.html\}},
author = {Booch, G and Jacobsen, I and Rumbaugh, J},
institution = {Rational},
title = {{Version 1.0 of the Unified Modeling Language}},
year = {1997}
}
@article{Nicholls2008,
abstract = {Two essential aspects of virtual screening are considered: experimental design and performance metrics. In the design of any retrospective virtual screen, choices have to be made as to the purpose of the exercise. Is the goal to compare methods? Is the interest in a particular type of target or all targets? Are we simulating a âreal-worldâ setting, or teasing out distinguishing features of a method? What are the confidence limits for the results? What should be reported in a publication? In particular, what criteria should be used to decide between different performance metrics? Comparing the field of molecular modeling to other endeavors, such as medical statistics, criminology, or computer hardware evaluation indicates some clear directions. Taken together these suggest the modeling field has a long way to go to provide effective assessment of its approaches, either to itself or to a broader audience, but that there are no technical reasons why progress cannot be made.},
author = {Nicholls, Anthony},
doi = {10.1007/s10822-008-9170-2},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Nicholls2007.pdf:pdf},
isbn = {1082200891},
issn = {0920654X},
journal = {Journal of Computer-Aided Molecular Design},
keywords = {AUC,Metrics,ROC curves,Statistics,Virtual screening},
number = {3-4},
pages = {239--255},
pmid = {18253702},
title = {{What do we know and when do we know it?}},
volume = {22},
year = {2008}
}
@article{harrison04,
author = {Harrison, W},
journal = {IEEE Software},
title = {{Best Practices: Who Says?}},
year = {2004}
}
@inproceedings{TOSUN20092,
address = {Washington, DC, USA},
author = {Tosun, Ayse and Bener, Ayse},
booktitle = {ESEM '09: Proceedings of the 2009 3rd International Symposium on Empirical Software Engineering and Measurement},
doi = {http://dx.doi.org/10.1109/ESEM.2009.5316006},
isbn = {978-1-4244-4842-5},
pages = {477--480},
publisher = {IEEE Computer Society},
title = {{Reducing false alarms in software defect prediction by decision threshold optimization}},
year = {2009}
}
@inproceedings{quinlan92b,
author = {Quinlan, J R},
booktitle = {5th Australian Joint Conference on Artificial Intelligence},
pages = {343--348},
title = {{Learning with \{C\}ontinuous \{C\}lasses}},
year = {1992}
}
@misc{wang93,
author = {Wang, P},
institution = {Center for Research on Concepts and Cognition, Indiana University, Bloomington, Indiana,},
title = {{From Inheritance Relation to Non-Axiomatic Logic}},
year = {1993}
}
@article{Li2000,
abstract = {While principal component analysis (PCA) has found wide application in process monitoring, slow and normal process changes often occur in real processes, which lead to false alarms for a fixed-model monitoring approach. In this paper, we propose two recursive PCA algorithms for adaptive process monitoring. The paper starts with an efficient approach to updating the correlation matrix recursively. The algorithms, using rank-one modification and Lanczos tridiagonalization, are then proposed and their computational complexity is compared. The number of principal components and the confidence limits for process monitoring are also determined recursively. A complete adaptive monitoring algorithm that addresses the issues of missing values and outlines is presented. Finally, the proposed algorithms are applied to a rapid thermal annealing process in semiconductor processing for adaptive monitoring.},
author = {Li, Weihua and Yue, H. Henry and Valle-Cervantes, Sergio and Qin, S. Joe},
doi = {10.1016/S0959-1524(00)00022-6},
file = {:Users/timm/svns/doc/00RecursivePCA.pdf:pdf},
issn = {09591524},
journal = {Journal of Process Control},
keywords = {adaptive process monitoring,cation,lanczos tridiagonalization,rank-one modi,recursive principal component analysis},
number = {5},
pages = {471--486},
title = {{Recursive PCA for adaptive process monitoring}},
volume = {10},
year = {2000}
}
@article{koru09,
author = {Koru, A G and Zhang, Dongsong and {El Emam}, K and Liu, Hongfang},
journal = {Software Engineering, IEEE Transactions on},
number = {2},
pages = {293--304},
title = {{An Investigation into the Functional Form of the Size-Defect Relationship for Software Modules}},
volume = {35},
year = {2009}
}
@article{compton92,
author = {Compton, P and Edwards, G and Srinivasan, A and Malor, P and Preston, P and Kang, B and Lazarus, L},
journal = {Artificial Intelligence in Medicine},
pages = {47--59},
title = {{Ripple-down-rules: Turning Knowledge Acquisition into Knowledge Maintenance}},
volume = {4},
year = {1992}
}
@article{Fung2005,
author = {Fung, B.C.M. and Yu, P.S.},
doi = {10.1109/ICDM.2005.142},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Wang et al. - Unknown - Template-Based Privacy Preservation in Classification Problems â.pdf:pdf},
isbn = {0-7695-2278-5},
journal = {Fifth IEEE International Conference on Data Mining (ICDM'05)},
pages = {466--473},
publisher = {Ieee},
title = {{Template-Based Privacy Preservation in Classification Problems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1565713},
year = {2005}
}
@article{denne95,
author = {Dennebouy, Y and Andersson, M and Auddino, A and Dupont, Y and Fontana, E and Gentile, M and Spaccapietra, S},
journal = {Journal of Visual Languages and Computing},
pages = {73--99},
title = {{Super: Visual Interfaces for Object and Relationship Data Models}},
year = {1995}
}
@misc{ithink94,
author = {Inc., High Performance Software},
title = {{iThink 3.0.5}},
year = {1994}
}
@article{Lu2006,
author = {Lu, Jingli and Yang, Ying and Webb, G.},
file = {:Users/timm/svns/doc/webb08.pdf:pdf},
journal = {Advanced Data Mining and Applications},
pages = {223--238},
publisher = {Springer},
title = {{Incremental discretization for naive-bayes classifier}},
url = {http://www.springerlink.com/index/e3471527150p1n66.pdf},
year = {2006}
}
@inproceedings{barr10,
author = {Barr, E and Bird, C and Hyatt, E and Menzies, Tim and Robles, G},
booktitle = {FoSER 2010},
month = nov,
title = {{On the Shoulders of Giants}},
year = {2010}
}
@book{harmon86,
author = {Harmon, D and King, D},
publisher = {John Wiley \& Sons},
title = {{Expert Systems: Artificial Intelligence in Business}},
year = {1983}
}
@inproceedings{motta95,
author = {Motta, E and Zdrahal, Z},
booktitle = {Proceedings of the 9th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge-Based Systems Workshop Banff, Canada},
title = {{The Trouble with What: Issues in Method-Independent Task Specifications}},
year = {1995}
}
@article{wakeland04,
annote = {Available from $\backslash$url\{http://www.sba.pdx.edu/faculty/davidr/draccess/WEB/publications/JOURNAL/SPIP-DOE.pdf\}},
author = {Waleland, W and Martin, R and Raffo, D},
journal = {Software Process: Improvement and Practice},
number = {2},
pages = {107--119},
title = {{Using Design of Experiments, Sensitivity Analysis. and Hybird Simulation to Evaluate Changes to a Software Development Process: A Case Study}},
volume = {9},
year = {2004}
}
@misc{purify,
author = {$\backslash$urlhttp://www.pureatria.com/products, Pure Atria},
title = {{Purify}}
}
@article{vabu88,
author = {van Harmelen, F and Bundy, A},
journal = {Artificial Intelligence},
pages = {401--412},
title = {{Explanation-Based Generalisation = Partial Evaluation}},
year = {1988}
}
@article{Li2006b,
author = {Li, Wentian},
doi = {10.1093/bioinformatics/btl189},
file = {:Users/timm/svns/doc/erin/references/Simplicity/Li06.pdf:pdf},
issn = {13674803},
journal = {Bioinformatics},
number = {18},
pages = {2187--2188},
pmid = {16957134},
title = {{The-more-the-better and the-less-the-better}},
volume = {22},
year = {2006}
}
@article{heust97,
author = {Van\~{}Heust, G and Schreiber, A Th. and Wielinga, B J},
journal = {International Journal of Human Computer Studies},
pages = {183--292},
title = {{Using explicit ontologies in KBS development}},
volume = {45},
year = {1997}
}
@article{mcderm81,
author = {McDermott, J},
journal = {AI Magazine},
number = {2},
pages = {21--29},
title = {{R1's formative years}},
volume = {2},
year = {1981}
}
@article{dekleer86b,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {163--196},
title = {{Extending the ATMS}},
volume = {28},
year = {1986}
}
@article{Lipowezky1998,
author = {Lipowezky, U},
journal = {Pattern Recognition Letters},
keywords = {global optimization,optimal prototype subset,single hypercube,test sample set},
number = {10},
pages = {907ï¿½918},
publisher = {Elsevier},
title = {{Selection of the optimal prototype subset for 1-NN classification}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865598000750},
volume = {19},
year = {1998}
}
@inproceedings{shull02,
address = {Washington, DC, USA},
author = {Shull, Forrest and Basili, Victor and Carver, Jeffrey and Maldonado, Jos\'{e} C and Travassos, Guilherme Horta and Mendon\c{c}a, Manoel and Fabbri, Sandra},
booktitle = {ISESE '02: Proceedings of the 2002 International Symposium on Empirical Software Engineering},
isbn = {0-7695-1796-X},
pages = {7},
publisher = {IEEE Computer Society},
title = {{Replicating Software Engineering Experiments: Addressing the Tacit Knowledge Problem}},
year = {2002}
}
@book{Meyer1988,
author = {Meyer, B},
publisher = {Prentice-Hall,Hemel Hemstead},
title = {{Object-oriented Software Construction}},
year = {1988}
}
@inproceedings{me94,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/ai94.pdf\}},
author = {Menzies, T J and Compton, P},
booktitle = {Proceedings of Australian AI'94},
editor = {Zhang, C and Debenham, J and Lukose, D},
pages = {149--156},
publisher = {World Scientific},
title = {{A \{P\}recise \{S\}emantics for \{V\}ague \{D\}iagrams}},
year = {1994}
}
@inproceedings{craven98,
author = {Craven, M and DiPasquo, D and Freitag, D and McCallum, A and Mitchell, T and Nigam, K and Slattery, S},
booktitle = {AAAI-98},
title = {{Learning to Extract Symbolic Knowledge from the World Wide Web}},
year = {1998}
}
@inproceedings{hui04,
author = {Hui, Y C and Prakash, E C and Chaudhari, N S},
booktitle = {TENCON 2004. 2004 IEEE Region 10 Conference},
isbn = {0-7803-8560-8},
pages = {306--309},
title = {{Game AI: artificial intelligence for 3D path finding}},
volume = {2},
year = {2004}
}
@inproceedings{he13,
author = {He, Zhimin and Peters, Fayola and Menzies, Tim},
booktitle = {ESEM'13},
title = {{Learning from Open-Source Projects: An Empirical Study on Defect Prediction}},
year = {2013}
}
@article{fenton94,
author = {Fenton, N and Pfleeger, S L and Glass, R L},
journal = {IEEE Software},
month = jul,
pages = {86--95},
title = {{Science and \{S\}ubstance: A \{C\}hallenge to \{S\}oftware \{E\}ngineers}},
year = {1994}
}
@inproceedings{me88,
annote = {Adelaide, Australia},
author = {Menzies, T J and Dean, M and Black, J and Fleming, J},
booktitle = {Ai '88},
title = {{Combining Heuristics with Simulation Models: An Expert System for the Optimal Management of Pig}},
year = {1988}
}
@incollection{joh83,
author = {Johnson, C K and Jordan, S R},
booktitle = {Building Expert Systems},
chapter = {10},
editor = {Hayes-Roth, F and Waterman, D A and Lenat, D B},
pages = {349--397},
publisher = {Addison-Wesley},
title = {{Emergency Management of Inland Oil and Hazardous Chemical Spills: A Case Study In Knowledge Engineering}},
year = {1983}
}
@inproceedings{cheeseman91,
author = {Cheeseman, P and Kanefsky, B and Taylor, W M},
booktitle = {Proceedings of IJCAI-91},
pages = {331--337},
title = {{Where the Really Hard Problems Are}},
year = {1991}
}
@article{waddington03,
author = {Waddington, David and Lardieri, Patrick},
journal = {IEEE Computer},
number = {2},
pages = {28--29},
title = {{Model-Centric Software Development}},
volume = {39},
year = {2006}
}
@article{Jagannathan,
author = {Jagannathan, Geetha and Wright, Rebecca N},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Jagannathan, Wright - Unknown - Privacy-Preserving Distributed -Means Clustering over Arbitrarily Partitioned Data.pdf:pdf},
journal = {Technology},
title = {{Privacy-Preserving Distributed -Means Clustering over Arbitrarily Partitioned Data}}
}
@inproceedings{crawford92,
author = {Crawford, J and Farquhar, A and Kuipers, B},
booktitle = {Recent Advances in Qualitative Physics},
editor = {Faltings, B and Struss, P},
publisher = {The MIT Press},
title = {{QPC: A Compiler from Physical Models into Qualitative Differential Equations}},
year = {1992}
}
@inproceedings{emer90,
author = {Emerson, E A},
booktitle = {Handbook of Theoretical Computer Science},
editor = {van Leeuwen, J},
pages = {995--1072},
publisher = {1990},
title = {{Temporal and Model Logic}}
}
@article{sieg95,
author = {Siegelmann, Hava T and Sontag, Eduardo D},
journal = {Journal of Computer and System Sciences},
number = {1},
pages = {132--150},
title = {{On the Computational Power of Neural Nets}},
volume = {50},
year = {1995}
}
@inproceedings{langley94,
author = {Langley, P and Sage, S},
booktitle = {Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence},
pages = {399--406},
title = {{Induction of selective Bayesian classifiers}},
year = {1994}
}
@article{Barrett2008,
address = {New York, New York, USA},
author = {Barrett, Leon and Narayanan, Srini},
doi = {10.1145/1390156.1390162},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Barrett, Narayanan - 2008 - Learning all optimal policies with multiple criteria.pdf:pdf},
isbn = {9781605582054},
journal = {Proceedings of the 25th international conference on Machine learning - ICML '08},
keywords = {pareto},
mendeley-tags = {pareto},
pages = {41--47},
publisher = {ACM Press},
title = {{Learning all optimal policies with multiple criteria}},
url = {http://portal.acm.org/citation.cfm?doid=1390156.1390162},
year = {2008}
}
@misc{On,
abstract = {December 7, 2010},
author = {On, Focus},
booktitle = {University of Buffalo},
file = {:Users/timm/svns/doc/HowRareIsThat.pdf:pdf},
keywords = {forensics},
mendeley-tags = {forensics},
title = {{How Rare is that Fingerprint ? Computational Forensics Provides the First Clues}},
url = {http://www.buffalo.edu/news/12073}
}
@article{Vendors,
author = {Vendors, How and Capitalize, Can and Models, New Revenue},
file = {:Users/timm/svns/doc/cost/07Pwc.pdf:pdf},
journal = {Technology},
title = {{Software Pricing Trends * How Vendors Can Capitalize on the}}
}
@inproceedings{owen03a,
abstract = {Formal methods, including model checking, is pow- erful but can be costly, in terms of memory, time, and modeling effort. Difficult problems, similar to the verification problem addressed by model checking, have been shown to exhibit a phase transition, suggesting that an easy range of problem instances might be solved much faster and with much less memory using a new type of model checker based on partial, random search. Here we compare the performance of Lurch, our pro- totype random search model checker, to the popular tools SMV and SPIN. The toolsâ performance is com- pared for a range of randomly generated models based on a simple tic-tac-toe game. Our results suggest that Lurch might be used in place of existing tools for sys- tems too large or too difficult to model small enough for conventional model checking.},
author = {Owen, David and Menzies, Tim},
booktitle = {Proc. of the 15th International Conference on Software Engineering \& Knowledge Engineering (SEKE 2003)},
pages = {158--165},
title = {{Lurch: a Lightweight Alternative to Model Checking}},
year = {2003}
}
@article{burn94,
author = {Burnett, M and Baker, M},
journal = {Journal of Visual Languages and Computing,},
month = sep,
pages = {287--300},
title = {{A Classification System for Visual Programming Languages}},
year = {1994}
}
@article{olvera10,
author = {Olvera-L\'{o}pez, J Arturo and Carrasco-Ochoa, J Ariel and Mart\'{\i}nez-Trinidad, J Francisco and Kittler, Josef},
journal = {Artif. Intell. Rev.},
month = aug,
number = {2},
pages = {133--143},
publisher = {Kluwer Academic Publishers},
title = {{A review of instance selection methods}},
volume = {34},
year = {2010}
}
@book{Strauss1994,
annote = {unread},
author = {Strauss, S H and Ebenau, R G},
publisher = {McGraw Hill},
title = {{Software Inspection Process}},
year = {1994}
}
@article{demillo95,
author = {DeMillo, R A and Mathur, A P and Wong, W E},
journal = {IEEE Transactions on Software Engineering},
month = oct,
number = {10},
pages = {854--861},
title = {{Some Critical Remarks on a Hierarchy of Fault-Detecting Abilities of Test Methods}},
volume = {21},
year = {1995}
}
@article{me12e,
author = {Menzies, Tim and Shepperd, Martin},
journal = {Empirical Software Engineering},
number = {1-2},
pages = {1--17},
title = {{Special issue on repeatable results in software engineering prediction}},
volume = {17},
year = {2012}
}
@article{ramesh92,
author = {Ramesh, B and Dhar, V},
journal = {IEEE Transactions on Software Engineering},
month = jun,
number = {6},
pages = {498--510},
title = {{Supporing Systems Development by Capturing Deliberations During Requirements Engineering}},
volume = {18},
year = {1992}
}
@inproceedings{cox86,
author = {Cox, P T and Pietrzykowski, T},
booktitle = {8th International Conference on Automated Deduction},
pages = {608--621},
publisher = {Springer-Verlag},
title = {{Causes for Events: Their Computation and Applications}},
year = {1986}
}
@inproceedings{me03g,
author = {{T. Menzies J. Smith}, D Raffo},
title = {{When is Pair Programming Better?}},
year = {2003}
}
@article{rumel86,
author = {Rumelhart, D E and Hinton, G E and Williams, R J},
journal = {Nature},
number = {323},
pages = {533--536},
title = {{Learning representations by back-propagating errors}},
year = {1986}
}
@inproceedings{kar96,
author = {Karsenty, Laurent},
booktitle = {CHI '96: Electronic Proceedings $\backslash$url\{http://www.acm.org/sigchi/chi96/proceedings/papers/Karsenty/lk\_txt.htm\}},
editor = {Bilger, Ralf and Guest, Steve and Taube, Michael J},
title = {{An Empirical Evaluation of Design Rationale Documents}},
year = {1996}
}
@phdthesis{yost92a,
author = {Yost, G R},
school = {Computer Science, Carnegie Mellon},
title = {{TAQL: A Problem Space Tool for Expert System Development}},
year = {1992}
}
@article{heinze02,
author = {Heinze, Clinton and Goss, Simon and Josefsson, Torgny and Bennett, Kerry and Waugh, Sam and Lloyd, Ian and Murray, Graeme and Oldfeild, John},
journal = {AI Magazine},
number = {2},
title = {{Interchanging agents and humans in military simulation}},
volume = {23},
year = {2002}
}
@incollection{fischer96,
author = {Fischer, G and Lemke, A C and McCall, R and Morch, A I},
booktitle = {Design Rationale: Concepts, Techniques, and Use},
editor = {Moran, T P and Carroll, J M},
pages = {267--293},
publisher = {Lawerence Erlbaum Associates},
title = {{Making Argumentation Serve Design}},
year = {1996}
}
@article{Dasgupta2005,
author = {Dasgupta, Sanjoy},
journal = {in Neural Information Processing Systems 17:},
number = {x},
title = {{Analysis of a greedy active learning strategy}},
volume = {1},
year = {2005}
}
@article{schooff99,
author = {Schooff, R M and Haimes, Y Y},
journal = {IEEE Transactions of Systems, Man, and Cybernetics},
number = {2},
pages = {272--284},
title = {{Dynamic Multistage Software Estimation}},
volume = {29},
year = {1999}
}
@inproceedings{lee96,
author = {Lee, M and Compton, P},
booktitle = {Proceedings of the 3rd World Congress on Expert System (WcES'96)},
title = {{From Heuristic to Causality}},
year = {1996}
}
@inproceedings{cor95,
author = {Corbridge, C and Major, N P and Shadbolt, N R},
booktitle = {Proceedings of the 9th \{AAAI\}-Sponsored \{B\}anff Knowledge Acquisition for Knowledge Based Systems},
title = {{Models \{E\}xposed: An \{E\}mpirical \{S\}tudy}},
year = {1995}
}
@inproceedings{gray11,
author = {Gray, D and Bowes, D and Davey, N and Sun, Yi and Christianson, B},
booktitle = {Evaluation Assessment in Software Engineering (EASE 2011), 15th Annual Conference on},
month = apr,
pages = {96--103},
title = {{The misuse of the NASA metrics data program data sets for automated software defect prediction}},
year = {2011}
}
@misc{sinha02,
annote = {Available from $\backslash$url\{http://www.exu.ilstu.edu/spin/presentations/Prabhuus\_presentation.pdf\}},
author = {Sinha, P},
title = {{Worldwide Implementation of the CMM and its Impact on the U.S. Software Development Community, SEI Software Process Improvement Network, June 6, Bradley University Student Center Peoria, Illinois}},
year = {2002}
}
@article{Oduguwa,
author = {Oduguwa, Abiola and Tiwari, Ashutosh and Roy, Rajkumar and Bessant, Conrad},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Oduguwa.pdf:pdf},
keywords = {bioinformatics,chemoinformatics,drug discovery,fuzzy,genetic algorithm,logic,neural networks},
title = {{An Overview of Soft Computing Techniques Used in the Drug Discovery Process}}
}
@book{clarke99,
address = {\{C\}ambridge, \{MA\}},
author = {Clarke, E and Grumberg, Orna and Peled, Doron A},
publisher = {\{MIT\} \{P\}ress},
title = {{\{M\}odel \{C\}hecking}},
year = {1999}
}
@inproceedings{nar95,
author = {Narayanan, N Hari and Suwa, Masaki and Motoda, H},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and {N.H. Narayanan}, B Chandrasekaran},
pages = {501--534},
publisher = {The AAAI Press},
title = {{Behaviour Hypothesis from Schematic Diagrams}},
year = {1995}
}
@inproceedings{men87a,
author = {Menzies, T J and Markey, B R},
booktitle = {Proceedings of the Third Australian Conference on Expert Systems, May 13-15},
title = {{A Micro-Computer, Rule-Based Prolog Expert-System for Process Control in a Petrochemical Plant}},
year = {1987}
}
@inproceedings{hun97,
author = {Hunter, A and Nuseibeh, B},
booktitle = {International Symposium on Requirements Engineering},
pages = {78--86},
title = {{Analysing Inconsistent Specifications}},
year = {1997}
}
@inproceedings{me97c,
author = {Menzies, T J and Cohen, R E},
booktitle = {European Symposium on the Validation and Verification of Knowledge Based Systems, Leuven, Belgium},
title = {{A Graph-Theoretic Optimisation of Temporal Abductive Validation}},
year = {1997}
}
@article{Foster2001,
abstract = {Evolution does not require DNA, or even living organisms. In computer science, the field known as 'evolutionary computation' uses evolution as an algorithmic tool, implementing random variation, reproduction and selection by altering and moving data within a computer. This harnesses the power of evolution as an alternative to the more traditional ways to design software or hardware. Research into evolutionary computation should be of interest to geneticists, as evolved programs often reveal properties - such as robustness and non-expressed DNA - that are analogous to many biological phenomena.},
author = {Foster, J a},
doi = {10.1038/35076523},
file = {:Users/timm/svns/doc/01babu.pdf:pdf},
isbn = {1471-0056 (Print)},
issn = {1471-0056},
journal = {Nature reviews. Genetics},
keywords = {algorithms,differential evolution,evolutionary computation,genetic,himmelblau function,optimization},
number = {6},
pages = {428--436},
pmid = {11389459},
title = {{Evolutionary computation.}},
volume = {2},
year = {2001}
}
@article{shults97,
author = {Shults, B and Kuipers, B},
journal = {Artificial Intelligence},
pages = {91--129},
title = {{Proving properties of continuous systems: qualitative simulation and temporal logic}},
volume = {92},
year = {1997}
}
@misc{lutz03b,
annote = {(submitted)},
author = {Lutz, R and Mikulski, Carmen},
title = {{Empirical Analysis of Safety-Critical Anomalies During Operations}},
year = {2003}
}
@article{tarjan81,
author = {Tarjan, R E},
journal = {Journal of the Association for Computing Machinery},
month = jul,
number = {3},
pages = {594--614},
title = {{Fast Algorithms for Solving Path Problems}},
volume = {28},
year = {1981}
}
@inproceedings{moher93,
author = {Moher, T G and Mak, D C and Blumenthal, B and Leventhal, L M},
booktitle = {Empirical Studies of Programmers: Fifth Workshop},
pages = {137--161},
title = {{Comparing the Comprehensibility of Textual and Graphical Programs: The Case of Petri Nets}},
year = {1993}
}
@article{Kiernan2002,
author = {Kiernan, Jerry},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Kiernan - 2002 - Hippocratic Databases.pdf:pdf},
journal = {Harvard Law Review},
number = {1890},
title = {{Hippocratic Databases}},
volume = {4},
year = {2002}
}
@article{me13za,
author = {Menzies, Tim},
file = {:Users/timm/svns/doc/13beyond.pdf:pdf},
journal = {IEEE Software},
month = jul,
title = {{Beyond Data Mining}},
year = {2013}
}
@article{Djordjevic2006a,
abstract = {SELEX (systematic evolution of ligands by exponential enrichment) is an experimental procedure that allows the extraction, from an initially random pool of DNA, of those oligomers with high affinity for a given DNA-binding protein. We address what is a suitable experimental and computational procedure to infer parameters of transcription factor-DNA interaction from SELEX experiments. To answer this, we use a biophysical model of transcription factor-DNA interactions to quantitatively model SELEX. We show that a standard procedure is unsuitable for obtaining accurate interaction parameters. However, we theoretically show that a modified experiment in which chemical potential is fixed through different rounds of the experiment allows robust generation of an appropriate dataset. Based on our quantitative model, we propose a novel bioinformatic method of data analysis for such a modified experiment and apply it to extract the interaction parameters for a mammalian transcription factor CTF/NFI. From a practical point of view, our method results in a significantly improved false positive/false negative trade-off, as compared to both the standard information theory based method and a widely used empirically formulated procedure.},
archivePrefix = {arXiv},
arxivId = {arXiv:q-bio/0512001v1},
author = {Djordjevic, Marko and Sengupta, Anirvan M},
doi = {10.1088/1478-3975/3/1/002},
eprint = {0512001v1},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Djordjevic05n2.pdf:pdf},
issn = {1478-3975},
journal = {Physical biology},
number = {1},
pages = {13--28},
pmid = {16582458},
primaryClass = {arXiv:q-bio},
title = {{Quantitative modeling and data analysis of SELEX experiments.}},
volume = {3},
year = {2006}
}
@article{mitchell86,
author = {Mitchell, T M and Keller, R M and Kedar-Cabelli, S T},
journal = {Machine Learning},
pages = {47--80},
title = {{Explanation-Based Generalization: A Unifying View}},
volume = {1},
year = {1986}
}
@misc{1012,
author = {IEEE-1012},
title = {{\{IEEE\} Standard 1012-2004 for Software Verification and Validation}},
year = {1998}
}
@inproceedings{me99l,
author = {Menzies, T},
booktitle = {11th Annual International Conference on Software Engineering and Knowledge Engineering, Kaiserslautern, Germany, June 17 - 19, 1999},
title = {{Knowledge Maintenance Heresies: Meta-Knowledge Complicates KM}},
year = {1999}
}
@inproceedings{harman10,
author = {Harman, Mark},
booktitle = {PROMISE},
pages = {1},
title = {{The relationship between search based software engineering and predictive modeling}},
year = {2010}
}
@article{Webb2005,
author = {Webb, Geoff},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/agrawal05.pdf:pdf},
keywords = {clustering,dimensionality reduction,subspace clustering},
pages = {5--33},
title = {{Automatic Subspace Clustering of High Dimensional Data}},
year = {2005}
}
@article{shavlik91,
author = {Shavlik, J W and Mooney, R L and Towell, G G},
journal = {Machine Learning},
pages = {111--143},
title = {{Symbolic and Neural Learning Algorithms: An Experimental Comparison}},
volume = {6},
year = {1991}
}
@inproceedings{MENZIES2005,
address = {New York, NY, USA},
author = {Menzies, Tim and Port, Dan and Chen, Zhihao and Hihn, Jairus},
booktitle = {PROMISE '05: Proceedings of the 2005 workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1083165.1083170},
isbn = {-159593-125-2},
pages = {1--6},
publisher = {ACM},
title = {{Simple software cost analysis: safe or unsafe?}},
year = {2005}
}
@inproceedings{YANG08,
address = {New York, NY, USA},
author = {Yang, Ye and He, Mei and Li, Mingshu and Wang, Qing and Boehm, Barry},
booktitle = {ESEM '08: Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
doi = {http://doi.acm.org/10.1145/1414004.1414016},
isbn = {978-1-59593-971-5},
pages = {61--69},
publisher = {ACM},
title = {{Phase distribution of software development effort}},
year = {2008}
}
@inproceedings{forb86,
author = {Forbus, K},
booktitle = {AAAI '86},
pages = {113--117},
title = {{Interpretating Measurements of Physical Systems}},
year = {1986}
}
@article{smythe89,
author = {Smythe, G A},
journal = {The Endocrine Pancreas},
publisher = {Raven Press},
title = {{Brain-hypothalmus, \{P\}ituitary and the \{E\}ndocrine \{P\}ancreas}},
year = {1989}
}
@incollection{bannon93,
author = {Bannon, L J and Bodker, S},
chapter = {Beyond the},
publisher = {Cambridge University Press},
title = {{Designing Interaction}},
year = {1993}
}
@inproceedings{me95m,
author = {Menzies, T J and Goss, S},
booktitle = {AI in Defence Workshop, Australian AI'95, also Technical Report TR95-31, Department of Software Development, Monash University},
title = {{Applications of Abduction \#3: ``Black-Box'' to ``Gray-Box'' Model}},
year = {1995}
}
@article{tosun2010,
author = {Tosun, A and Bener, A and Turhan, B and Menzies, T},
title = {{No Title}}
}
@article{Descent2010,
author = {Descent, Steepest},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Descent - 2010 - Evolutionary computation for optimization.pdf:pdf},
journal = {Materials and Manufacturing Processes},
number = {March},
pages = {17--20},
title = {{Evolutionary computation for optimization}},
year = {2010}
}
@article{Fingerprint2010,
author = {Fingerprint, Integrated Automated},
file = {:Users/timm/svns/doc/IEEESpectrumBeyondCSIRiseofComputationalForensics.pd.pdf:pdf},
journal = {Computing},
keywords = {forensics},
mendeley-tags = {forensics},
title = {{Beyond C . S . I .: The Rise of Computational Forensics}},
year = {2010}
}
@inproceedings{quinlan96,
address = {Berlin},
author = {Quinlan, J R},
booktitle = {Proceedings of the 7th International Workshop on Algorithmic Learning Theory},
editor = {Arikawa, Setsuo and Sharma, Arun K},
isbn = {3-540-61863-5},
pages = {143--155},
publisher = {Springer},
series = {LNAI},
title = {{Boosting first-order learning}},
volume = {1160},
year = {1996}
}
@article{Ibm1993,
author = {Ibm, Agrawal and Road, Tomasz Almaden},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/agrawal93.pdf:pdf},
journal = {IBM Almaden Research Center},
pages = {207--216},
title = {{Mining Association in Large Databases}},
year = {1993}
}
@inproceedings{schnieder98,
author = {Schneider, F and Easterbrook, S M and Callahan, J R and Holzmann, G J},
booktitle = {3rd IEEE International Conference On Requirements Engineering},
title = {{Validating Requirements for Fault Tolerant Systems using Model Checking}},
year = {1998}
}
@inproceedings{Ramakrishnan1995,
author = {Ramakrishnan, S and Menzies, T},
booktitle = {Proceedings SEEP'96, New Zealand},
title = {{An Ongoing Experiment in O-O Software Process and Product Measurements}},
year = {1996}
}
@article{shepperd12z,
author = {Shepperd, Martin J and MacDonell, Steven G},
journal = {Information \{\&\} Software Technology},
number = {8},
pages = {820--827},
title = {{Evaluating prediction systems in software project estimation}},
volume = {54},
year = {2012}
}
@inproceedings{deb95a,
author = {Debenham, J},
booktitle = {Proceedings Sixth International Conference on Database and Expert Systems Applications DEXA'95, London, September},
title = {{Understanding Expert Systems Maintenance}},
year = {1995}
}
@article{Poli2007,
abstract = {Particle swarm optimization (PSO) has undergone many changes since its introduction in 1995. As researchers have learned about the technique, they have derived new versions, developed new applications, and published theoretical studies of the effects of the various parameters and aspects of the algorithm. This paper comprises a snapshot of particle swarming from the authorsâ perspective, including variations in the algorithm, current and ongoing research, applications and open problems.},
author = {Poli, Riccardo and Kennedy, James and Blackwell, Tim},
doi = {10.1007/s11721-007-0002-0},
file = {:Users/timm/svns/doc/pso/07psoReview.pdf:pdf},
isbn = {9781612840529},
issn = {1935-3812},
journal = {Swarm Intelligence},
keywords = {particle swarm optimization,particle swarms,pso,real world applications,social networks,swarm,swarm dynamics,theory},
number = {1},
pages = {33--57},
pmid = {21738602},
title = {{Particle swarm optimization}},
volume = {1},
year = {2007}
}
@inproceedings{RANA2009,
address = {Berlin, Heidelberg},
author = {Rana, Zeeshan Ali and Awais, Mian Muhammad and Shamail, Shafay},
booktitle = {ICIC'09: Proceedings of the Intelligent computing 5th international conference on Emerging intelligent computing technology and applications},
isbn = {3-642-04019-5, 978-3-642-04019-1},
pages = {144--153},
publisher = {Springer-Verlag},
title = {{An FIS for early detection of defect prone modules}},
year = {2009}
}
@inproceedings{duda76,
author = {Duda, R and Hart, P and Nilsson, N},
booktitle = {Technical Report 124, Artificial Intelligence Center, SRI International},
title = {{Subjective bayesian methods for rule-based inference systems}},
year = {1976}
}
@inproceedings{cai98,
author = {Cai, C H and Fu, A W C and Cheng, C H and Kwong, W W},
booktitle = {Proceedings of International Database Engineering and Applications Symposium (IDEAS 98)},
month = aug,
title = {{Mining Association Rules with Weighted Items}},
year = {1998}
}
@article{Schneider2010,
author = {Schneider, Jeff},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Schneider - 2010 - Projection Penalties Dimension Reduction without Loss.pdf:pdf},
journal = {Forbes},
keywords = {Dimensionality reduction, regularization, kernel m},
title = {{Projection Penalties : Dimension Reduction without Loss}},
year = {2010}
}
@article{gregor02,
annote = {Available from $\backslash$url\{http://dl.acs.org.au/index.php/ajis/article/viewPDFInterstitial/439/399?ads=\}},
author = {Gregor, S},
journal = {Australasian Journal of Information Systems},
month = dec,
title = {{Design Theory in Information Systems}},
year = {2002}
}
@inproceedings{RamMe1996,
author = {Ramakrishnan, S and Menzies, T and Hasslinger, M and Bok, P and Mccarthy, H and Devakadadcham, B and Moulder, D},
booktitle = {Proceedings of Tools-Pacific, Melbourne},
title = {{On Building an Effective Measurement System for OO Software Process}},
year = {1996}
}
@book{pree95,
author = {Pree, W},
publisher = {Addison-Wesley},
title = {{Design Patterns for Object-Oriented Software Development}},
year = {1995}
}
@article{Book2008,
abstract = {It is well known that a programâs cost is related to its schedule, yet when a programâs schedule estimate is updated, it is not often that the cost estimate is updated in parallel to reflect consistency with the new schedule estimate. One reason for this deficiency in estimating is probably the unfortunate wall of separation that seems to divide those analysts who do cost estimating from those analysts who do schedule estimating. Another appears to be a lack of understanding of the extent of the impact of schedule growth on cost growth.},
author = {Book, Stephen a. and Book, Stephen a.},
file = {:Users/timm/svns/doc/cost/07Quantify.pdf:pdf},
journal = {The Measurable News},
number = {1},
pages = {11--15},
title = {{Quantifying the Relationship between Schedule and Cost}},
year = {2008}
}
@inproceedings{uribe94,
author = {Uribe, Tomas E and Stickel, Mark E},
booktitle = {In Proc. of the 1st International Conference on Constraints in Computational Logics},
pages = {34--49},
publisher = {Springer-Verlag},
title = {{Ordered Binary Decision Diagrams and the Davis-Putnam procedure}},
year = {1994}
}
@inproceedings{me03c,
abstract = {To meet the needs of busy people who$\backslash$nonly want to know enough to achieve$\backslash$nthe most benefits, the TAR2 treatment$\backslash$nlearner generates easy-to-read and$\backslash$nimmediately useful data mining rules.},
author = {Menzies, Tim and Menzies, Tim and Hu, Ying and Hu, Ying},
booktitle = {IEEE Computer Society},
month = nov,
title = {{Data Mining for$\backslash$nVery Busy People}},
year = {2003}
}
@article{bachant84,
author = {Bachant, J and McDermott, J},
journal = {\{AI\} Magazine},
pages = {21--32},
title = {{\{R1\} \{R\}evisited: \{F\}our \{Y\}ears in the \{T\}renches}},
year = {1984}
}
@inproceedings{memaco92,
author = {Menzies, T and Mahidadia, A and Compton, P},
booktitle = {Proceedings of the 7th \{AAAI\}-Sponsored \{B\}anff Knowledge Acquisition for Knowledge-Based Systems Workshop \{B\}anff, \{C\}anada, October 11-16},
title = {{Using \{C\}ausality as a \{G\}eneric \{K\}nowledge \{R\}epresentation, or \{W\}hy and \{H\}ow \{C\}entralised \{K\}nowledge \{S\}ervers \{C\}an \{U\}se \{C\}ausality}},
year = {1992}
}
@article{Bavota2012a,
abstract = {Changes during software evolution and poor design decisions often lead to packages that are hard to understand and maintain, because they usually group together classes with unrelated responsibilities. One way to improve such packages is to decompose them into smaller, more cohesive packages. The difficulty lies in the fact that most definitions and interpretations of cohesion are rather vague and the multitude of measures proposed by researchers usually capture only one aspect of cohesion. We propose a new technique for automatic re-modularization of packages, which uses structural and semantic measures to decompose a package into smaller, more cohesive ones. The paper presents the new approach as well as an empirical study, which evaluates the decompositions proposed by the new technique. The results of the evaluation indicate that the decomposed packages have better cohesion without a deterioration of coupling and the re-modularizations proposed by the tool are also meaningful from a functional point of view.},
annote = {Laura. Fixed on 10/16/2012},
author = {{Bavota Gabriele}, De Lucia Andrea Marcus Andrian and Oliveto, Rocco},
journal = {Empirical Software Engineering (EMSE)},
keywords = {modularity SEVERE},
pages = {1--32},
title = {{Using structural and semantic measures to improve software modularization}}
}
@inproceedings{mozina04,
address = {New York, NY, USA},
author = {Mo\v{z}ina, Martin and Dem\v{s}ar, Janez and Kattan, Michael and Zupan, Bla\v{z}},
booktitle = {PKDD '04: Proceedings of the 8th European Conference on Principles and Practice of Knowledge Discovery in Databases},
isbn = {3-540-23108-0},
pages = {337--348},
publisher = {Springer-Verlag New York, Inc.},
title = {{Nomograms for visualization of naive Bayesian classifier}},
year = {2004}
}
@inproceedings{chen05,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05/fsscocomo.pdf\}},
author = {Chen, Zhihao and Menzies, Tim and Port, Dan and Boehm, Barry},
booktitle = {ACM SIGSOFT Software Engineering Notes},
doi = {10.1145/1082983.1083171},
issn = {01635948},
number = {4},
pages = {1},
title = {{Feature subset selection can improve software cost estimation accuracy}},
volume = {30},
year = {2005}
}
@inproceedings{keim99,
author = {Keim, G A and Shazeer, N and Littman, M L and Agarwal, S and Cheves, C M and Fitzgerald, J and Grosland, J and Jiang, F and Pollard, S and Weinmeister, K},
booktitle = {Proceedings of the Sixteenth National Conference on Artificial Intelligence (AAAI-99)},
pages = {710--717},
title = {{Proverb: The probabilistic cruciverbalist}},
year = {1999}
}
@inproceedings{ostrand10,
author = {Ostrand, Thomas J and Weyuker, Elaine J and Bell, Robert M},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering},
pages = {19:1----19:10},
series = {PROMISE '10},
title = {{Programmer-based fault prediction}},
year = {2010}
}
@inproceedings{koru07,
author = {Koru, A G and Zhang, D and Liu, H},
booktitle = {Proceceedings PROMISE'07 (ICSE)},
title = {{Modeling the Effect of Size on Defect Proneness for Open-Source Software}},
year = {2007}
}
@article{Kamvar2003,
abstract = {We present a simple, easily implemented spectral learning algorithm which applies equally whether we have no supervisory information, pairwise link constraints, or labeled examples. In the unsupervised case, it performs consistently with other spectral clustering algorithms. In the supervised case, our approach achieves high accuracy on the categorization of thousands of documents given only a few dozen labeled training documents for the 20 Newsgroups data set. Furthermore, its classification accuracy increases with the addition of unlabeled documents, demonstrating effective use of unlabeled data. By using normalized affinity matrices which are both symmetric and stochastic, we also obtain both a probabilistic interpretation of our method and certain guarantees of performance.},
author = {Kamvar, Sepandar D. and Klein, Dan and Manning, Christopher D.},
doi = {10.1.1.13.6919},
file = {:Users/timm/svns/doc/08spectralLearning.pdf:pdf},
isbn = {9789533070100},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {561--566},
title = {{Spectral learning}},
year = {2003}
}
@article{fen95a,
author = {Fensel, D},
journal = {The Knowledge Engineering Review},
number = {4},
title = {{Formal Specification Languages in Knowledge and Software Engineering}},
volume = {10},
year = {1995}
}
@misc{fen97a,
annote = {$\backslash$url\{http://www.aifb.uni-karlsruhe.de/WBS/dfe/dlfl/summary.html\}},
author = {{D. Fensel M.-C. Rousset}, S Decker},
howpublished = {to appear in Data and Knowledge Engineering},
title = {{Workshop on Comparing Description and Frame Logics}},
year = {1997}
}
@article{vose86,
author = {Vose, G M and Williams, G},
journal = {Byte},
pages = {84--92},
title = {{LabVIEW: Laboratory Virtual Instrument Engineering Workbench}},
volume = {11},
year = {1986}
}
@misc{Norvig2011,
author = {Norvig, Peter},
booktitle = {New York Post},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Norvig - 2011 - The machine age.pdf:pdf},
title = {{The machine age}},
url = {http://www.getcited.org/pub/102527552},
year = {2011}
}
@misc{kummer00,
author = {Kummer, O},
title = {{The petri nets bibliography; keyword: reliability. $\backslash$url\{http://www.informatik.uni-hamburg.de/TGI/pnbib/keywords/r/reliability.html\}}},
year = {2000}
}
@article{Shepperd2014,
author = {Shepperd, Martin and Bowes, David and Hall, Tracy},
doi = {10.1109/TSE.2014.2322358},
file = {:Users/timm/svns/doc/14shepperdResearcherBias.pdf:pdf},
issn = {0098-5589},
number = {6},
pages = {603--616},
title = {{Researcher Bias : The Use of Machine Learning in Software Defect Prediction}},
volume = {40},
year = {2014}
}
@inproceedings{owen03d,
author = {Owen, David and Menzies, Tim and Heimdahl, Mats and Gao, Jimin},
title = {{Finding \{F\}aults \{Q\}uickly in \{F\}ormal \{M\}odels \{U\}sing \{R\}andom \{S\}earch}},
year = {2004}
}
@misc{joseph94,
author = {Josephson, John R and Josephson\~{}(eds), Susan G},
publisher = {Cambridge University Press},
title = {{Abductive Inference Computation, Philosophy, Technology}},
year = {1994}
}
@article{vandebrug86,
author = {de Brug, A Van and Bachant, J and McDermott, J},
journal = {IEEE Expert},
pages = {33--39},
title = {{The \{T\}aming of \{R1\}}},
year = {1986}
}
@article{gordon85,
annote = {Dempster-Shafer theory explained and generalized.},
author = {Gordon, J and Shortliffe, E H},
journal = {Artificial Intelligence},
month = jul,
number = {3},
pages = {323--357},
title = {{A Method for Managing Evidential Reasoning in a Hierarchical Hypothesis Space}},
volume = {26},
year = {1985}
}
@article{bieman92,
author = {Bieman, J M and Schultz, J L},
journal = {Software Engineering Journal},
number = {1},
pages = {43--51},
title = {{An empirical evaluation (and specification) of the all-du-paths testing criterion}},
volume = {7},
year = {1992}
}
@inproceedings{me05d,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05learncost.pdf\}},
author = {Menzies, T and Port, D and Chen, Z and Hihn, J and Stukes, S},
booktitle = {IEEE ASE, 2005},
title = {{Specialization and Extrapolation of Induced Domain Models: Case Studies in Software Effort Estimation}},
year = {2005}
}
@inproceedings{madachy11,
author = {Madachy, Raymond and Boehm, Barry and Clark, Brad and Tan, Thomas and Rosa, Wilson},
booktitle = {ESEM'11},
title = {{US DoD Application Domain Empirical Software Cost Analysis}},
year = {2011}
}
@article{huang05,
author = {Huang, J and Ling, C},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = mar,
number = {3},
pages = {299--310},
title = {{Using AUC and Accuracy in Evaluating Learning Algorithms}},
volume = {17},
year = {2005}
}
@article{Schellhammer2007,
abstract = {Structure-based virtual screening today is basically organized as a sequential process where the molecules of a screening library are evaluated for instance with respect to their fit with a biological target. In this paper, we present a novel structure-based screening paradigm avoiding sequential searching and therefore enabling sublinear runtime behavior. We implemented the novel paradigm in the virtual screening tool TrixX and successfully applied it in screening experiments on four targets from relevant therapeutic areas. With the screening paradigm implemented in TrixX, we propose some important extensions and modifications to traditional virtual screening approaches: Instead of processing all compounds in the screening library sequentially, TrixX first analyzes the geometric and physicochemical binding site characteristics and then draws compounds with matching features from a compound catalog. The catalog organizes the compounds by their physicochemical and geometric features making use of relational database technology with indexed tables in order to support efficient queries for compounds with specific features. A key element of the compound catalog is a highly selective geometric descriptor that carries information on the type of functional groups of the compound, their Euclidian distance, the preferred interaction direction of each functional group, and the location of steric bulk around the triangle. In a re-docking experiment with 200 protein-ligand complexes, we could show that TrixX is able to correctly predict the location of ligand functional groups in co-crystallized complexes. In a retrospective virtual screening experiment for four different targets, the enrichment factors of TrixX are comparable to the enrichment factors of FlexX and FlexX-Scan. With computing times clearly below one second per compound, TrixX counts among the fastest virtual screening tools currently available and is nearly two orders of magnitude faster than standard FlexX.},
author = {Schellhammer, Ingo and Rarey, Matthias},
doi = {10.1007/s10822-007-9103-5},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Schellhammer2007.pdf:pdf},
issn = {0920654X},
journal = {Journal of Computer-Aided Molecular Design},
keywords = {FlexX,Geometric hashing,Molecular descriptor,Molecular docking,Relational database,Structure-based virtual screening,TrixX},
number = {5},
pages = {223--238},
pmid = {17294247},
title = {{TrixX: Structure-based molecule indexing for large-scale virtual screening in sublinear time}},
volume = {21},
year = {2007}
}
@article{me99j,
author = {Menzies, Tim},
journal = {International Journal of Human-Computer Studies, special issue on evaluation of KE techniques},
month = oct,
number = {4},
pages = {783--799},
title = {{Critical Success Metrics: Evaluation at the Business-Level}},
volume = {51},
year = {1999}
}
@inproceedings{craw94,
author = {Craw, S and Sleeman, D and Boswell, R and Carbonara, L},
booktitle = {Proceedings of the MLNet Familiarization Workshop on Theory Revision and Restructuring in Machine Learning (ECML-94)},
editor = {Wrobel, S},
pages = {32--34},
title = {{Is knowledge refinement different from theory revision?}},
year = {1994}
}
@inproceedings{provost98case,
author = {Provost, Foster and Fawcett, Tom and Kohavi, Ron},
booktitle = {Proc. 15th International Conf. on Machine Learning},
pages = {445--453},
publisher = {Morgan Kaufmann, San Francisco, CA},
title = {{The case against accuracy estimation for comparing induction algorithms}},
year = {1998}
}
@inproceedings{heitmeyer02,
author = {Heitmeyer, C L},
booktitle = {Encyclopedia of Software Engineering},
editor = {Marciniak, John J},
isbn = {0-471-02895-9},
month = jan,
title = {{Software Cost Reduction}},
year = {2002}
}
@book{fenton96,
author = {Fenton, N E and Pfleeger, S L},
publisher = {International Thompson Press},
title = {{Software Metrics: A Rigorous \& Practical Approach (second edition)}},
year = {1995}
}
@misc{boehm09a,
annote = {Keynote address, PROMISE'09},
author = {Boehm, B},
title = {{No Title}},
year = {2009}
}
@inproceedings{selman92,
author = {Selman, B and Levesque, H and Mitchell, D},
booktitle = {\{AAAI\} '92},
pages = {440--446},
title = {{A New Method for Solving Hard Satisfiability Problems}},
year = {1992}
}
@article{benj98,
annote = {To appear},
author = {Benjamins, R and Fensel, D and Chandrasekaran, B},
journal = {International Journal of Human-Computer Studies},
title = {{PSMs do IT! -- Summary of track on Sharable and Reusable Problem-Solving Methods of the 10th KAW'96, Banff, Canada}},
year = {1998}
}
@misc{herb94,
author = {Herbsleb, James and Carleton, Anita and Rozum, James and Siegel, Jane and Zubrow, David},
institution = {Software Engineering Institute, Carnegie Mellon University},
month = aug,
title = {{Benefits of CMM-Based Software Process Improvement: Initial Results}},
year = {1994}
}
@misc{fea03c,
author = {Feather, M S and Menzies, T and Connelly, J R},
booktitle = {Proceedings of the 11th IEEE International Requirements Engineering Conference; Monterey Bay, California},
month = sep,
title = {{Relating Practitioner Needs to Research Activities}},
year = {2003}
}
@inproceedings{mccarthy93,
author = {McCarthy, J},
booktitle = {IJCAI '93},
pages = {555--560},
title = {{Notes on Formalizing Context}},
year = {1993}
}
@article{Yoon2010,
author = {Yoon, Kyung-A and Bae, Doo-Hwan},
doi = {10.1016/j.infsof.2009.08.005},
file = {:Users/timm/svns/doc/yoon10.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
month = feb,
number = {2},
pages = {137--151},
title = {{A pattern-based outlier detection method identifying abnormal attributes in software project data}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950584909001256},
volume = {52},
year = {2010}
}
@article{Azuaje2003,
abstract = {This article focuses on clustering techniques for the analysis of microarray data and discusses contributions and applications for the implementation of intelligent diagnostic systems and therapy design studies. Approaches to validating and visualising expression clustering results and software and other relevant resources to support clustering-based analyses are reviewed. Finally, this paper addresses current limitations and problems that need to be investigated for the development of an advanced generation of pattern discovery tools.},
author = {Azuaje, Francisco},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/Azuaje02.pdf:pdf},
isbn = {1467-5463 (Print)},
issn = {1467-5463},
journal = {Briefings in bioinformatics},
keywords = {annotation and visualisation,cluster,clustering,expression data},
number = {1},
pages = {31--42},
pmid = {12715832},
title = {{Clustering-based approaches to discovering and visualising microarray data patterns.}},
volume = {4},
year = {2003}
}
@book{reisig82,
author = {Reisig, W},
publisher = {Springer Verlag},
title = {{Petri Nets}},
year = {1982}
}
@article{marques92,
author = {Marques, D and Dallemagne, G and Kliner, G and McDermott, J and Tung, D},
journal = {IEEE Expert},
month = jun,
pages = {16--29},
title = {{Easy \{P\}rogramming: Empowering \{P\}eople to \{B\}uild \{T\}heir Own \{A\}pplications}},
year = {1992}
}
@misc{bse,
author = {Cohen, R F},
title = {{A \{R\}eport on the \{B\}achelor of \{E\}ngineering (\{S\}oftware \{E\}ngineering) \{D\}egree at the \{U\}niversity of \{N\}ewcastle}}
}
@article{deKleer86d,
author = {DeKleer, J and Brown, J S},
journal = {Artificial Intelligence},
pages = {33--61},
title = {{Theories of Causal Ordering}},
volume = {29},
year = {1986}
}
@inproceedings{xie12,
author = {Xie, Tao},
booktitle = {Proc. 12th International Working Conference on Source Code Analysis and Manipulation (SCAM 2012), Keynote Paper},
month = sep,
title = {{Cooperative Testing and Analysis: Human-Tool, Tool-Tool, and Human-Human Cooperations to Get Work Done.}},
url = {http://www.csc.ncsu.edu/faculty/xie/publications/scam12-keynote.pdf},
year = {2012}
}
@article{selman96knowledge,
author = {Selman, Bart and Kautz, Henry},
journal = {Journal of the ACM},
number = {2},
pages = {193--224},
title = {{Knowledge compilation and theory approximation}},
volume = {43},
year = {1996}
}
@article{me99r,
abstract = {So, Iâm to be marooned on a desert island with a handful of books relating to software engineering? I have two immediate, conflicting, reactions. One is to complete the punchline to a music-hall joke: "Second prize, marooned with two handfuls of software engineering books". The other is to think, I take a handful of books on a short train journey, because Iâm terrified of being caught without reading material: how will I last on the island? This wins over the joke, and I start to compose my list. ...},
annote = {Available from $\backslash$url\{http://menzies.us/desert.html\}},
author = {Potts, C.},
doi = {10.1023/A:1008684813868},
issn = {09288910},
journal = {Automated Software Engineering},
number = {4},
pages = {463--466},
title = {{Desert island column}},
volume = {4},
year = {1997}
}
@misc{bse,
author = {Cohen, R F},
title = {{A \{R\}eport on the \{B\}achelor of \{E\}ngineering (\{S\}oftware \{E\}ngineering) \{D\}egree at the \{U\}niversity of \{N\}ewcastle}}
}
@article{Harman2010,
author = {Harman, Mark and Court, Regent},
file = {:Users/timm/svns/doc/harmanTSE10.pdf:pdf;:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Harman, Court - 2010 - A Theoretical and Empirical Study of Search Based Testing Local , Global and Hybrid Search(2).pdf:pdf},
journal = {Tse, to appear},
keywords = {sbse},
title = {{A Theoretical and Empirical Study of Search Based Testing : Local , Global and Hybrid Search}},
year = {2010}
}
@inproceedings{shu86,
author = {Shu, N C},
booktitle = {Visual Languages},
editor = {Chang, S K and Ligomenides, P A},
pages = {11--34},
title = {{Visual Programming Languages: A Perspective and a Dimensional Analysis}},
year = {1986}
}
@article{court93,
author = {Courtney, R E and Gustafson, D A},
journal = {Software Engineering Journal},
month = jan,
number = {1},
pages = {5--13},
title = {{Shotgun correlations in software measures}},
volume = {8},
year = {1993}
}
@inproceedings{decu95,
author = {DeCuyper, J and Keymeulen, D and Steels, L},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and {N.H. Narayanan}, B Chandrasekaran},
pages = {731--752},
publisher = {The AAAI Press},
title = {{A Hybrid Architecture for Modeling Liquid Behavior}},
year = {1995}
}
@inproceedings{me09k,
abstract = {Concept location is a critical activity during software evolution as it produces the location where a change is to start in response to a modification request, such as, a bug report or a new feature request. Lexical-based concept location techniques rely on matching the text embedded in the source code to queries formulated by the developers. The efficiency of such techniques is strongly dependent on the ability of the developer to write good queries. We propose an approach to augment information retrieval (IR) based concept location via an explicit relevance feedback (RF) mechanism. RF is a two-part process in which the developer judges existing results returned by a search and the IR system uses this information to perform a new search, returning more relevant information to the user. A set of case studies performed on open source software systems reveals the impact of RF on IR based concept location.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09irrf.pdf\}},
author = {Gay, Gregory and Haiduc, Sonia and Marcus, Andrian and Menzies, Tim},
booktitle = {IEEE International Conference on Software Maintenance, ICSM},
doi = {10.1109/ICSM.2009.5306315},
isbn = {9781424448289},
issn = {1063-6773},
pages = {351--360},
title = {{On the use of relevance feedback in IR-based concept location}},
year = {2009}
}
@book{rosen93,
author = {Rosenbloom, P S and Laird, J E and Newell, A},
institution = {The MIT Press},
publisher = {The MIT Press},
title = {{The SOAR Papers}},
year = {1993}
}
@inproceedings{me02d,
abstract = {Formal analysis of software is a powerful analysis tool, but can be too costly. Random search of formal models can reduce that cost, but is theoretically incomplete. However, random search of finite-state machines exhibits an early saturation effect, i.e., random search quickly yields all that can be found, even after a much longer search. Hence, we avoid the theoretical problem of incompleteness, provided that testing continues until after the saturation point. Such a random search is rapid, consumes little memory, is simple to implement, and can handle very large formal models (in one experiment shown here, over 10<sup>178</sup> states).},
author = {Menzies, T. and Owen, D. and Cukic, B.},
booktitle = {13th International Symposium on Software Reliability Engineering, 2002. Proceedings.},
doi = {10.1109/ISSRE.2002.1173208},
isbn = {0-7695-1763-3},
issn = {1071-9458},
title = {{Saturation effects in testing of formal models}},
year = {2002}
}
@book{schank77,
author = {Schank, R C and Abelson, R P},
publisher = {Psychology Press},
title = {{Scripts, plans, goals and understanding: an inquiry into human knowledge structures}},
year = {1977}
}
@inproceedings{perry99,
author = {Perry, D E},
booktitle = {Proceedings of WISR9: The 9th annual workshop on Institutionalizing Software Reuse},
title = {{Some holes in the emperor's reused clothes}},
year = {1999}
}
@article{Wong2009,
author = {Wong, W. Eric and Tse, T.H. and Glass, Robert L. and Basili, Victor R. and Chen, T.Y.},
doi = {10.1016/j.jss.2009.06.018},
file = {:Users/timm/svns/doc/wong10.pdf:pdf},
issn = {01641212},
journal = {Journal of Systems and Software},
month = aug,
number = {8},
pages = {1370--1373},
title = {{An assessment of systems and software engineering scholars and institutions (2002â2006)}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0164121209001265},
volume = {82},
year = {2009}
}
@book{Humphrey1989,
author = {Humphrey, W S},
publisher = {Addison-Wesley, Readings, Mass},
title = {{Managing the Software Process}},
year = {1989}
}
@article{Grosan2010b,
author = {Grosan, Crina and Abraham, Ajith},
doi = {10.1016/j.ins.2009.12.018},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Grosan, Abraham - 2010 - Approximating Pareto frontier using a hybrid line search approach.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {pareto},
mendeley-tags = {pareto},
month = jul,
number = {14},
pages = {2674--2695},
title = {{Approximating Pareto frontier using a hybrid line search approach}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0020025509005489},
volume = {180},
year = {2010}
}
@misc{fea03c,
abstract = { Many organizations look to research to yield new and improved products and practices. Connecting practitioners who have the need for research results to the researchers producing those results is important to guiding research and utilizing its results. Likewise, connecting researchers working on related topics to one another, and connecting practitioners with related needs to one another, is important to establishing communities of shared interests. We demonstrate an approach that helps identify fruitful such connections.},
author = {Feather, M.S. and Menzies, T. and Connelly, J.R.},
booktitle = {Proceedings. 11th IEEE International Requirements Engineering Conference, 2003.},
doi = {10.1109/ICRE.2003.1232783},
isbn = {0-7695-1980-6},
issn = {1090-705X},
month = sep,
title = {{Relating practitioner needs to research activities}},
year = {2003}
}
@inproceedings{wilson97,
author = {Wilson, W M and Rosenberg, L H and Hyatt, L E},
booktitle = {ICSE '97},
month = may,
pages = {161--171},
title = {{Automated Analysis of Requirement Specifications}},
year = {1997}
}
@article{mittas12,
author = {Mittas, Nikolaos and Angelis, Lefteris},
journal = {Empirical Software Engineering},
number = {1},
pages = {34--61},
title = {{A permutation test based on regression error characteristic curves for software cost estimation models}},
volume = {17},
year = {2012}
}
@inproceedings{frakes99,
author = {Frakes, W B},
booktitle = {Proceedings of WISR9: The 9th annual workshop on Institutionalizing Software Reuse},
title = {{Domain engineering education}},
year = {1999}
}
@misc{me97r,
author = {Menzies, T and Waugh, S and Goss, S and Cohen, Robert F},
howpublished = {Submitted to FOIS '97},
title = {{Evaluating a Temporal Causal Ontology}},
year = {1997}
}
@inproceedings{cio02,
author = {Ciolkowski, M and Laitenberger, O and Rombach, D H and Shull, F and Perry, D},
booktitle = {Proceedings of ICSE 2002},
pages = {641--642},
title = {{Software inspections, reviews and walkthroughs}},
year = {2002}
}
@article{simons99,
author = {Simons, Daniel and Chabris, Christopher},
number = {9},
pages = {1059--1074},
title = {{Gorillas in our midst: sustained inattentional blindness for dynamic events.}},
volume = {28},
year = {1999}
}
@inproceedings{han99,
author = {Han, K and Veloso, M},
booktitle = {Proceedings of the Sixteenth Interntional Joint Conference on Artificial Intelligence. Workshop on Team Behaviour and Plan Recognition},
pages = {47--52},
title = {{Automated robot behaviour recognition applied to robot soccer}},
year = {1999}
}
@article{Fung2009,
author = {Fung, Benjamin C.M. and Wang, Ke and Wang, Lingyu and Hung, Patrick C.K.},
doi = {10.1016/j.datak.2008.12.001},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Fung et al. - Unknown - Privacy-Preserving Data Publishing for Cluster Analysis.pdf:pdf},
issn = {0169023X},
journal = {Data \& Knowledge Engineering},
keywords = {anonymity,cluster analysis,knowledge discovery,preprint submitted to elsevier,privacy},
month = jun,
number = {6},
pages = {552--575},
title = {{Privacy-preserving data publishing for cluster analysis}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0169023X08001766},
volume = {68},
year = {2009}
}
@article{gray06,
author = {Gray, J and Lin, Y and Zhang, J},
journal = {IEEE Computer},
month = feb,
number = {2},
pages = {51--58},
title = {{Automating Change Evolution in Model-Driven Engineering}},
volume = {39},
year = {2006}
}
@article{Slamanig2008a,
author = {Slamanig, Daniel and Stingl, Christian},
doi = {10.1109/ARES.2008.115},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Slamanig, Stingl - 2008 - Privacy Aspects of eHealth.pdf:pdf},
isbn = {978-0-7695-3102-1},
journal = {2008 Third International Conference on Availability, Reliability and Security},
month = mar,
pages = {1226--1233},
publisher = {Ieee},
title = {{Privacy Aspects of eHealth}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4529483},
year = {2008}
}
@inproceedings{me98c,
author = {Menzies, T J and Waugh, S},
booktitle = {Proceedings of the Australian AI '98 conference},
publisher = {World-Scientific},
title = {{Lower Limits on the Size of Test Data Sets}},
year = {1998}
}
@article{hulten03,
annote = {Available from $\backslash$url\{http://www.cs.washington.edu/homes/ghulten/papers/genframe-jcgs.pdf\}},
author = {Hulten, G and Domingos, P},
journal = {Journal of Computational and Graphical Statistics},
title = {{A General Framework for Mining Massive Data Streams}},
volume = {12},
year = {2003}
}
@mastersthesis{province15,
author = {Province, B},
school = {CSEE, WVU},
title = {{Explorataions of the Low Dimensionality of SE data (in preperation)}},
year = {2015}
}
@inproceedings{owen04a,
annote = {Tech report, Computer Science, West Virginia University},
author = {Owen, David and Menzies, Tim},
title = {{Experiments with LURCH}},
year = {2004}
}
@inproceedings{corn02,
author = {Cornford, S and Dunphy, J and Feather, M S},
booktitle = {IEEE Aerospace Conference, Big Sky Montana},
month = mar,
pages = {9--16},
title = {{Optimizing the Design of end-to-end Spacecraft Systems using risk as a currency}},
year = {2002}
}
@misc{leiws,
annote = {$\backslash$url\{http://en.wikipedia.org/wiki/Lennox\_Lewis\}},
title = {{Lennox Lewis}}
}
@phdthesis{elrawas08,
annote = {Available from $\backslash$url\{http://unbox.org/wisp/var/ous/thesis/thesis.pdf\}},
author = {El-Rawas, O},
school = {Lane Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{Software Process Control Without Calibration}},
year = {2008}
}
@book{verm99,
author = {Vermesan, A and Coenen, F},
isbn = {0-7923-8645-0},
publisher = {Kluwer Academic Publishing, Utrecht, Netherlands},
title = {{Validation and Verication of Knowledge Based Systems: Theory, Tools and Practice}},
year = {1999}
}
@inproceedings{me00f,
abstract = {Modern software is often constructed using \&amp;ldquo;spiral
specification\&amp;rdquo;; i.e. the specification is a dynamic document that
is altered by experience with the current version of the system.
Mathematically, many of the sub-tasks within spiral specification belong
to the NP-complete class of tasks. In the traditional view of computer
science, such tasks are fundamentally intractable and only solvable
using incomplete, approximate methods that can be undependable. This
traditional view suggests that we should routinely expect spiral
specification to always be performed very poorly. This paper is an
antidote to such pessimism. Contrary to the traditional view, we can
expect that spiral specification can usually be performed adequately,
providing that analysts augment their current tools with random probing
},
author = {Menzies, T.},
booktitle = {Tenth International Workshop on Software Specification and Design. IWSSD-10 2000},
doi = {10.1109/IWSSD.2000.891157},
isbn = {0-7695-0884-7},
title = {{The complexity of TRMCS-like spiral specification}},
year = {2000}
}
@article{littlewood97,
author = {Littlewood, B and Wright, D},
journal = {IEEE Transactions on Software Engineering},
month = nov,
number = {11},
pages = {673--683},
title = {{Some Conservative Stopping Rules for the Operational Testing of Safety-Critical Software}},
volume = {23},
year = {1997}
}
@inproceedings{Kocaguneli2009a,
author = {Kocaguneli, Ekrem and Kultur, Y. and Bener, A.B.},
booktitle = {ISSRE '09},
file = {:Users/timm/svns/doc/ekrem09a.pdf:pdf},
title = {{Combining Multiple Learners Induced on Multiple Datasets for Software Effort Prediction}},
url = {http://www.issre2009.org/papers/issre2009\_245.pdf},
year = {2009}
}
@article{Tarasov2009,
abstract = {To estimate how sophisticated should an empirical scoring function be to ensure successful docking, scoring and virtual screening a new scoring function NScore (naive score) has been developed and tested. NScore is an extremely simple function and has the minimum possible number of parameters; nevertheless, it allows all the main effects determining the ligand-protein interaction to be taken into account. The fundamental difference of NScore from the currently used empirical functions is that all its parameters are selected on the basis of general physical considerations, without any adjustment or training with the use of experimental data on ligand-protein interaction. The results of docking and scoring with the use of NScore in an independent test sets of proteins and ligands have proved to be as good as those yielded by the ICM, GOLD, and Glide software packages, which use sophisticated empirical scoring functions. With respect to some parameters, the results of docking with the use of NScore are even better than those obtained using other functions. Since no training set is used in the development of NScore, this scoring function is indeed versatile in that it does not depend on the specific goal or target. We have performed virtual screening for ten targets and obtained results almost as good as those yielded by the Glide and better than GOLD and DOCK software.},
author = {Tarasov, Dmitry and Tovbin, Dmitry},
doi = {10.1007/s00894-008-0390-0},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Tarasov2008.pdf:pdf},
isbn = {0948-5023 (Electronic)},
issn = {16102940},
journal = {Journal of Molecular Modeling},
keywords = {Docking,Interaction,Ligand-protein,New scoring function NScore,Scoring,Virtual screening},
number = {3},
pages = {329--341},
pmid = {19066998},
title = {{How sophisticated should a scoring function be to ensure successful docking, scoring and virtual screening?}},
volume = {15},
year = {2009}
}
@inproceedings{koe95,
author = {Koedinger, K R and Anderson, J R},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and {N.H. Narayanan}, B Chandrasekaran},
pages = {577--625},
publisher = {The AAAI Press},
title = {{Abstract Planning and Conceptual Chunks}},
year = {1995}
}
@inproceedings{JIANG20082,
address = {New York, NY, USA},
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim},
booktitle = {DEFECTS '08: Proceedings of the 2008 workshop on Defects in large software systems},
doi = {http://doi.acm.org/10.1145/1390817.1390822},
isbn = {978-1-60558-051-7},
pages = {16--20},
publisher = {ACM},
title = {{Can data transformation help in the detection of fault-prone modules?}},
year = {2008}
}
@inproceedings{williams03,
annote = {$\backslash$url\{http://www.cs.cornell.edu/gomes/FILES/backdoors.pdf\}},
author = {Williams, R and Gomes, C P and Selman, B},
booktitle = {Proceedings of IJCAI 2003},
title = {{Backdoors to Typical Case Complexity}},
year = {2003}
}
@article{valerdi11b,
author = {Valerdi, Ricardo},
journal = {IEEE Systems Journal},
number = {1},
pages = {91--98},
title = {{Heuristics for Systems Engineering Cost Estimation}},
volume = {5},
year = {2011}
}
@inproceedings{waugh97,
annote = {$\backslash$url\{http://www.cse.unsw.edu.au/\~{}timm/pub/docs\}},
author = {Waugh, S and Menzies, T J and Goss, S},
booktitle = {Advanced Topics in Artificial Intelligence: 10th Australian Joint Conference on AI},
editor = {Sattar, Abdul},
isbn = {3-540-63797-4},
publisher = {Springer-Verlag},
title = {{Evaluating a Qualitative Reasoner}},
year = {1997}
}
@article{chen97,
author = {Chen, I},
journal = {IEEE Transactions on Reliability},
number = {1},
pages = {81--87},
title = {{Effect of Parallel Planning on the System Reliability of Real-Time Expert Systems}},
volume = {46},
year = {1997}
}
@article{dijk59,
author = {Dijkstra, E W},
journal = {Numerische Mathematik},
pages = {269--271},
title = {{A note on two problems in connexion with graphs}},
volume = {1},
year = {1959}
}
@inproceedings{cruz09,
author = {Cruz, A E C and Ochimizu, K},
booktitle = {Empirical Software Engineering and Measurement, 2009. ESEM 2009. 3rd International Symposium on},
pages = {460--463},
title = {{Towards logistic regression models for predicting fault-prone code across software projects}},
year = {2009}
}
@inproceedings{fea01,
author = {Feather, M and In, H and Kiper, J and Kurtz, J and Menzies, T},
booktitle = {ECE UBC tech report},
title = {{First Contract: Better, Earlier Decisions for Software Projects}},
year = {2001}
}
@article{Djordjevic2007,
abstract = {Systematic Evolution of Ligands by EXponential enrichment (SELEX) is an experimental procedure that allows extraction, from an initially random pool of oligonucleotides, of the oligomers with a desired binding affinity for a given molecular target. The procedure can be used to infer the strongest binders for a given DNA or RNA binding protein, and the highest affinity binding sequences isolated through SELEX can have numerous research, diagnostic and therapeutic applications. Recently, important new modifications of the SELEX protocol have been proposed. In particular, a modification of the standard SELEX procedure allows generating a dataset from which protein-DNA interaction parameters can be determined with unprecedented accuracy. Another variant of SELEX allows investigating interactions of a protein with nucleic-acid fragments derived from the entire genome of an organism. We review here different SELEX-based methods, with particular emphasis on the experimental design and on the applications aimed at inferring protein-DNA interactions. In addition to the experimental issues, we also review relevant methods of data analysis, as well as theoretical modeling of SELEX. ?? 2007 Elsevier B.V. All rights reserved.},
author = {Djordjevic, Marko},
doi = {10.1016/j.bioeng.2007.03.001},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Djordjevic07.pdf:pdf},
isbn = {1389-0344},
issn = {13890344},
journal = {Biomolecular Engineering},
keywords = {Genomic SELEX,High-throughput SELEX,In vitro selection,Protein-nucleic acid interactions,SELEX modeling,SELEX-SAGE},
number = {2},
pages = {179--189},
pmid = {17428731},
title = {{SELEX experiments: New prospects, applications and data analysis in inferring regulatory pathways}},
volume = {24},
year = {2007}
}
@article{nus01,
author = {Nuseibeh, B A and Easterbrook, S M and Russo, A},
journal = {Journal of Systems and Software},
number = {2},
pages = {171--180},
title = {{Making Inconsistency Respectable in Software Development}},
volume = {58},
year = {2001}
}
@inproceedings{hame94,
author = {Haynes, P and Menzies, T J},
booktitle = {Tools '94},
pages = {121--129},
publisher = {Prentice Hall},
title = {{The \{E\}ffects of \{C\}lass \{C\}oupling on \{C\}lass \{S\}ize in \{S\}malltalk \{S\}ystems}},
year = {1994}
}
@phdthesis{chulani99a,
annote = {Available on-line at $\backslash$url\{http://citeseer.ist.psu.edu/devnani-chulani99bayesian.html\}},
author = {Devnani-Chulani, Sunita},
school = {Graduate School, University of Southern California},
title = {{Bayesian Analysis of Software Cost and Quality Models}},
year = {1999}
}
@inproceedings{me96j,
author = {Menzies, T and Ramakrishnan, S},
booktitle = {Tools Pacific, Melbourne},
title = {{Comparing and Generalising Models for Metrics Repositories}},
year = {1996}
}
@article{DietrichWettscherreckDavidW.Aha1997,
author = {{Dietrich Wettscherreck, David W. Aha}, Takao Mohri},
file = {:Users/timm/svns/doc/a\_review\_and\_empirical\_evaluation\_of\_fea\_117226.pdf:pdf},
issn = {0269-2821},
journal = {Artificial Intelligence Review},
number = {1},
pages = {273--314},
publisher = {Springer},
title = {{A review and empirical evaluation of feature weighting methods for a class of lazy learning algorithms}},
url = {http://www.springerlink.com/index/R1323574686528KT.pdf},
volume = {11},
year = {1997}
}
@inproceedings{FayIra93Multi,
author = {Fayyad, U M and Irani, I H},
booktitle = {Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence},
pages = {1022--1027},
title = {{Multi-interval Discretization of Continuous-valued Attributes for Classification Learning}},
year = {1993}
}
@inproceedings{me07g,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07fix.pdf\}},
author = {Menzies, T and Elrawas, O and Baker, D and Hihn, J and Lum, K},
booktitle = {International Workshop on Living with Uncertainty (an ASE'07 co-located event)},
title = {{On the Value of Stochastic Abduction (if you fix everything, you lose fixes for everything else)}},
year = {2007}
}
@book{kelton02,
author = {Kelton, D and Sadowski, R and Sadowski, D},
publisher = {McGraw-Hill},
title = {{Simulation with Arena, second edition}},
year = {2002}
}
@book{alex64,
author = {Alexander, C},
publisher = {Harvard University Press},
title = {{Notes on Synthesis of Form}},
year = {1964}
}
@book{fenton91,
author = {Fenton, N E},
publisher = {Chapman and Hall, London},
title = {{Software Metrics}},
year = {1991}
}
@inproceedings{kocharm13,
abstract = {We offer a case study illustrating three rules for reporting$\backslash$nresearch to industrial practitioners. Firstly, report ârelevantâ$\backslash$nresults; e.g. this paper explores the effects of distributed development$\backslash$non software products. Second: ârecheckâ old results if new results call$\backslash$nthem into question. Many papers say distributed development can be$\backslash$nharmful to software quality. Previous work by Bird et al. allayed that$\backslash$nconcern but a recent paper by Posnett et al. suggests that the Bird$\backslash$nresult was biased by the kinds of files it explored. Hence, this paper$\backslash$nrechecks that result and finds significant differences in Microsoft$\backslash$nproducts (Office 2010) between software built by distributed or$\backslash$ncollocated teams. At first glance, this recheck calls into question the$\backslash$nwidespread practice of distributed development. Our third rule is to$\backslash$nâreflectâ on results to avoid confusing practitioners with an arcane$\backslash$nmathematical analysis. For example, on reflection, we found that the$\backslash$neffect size of the differences seen in the collocated and distributed$\backslash$nsoftware was so small that it need not concern industrial practitioners.$\backslash$nOur conclusion is that at least for Microsoft products, distributed$\backslash$ndevelopment is not considered harmful.},
author = {Kocaguneli, Ekrem and Zimmermann, Thomas and Bird, Christian and Nagappan, Nachiappan and Menzies, Tim},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2013.6606637},
file = {:Users/timm/svns/doc/13distributed.pdf:pdf},
isbn = {9781467330763},
issn = {02705257},
pages = {882--890},
title = {{Distributed development considered harmful?}},
year = {2013}
}
@inproceedings{clancey91a,
author = {Clancey, W},
booktitle = {NATO Workshop on Emergance, Situatedness, Subsumption, and Symbol},
title = {{A Boy Scout, Toto, and a Bird: How Situated Cognition is Different from Situated Robotics}},
year = {1991}
}
@article{Slamanig2008,
author = {Slamanig, Daniel and Stingl, Christian},
doi = {10.1109/ARES.2008.115},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Slamanig, Stingl - 2008 - Privacy Aspects of eHealth.pdf:pdf},
isbn = {978-0-7695-3102-1},
journal = {2008 Third International Conference on Availability, Reliability and Security},
month = mar,
pages = {1226--1233},
publisher = {Ieee},
title = {{Privacy Aspects of eHealth}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4529483},
year = {2008}
}
@misc{stukes91,
author = {Stukes, S and Apgar, H},
month = mar,
title = {{Applications Oriented Software Data Collection: Software Model Calibration Report, \{TR\}-9007/549-1, Management Consulting and Research}},
year = {1991}
}
@inproceedings{yolanda97,
author = {Gil, Y and Tallis, M},
booktitle = {Proceedings of the Fourteenth National Conference on Artificial Intelligence (AAAI-97)},
title = {{A Script-Based Approach to Modifying Knowledge Bases}},
year = {1997}
}
@article{krall12,
author = {Krall, J and Menzies, T},
journal = {Journal of Software Engineering and Applications},
number = {7},
pages = {459--466},
title = {{Aspects of Replayability and Software Engineering: Towards a Methodology of Developing Games}},
year = {2012}
}
@article{Baralis2004,
author = {Baralis, Elena and Baralis, Elena and Politecnico, Silvia Chiusano and Politecnico, Silvia Chiusano and The, Introduction and The, Introduction and Machines, Vector and Machines, Vector},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/baralis04.pdf:pdf},
journal = {Database},
number = {4},
pages = {635--674},
title = {{Classi cation Rule Sets}},
volume = {29},
year = {2004}
}
@book{simon60,
author = {Simon, H A},
publisher = {Prentice Hall},
title = {{The New Science of Management Decision}},
year = {1960}
}
@article{me99q,
author = {Menzies, T and Cukic, B},
journal = {IEEE Software},
number = {5},
pages = {107--112},
title = {{When to Test Less}},
volume = {17},
year = {2000}
}
@misc{chiang03,
author = {Chiang, E},
title = {{Learning controllers for nonfunctional requirements}},
year = {2003}
}
@inproceedings{passos11,
author = {Passos, Carol and Braun, Ana Paula and Cruzes, Daniela S and Mendonca, Manoel},
booktitle = {ESEM'11},
title = {{Analyzing the Impact of Beliefs in Software Project Practices}},
year = {2011}
}
@article{preece92b,
author = {Preece, A D and Shinghal, R and Batarekh, A},
journal = {Expert Systems with Applications},
number = {2},
pages = {421--436},
title = {{Verifying expert systems: a logical framework and a practical tool}},
volume = {5},
year = {1992}
}
@article{Fayyad1996,
author = {Fayyad, Usama and Piatetsky-shapiro, Gregory and Smyth, Padhraic},
file = {:Users/timm/svns/doc/fayyad06.pdf:pdf},
journal = {AI Magazine},
pages = {37--54},
title = {{From Data Mining to Knowledge Discovery in Databases}},
year = {1996}
}
@inproceedings{sammut86,
author = {Sammut, C and Banerji, R B},
booktitle = {Machine Learning: An Artificial Intelligence Approach},
editor = {Michalski, R S and Carbonell, J G and Mitchell, T M},
pages = {167--192},
publisher = {Los Altos, California: Morgan Kaufmann},
title = {{Learning Concepts by Asking Questions}},
volume = {2},
year = {1986}
}
@inproceedings{men93j,
author = {Menzies, T J and Spurret, R},
booktitle = {Tools Pacific 12},
pages = {213--224},
publisher = {Prentice Hall},
title = {{How to \{E\}dit $\backslash$"it$\backslash$"; or a \{B\}lack-Box \{C\}onstraint \{B\}ased \{F\}ramework for \{U\}ser \{I\}nteraction with \{A\}rbitrary \{S\}tructures}},
year = {1993}
}
@book{boss94,
annote = {ISBN 1-56881-033-4},
author = {Bossel, H},
publisher = {A.K. Peters Ltd},
title = {{Modeling and Simulations}},
year = {1994}
}
@inproceedings{pecheur02,
author = {Nelson, S and Pecheur, C},
booktitle = {Second Goddard Workshop on Formal Aspects of Agent-Based Systems (FAABS II), Greenbelt, MD},
month = oct,
title = {{Formal Verification of a Next-Generation Space Shuttle}},
volume = {2699},
year = {2002}
}
@misc{me98g,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/99ab.pdf\}},
author = {Menzies, T and Waugh, S},
title = {{Abduction: Experiments and Implications}},
year = {1999}
}
@inproceedings{burk04,
author = {Burkleaux, T and Menzies, Tim and Owen, D},
booktitle = {Proceedings of WITSE 2005},
title = {{LEAN = (LURCH+TAR3) = Reusable Modeling Tools}},
year = {2005}
}
@inproceedings{nagappan05,
author = {Nagappan, Nachiappan and Ball, Thomas},
booktitle = {ICSE 2005, St. Louis},
title = {{Static Analysis Tools as Early Indicators of Pre-Release Defect Density}},
year = {2005}
}
@article{Zitzler,
author = {Zitzler, Eckart and Laumanns, Marco and Bleuler, Stefan},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zitzler, Laumanns, Bleuler - Unknown - A Tutorial on Evolutionary Multiobjective Optimization.pdf:pdf},
keywords = {pareto},
mendeley-tags = {pareto},
title = {{A Tutorial on Evolutionary Multiobjective Optimization}}
}
@inproceedings{bennett00,
author = {Bennett, K H and Rajlich, V},
booktitle = {The Future of Software Engineering},
editor = {Finkelstein, A},
isbn = {ISBN 01-58113-253-0},
pages = {73--87},
publisher = {ACM},
title = {{Software maintenance and evolution: a roadmap}},
year = {2000}
}
@inproceedings{MA2007,
address = {Washington, DC, USA},
author = {Ma, Yan and Cukic, Bojan},
booktitle = {PROMISE '07: Proceedings of the Third International Workshop on Predictor Models in Software Engineering},
doi = {http://dx.doi.org/10.1109/PROMISE.2007.1},
isbn = {0-7695-2954-2},
pages = {1},
publisher = {IEEE Computer Society},
title = {{Adequate and Precise Evaluation of Quality Models in Software Engineering Studies}},
year = {2007}
}
@article{Shepperd2000,
author = {Shepperd, Martin},
file = {:Users/timm/svns/doc/cost/07shepperd.pdf:pdf},
isbn = {0769528295},
keywords = {challenge,cost models,effort prediction,empirical soft-,i believe this is,nonetheless,remains a largely unsolved,software project management,still an important topic,ware engineering},
title = {{Software project economics : a roadmap Software project economics : a roadmap}},
year = {2000}
}
@inproceedings{cukic00,
author = {Cukic, B and Chakrawarthy, D},
booktitle = {Proceedings of the 5th International Symposium on High Assurance Systems Engineering, Albuquerque, NM, November},
title = {{Bayesian Framework for Reliability Assurance of a Deployed Safety Critical System}},
year = {2000}
}
@inproceedings{gent95,
author = {Gent, I and MacIntyre, E and Prosser, P and Walsh, T},
booktitle = {International Conference on Principles and Practice of Constraint Programming},
title = {{Scaling Effects in CSP Phase Transistion}},
year = {1995}
}
@inproceedings{pohl11,
author = {Pohl, R and Lauenroth, K and Pohl, K},
booktitle = {Automated Software Engineering (ASE), 2011 26th IEEE/ACM International Conference on},
file = {:Users/timm/svns/doc/11featureMaps.pdf:pdf},
pages = {313--322},
title = {{A performance comparison of contemporary algorithmic approaches for automated analysis operations on feature models}},
year = {2011}
}
@inproceedings{me06f,
annote = {Available from $\backslash$url\{http://menzies.us/06deviations.pdf\}},
author = {Menies, T and Lum, K and Hihn, J},
booktitle = {Promise 2006},
pages = {1--5},
title = {{The Deviance Problem in Effort Estimation}},
year = {2006}
}
@article{Neubauer2009,
address = {New York, New York, USA},
author = {Neubauer, Thomas and Ekelhart, Andreas},
doi = {10.1145/1529282.1529465},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Neubauer, Ekelhart - 2009 - An Evaluation of Technologies for the Pseudonymization of Medical Data.pdf:pdf},
isbn = {9781605581668},
journal = {Proceedings of the 2009 ACM symposium on Applied Computing - SAC '09},
keywords = {Health Care, Privacy, Security,e-health,privacy,pseudonymization,security},
pages = {857},
publisher = {ACM Press},
title = {{An evaluation of technologies for the pseudonymization of medical data}},
url = {http://portal.acm.org/citation.cfm?doid=1529282.1529465},
year = {2009}
}
@phdthesis{acree80,
author = {Acree, A T},
school = {School of Information and Computer Science, Georgia Institute of Technology},
title = {{On Mutations}},
year = {1980}
}
@inproceedings{meseguer92a,
author = {Meseguer, P},
booktitle = {Proceedings of the 10th European Conference on Artificial Intelligence, ECAI-92},
pages = {840--844},
title = {{Incremental Verification of Rule-Based Expert Systems}},
year = {1992}
}
@inproceedings{nich92,
author = {Nicholson, A E and Brady, J M},
booktitle = {Proc. of the 10th European Conf. on Artificial Intelligence (ECAI-92)},
title = {{The data association problem when monitoring robot vehicles using dynamic belief networks}},
year = {1992}
}
@misc{mcgibbon96,
author = {McGibbon, T},
month = sep,
title = {{A Business Case for Software Process Improvement, Data Analysis Center for Software State-of-the-Art Report, prepared for Rome Laboratory,}},
year = {1996}
}
@article{chandola09,
author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
journal = {ACM Comput. Surv.},
month = jul,
number = {3},
pages = {15:1----15:58},
title = {{Anomaly detection: A survey}},
volume = {41},
year = {2009}
}
@article{Das2009,
abstract = {Differential evolution (DE) is well known as a simple and efficient scheme for global optimization over continuous spaces. It has reportedly outperformed a few evolutionary algorithms (EAs) and other search heuristics like the particle swarm optimization (PSO) when tested over both benchmark and real-world problems. DE, however, is not completely free from the problems of slow and/or premature convergence. This paper describes a family of improved variants of the DE/target-to-best/1/bin scheme, which utilizes the concept of the neighborhood of each population member. The idea of small neighborhoods, defined over the index-graph of parameter vectors, draws inspiration from the community of the PSO algorithms. The proposed schemes balance the exploration and exploitation abilities of DE without imposing serious additional burdens in terms of function evaluations. They are shown to be statistically significantly better than or at least comparable to several existing DE variants as well as a few other significant evolutionary computing techniques over a test suite of 24 benchmark functions. The paper also investigates the applications of the new DE variants to two real-life problems concerning parameter estimation for frequency modulated sound waves and spread spectrum radar poly-phase code design.},
author = {Das, Swagatam and Abraham, Ajith and Chakraborty, Uday K. and Konar, Amit},
doi = {10.1109/TEVC.2008.2009457},
file = {:Users/timm/svns/doc/09-de-neighbors.pdf:pdf},
isbn = {1089-778X},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Differential evolution,Evolutionary algorithms,Meta-heuristics,Numerical optimization,Particle swarm optimization},
number = {3},
pages = {526--553},
title = {{Differential evolution using a neighborhood-based mutation operator}},
volume = {13},
year = {2009}
}
@inproceedings{me09f,
abstract = {"Faster, Better, Cheaper" (FBC) was a development philosophy adopted by the NASA administration in the mid to late 1990s. that lead to some some dramatic successes such as Mars Pathfinder as well as a number highly publicized mission failures, such as the Mars Climate Orbiter \& Polar Lander. $\backslash$nThe general consensus on FBC was "Faster, Better, Cheaper? Pick any two". According to that view, is impossibly to optimize on all three criteria without compromising the third. This paper checks that view using an AI search tool called STAR. We show that FBC is indeed feasible and produces similar or better results when compared to other methods However, for FBC to work, there must be a balanced concern and concentration on the quality aspects of a project. If not, "FBC" becomes "CF" (cheaper and faster) with the inevitable lose in project quality.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09bfc.pdf\}},
author = {Menzies, Tim and El-Rawas, Oussama and Hihn, Jairus and Boehm, Barry},
booktitle = {Proceedings of the 5th International Conference on Predictor Models in Software Engineering - PROMISE '09},
doi = {10.1145/1540438.1540442},
isbn = {9781605586342},
keywords = {cheaper,cocomo,faster better,predictor models,simulated annealing,software engineering,software processes},
pages = {1},
title = {{Can we build software faster and better and cheaper?}},
url = {http://portal.acm.org/citation.cfm?doid=1540438.1540442},
year = {2009}
}
@inproceedings{fa07,
author = {{J. Falk J. Gladigau}, M Glaï¿½ C Haubelt S Helwig J Keinert M Lukasiewycz T Schlichter T Streichert M Streubï¿½hr and Teich, J},
booktitle = {Proceedings of Design Automation and Test in Europe},
month = apr,
title = {{SystemCoDesigner ï¿½ The System-Level Hardware-Software-Co-Design Tool}},
year = {2007}
}
@inproceedings{macdonell07,
author = {MacDonell, S G and Shepperd, M J},
booktitle = {Empirical Software Engineering and Measurement, ESEM 2007},
pages = {401--409},
title = {{Comparing Local and Global Software Effort Estimation Models -- Reflections on a Systematic Review}},
year = {2007}
}
@inproceedings{Hinneburg1998,
author = {Hinneburg, A. and Keim, D.A.},
booktitle = {KDD '98},
file = {:Users/timm/svns/doc/hinneburg98.pdf:pdf},
keywords = {Grid cluster},
publisher = {Bibliothek der Universit$\backslash$$\backslash$"at Konstanz},
title = {{An efficient approach to clustering in large multimedia databases with noise}},
url = {http://www.aaai.org/Papers/KDD/1998/KDD98-009.pdf},
year = {1998}
}
@article{Shirai2014,
abstract = {To meet critical business challenges, software development teams need data to effectively manage product quality, cost, and schedule. The Team Software ProcessSM (TSPSM) provides a framework that teams use to collect software process data in real time, using a defined disciplined process. This data holds promise for use in software engineering research. We combined data from 109 industrial projects into a database to support performance benchmarking and model development. But is the data of sufficient quality to draw conclusions? We applied various tests and techniques to identify data anomalies that affect the quality of the data in several dimensions. In this paper, we report some initial results of our analysis, describing the amount and the rates of identified anomalies and suspect data, including incorrectness, inconsistency, and credibility. To illustrate the types of data available for analysis, we provide three examples. The preliminary results of this empirical study suggest that some aspects of the data quality are good and the data are generally credible, but size data are often missing},
author = {Shirai, Yasutaka and Nichols, William and Kasunic, Mark},
doi = {10.1145/2600821.2600841},
file = {:Users/timm/svns/doc/14tsp.pdf:pdf},
isbn = {9781450327541},
journal = {ICSSP 2014 Proceedings of the 2014 International Conference on Software and System Process},
keywords = {data quality,database,team software process,tsp},
pages = {25--29},
title = {{Initial Evaluation of Data Quality in a TSP Software Engineering Project Data Repository}},
year = {2014}
}
@book{wirfs90,
author = {Wirfs-Brock, R J and Wilkerson, B and Weiner, L},
publisher = {Prentice-Hall},
title = {{Designing Object-Oriented Software}},
year = {1990}
}
@inproceedings{me00x,
author = {Menzies, T J},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{SE/KE Reuse Research: Common Themes and Empirical Results}},
year = {2002}
}
@inproceedings{zheng14z,
author = {Zheng, Pengfei and Zhou, Yangfan and Lyu, M R and Qi, Yong},
booktitle = {Services Computing (SCC), 2014 IEEE International Conference on},
doi = {10.1109/SCC.2014.76},
month = jun,
pages = {528--535},
title = {{Granger Causality-Aware Prediction and Diagnosis of Software Degradation}},
year = {2014}
}
@phdthesis{Muller86,
author = {Muller, H A},
school = {Rice University},
title = {{Rigi - A Model for Software System Construction, Integration, and Evaluation based on Module Interface Specifications}},
year = {1986}
}
@misc{lee04,
author = {Lee, S C and Santo, A G},
title = {{Tradeoffs in functional allocation between spacecraft autonomy and ground operations: the \{NEAR\} (\{N\}ear \{E\}arth \{A\}steroid \{R\}endezvous) \{E\}xperience, \{J\}ohn \{H\}opkins \{APL\}, \{A\}ugust 9-12, \{U\}tah \{S\}tate \{U\}niversity , \{E\}ccles \{C\}onference \{C\}enter, \{L}}},
year = {2004}
}
@incollection{Amarel86,
address = {Los Altos, CA},
author = {Amarel, S},
booktitle = {Machine Learning: An Artificial Intelligence Approach: Volume II},
editor = {Michalski, R S and Carbonell, J G and Mitchell, T M},
pages = {499--569},
publisher = {Kaufmann},
title = {{Program Synthesis as a Theory Formation Task: Problem Representations and Solution Methods}},
year = {1986}
}
@article{scanlon89,
author = {Scanlan, D A},
journal = {IEEE Computer},
number = {5},
pages = {28--36},
title = {{Structured Flowcharts Outperform Psuedocode: an Experimental Comparison}},
volume = {6},
year = {1989}
}
@inproceedings{cohen97,
author = {Cohen, William W and Devanbu, Prem},
booktitle = {Proc. 14th International Conference on Machine Learning},
pages = {66--74},
publisher = {Morgan Kaufmann},
title = {{A comparative study of inductive logic programming methods for software fault prediction}},
year = {1997}
}
@article{reifer79,
author = {Reifer, D J},
journal = {IEEE Transactions on Reliability},
pages = {247--249},
title = {{Software Failure Modes and Effects Analysis}},
year = {1979}
}
@article{smith90,
annote = {automatic programming},
author = {Smith, D R},
journal = {IEEE Transactions on Software Engineering (SE), Sept},
number = {9},
title = {{\{KIDS\}: \{A\} Semi-Automated Program Development System}},
volume = {16},
year = {1990}
}
@article{Erik2010,
abstract = {The general purpose optimization method known as Particle Swarm Optimization (PSO) has a number of parameters that determine its be- haviour and eï¬cacy in optimizing a given problem. This paper gives a list of good choices of parameters for various optimization scenarios which should help the practitioner achieve better results with little eï¬ort.},
author = {Erik, Magnus and Pedersen, Hvass and Pedersen, Magnus Erik Hvass},
file = {:Users/timm/svns/doc/pso/Off-The-Shelf\_PSO-2010.pdf:pdf},
journal = {Technical Report HL1001, Hvass Laboratories},
keywords = {numerical optimization,parameters,particle swarm},
pages = {1--12},
title = {{Good parameters for particle swarm optimization}},
url = {http://www.hvass-labs.org/people/magnus/publications/pedersen10good-pso.pdf},
volume = {HL1001},
year = {2010}
}
@article{BAKIR2010,
address = {Hingham, MA, USA},
author = {Bakir, Ayse and Turhan, Burak and Bener, Ayse B},
doi = {http://dx.doi.org/10.1007/s11219-009-9081-z},
issn = {0963-9314},
journal = {Software Quality Control},
number = {1},
pages = {57--80},
publisher = {Kluwer Academic Publishers},
title = {{A new perspective on data homogeneity in software cost estimation: a study in the embedded systems domain}},
volume = {18},
year = {2010}
}
@inproceedings{pelanek04,
author = {Pelanek, R},
booktitle = {Proceedings SPIN'04 Workshop},
title = {{Typical Structural Properties of State Spaces}},
year = {2004}
}
@inproceedings{gel03a,
abstract = { Model-based software has become quite popular in recent years, making its way into a broad range of areas, including the aerospace industry. The models provide an easy graphical interface to develop systems, which can generate the sometimes tedious code that follows. While there are many tools available to assess standard procedural code, there are limits to the testing of model-based systems. A major problem with the models are that their internals often contain gray areas of unknown system behavior. These possible behaviors form what is known as a data cloud, which is an overwhelming range of possibilities of a system that can overload analysts (Menzies et al., 2003). With large data clouds, it is hard to demonstrate which particular decision leads to a particular outcome. Even if definite decisions can't be made, it is possible to reduce the variance of and condense the clouds (Menzies et al., 2003). This paper presents two case studies; one with a simple illustrative model and another with a more complex application. The TAR3 treatment learning tool summarizes the particular attribute ranges that selects for particular behaviors of interest, reducing the data clouds.},
author = {Geletko, D. and Menzies, T.},
booktitle = {28th Annual NASA Goddard Software Engineering Workshop, 2003. Proceedings.},
doi = {10.1109/SEW.2003.1270729},
isbn = {0-7695-2064-2},
title = {{Model-based software testing via incremental treatment learning}},
year = {2003}
}
@article{Meingast2006,
abstract = {The face of health care is changing as new technologies are being incorporated into the existing infrastructure. Electronic patient records and sensor networks for in-home patient monitoring are at the current forefront of new technologies. Paper-based patient records are being put in electronic format enabling patients to access their records via the Internet. Remote patient monitoring is becoming more feasible as specialized sensors can be placed inside homes. The combination of these technologies will improve the quality of health care by making it more personalized and reducing costs and medical errors. While there are benefits to technologies, associated privacy and security issues need to be analyzed to make these systems socially acceptable. In this paper we explore the privacy and security implications of these next-generation health care technologies. We describe existing methods for handling issues as well as discussing which issues need further consideration.},
author = {Meingast, Marci and Roosta, Tanya and Sastry, Shankar},
doi = {10.1109/IEMBS.2006.260060},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Meingast, Roosta, Sastry - 2006 - Security and privacy issues with health care information technology.pdf:pdf},
issn = {1557-170X},
journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
keywords = {Biomedical Technology,Computer Communication Networks,Computer Security,Confidentiality,Database Management Systems,Equipment Design,Humans,Information Management,Internet,Medical Informatics Applications,Medical Records Systems, Computerized,Monitoring, Physiologic,Monitoring, Physiologic: instrumentation,Monitoring, Physiologic: methods,Privacy,Telemedicine,Telemedicine: instrumentation,Telemedicine: methods},
month = jan,
pages = {5453--8},
pmid = {17946702},
title = {{Security and privacy issues with health care information technology.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17946702},
volume = {1},
year = {2006}
}
@article{hils92,
author = {Hils, D D},
journal = {Journal of Visual Languages and Computing},
number = {1},
pages = {69--101},
title = {{Visual Languages and Computing Survey}},
volume = {3},
year = {1992}
}
@inproceedings{chen12,
author = {Chen, Ning and Kim, Sunghun},
booktitle = {ASE'2012, Essen, Germany, September 3-7, 2012},
title = {{Puzzle-based Automatic Testing: bringing humans into the loop by solving puzzles}}
}
@article{webb00a,
author = {{Z. Zheng}, Z and Webb, G},
journal = {Machine Learning},
number = {1},
pages = {53--84},
title = {{Lazy Learning of Bayesian Rules}},
volume = {41},
year = {2000}
}
@inproceedings{gaines92a,
author = {Gaines, B R and Compton, P},
booktitle = {Proceedings, Australian AI '92},
pages = {349--354},
publisher = {World Scientific},
title = {{Induction of Ripple Down Rules}},
year = {1992}
}
@inproceedings{me98c,
author = {Menzies, T J and Waugh, S},
booktitle = {Proceedings of the Australian AI '98 conference},
publisher = {World-Scientific},
title = {{Lower Limits on the Size of Test Data Sets}},
year = {1998}
}
@article{dekleer84,
author = {DeKleer, J and Brown, J S},
journal = {Artificial Intelligence},
pages = {7--83},
title = {{A Qualitative Physics Based on Confluences}},
volume = {25},
year = {1984}
}
@article{Zhao2004b,
author = {Zhao, H.},
doi = {10.1109/TKDE.2004.3},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zhao - 2004 - Constrained cascade generalization of decision trees.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = jun,
number = {6},
pages = {727--739},
title = {{Constrained cascade generalization of decision trees}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1294893},
volume = {16},
year = {2004}
}
@article{Uitert,
author = {Uitert, Miranda Van and Meuleman, Wouter and Wessels, Lodewyk},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/BicBin\_code/BicBinStringResults.pdf:pdf},
pages = {1--14},
title = {{Additional STRING results for BicBin}}
}
@article{me09b,
abstract = {We propose a practical defect prediction approach for companies that do not track defect related data. Specifically, we investigate the applicability of cross-company (CC) data for building localized defect predictors using static code features. Firstly, we analyze the conditions, where CC data can be used as is. These conditions turn out to be quite few. Then we apply principles of analogy-based learning (i.e. nearest neighbor (NN) filtering) to CC data, in order to fine tune these models for localization. We compare the performance of these models with that of defect predictors learned from within-company (WC) data. As expected, we observe that defect predictors learned from WC data outperform the ones learned from CC data. However, our analyses also yield defect predictors learned from NN-filtered CC data, with performance close to, but still not better than, WC data. Therefore, we perform a final analysis for determining the minimum number of local defect reports in order to learn WC defect predictors. We demonstrate in this paper that the minimum number of data samples required to build effective defect predictors can be quite small and can be collected quickly within a few months. Hence, for companies with no local defect data, we recommend a two-phase approach that allows them to employ the defect prediction process instantaneously. In phase one, companies should use NN-filtered CC data to initiate the defect prediction process and simultaneously start collecting WC (local) data. Once enough WC data is collected (i.e. after a few months), organizations should switch to phase two and use predictors learned from WC data.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ccwc.pdf\}},
author = {Turhan, Burak and Menzies, Tim and Bener, AyÅe B. and {Di Stefano}, Justin},
doi = {10.1007/s10664-008-9103-7},
issn = {13823256},
journal = {Empirical Software Engineering},
keywords = {Cross-company,Defect prediction,Learning,Metrics (product metrics),Nearest-neighbor filtering,Within-company},
number = {5},
pages = {540--578},
title = {{On the relative value of cross-company and within-company data for defect prediction}},
volume = {14},
year = {2009}
}
@inproceedings{me05b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05sawtooth.pdf\}},
author = {Menzies, Tim and Orrego, Andres},
title = {{Incremental Discreatization and Bayes Classifiers Handles Concept Drift and Scaled Very Well}},
year = {2005}
}
@inproceedings{fujita98,
author = {Fujita, M},
booktitle = {Asia and South Pacific - Design Automation Conference},
title = {{Model Checking: Its Basics and Reality}},
year = {1998}
}
@article{Sweeney02,
journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems (IJUFKS)},
number = {5},
pages = {557--570},
title = {{k-Anonymity: A Model for Protecting Privacy}},
volume = {10},
year = {2002}
}
@inproceedings{HECKMAN2008,
address = {New York, NY, USA},
author = {Heckman, Sarah and Williams, Laurie},
booktitle = {ESEM '08: Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
doi = {http://doi.acm.org/10.1145/1414004.1414013},
isbn = {978-1-59593-971-5},
pages = {41--50},
publisher = {ACM},
title = {{On establishing a benchmark for evaluating static analysis alert prioritization and classification techniques}},
year = {2008}
}
@book{fowler97,
author = {Fowler, M},
publisher = {Addison Wesley},
title = {{Analysis Patterns: Reusable Object Models}},
year = {1997}
}
@article{born81,
author = {Borning, A},
journal = {ACM Transactions on Programming Languages and Systems},
month = oct,
number = {4},
pages = {353--387},
title = {{The Programming Language Aspects of ThingLab: a Constraint-Oriented Simulation Laboratory}},
volume = {3},
year = {1981}
}
@phdthesis{davis76,
author = {Davis, R},
school = {Stanford},
title = {{Applications of Meta-Level Knowledge to the Construction, Mainteance and Use of Large Knowledge Bases}},
year = {1976}
}
@article{langley86,
author = {Langley, Pat},
journal = {Machine Learning},
number = {1},
pages = {5--10},
title = {{Editorial: On Machine Learning}},
volume = {1},
year = {1986}
}
@inproceedings{khoshgoftaar01,
author = {Khoshgoftaar, T},
booktitle = {Proceedings of the 12th International Symposium on Software Reliability Engineering, Hong Kong},
month = nov,
pages = {66--73},
title = {{An Application of Zero-Inflated Poisson Regression for Software Fault Prediction}},
year = {2001}
}
@article{budgen08,
author = {Budgen, David and Kitchenham, Barbara and Charters, Stuart and Turner, Mark and Brereton, Pearl and Linkman, Stephen},
journal = {Empirical Software Engineering},
number = {4},
pages = {435--468},
title = {{Presenting software engineering results using structured abstracts: a randomised experiment}},
volume = {13},
year = {2008}
}
@article{have00,
author = {Havelund, K and Pressburger, T},
journal = {International Journal on Software Tools for Technology Transfer},
month = apr,
number = {4},
title = {{Model Checking Java Programs Using Java PathFinder}},
volume = {2},
year = {2000}
}
@article{Manegold2010b,
author = {Manegold, S. and Laurent, D. and Lupu, M. and Onose, N. and R\'{e}, C. and Sans, V. and Senellart, P. and Wu, T. and Shasha, D. and Manolescu, I. and Afanasiev, L. and Feng, J. and Gou, G. and Hadjieleftheriou, M. and Harizopoulos, S. and Kalnis, P. and Karanasos, K.},
doi = {10.1145/1815933.1815944},
file = {:Users/timm/svns/doc/manegold09.pdf:pdf},
issn = {01635808},
journal = {ACM SIGMOD Record},
month = dec,
number = {3},
pages = {40},
title = {{Repeatability \& workability evaluation of SIGMOD 2009}},
url = {http://portal.acm.org/citation.cfm?doid=1815933.1815944},
volume = {38},
year = {2010}
}
@book{shull07,
editor = {{F. Shull J. Singer} and Sjoberg, D},
publisher = {Spring},
title = {{Guide to Advanced Empirical Software Engineering}},
year = {2007}
}
@book{rum91,
author = {Rumbaugh, J and Blaha, M and Premerlani, W and Eddy, F and Lorenson, W},
publisher = {Prentice-Hall},
title = {{Object-Oriented Modeling and Design}},
year = {1991}
}
@article{silver92a,
author = {Silverman, B G},
journal = {IEEE Expert},
month = apr,
pages = {18--25},
title = {{Building a Better Critic: Recent Empirical Results}},
year = {1992}
}
@inproceedings{me96m,
author = {Menzies, Tim},
booktitle = {Proceedings of the ECAI '96 workshop on Modelling Conflicts in AI},
title = {{Expert Systems Inference = Modeling Conflicts}},
year = {1996}
}
@inproceedings{harman02,
author = {Harman, M and Hierons, R and Proctor, M},
booktitle = {GECO 2002: Proceedings of the Genetic and Evolutionary Computation Conference},
month = jul,
pages = {1351--1358},
publisher = {Morgan Kaufmann},
title = {{A new representation and crossover operator for search-based optimization of software modularization}},
year = {2002}
}
@inproceedings{krieger80,
author = {Krieger, D T},
booktitle = {Neuroendocrinology},
editor = {Krieger, D T and Hughes, J C},
pages = {3--122},
publisher = {Sinauer Associates, Inc.},
title = {{The Hypothalmus and Neuroendocrinology}},
year = {1980}
}
@article{ouni13,
author = {Ouni, Ali and Kessentini, Marouane and Sahraoui, Houari and Boukadoum, Mounir},
doi = {10.1007/s10515-011-0098-8},
issn = {0928-8910},
journal = {Automated Software Engineering},
keywords = {Maintainability defects; Software maintenance; Sea},
number = {1},
pages = {47--79},
publisher = {Springer US},
title = {{Maintainability defects detection and correction: a multi-objective approach}},
url = {http://dx.doi.org/10.1007/s10515-011-0098-8},
volume = {20},
year = {2013}
}
@inproceedings{rymon93setree,
author = {Rymon, Ron},
booktitle = {International Conference on Machine Learning},
pages = {268--275},
title = {{An \{SE\}-tree based Characterization of the Induction Problem}},
year = {1993}
}
@article{Dasgupta2010,
author = {Dasgupta, Sajib and Ng, Vincent},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Dasgupta, Ng - 2010 - Mining Clustering Dimensions.pdf:pdf},
journal = {Work},
title = {{Mining Clustering Dimensions}},
year = {2010}
}
@article{Attarzadeh2009,
abstract = {Software development effort estimation is the process of predicting the most realistic use of effort required for developing software based on some parameters. It has always characterised one of the biggest challenges in Computer Science for the last decades. Because time and cost estimate at the early stages of the software development are the most difficult to obtain, and they are often the least accurate. Traditional algorithmic techniques such as regression models, Software Life Cycle Management (SLIM), COCOMO model, function points, etc, require an estimation process in a long term. But, nowadays that is not acceptable for software developers and companies. Newer soft computing techniques to effort estimation based on non-algorithmic techniques such as Fuzzy Logic (FL) may offer an alternative for solving the problem. This work aims to propose a fuzzy logic realistic model to achieve more accuracy in software effort estimation. In this innovative model, by applying fuzzy logic and using training procedure to the system, the accuracy of the results is desirable in comparison with the famous traditional algorithmic technique, COCOMO II model. This novelty model will lead researchers to focus on non-algorithmic models to overcome the estimation problems. Our validation experiment was carried out on artificial dataset as well as the COCOMO standard dataset.},
author = {Attarzadeh, I. and Ow, Siew Hock Ow Siew Hock},
doi = {10.1109/ICCEE.2009.97},
file = {:Users/timm/svns/doc/cost/09Iman.pdf:pdf},
isbn = {978-1-4244-5365-8},
journal = {2009 Second International Conference on Computer and Electrical Engineering},
keywords = {COCOMO model,Software engineering,soft computing techniques,software cost estimation models},
pages = {114--118},
title = {{Proposing a New High Performance Model for Software Cost Estimation}},
volume = {2},
year = {2009}
}
@article{thelin03,
author = {{Thomas Thelin Per Runeson}, Claes Wohlin},
journal = {IEEE Transactions of Software Engineering},
number = {8},
pages = {687--704},
title = {{An Experimental Comparison of Usage-Based and Checklist-Based Reading}},
volume = {29},
year = {2003}
}
@article{benj97,
author = {Benjamins, R and Aben, M},
journal = {International Journal of Human-Computer Studies},
pages = {259--288},
title = {{Structure-Preserving Knowledge-Based Systems Development Thorugh Reusable Libraries: A Case Study in Diagnosis}},
volume = {47},
year = {1997}
}
@article{jiang02,
author = {Jiang, J J and Klein, G and Chen, H and Lin, L},
journal = {International Journal of Project Management},
month = oct,
number = {7},
pages = {507--515},
title = {{Reducing user-related risks during and prior to system development}},
volume = {20},
year = {2002}
}
@misc{spear00,
title = {{No Title}}
}
@article{zloof81,
author = {Zloof, M M},
journal = {Computer},
month = may,
pages = {13--22},
title = {{QBE/OBE: A Language for Office and Business Automation}},
year = {1981}
}
@phdthesis{funt76,
author = {Funt, B V},
publisher = {University of British Columbia},
title = {{WHISPER: a Computer Implementation Using Analogues in Reasoning.}},
year = {1976}
}
@misc{kendall01,
author = {Kendall, Graham},
title = {{Tutorial notes on the history of AI}},
year = {2001}
}
@article{me10d,
abstract = {There exists a large and growing number of proposed estimation methods but little conclusive evidence ranking one method over another. Prior effort estimation studies suffered from  conclusion instability , where the rankings offered to different methods were not stable across (a)Â different evaluation criteria; (b)Â different data sources; or (c)Â different random selections of that data. This paper reports a study of 158 effort estimation methods on data sets based on COCOMO features. Four  best  methods were detected that were consistently better than the  rest  of the other 154 methods. These rankings of  best  and  rest  methods were stable across (a)Â three different evaluation criteria applied to (b)Â multiple data sets from two different sources that were (c)Â divided into hundreds of randomly selected subsets using four different random seeds. Hence, while there exists no single universal  best  effort estimation method, there appears to exist a small number (four) of most useful methods. This result both complicates and simplifies effort estimation research. The complication is that any future effort estimation analysis should be preceded by a  selection study  that finds the best local estimator. However, the simplification is that such a study need not be labor intensive, at least for COCOMO style data sets.},
author = {Menzies, Tim and Jalali, Omid and Hihn, Jairus and Baker, Dan and Lum, Karen},
doi = {10.1007/s10515-010-0070-z},
issn = {09288910},
journal = {Automated Software Engineering},
keywords = {COCOMO,Data mining,Effort estimation,Evaluation},
month = dec,
number = {4},
pages = {409--437},
title = {{Stable rankings for different effort models}},
volume = {17},
year = {2010}
}
@book{sterling94,
author = {Sterling, L and Shapiro, E},
publisher = {MIT Press},
title = {{The Art of Prolog (second edition)}},
year = {1994}
}
@article{Qin2009,
author = {Qin, a K and Huang, V L and Suganthan, P N},
file = {:Users/timm/svns/doc/09de.pdf:pdf},
number = {2},
pages = {398--417},
title = {{Adaptation for Global Numerical Optimization}},
volume = {13},
year = {2009}
}
@article{m-ilp-91,
author = {Muggleton, S},
journal = {New Generation Computing},
pages = {295--318},
title = {{Inductive Logic Programming}},
volume = {8},
year = {1991}
}
@article{davis79,
author = {Davis, R},
journal = {Artificial Intelligence},
number = {2},
pages = {121--157},
title = {{Interactive Transfer of Expertise: Acqusiition of New Inference Rules}},
volume = {12},
year = {1979}
}
@inproceedings{WATANABE08,
address = {New York, NY, USA},
author = {Watanabe, Shinya and Kaiya, Haruhiko and Kaijiri, Kenji},
booktitle = {PROMISE '08: Proceedings of the 4th international workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1370788.1370794},
isbn = {978-1-60558-036-4},
pages = {19--24},
publisher = {ACM},
title = {{Adapting a fault prediction model to allow inter languagereuse}},
year = {2008}
}
@misc{discouse,
annote = {Available on-line at $\backslash$url\{ http://swan.mindinformatics.org/spec/1.2/discourserelationships.html\}},
author = {Ciccarese, Paolo and Clark, Tim and Kinoshita, June and Ocana, Marco and Wong, Gwen and Wu, Elizabeth},
title = {{Scientific Discourse Relationships Ontology Specification}},
year = {2007}
}
@article{Liu2004,
author = {Liu, H and Motoda, H and Yu, L},
doi = {10.1016/j.artint.2004.05.009},
file = {:Users/timm/svns/doc/Liu04.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {ac,asu,corresponding author,dimensionality reduction,e-mail addresses,edu,feature selection and ranking,h,hliu,jp,learning,leiyu,liu,motoda,osaka-u,sampling,sanken},
month = nov,
number = {1-2},
pages = {49--74},
title = {{A selective sampling approach to active feature selection}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370204000980},
volume = {159},
year = {2004}
}
@article{aikins83,
author = {Aikins, Janice S},
journal = {Artificial Intelligence},
number = {2},
pages = {163--210},
title = {{Prototypical Knowledge for Expert Systems}},
volume = {20},
year = {1983}
}
@inproceedings{deb95b,
author = {Debenham, J},
booktitle = {Proceedings Seventh International Conference on Software Engineering and Knowledge Engineering SEKE'95, Washington, June},
title = {{A Unified Approach to Requirements Specification and Systems Analysis in the Design of Knowledge-Based Systems}},
year = {1995}
}
@misc{nilsson00,
author = {Nilsson, N J},
title = {{AI RISING, invited talk, AAAI}},
year = {2000}
}
@article{will00,
author = {Williams, L and Kessler, R R and Cunningham, W and Jeffries, R},
journal = {IEEE Software},
title = {{Strengthening the Case for Pair-Programming}},
year = {2000}
}
@article{bol95,
author = {Boland, R J and Tenkasi, R V},
journal = {Organization Science},
number = {4},
title = {{Perspective Making and Perspective Taking in Communities of Knowledge}},
volume = {6},
year = {1995}
}
@article{Kitchenham2009a,
author = {Kitchenham, B and Pearlbrereton, O and Budgen, D and Turner, M and Bailey, J and Linkman, S},
doi = {10.1016/j.infsof.2008.09.009},
file = {:Users/timm/svns/doc/Kitchenham\_2009.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {evidence-based software engineering,systematic literature review},
month = jan,
number = {1},
pages = {7--15},
title = {{Systematic literature reviews in software engineering â A systematic literature review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950584908001390},
volume = {51},
year = {2009}
}
@article{fea03,
author = {Feather, M S and Cornford, S L},
journal = {Requirements Engineering Journal},
title = {{Quantitative Risk-based Requirements Reasoning}},
year = {2003}
}
@inproceedings{tosun09,
author = {Tosun, A and Bener, A and Turhan, B},
booktitle = {PROMISE'09},
title = {{Practical Considerations of Deploying AI in Defect Prediction: A Case Study within the Turkish Telecommunication Industry}},
year = {2009}
}
@inproceedings{me11m,
author = {Menzies, Tim and Butcher, Andrew and Marcus, Andrian and Zimmermann, Thomas and Cok, David},
booktitle = {IEEE ASE'11},
title = {{Local vs Global Models for Effort Estimation and Defect Prediction}},
year = {2011}
}
@incollection{harman07,
author = {Harman, Mark},
booktitle = {Future of Software Engineering, ICSE'07},
title = {{The Current State and Future of Search Based Software Engineering}},
year = {2007}
}
@book{Hetland2010,
abstract = {Python Algorithms explains the Python approach to algorithm analysis and design. Written by Magnus Lie Hetland, author of Beginning Python, this book is sharply focused on classical algorithms, but it also gives a solid understanding of fundamental algorithmic problem-solving techniques. The book deals with some of the most important and challenging areas of programming and computer science, but in a highly pedagogic and readable manner. The book covers both algorithmic theory and programming practice, demonstrating how theory is reflected in real Python programs. Well-known algorithms and data structures that are built into the Python language are explained, and the user is shown how to implement and evaluate others himself. What youâll learn Transform new problems to well-known algorithmic problems with efficient solutions, or show that the problems belong to classes of problems thought not to be efficiently solvable. Analyze algorithms and Python programs both using mathematical tools and basic experiments and benchmarks. Prove correctness, optimality, or bounds on approximation error for Python programs and their underlying algorithms. Understand several classical algorithms and data structures in depth, and be able to implement these efficiently in Python. Design and implement new algorithms for new problems, using time-tested design principles and techniques. Speed up implementations, using a plethora of tools for high-performance computing in Python. Who this book is for The book is intended for Python programmers who need to learn about algorithmic problem-solving, or who need a refresher. Students of computer science, or similar programming-related topics, such as bioinformatics, may also find the book to be quite useful. Table of Contents Introduction The Basics Counting 101 Induction and Recursion ... and Reduction Traversal: The Skeleton Key of Algorithmics Divide, Combine, and Conquer Greed Is Good? Prove It! Tangled Dependencies and Memoization From A to B with Edsger and Friends Matchings, Cuts, and Flows Hard Problems and (Limited) Sloppiness},
author = {Hetland, Magnus Lie},
booktitle = {Mastering Basic Algorithms in the Python Language},
doi = {10.1007/978-1-4302-3238-4},
file = {:Users/timm/svns/doc/python-algorithms.pdf:pdf},
isbn = {<null>},
issn = {09242244},
pages = {336},
pmid = {15466169},
title = {{Python Algorithms}},
url = {http://books.google.com/books?id=9\_AXCmGDiz8C\&printsec=frontcover\&dq=intitle:Python+Algorithms\&hl=\&cd=1\&source=gbs\_api$\backslash$npapers2://publication/uuid/3D337050-3F0A-44F8-9602-0C3E9A7D6ACE},
year = {2010}
}
@incollection{veld93,
author = {de Velde, W Van},
booktitle = {Second Generation Expert Systems},
editor = {David, J-M. and Krivine, J-P. and Simmons, R},
publisher = {Springer Verlag},
title = {{Issues in Knowledge Level Modeling}},
year = {1993}
}
@article{Aggarwala,
author = {Aggarwal, Charu C and Yu, Philip S},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Aggarwal, Yu - Unknown - A Condensation Approach to Privacy Preserving Data Mining.pdf:pdf},
title = {{A Condensation Approach to Privacy Preserving Data Mining}}
}
@article{hirakawa94,
author = {Hirakawa, M and Ichikawa, T},
journal = {Software- Concepts and Tools},
pages = {61--67},
title = {{Visual Language Studies - A Perspective}},
year = {1994}
}
@misc{me09c,
author = {Gundy-Burlet, K and Schumann, J and Menzies, T and Barrett, T},
booktitle = {AIAA Aerospace, 2009},
title = {{Parametric Analysis of a Hover Test Vehicle Using Advanced Test Generation and Data Analysis}},
year = {2009}
}
@article{Li2006,
author = {Li, Jingzhou and Ruhe, Guenther},
journal = {International Symposium on Empirical Software Engineering},
pages = {74},
publisher = {ACM},
title = {{A comparative study of attribute weighting heuristics for effort estimation by analogy}},
url = {http://portal.acm.org/citation.cfm?id=1159733.1159746},
year = {2006}
}
@inproceedings{raffo94,
author = {Raffo, D M},
booktitle = {Proceedings of CASCON 94, held in Toronto, Ontario, Canada, Oct.31-Nov.3},
publisher = {IBM Canada Ltd. Laboratory, Center for Advanced Studies; and National Research Council for Canada},
title = {{Capturing Software Process and Product Characteristics in Process Models Using Task Element Decomposition}},
year = {1994}
}
@article{Glokler2010,
abstract = {Automation in combination with high throughput screening methods has revolutionised molecular biology in the last two decades. Today, many combinatorial libraries as well as several systems for automation are available. Depending on scope, budget and time, a different combination of library and experimental handling might be most effective. In this review we will discuss several concepts of combinatorial libraries and provide information as what to expect from these depending on the given context.},
author = {Gl\"{o}kler, J\"{o}rn and Sch\"{u}tze, Tatjana and Konthur, Zolt\'{a}n},
doi = {10.3390/molecules15042478},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/GloklerSchutzeReview10.pdf:pdf},
issn = {14203049},
journal = {Molecules},
keywords = {Automation,In vitro evolution,Phage display,Random combinatorial library,SELEX},
number = {4},
pages = {2478--2490},
pmid = {20428057},
title = {{Automation in the high-throughput selection of random combinatorial libraries-different approaches for select applications}},
volume = {15},
year = {2010}
}
@book{hall92,
author = {P.A.V.Hall},
publisher = {Chapman \& Hall},
title = {{Software reuse and reverse engineering in practice}},
year = {1992}
}
@inproceedings{me01a,
author = {Menzies, Tim},
booktitle = {AAAI Stanford Spring Symposium on Model-based Validation of AI Systems},
pages = {0--5},
title = {{Average Case Coverage for Validation of AI Systems}},
year = {1995}
}
@inproceedings{ostrand04,
address = {New York, NY, USA},
author = {Ostrand, Thomas J and Weyuker, Elaine J and Bell, Robert M},
booktitle = {ISSTA '04: Proceedings of the 2004 ACM SIGSOFT international symposium on Software testing and analysis},
pages = {86--96},
publisher = {ACM},
title = {{Where the bugs are}},
year = {2004}
}
@article{Bouveyron2007,
abstract = {Clustering in high-dimensional spaces is a difficult problem which is recurrent in many domains, for example in image analysis. The difficulty is due to the fact that high-dimensional data usually exist in different low-dimensional subspaces hidden in the original space. A family of Gaussian mixture models designed for high-dimensional data which combine the ideas of subspace clustering and parsimonious modeling are presented. These models give rise to a clustering method based on the expectation-maximization algorithm which is called high-dimensional data clustering (HDDC). In order to correctly fit the data, HDDC estimates the specific subspace and the intrinsic dimension of each group. Experiments on artificial and real data sets show that HDDC outperforms existing methods for clustering high-dimensional data. ?? 2007 Elsevier B.V. All rights reserved.},
author = {Bouveyron, C. and Girard, S. and Schmid, C.},
doi = {10.1016/j.csda.2007.02.009},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/Bouveyron07.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {Gaussian mixture models,High-dimensional data,Model-based clustering,Parsimonious models,Subspace clustering},
number = {1},
pages = {502--519},
title = {{High-dimensional data clustering}},
volume = {52},
year = {2007}
}
@misc{me99i,
annote = {NASA IVV Facility Technical Report},
author = {Menzies, T and Houle, M E and Powell, J},
title = {{RAPTURE/SP2: Efficient Testing of Temporal Properties Without Search Space Explosion}},
year = {1999}
}
@inproceedings{me00x,
author = {Menzies, T J},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{SE/KE Reuse Research: Common Themes and Empirical Results}},
year = {2002}
}
@book{seidman00,
author = {Seidman, C},
publisher = {Microsoft Press},
title = {{Data Mining with Microsoft SQL Server}},
year = {2000}
}
@article{me09e,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09nodata.pdf\}},
author = {Menzies, T and Williams, S and Elrawas, O and Baker, D and Boehm, B and Hihn, J and Lum, K and Madachy, R},
journal = {Software Process Improvement and Practice},
month = jul,
number = {4},
pages = {213--225},
title = {{Accurate estimates without local data?}},
url = {http://www3.interscience.wiley.com/journal/122364893/abstract},
volume = {14},
year = {2009}
}
@article{fenton00b,
author = {Fenton, N and Ohlsson, N},
journal = {IEEE Transactions on Software Engineering},
month = aug,
pages = {797--814},
title = {{Quantitative Analysis of Faults and Failures in a Complex Software System}},
year = {2000}
}
@inproceedings{althoff99,
author = {Althoff, K-D. and Birk, A and Hartkopf, S and Muller, W and Nick, M and Surmann, D and Tautz, C},
booktitle = {Proceedings of the 11th International Conference on Software Engineering and Knowledge Engineering, SEKE'99, Kaiserslauten, Germany},
month = jun,
pages = {10--19},
title = {{Managing Software Engineering Experience for Comprehensive Reuse}},
year = {1999}
}
@inproceedings{ang96,
author = {Angele, J and Fensel, D and Studer, R},
booktitle = {Domain Knowledge for Interactive System Design},
editor = {Et.al., A Sutcliffe},
publisher = {Chapman \& Hall},
title = {{Domain and Task Modelling in MIKE}},
year = {1996}
}
@inproceedings{me96e,
author = {Menzies, T J},
booktitle = {Proceedings of the 10th Knowledge Acquisition Workshop for Knowledge-Based Systems, Banff,Canada},
title = {{Assessing Responses to Situated Congition}},
year = {1996}
}
@article{prab97,
annote = {To appear.},
author = {Prabhaker, S and Goel, A},
journal = {Journal of Artificial Intelligence in Engineering},
title = {{Addressing Incompleteness of Device Models by Adaptable Functional Modelling of Devices for Operating Environments}},
year = {1997}
}
@article{gay10,
author = {Gay, Gregory and Menzies, Tim and Davies, Misty and Gundy-Burlet, Karen},
journal = {Automated Software Engineering},
month = dec,
number = {4},
title = {{Automatically finding the control variables for complex system behavior}},
year = {2010}
}
@article{Brin1997,
abstract = {We consider the problem of analyzing market-basket data and present several important contributions. First, we present a new algorithm for nding large itemsets which uses fewer passes over the data than classic algorithms, and yet uses fewer candidate itemsets than methods based on sampling. We investigate the idea of item reordering, which can im- prove the low-level e ciency of the algorithm. Second, we present a new way of generating $\backslash$implication rules," which are normalized based on both the antecedent and the con- sequent and are truly implications (not simply a measure of co-occurrence), and we show how they produce more in- tuitive results than other methods. Finally, we show how di erent characteristics of real data, as opposed to synthetic data, can dramatically a ect the performance of the system and the form of the results.},
author = {Brin, Sergey and Motwani, Rajeev and Ullman, Jeffrey D. and Tsur, Shalom},
doi = {10.1145/253262.253325},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/brin97.pdf:pdf},
isbn = {0897919114},
issn = {01635808},
journal = {ACM SIGMOD Record},
number = {2},
pages = {255--264},
title = {{Dynamic itemset counting and implication rules for market basket data}},
volume = {26},
year = {1997}
}
@inproceedings{pease00,
author = {Pease, A and Chaudhri, V and Lehmann, F and Farquhar, A},
booktitle = {Proceedings of KR-2000},
title = {{Practical Knowledge Representation and the DARPA High Performance Knowledge Bases Project}},
year = {2000}
}
@inproceedings{RamMe1996,
author = {Ramakrishnan, S and Menzies, T and Hasslinger, M and Bok, P and Mccarthy, H and Devakadadcham, B and Moulder, D},
booktitle = {Proceedings of Tools-Pacific, Melbourne},
title = {{On Building an Effective Measurement System for OO Software Process}},
year = {1996}
}
@book{musa98,
author = {Musa, John},
isbn = {0079132715},
publisher = {McGraw-Hill},
title = {{Software Reliability Engineered Testing}},
year = {1998}
}
@book{duda2012,
author = {Duda, Richard O and Hart, Peter E and Stork, David G},
publisher = {John Wiley \& Sons},
title = {{Pattern classification}},
year = {2012}
}
@inproceedings{wagner07,
author = {Wagner, T and Beume, N and Naujoks, B},
title = {{No Title}}
}
@article{boehm99,
author = {B.Boehm and H.In},
journal = {Software Quality Professional},
month = mar,
number = {2},
pages = {38--50},
title = {{Conflict Analysis and Negotiation Aids for Cost-Quality Requirements}},
volume = {1},
year = {1999}
}
@misc{budgen06,
annote = {Keynote address, CSEET'06},
author = {Budgen, D},
title = {{No Title}},
year = {2006}
}
@article{will91,
author = {Williams, B C and DeKleer, J},
journal = {Artificial Intelligence},
pages = {1--9},
title = {{Qualitative Reasoning about Physical Systems: a Return to Roots}},
volume = {51},
year = {1991}
}
@article{KORU2009,
address = {Hingham, MA, USA},
author = {Koru, A G\"{u}ne$\backslash$cs and Emam, Khaled El and Zhang, Dongsong and Liu, Hongfang and Mathew, Divya},
doi = {http://dx.doi.org/10.1007/s10664-008-9080-x},
issn = {1382-3256},
journal = {Empirical Softw. Engg.},
number = {5},
pages = {473--498},
publisher = {Kluwer Academic Publishers},
title = {{Theory of relative defect proneness}},
volume = {13},
year = {2008}
}
@inproceedings{me06c,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06bad.pdf\}},
author = {Orrego, Andres},
booktitle = {Citeseer},
title = {{Bayesian Anomaly Detection (BAD v0. 1)}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.74.3186\&amp;rep=rep1\&amp;type=pdf},
year = {2003}
}
@inproceedings{me95m,
author = {Menzies, T J and Goss, S},
booktitle = {AI in Defence Workshop, Australian AI'95, also Technical Report TR95-31, Department of Software Development, Monash University},
title = {{Applications of Abduction \#3: ``Black-Box'' to ``Gray-Box'' Model}},
year = {1995}
}
@article{darke96,
author = {Darke, P and Shanks, G},
journal = {Requirements Engineering},
number = {2},
pages = {88--105},
title = {{Stakeholder Viewpoints in Requirements Definition: A Framework for Understanding Viewpoint Development Approaches}},
volume = {1},
year = {1996}
}
@book{karolak96,
author = {Karolak, D},
publisher = {IEEE Computer Society Press},
title = {{Software Engineering Risk Management}},
year = {1996}
}
@misc{me01b,
author = {Menzies, T},
booktitle = {ASERC workshop on Quantiative Software Engineering},
title = {{Applictions of Computational Intelligence to Quantitative Software Engineering}},
year = {2001}
}
@article{Hand2007a,
abstract = {Data mining is the discovery of interesting, unexpected or valuable structures in large datasets. As such, it has two rather different aspects. One of these concerns large-scale, 'global' structures, and the aim is to model the shapes, or features of the shapes, of distributions. The other concerns small-scale, 'local' structures, and the aim is to detect these anomalies and decide if they are real or chance occurrences. In the context of signal detection in the pharmaceutical sector, most interest lies in the second of the above two aspects; however, signal detection occurs relative to an assumed background model, therefore, some discussion of the first aspect is also necessary. This paper gives a lightning overview of data mining and its relation to statistics, with particular emphasis on tools for the detection of adverse drug reactions.},
author = {Hand, David J},
file = {:Users/timm/svns/doc/hand01.pdf:pdf},
issn = {0114-5916},
journal = {Drug safety : an international journal of medical toxicology and drug experience},
keywords = {Adverse Drug Reaction Reporting Systems,Adverse Drug Reaction Reporting Systems: organizat,Databases, Factual,Drug Industry,Humans,Information Systems,Information Systems: organization \& administration,Product Surveillance, Postmarketing},
month = jan,
number = {7},
pages = {621--2},
pmid = {17604416},
title = {{Principles of data mining.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17604416},
volume = {30},
year = {2007}
}
@incollection{hayes85,
author = {Hayes, P J},
booktitle = {Formal Theories of the Commonsense World},
editor = {Hobbs, J R and Moore, R C},
pages = {1--36},
publisher = {Albex Publishing Corp},
title = {{The Second Naive Physics Manifesto}},
year = {1985}
}
@article{neto08,
author = {Neto, Arilo Dias and Subramanyan, Rajesh and Vieira, Marlon and Travassos, Guilherme Horta and Shull, Forrest},
issn = {0740-7459},
journal = {IEEE Software},
number = {3},
pages = {10--13},
title = {{Improving Evidence about Software Technologies: A Look at Model-Based Testing}},
volume = {25},
year = {2008}
}
@phdthesis{orrego04,
author = {Orrego, A S},
school = {Computer Science, West Virginia University},
title = {{SAWTOOTH: Learning from Huge Amounts of Data}},
year = {2004}
}
@phdthesis{davis76,
author = {Davis, R},
school = {Stanford},
title = {{Applications of Meta-Level Knowledge to the Construction, Mainteance and Use of Large Knowledge Bases}},
year = {1976}
}
@article{cortes95,
author = {Cortes, Corinna and Vapnik, Vladimir},
issn = {0885-6125},
journal = {Machine Learning},
number = {3},
pages = {273--297},
title = {{Support-vector networks}},
volume = {20},
year = {1995}
}
@article{LIU2007,
address = {USA},
author = {Liu, Yi and Yao, Jenq-Foung and Williams, Gita and Adkins, Gerald},
issn = {1937-4771},
journal = {J. Comput. Small Coll.},
number = {5},
pages = {55--61},
publisher = {Consortium for Computing Sciences in Colleges},
title = {{Studying software metrics based on real-world software systems}},
volume = {22},
year = {2007}
}
@book{norvig03,
address = {Upper Saddle River, NJ, USA},
author = {Russell, Stuart J and Norvig, Peter and Candy, John F and Malik, Jitendra M and Edwards, Douglas D},
isbn = {0-13-103805-2},
pages = {97--104},
publisher = {Prentice-Hall, Inc.},
title = {{Artificial intelligence: a modern approach}},
year = {2003}
}
@article{Vaidya,
author = {Vaidya, Jaideep},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Vaidya - Unknown - Privacy Preserving Na Â¨ Ä±ve Bayes Classifier for Vertically Partitioned Data.pdf:pdf},
journal = {Evaluation},
keywords = {distributed classification,privacy,security},
title = {{Privacy Preserving Na Â¨ Ä±ve Bayes Classifier for Vertically Partitioned Data}}
}
@manual{swiprolog,
author = {Wielemaker, Jan},
title = {{SWI-Prolog}}
}
@incollection{easter07,
author = {Easterbrook, S M and Singer, J and Storey, M and Damian, D},
booktitle = {Guide to Advanced Empirical Software Engineering},
editor = {Shull, F and Singer, J},
publisher = {Springer},
title = {{Selecting Empirical Methods for Software Engineering Research}},
year = {2007}
}
@inproceedings{me01e,
abstract = { Software management oracles often contain numerous subjective features. At each subjective point, a range of behaviors is possible. Stochastic simulation samples a subset of the possible behaviors. After many such stochastic simulations, the TAR2 treatment learner can find control actions that have (usually) the same impact despite the subjectivity of the oracle.},
author = {Menzies, T. and Kiper, J.D.},
booktitle = {Proceedings 16th Annual International Conference on Automated Software Engineering (ASE 2001)},
doi = {10.1109/ASE.2001.989836},
isbn = {0-7695-1426-X},
issn = {1527-1366},
title = {{Better reasoning about software engineering activities}},
year = {2001}
}
@incollection{roy94,
annote = {To appear.},
author = {Roy, M and Cruz-Neira, C and Fanti, T De},
chapter = {Cosmic Wor},
publisher = {MIT Press},
title = {{Networks and Virtual Environments of Presence Teleoperators and Virtual Envionrment}},
year = {1994}
}
@inproceedings{me07,
author = {Tar, The and Learner, Treatment},
booktitle = {Review Literature And Arts Of The Americas},
keywords = {contrast set learning,tar3,treatment learning},
title = {{Just Enough Learning ( of Association Rules ):}},
year = {2007}
}
@article{simons99,
author = {Simons, D J and Chabris, C F},
journal = {Perception},
pages = {1059--1074},
title = {{Gorillas in our Midst: Sustained Inattentional Blindless for Dynamic Events Perception}},
volume = {28},
year = {1999}
}
@article{me11a,
author = {Kocaguneli, E and Menzies, T and Keung, J},
file = {:Users/timm/svns/doc/cost/11comba.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
title = {{On the Value of Ensemble Effort Estimation}},
volume = {Available },
year = {2011}
}
@book{knuth92,
author = {Knuth, D},
publisher = {Center for the Study of Language and Information, CLSI},
title = {{Literate Programming}},
year = {1992}
}
@article{simon80,
author = {Larkin, J and McDermott, J and Simon, D P and Simon, H A},
journal = {Science},
pages = {1335--1342},
title = {{Expert and Novice Performance in Solving Physics Problems}},
volume = {208},
year = {1980}
}
@incollection{hallt10,
author = {Hall, Tracy and Bowes, David and Liebchen, Gernot and Wernick, Paul},
booktitle = {Product-Focused Software Process Improvement},
pages = {107--115},
publisher = {Springer Berlin Heidelberg},
title = {{Evaluating three approaches to extracting fault data from software change repositories}},
year = {2010}
}
@inproceedings{YanWeb02Comparative,
author = {Yang, Ying and Webb, Geoffrey I},
booktitle = {Proceedings of PKAW 2002: The 2002 Pacific Rim Knowledge Acquisition Workshop},
pages = {159--173},
title = {{A Comparative Study of Discretization Methods for Naive-Bayes Classifiers}},
year = {2002}
}
@inproceedings{simmons96,
author = {Simmons, D B and Ellis, N C and W, Kuo},
booktitle = {Proceedings of the Eigth International Conference on Software Engineering and Knowledge Engineering},
pages = {323--329},
title = {{Software Process Agents}},
year = {1996}
}
@inproceedings{andrews07,
abstract = {Randomized testing has been shown to be an effective method fortesting software units. However, the thoroughness of randomized unit testing varies widely according to the settings of certain parameters, such as the relative frequencies with which methods are called. In this paper, we describe a system which uses agenetic algorithm to find parameters for randomized unit testing that optimize test coverage. We compare our coverage results to previous work, and report on case studies and experiments on system options. Copyright 2007 ACM.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07ase-nighthawk.pdf\}},
author = {Andrews, J.H. and Li, F.C.H. and Menzies, Tim},
booktitle = {Proceedings of the twenty-second IEEE/ACM international conference on Automated software engineering},
doi = {10.1145/1321631.1321654},
isbn = {9781595938824},
keywords = {genetic algorithms,randomized testing,test coverage},
pages = {144--153},
title = {{Nighthawk: A two-level genetic-random unit test data generator}},
url = {http://dl.acm.org/citation.cfm?id=1321654},
year = {2007}
}
@misc{me95l,
author = {Menzies, T J},
institution = {Department of Software Development, Monash University},
number = {TR95-35},
title = {{Frameworks for Assessing Visual Languages}},
year = {1995}
}
@inproceedings{owen03d,
author = {Owen, David and Menzies, Tim and Heimdahl, Mats and Gao, Jimin},
title = {{Finding \{F\}aults \{Q\}uickly in \{F\}ormal \{M\}odels \{U\}sing \{R\}andom \{S\}earch}},
year = {2004}
}
@inproceedings{cass00,
author = {Cass, A G and Lerner, B Staudt and McCall, E K and Osterweil, L J and Jr., Stanley M Sutton and Wise, A},
booktitle = {Proceedings of the 22nd International Conference on Software Engineering (ICSE 2000)},
month = jun,
pages = {754--757},
title = {{Little-JIL/Juliette: A Process Definition Language and Interpreter}},
year = {2000}
}
@article{Yeung2000,
author = {Yeung, Ka Yee},
file = {:Users/timm/svns/doc/01yeungPcaClustering.pdf:pdf},
keywords = {be addressed,bioinformatics,clustering,dimension reduction,gene expression analysis,principal component analysis,to appear,to whom correspondence should},
title = {{An empirical study on Principal Component Analysis for clustering gene expression data}},
year = {2000}
}
@book{coad97,
author = {Coad, P and North, D and Mayfield, M},
publisher = {Prentice Hall},
title = {{Object Models: Strategies, Patterns, and Applications}},
year = {1997}
}
@book{voas98,
author = {Voas, J and McGraw, G},
isbn = {0-471-18381-4},
publisher = {John Wiley \& Sons},
title = {{Software Fault Injection: Inoculating Programs Against Error}},
year = {1998}
}
@article{Williams2010a,
author = {Williams, James},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Williams - 2010 - Social Networking Applications in Health Care Threats to the Privacy and Security of Health Information.pdf:pdf},
journal = {Workshop on Software Engineering in Health Care},
keywords = {0,[Electronic Manuscript],health information privacy,medicine 2,personal health record,social networks},
pages = {39--49},
title = {{Social networking applications in health care: threats to the privacy and security of health information}},
url = {http://portal.acm.org/citation.cfm?id=1809091},
year = {2010}
}
@book{hof81,
author = {Hofstader, D R and Dennett, D C},
title = {{The Mind's I}},
year = {1981}
}
@inproceedings{pople77,
author = {Pople, H E},
booktitle = {IJCAI '77},
pages = {1030--1037},
title = {{The Formation of Composite Hypothess in Diagnositic Problem Soving: An Exercise in Synthetic Reasoning}},
year = {1977}
}
@article{Gopinath2007,
abstract = {SELEX (systematic evolution of ligands by exponential enrichment) is a process that involves the progressive purification from a combinatorial library of nucleic acid ligands with a high affinity for a particular target by repeated rounds of partitioning and amplification. With the development of aptamer technology over the last decade, various modified SELEX processes have arisen that allow various aptamers to be developed against a wide variety of molecules, irrespective of the target size. In the present review, the separation methods used in such SELEX processes are reviewed.},
author = {Gopinath, S. C B},
doi = {10.1007/s00216-006-0826-2},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Gopinath07.pdf:pdf},
isbn = {1618-2642},
issn = {16182642},
journal = {Analytical and Bioanalytical Chemistry},
keywords = {Aptamer,DNA,RNA,SELEX,Separation},
number = {1},
pages = {171--182},
pmid = {17072603},
title = {{Methods developed for SELEX}},
volume = {387},
year = {2007}
}
@misc{soft02,
author = {Ciolkowski, M and Laitenberger, O and Rombach, D and Shull, F and Perry, D},
booktitle = {Proceedings of the 2003 International Conference on Software Enginereing},
pages = {641--642},
title = {{Software Inspections, Reviews \& Walkthroughs, an ICSE 2002 IMPACT Presentations}},
year = {2002}
}
@inproceedings{me08fh,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08antares.pdf\}},
author = {Gundy-Burlet, K and Schumann, J and Menzies, T and Barrett, T},
booktitle = {9th International Symposium on Artifical Intelligence, Robotics and Automation in Space},
title = {{Parametric Analysis of ANTARES Re-entry Guidance Algorithms Using Advanced Test Generation and DAta Analysis}},
year = {2008}
}
@inproceedings{schn01,
author = {Schneidewind, N F},
booktitle = {Proceedings of the 7th International Software Metrics Symposium, London},
month = apr,
pages = {328--337},
title = {{Investigation of Logistic Regression as a Discriminant of Software Quality}},
year = {2001}
}
@inproceedings{delaVega03,
author = {de la Vega, W Fernandez and Karpinski, Marek and Kenyon, Claire and Rabani, Yuval},
booktitle = {Proceedings of the thirty-fifth annual ACM symposium on Theory of computing},
isbn = {1-58113-674-9},
pages = {50--58},
series = {STOC '03},
title = {{Approximation schemes for clustering problems}},
year = {2003}
}
@article{Chen2008,
abstract = {Clustering high dimensional data has become a challenge in data mining due to the curse of dimensionality. To solve this problem, subspace clustering has been defined as an extension of traditional clustering that seeks to find clusters in subspaces spanned by different combinations of dimensions within a dataset. This paper presents a new subspace clustering algorithm that calculates the local feature weights automatically in an EM-based clustering process. In the algorithm, the features are locally weighted by using a new unsupervised weighting method, as a means to minimize a proposed clustering criterion that takes into account both the average intra-clusters compactness and the average inter-clusters separation for subspace clustering. For the purposes of capturing accurate subspace information, an additional outlier detection process is presented to identify the possible local outliers of subspace clusters, and is embedded between the E-step and M-step of the algorithm. The method has been evaluated in clustering real-world gene expression data and high dimensional artificial data with outliers, and the experimental results have shown its effectiveness.},
author = {Chen, Lifei and Jiang, Qingshan},
doi = {10.1007/s11704-008-0007-x},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/chen08.pdf:pdf},
issn = {16737350},
journal = {Frontiers of Computer Science in China},
keywords = {Clustering criterion,EM algorithm,High dimensional clustering,Outlier detection,Subspace clustering},
number = {1},
pages = {81--86},
title = {{An extended EM algorithm for subspace clustering}},
volume = {2},
year = {2008}
}
@article{gaines95,
author = {Gaines, B R and Shaw, M L G},
journal = {The Knowledge Engineering Review},
title = {{Knowledge Acquisition Tools based on Personal Construct Psychology}},
year = {1993}
}
@article{basili91,
author = {Basili, V R and Rombach, H D},
journal = {Software Engineering Journal},
month = sep,
pages = {303--316},
title = {{Support for Comprehensive Reuse}},
year = {1991}
}
@misc{me98g,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/99ab.pdf\}},
author = {Menzies, T and Waugh, S},
title = {{Abduction: Experiments and Implications}},
year = {1999}
}
@misc{ram95a,
author = {Ramakrishnan, S},
number = {TR95-8},
title = {{An \{E\}xperimental \{A\}pproach to \{O-O\} \{S\}oftware \{P\}rocess and \{P\}roduct \{M\}easurements}},
year = {1995}
}
@article{reiss87,
author = {Reiss, S P},
journal = {IEEE Software},
month = nov,
pages = {16--27},
title = {{Working in the Garden Environment for Conceptual Programming}},
year = {1987}
}
@article{dorigo97,
author = {Dorigo, M and Gambardella, L M},
journal = {IEEE Transactions on Evolutionary Computation},
month = apr,
number = {1},
pages = {53--66},
title = {{Ant Colony System: \{A\} Cooperative Learning Approach to the Traveling Salesman Problem}},
type = {Paper},
volume = {1},
year = {1997}
}
@article{toh04,
author = {Toh, K and Yau, W and Jiang, X},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
month = feb,
pages = {224--233},
title = {{A Reduced Multivariate Polynomial Model for Multimodal Biometrics and Classifiers Fusion}},
year = {2004}
}
@article{Brickellb,
author = {Brickell, Justin and Shmatikov, Vitaly},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Brickell, Shmatikov - Unknown - The Cost of Privacy Destruction of Data-Mining Utility in Anonymized Data Publishing Categories and S(2).pdf:pdf},
journal = {ReCALL},
title = {{The Cost of Privacy : Destruction of Data-Mining Utility in Anonymized Data Publishing Categories and Subject Descriptors}}
}
@article{Ag2003,
author = {Ag, Chrysler and Tic, Cicyt and Evanco, William M and Spencer, N and Keppel, H and Brader, D and Brader, M},
file = {:Users/timm/svns/doc/Evanco.pdf:pdf},
journal = {Statistics},
number = {7},
title = {{Comments on â The Confounding Effect of Class Size on the Validity of Object-Oriented Metrics â Comments on â The Confounding Effect of Class Size on the Validity of Object-Oriented Metrics â}},
volume = {29},
year = {2003}
}
@inproceedings{me00s,
author = {Menzies, T and Cukic, B},
booktitle = {International Workshop on Empirical Studies of Software Maintenance (WESS 2000), October 14, San Jose CA},
title = {{Maintaining Maintainability = Recognizing Reachability}},
year = {2000}
}
@inproceedings{zimmermann09,
author = {{T. Zimmermann N. Nagappan}, H Gall E Giger and Murphy, B},
booktitle = {ESEC/FSE'09},
month = aug,
title = {{Cross-Project Defect Prediction}},
year = {2009}
}
@inproceedings{port08,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08simrequire.pdf\}},
author = {Port, D and Olkov, A and Menzies, T},
booktitle = {IEEE ASE'08},
title = {{Using Simulation to Investigate Requirements Prioritization Strategies}},
year = {2008}
}
@misc{shepperd11,
annote = {Available on-line at http://goo.gl/JbXcL},
author = {Shepperd, Martin},
booktitle = {Crest Open Workshop, University College, London},
title = {{It doesn't matter what you do but does matter who does it!}},
year = {2011}
}
@article{singer00backbone,
author = {Singer, Josh and Gent, Ian P and Smaill, Alan},
journal = {Journal of Artificial Intelligence Research},
pages = {235--270},
title = {{Backbone Fragility and the Local Search Cost Peak}},
url = {citeseer.nj.nec.com/singer00backbone.html},
volume = {12},
year = {2000}
}
@article{Sedighizadeh2009,
abstract = {The Particle Swarm Optimization (PSO) algorithm, as one of the latest algorithms inspired from the nature, was introduced in the mid 1990s and since then, it has been utilized as an optimization tool in various applications, ranging from biological and medical applications to computer graphics and music composition. In this paper, following a brief introduction to the PSO algorithm, the chronology of its evolution is presented and all major PSO-based methods are comprehensively surveyed. Next, these methods are studied separately and their important factors and parameters are summarized in a comparative table. In addition, a new taxonomy of PSO-based methods is presented. It is the purpose of this paper is to present an overview of previous and present conditions of the PSO algorithm as well as its opportunities and challenges. Accordingly, the history, various methods, and taxonomy of this algorithm are discussed and its different applications together with an analysis of these applications are evaluated.},
author = {Sedighizadeh, Davoud and Masehian, Ellips},
doi = {10.7763/IJCTE.2009.V1.80},
file = {:Users/timm/svns/doc/pso/09reviewPSO.pdf:pdf},
isbn = {9821828841},
issn = {17938201},
journal = {International Journal of Computer Theory and Engineering},
keywords = {Applications.,Heuristic Optimization,Optimization (PSO),Particles Swarm,Taxonomy},
number = {5},
pages = {486--502},
title = {{Particle Swarm Optimization Methods , Taxonomy and Applications}},
volume = {1},
year = {2009}
}
@article{hay96,
author = {Haynes, P and Henderson-Sellers, B},
journal = {American Programmer},
pages = {35--41},
title = {{Cost Estimation of OO Projects: Empirical Observations, Practical Applications}},
year = {1996}
}
@article{wick92,
author = {Wick, M R and Thompson, W B},
journal = {Artificial Intelligence},
pages = {33--70},
title = {{Reconstructive Expert System Explanation}},
volume = {54},
year = {1992}
}
@article{viola01boosting,
author = {Viola, P and Jones, M},
journal = {Proc. CVPR},
pages = {511--518},
title = {{Rapid object detection using a boosted cascade of simple features}},
volume = {1},
year = {2001}
}
@inproceedings{come96,
author = {Connell, M and Menzies, T J},
booktitle = {Tools Pacific, 1996, Melbourne},
title = {{Quality Metrics: Test Coverage Analysis for Smalltalk}},
year = {1996}
}
@inproceedings{me03b,
author = {Liu, Y and Menzies, T and Cukic, B},
title = {{Detecting Novelties by Mining Association Rules}},
year = {2003}
}
@article{benj95,
author = {Benjamins, R},
journal = {International Journal of Expert Systems: Research \& Applications},
number = {2},
pages = {93--120},
title = {{Problem-Solving Methods for Diagnosis and their Role in Knowledge Acquisition}},
volume = {8},
year = {1995}
}
@article{Fung,
author = {Fung, Benjamin C M and Wang, Ke and Wang, Lingyu and Hung, Patrick C K},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Fung et al. - Unknown - Privacy-Preserving Data Publishing for Cluster Analysis.pdf:pdf},
journal = {Systems Engineering},
keywords = {anonymity,cluster analysis,knowledge discovery,preprint submitted to elsevier,privacy},
number = {December 2008},
pages = {1--43},
title = {{Privacy-Preserving Data Publishing for Cluster Analysis}}
}
@article{vienneau95,
author = {Vienneau, R},
journal = {Journal of Parametrics},
month = apr,
pages = {18--36},
title = {{The Present Value of Software Maintenance}},
year = {1995}
}
@techreport{gent97,
author = {Gent, I P and Grant, S A and MacIntyre, E and Prosser, P and P.Shar and Smith, B M and Walsh, T},
institution = {University of Leeds, School of Computer Studies},
number = {97.27},
title = {{How not to do it}},
year = {1997}
}
@inproceedings{wang00,
author = {Wang, K and He, Y and Cheung, D and Chin, F},
booktitle = {10th ACM International Conference on Informationand Knowledge Management (CIKM 2001), Atlanta},
title = {{Mining confident rules without support requirement}},
year = {2001}
}
@article{wallace99,
author = {Wallace, C S and Dowe, D L},
journal = {The Computer Journal},
title = {{Minimum Message Length and Kolmogorov Complexity}},
year = {1999}
}
@inproceedings{bradshaw91,
author = {Bradshaw, J M and Ford, K M and Adams-Webber, J},
booktitle = {6th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge-Based Systems Workshop, ,October 6-11 1991, Banff, Canada},
pages = {4.1 -- 4.25},
title = {{Knowledge Representation of Knowledge Acquisition: A Three-Schemata Approach}},
year = {1991}
}
@article{Simkevitz2009a,
author = {Simkevitz, Howard},
doi = {10.1109/CONGRESS.2009.16},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Simkevitz - 2009 - Why Privacy Matters in Health Care Delivery A Value Proposition.pdf:pdf},
isbn = {978-1-4244-5344-3},
journal = {2009 World Congress on Privacy, Security, Trust and the Management of e-Business},
month = aug,
pages = {193--201},
publisher = {Ieee},
title = {{Why Privacy Matters in Health Care Delivery: A Value Proposition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5341698},
year = {2009}
}
@article{dej13z,
author = {Dejaeger, K and Verbraken, T and Baesens, B},
doi = {10.1109/TSE.2012.20},
issn = {0098-5589},
journal = {Software Engineering, IEEE Transactions on},
month = feb,
number = {2},
pages = {237--257},
title = {{Toward Comprehensible Software Fault Prediction Models Using Bayesian Network Classifiers}},
volume = {39},
year = {2013}
}
@inproceedings{me09k,
abstract = {Concept location is a critical activity during software evolution as it produces the location where a change is to start in response to a modification request, such as, a bug report or a new feature request. Lexical-based concept location techniques rely on matching the text embedded in the source code to queries formulated by the developers. The efficiency of such techniques is strongly dependent on the ability of the developer to write good queries. We propose an approach to augment information retrieval (IR) based concept location via an explicit relevance feedback (RF) mechanism. RF is a two-part process in which the developer judges existing results returned by a search and the IR system uses this information to perform a new search, returning more relevant information to the user. A set of case studies performed on open source software systems reveals the impact of RF on IR based concept location.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09irrf.pdf\}},
author = {Gay, Gregory and Haiduc, Sonia and Marcus, Andrian and Menzies, Tim},
booktitle = {IEEE International Conference on Software Maintenance, ICSM},
doi = {10.1109/ICSM.2009.5306315},
isbn = {9781424448289},
issn = {1063-6773},
pages = {351--360},
title = {{On the use of relevance feedback in IR-based concept location}},
year = {2009}
}
@article{Kriegel2009,
abstract = {Clustering in high-dimensional spaces is a difficult problem which is recurrent in many domains, for example in image analysis. The difficulty is due to the fact that high-dimensional data usually exist in different low-dimensional subspaces hidden in the original space. A family of Gaussian mixture models designed for high-dimensional data which combine the ideas of subspace clustering and parsimonious modeling are presented. These models give rise to a clustering method based on the expectationmaximization algorithm which is called high-dimensional data clustering (HDDC). In order to correctly fit the data, HDDC estimates the specific subspace and the intrinsic dimension of each group. Experiments on artificial and real data sets show that HDDC outperforms existing methods for clustering high-dimensional data.},
author = {Kriegel, Hans-Peter and Kr\"{o}ger, Peer and Zimek, Arthur},
doi = {10.1145/1497577.1497578},
file = {:Users/timm/svns/doc/09highDimensionalClusteringReview.pdf:pdf},
isbn = {1556-4681},
issn = {15564681},
journal = {ACM Transactions on Knowledge Discovery from Data},
number = {1},
pages = {1--58},
title = {{Clustering high-dimensional data}},
volume = {3},
year = {2009}
}
@misc{CLCS03,
annote = {$\backslash$url\{http://www.spaceref.com/news/viewnews.html?id=475\}},
author = {Spareref.com},
title = {{NASA to Shut Down Checkout \& Launch Control System}}
}
@book{down94,
author = {Down, A and Coleman, M and Absolon, P},
publisher = {McGraw-Hill},
title = {{Risk Management for Software Projects}},
year = {1994}
}
@article{ropp00,
author = {Ropponen, J and Lyytinen, K},
journal = {IEEE Transactions on Software Engineering},
pages = {98--112},
title = {{Components of software development risk: how to address them? A project manager survey}},
year = {2000}
}
@article{Harman2010d,
author = {Harman, Mark and McMinn, Phil},
doi = {10.1109/TSE.2009.71},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Harman, Court - 2010 - A Theoretical and Empirical Study of Search Based Testing Local , Global and Hybrid Search(2).pdf:pdf},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
month = mar,
number = {2},
pages = {226--247},
title = {{A Theoretical and Empirical Study of Search-Based Testing: Local, Global, and Hybrid Search}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5342440},
volume = {36},
year = {2010}
}
@inproceedings{ginsberg87,
author = {Ginsberg, A},
booktitle = {Proc. 3rd Annual Expert Systems in Government Conference},
organization = {IEEE Computer Society},
pages = {102--111},
title = {{A new \{A\}pproach to \{C\}hecking \{K\}nowledge \{B\}ases for \{I\}nconsistency and \{R\}edundancy}},
year = {1987}
}
@inproceedings{me96i,
author = {Menzies, T J},
booktitle = {Proceedings of the Eighth International Conference on Software Engineering and Knowledge Engineering},
isbn = {0-9641699-3-2},
publisher = {Knowledge Systems Institute, Skokie, Illinois, USA},
title = {{Visual Programming, Knowledge Engineering, and Visual Programming}},
year = {1996}
}
@book{der96,
author = {Deransart, P and Ed-Dbali, A and Cervoni, L},
publisher = {Sprunger},
title = {{Prolog: The Standard}},
year = {1996}
}
@inproceedings{Marcus2010b,
abstract = {Software systems are designed and engineered to process data. However, software is data too. The size and variety of today's software artifacts and the multitude of stakeholder activities result in so much data that individuals can no longer reason about all of it. We argue in this position paper that data mining, statistical analysis, machine learning, information retrieval, data integration, etc., are necessary solutions to deal with software data. New research is needed to adapt existing algorithms and tools for software engineering data and processes, and new ones will have to be created.
In order for this type of research to succeed, it should be supported with new approaches to empirical work, where data and results are shared globally among researchers and practitioners. Software engineering researchers can get inspired by other fields, such as, bioinformatics, where results of mining and analyzing biological data are often stored in databases shared across the world.},
address = {Santa Fe, NM},
annote = {Laura. Fixed on 10/01/2012},
author = {Marcus, Andrian and Menzies, Tim},
booktitle = {FSE/SDP Workshop on Future of Software Engineering Research (FoSER'10)},
keywords = {data\_mining machine\_learning information\_retrieval},
pages = {229},
title = {{Software is Data Too}}
}
@article{boley98,
author = {Boley, Daniel},
file = {:Users/timm/svns/doc/98principalDirectionDivisvePartitioning.pdf:pdf},
journal = {Data Min. Knowl. Discov.},
month = dec,
number = {4},
pages = {325--344},
title = {{Principal Direction Divisive Partitioning}},
volume = {2},
year = {1998}
}
@article{me97zg,
author = {Menzies, T},
journal = {The Knowledge Engineering Review},
number = {1},
pages = {1--46},
title = {{Knowledge Maintenance: The State of the Art}},
volume = {14},
year = {1999}
}
@article{Heikkila2013,
author = {Heikkila, Ville T. and Paasivaara, Maria and Lassenius, Casper},
doi = {10.1109/ESEM.2013.27},
file = {:Users/timm/svns/doc/finland.pdf:pdf},
isbn = {978-0-7695-5056-5},
issn = {19493770},
journal = {International Symposium on Empirical Software Engineering and Measurement},
keywords = {Scrum,large-scale agile software development,release planning,software engineering},
pages = {85--94},
title = {{ScrumBut, but does it matter? A mixed-method study of the planning process of a multi-team scrum organization}},
year = {2013}
}
@inproceedings{me99a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/99re.pdf\}},
author = {Menzies, T J and Easterbrook, S and Nuseibeh, Bashar and Waugh, Sam},
booktitle = {RE '99},
title = {{An Empirical Investigation of Multiple Viewpoint Reasoning in Requirements Engineering}},
year = {1999}
}
@inproceedings{HOLZ2008,
address = {Berlin, Heidelberg},
author = {Holz, Wolfgang and Premraj, Rahul and Zimmermann, Thomas and Zeller, Andreas},
booktitle = {PROFES '08: Proceedings of the 9th international conference on Product-Focused Software Process Improvement},
doi = {http://dx.doi.org/10.1007/978-3-540-69566-0\_6},
isbn = {978-3-540-69564-6},
pages = {34--44},
publisher = {Springer-Verlag},
title = {{Predicting Software Metrics at Design Time}},
year = {2008}
}
@article{musilek00,
address = {New York, NY, USA},
author = {Mus\'{\i}lek, Petr and Pedrycz, Witold and Succi, Giancarlo and Reformat, Marek},
doi = {http://doi.acm.org/10.1145/373975.373984},
issn = {1559-6915},
journal = {SIGAPP Appl. Comput. Rev.},
number = {2},
pages = {24--29},
publisher = {ACM Press},
title = {{Software cost estimation with fuzzy models}},
volume = {8},
year = {2000}
}
@article{SergioM.Savaresi2000,
abstract = {This paper deals with the problem of clustering a data-set.$\backslash$nIn particular, the bisecting divisive approach is here$\backslash$nconsidered. This approach can be naturally divided into two$\backslash$nsub-problems: the problem of choosing which cluster must be$\backslash$ndivided, and the problem of splitting the selected cluster.$\backslash$nThe focus here is on the first problem. The contribution of$\backslash$nthis work is to propose a new simple technique for the$\backslash$nselection of the cluster to split. This technique is based$\backslash$nupon the shape of the cluster. This result is presented with$\backslash$nreference to two specific splitting algorithms: the$\backslash$ncelebrated bisecting K-means algorithm, and the recently$\backslash$nproposed Principal Direction Divisive Partitioning (PDDP)$\backslash$nalgorithm. The problem of evaluating the quality of a$\backslash$npartition is also discussed. Keywords. Unsupervised$\backslash$nclustering; cluster selection; quality of clusters; K-means;$\backslash$nPrincipal Direction Divisive Partitioning. 1.},
author = {{Sergio M. Savaresi}, Daniel L. Boley and {Sergio M. Savaresi}, Daniel L. Boley},
file = {:Users/timm/svns/doc/02\_part2\_principalDirectionDivisvePartitioning.pdf:pdf},
keywords = {1,classical problem of unsupervised,cluster selection,clustering of a data-set,divisive partitioning,focuses on is the,in,introduction and problem statement,k-means,principal direction,quality of clusters,the problem this paper,unsupervised clustering},
pages = {1--16},
title = {{Choosing the Cluster to Split in Bisecting Divisive Clustering Algorithms}},
url = {http://citeseer.ist.psu.edu/497394.html$\backslash$nhttp://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.25.3507},
year = {2000}
}
@misc{codesurfer,
title = {{CodeSurfer\^{}\{$\backslash$mbox $\backslash$textregistered\}}},
url = {$\backslash$url\{http://www.grammatech.com/products/codesurfer\}},
year = {2005}
}
@article{Bhumiratanaa,
author = {Bhumiratana, Bhume and Bishop, Matt},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Bhumiratana, Bishop - Unknown - Privacy Aware Data Sharing Balancing the Usability and Privacy of Datasets.pdf:pdf},
journal = {Policy},
keywords = {data anonymization,data shar-,information security,ing,ontology,privacy,security policy},
title = {{Privacy Aware Data Sharing : Balancing the Usability and Privacy of Datasets}}
}
@inproceedings{me07f,
abstract = {Adoption of advanced automated SE (ASE) tools would be favored if a business case could be made that these tools are more valuable than alternate methods. In theory, software prediction models can be used to make that case. In practice, this is complicated by the "local tuning" problem. Normally, predictors for software effort and defects and threat use local data to tune their predictions. Such local tuning data is often unavailable. This paper shows that assessing the relative merits of different SE methods need not require precise local tunings. STAR1 is a simulated annealer plus a Bayesian post-processor that explores the space of possible local tunings within software prediction models. STAR1 ranks project decisions by their effects on effort and defects and threats. In experiments with two NASA systems, STAR1 found that ASE tools were necessary to minimize effort/ defect/ threats.},
address = {New York, NY, USA},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07casease-v0.pdf\}},
author = {Menzies, Tim and Feather, Martin S and Madachy, Ray and Boehm, Barry W.},
booktitle = {Proc. ASE},
doi = {http://doi.acm.org/10.1145/1321631.1321676},
isbn = {978-1-59593-882-4},
pages = {303--312},
publisher = {ACM},
title = {{The Business Case for Automated Software Engineering}},
url = {http://portal.acm.org/citation.cfm?id=1321631.1321676},
year = {2007}
}
@article{Abbass1999b,
author = {Abbass, H.a. and Sarker, R. and Newton, C.},
doi = {10.1109/CEC.2001.934295},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Abbass, Sarker, Newton - 1999 - PDE a Pareto-frontier differential evolution approach for multi-objective optimization problems.pdf:pdf},
isbn = {0-7803-6657-3},
journal = {Proceedings of the 2001 Congress on Evolutionary Computation (IEEE Cat. No.01TH8546)},
pages = {971--978},
publisher = {Ieee},
title = {{PDE: a Pareto-frontier differential evolution approach for multi-objective optimization problems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=934295},
year = {1999}
}
@inproceedings{kim12,
author = {Kim, Yang Sok and Kang, Byeong Ho and Ryu, Seung Hwan and Compton, Paul and Han, Soyeon Caren and Menzies, Tim},
booktitle = {Knowledge Management and Acquisition for Intelligent Systems Lecture Notes in Computer Science},
pages = {258--271},
title = {{Crowd-Sourced Knowledge Bases}},
volume = {7457},
year = {2012}
}
@inproceedings{yost94,
author = {Yost, G},
booktitle = {Proceedings of the 8th \{AAAI\}-Sponsored \{B\}anff Knowledge Acquisition for Knowledge-Based Systems Workshop},
editor = {Gaines, B R and Musen, M},
pages = {46.1--46.22},
title = {{Implementing the \{S\}isyphus-93 Task Using \{SOAR\}/\{TAQL\}}},
year = {1994}
}
@article{Hamula2006,
abstract = {Advances in systematic evolution of ligands by exponential enrichment (SELEX), a selection protocol for aptamers, have resulted in increased applications of DNA and RNA aptamers in developing analytical techniques. We review recent developments in SELEX techniques as well as new aptamer-based bioanalytical applications. Â© 2006 Elsevier Ltd. All rights reserved.},
author = {Hamula, Camille L a and Guthrie, Jeffrey W. and Zhang, Hongquan and Li, Xing Fang and Le, X. Chris},
doi = {10.1016/j.trac.2006.05.007},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Hamula06.pdf:pdf},
isbn = {0165-9936},
issn = {01659936},
journal = {TrAC - Trends in Analytical Chemistry},
keywords = {Affinity binding,Aptamer,Bioanalytical assay,Biosensor,Chiral separation,In vitro selection,Protein,SELEX},
number = {7},
pages = {681--691},
title = {{Selection and analytical applications of aptamers}},
volume = {25},
year = {2006}
}
@misc{faa06,
author = {Administration, Federal Aviation},
title = {{System Engineering Manual Version 3.1, Section 4.6: Trade Studies}},
year = {2006}
}
@inproceedings{me03a,
abstract = { When it is impractical to rigorously assess all parts of complex systems, test engineers use defect detectors to focus their limited resources. We define some properties of an ideal defect detector and assess different methods of generating one. In the case study presented here, traditional methods of generating such detectors (e.g. reusing detectors from the literature, linear regression, model trees) were found to be inferior to those found via a PACE analysis.},
author = {Menzies, T. and Stefano, J.D. and Ammar, K. and McGill, K. and Callis, P. and Davis, J. and Chapman, R.},
booktitle = {Proceedings. 5th International Workshop on Enterprise Networking and Computing in Healthcare Industry (IEEE Cat. No.03EX717)},
doi = {10.1109/METRIC.2003.1232459},
isbn = {0-7695-1987-3},
issn = {1530-1435},
title = {{When can we test less?}},
year = {2003}
}
@article{char94,
author = {Charniak, E and Shimony, S E},
journal = {Artificial Intelligence},
pages = {345--374},
title = {{Cost-based abduction and MAP explanation}},
year = {1994}
}
@inproceedings{clancey96a,
author = {Clancey, W and Sachs, P and Sierhuis, M and van Hoof, R},
booktitle = {Proceedings PKAW '96: Pacific Knowledge Acquisition Workshop},
editor = {Compton, P and Mizoguchi, R and Motoda, H and Menzies, Tim},
publisher = {Department of Artificial Intelligence},
title = {{Brahms: Simulating Practice for Work Systems Design}},
year = {1996}
}
@article{Chu2010,
abstract = {Instead of finding clusters in the full feature space, subspace clustering is an emergent task which aims at detecting clusters embedded in subspaces. Most of previous works in the literature are density-based approaches, where a cluster is regarded as a high-density region in a subspace. However, the identification of dense regions in previous works lacks of considering a critical problem, called "the density divergence problemrdquo in this paper, which refers to the phenomenon that the region densities vary in different subspace cardinalities. Without considering this problem, previous works utilize a density threshold to discover the dense regions in all subspaces, which incurs the serious loss of clustering accuracy (either recall or precision of the resulting clusters) in different subspace cardinalities. To tackle the density divergence problem, in this paper, we devise a novel subspace clustering model to discover the clusters based on the relative region densities in the subspaces, where the clusters are regarded as regions whose densities are relatively high as compared to the region densities in a subspace. Based on this idea, different density thresholds are adaptively determined to discover the clusters in different subspace cardinalities. Due to the infeasibility of applying previous techniques in this novel clustering model, we also devise an innovative algorithm, referred to as DENCOS (density conscious subspace clustering), to adopt a divide-and-conquer scheme to efficiently discover clusters satisfying different density thresholds in different subspace cardinalities. As validated by our extensive experiments on various data sets, DENCOS can discover the clusters in all subspaces with high quality, and the efficiency of DENCOS outperformes previous works.},
author = {Chu, Yi Hong and Huang, Jen Wei and Chuang, Kun Ta and Yang, De Nian and Chen, Ming Syan},
doi = {10.1109/TKDE.2008.224},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/chu10.pdf:pdf},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {And association rules,Classification,Clustering,Data clustering,Data mining,Subspace clustering.},
number = {1},
pages = {16--30},
title = {{Density conscious subspace clustering for high-dimensional data}},
volume = {22},
year = {2010}
}
@inproceedings{me99f,
author = {Menzies, T and Cukic, B},
booktitle = {Proceedings, AAAI '99 workshop on Intelligent Software Engineering, Orlando, Florida},
month = jul,
title = {{Intelligent Testing can be Very Lazy}},
year = {1999}
}
@inproceedings{pressburger06,
annote = {Available from $\backslash$url\{http://ti.arc.nasa.gov/m/tech/rse/publications/papers/IEEE06/infuse.pdf\}},
author = {Pressburger, T and Hinchey, M and Feather, M S and Markosian, L},
booktitle = {IEEE International Conference on Space Mission Challenges for Information Technology},
title = {{Infusing Software Engineering Technology into Practice at NASA}},
year = {2006}
}
@inproceedings{me09n,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09ourmine.pdf\}},
author = {Gay, G and Menzies, T and Cukic, B and Turhan, Burak},
booktitle = {PROMISE'09},
title = {{How to Build Repeatable Experiments}},
year = {2009}
}
@article{JIA2009,
address = {Los Alamitos, CA, USA},
author = {Jia, Hao and Shu, Fengdi and Yang, Ye and Li, Qi},
doi = {http://doi.ieeecomputersociety.org/10.1109/ICSM.2009.5306382},
isbn = {978-1-4244-4897-5},
journal = {Software Maintenance, IEEE International Conference on},
pages = {519--522},
publisher = {IEEE Computer Society},
title = {{Data transformation and attribute subset selection: Do they help make differences in software failure prediction?}},
volume = {0},
year = {2009}
}
@article{kumar92,
author = {Kumar, V},
journal = {AI Magazine},
pages = {32--44},
title = {{Algorithms for Constraint-Satisfaction Problems: A Survery}},
year = {1992}
}
@misc{kruchten03,
author = {Kruchten, Philippe},
month = feb,
title = {{What Is the Rational Unified Process?}},
year = {2003}
}
@incollection{steier93,
author = {Steier, D M},
booktitle = {The SOAR Papers},
editor = {Rosenbloom, P S and Laird, J E and Newell, A},
pages = {533--536},
publisher = {MIT Press},
title = {{\{CYPRESS\}-\{SOAR\}: A Case Study in Search and Learning in Algorithm Design}},
volume = {1},
year = {1993}
}
@article{holzman87:scatter,
author = {Holzmann, Gerhard J},
journal = {IEEE Transactions on Software Engineering},
month = jun,
number = {6},
title = {{Automated protocal validation in Argos: Assertion proving and Scatter searching}},
volume = {13},
year = {1987}
}
@book{raymond01,
author = {Raymond, E S and Young, B},
isbn = {0596001088},
publisher = {O'Reilly \& Associates},
title = {{The Cathedral and the Bazaar: Musings on Linux and Open Source by an Accidental Revolutionary}},
year = {2001}
}
@inproceedings{JALALI2007,
address = {Washington, DC, USA},
author = {Jalali, Omid and Jalali, Omid and Menzies, Tim and Menzies, Tim and Baker, Dan and Baker, Dan},
booktitle = {Jet Propulsion},
doi = {http://dx.doi.org/10.1109/PROMISE.2007.3},
isbn = {0-7695-2954-2},
pages = {1--9},
publisher = {IEEE Computer Society},
title = {{Column Pruning Beats Strati cation in Effort Estimation}},
year = {2007}
}
@article{Nebro2008a,
author = {Nebro, Antonio J. and Luna, Francisco and Alba, Enrique and Dorronsoro, Bernab\'{E} and Durillo, Juan J. and Beham, Andreas},
doi = {10.1109/TEVC.2007.913109},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Nebro et al. - 2008 - AbYSS Adapting Scatter Search to Multiobjective Optimization.pdf:pdf},
issn = {1089-778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {diversity,external archive,hybridization,multiobjective optimization,pareto,performance comparison,scatter search},
mendeley-tags = {pareto},
month = aug,
number = {4},
pages = {439--457},
title = {{AbYSS: Adapting Scatter Search to Multiobjective Optimization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4455350},
volume = {12},
year = {2008}
}
@article{ElEmam2001,
author = {{El Emam}, K. and Benlarbi, S. and Goel, N. and Rai, S.N.},
doi = {10.1109/32.935855},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/El Emam et al. - 2001 - The confounding effect of class size on the validity of object-oriented metrics.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
month = jul,
number = {7},
pages = {630--650},
title = {{The confounding effect of class size on the validity of object-oriented metrics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=935855},
volume = {27},
year = {2001}
}
@article{minsky91,
author = {Minsky, M},
journal = {Artificial Intelligence},
pages = {371--396},
title = {{Society of \{M\}ind: A \{R\}esponse to \{F\}our \{R\}eviews}},
volume = {48},
year = {1991}
}
@article{Valente99,
author = {Valente, A and Russ, T and MacGrecor, R and Swartout, W},
journal = {IEEE Intelligent Systems},
month = jan,
number = {1},
pages = {27--36},
title = {{Building and (Re)Using an Ontology for Air Campaign Planning}},
volume = {14},
year = {1999}
}
@inproceedings{bayana03,
author = {Bayana, S and Owen, D and Menzies, T and Mukhopadhyay, S},
title = {{God Does Play Dice: Diagnosis and Validation for Autonomous Systems}},
year = {2004}
}
@book{rump88,
author = {Rump, S M},
publisher = {Academic Press},
title = {{Reliability in Computing. The Role of Interval Methods in Scientific Computing}},
year = {1988}
}
@inproceedings{bingham01,
author = {Bingham, Ella and Mannila, Heikki},
file = {:Users/timm/svns/doc/01randomProj.pdf:pdf},
pages = {245--250},
series = {KDD '01},
title = {{Random projection in dimensionality reduction: applications to image and text data}},
year = {2001}
}
@inproceedings{wu93,
author = {Wu, X},
booktitle = {Proceedings of the 21st ACMl Computer Science Conference},
pages = {168--175},
title = {{The HCV induction algorithm.}},
year = {1993}
}
@inproceedings{MENZIES2005,
address = {New York, NY, USA},
author = {Menzies, Tim and Port, Dan and Chen, Zhihao and Hihn, Jairus},
booktitle = {ACM SIGSOFT Software Engineering Notes},
doi = {10.1145/1082983.1083170},
isbn = {-159593-125-2},
issn = {01635948},
number = {4},
pages = {1},
publisher = {ACM},
title = {{Simple software cost analysis}},
volume = {30},
year = {2005}
}
@inproceedings{me98f,
author = {Menzies, T J and Waugh, S},
booktitle = {Proceedings, Pacific Rim Conference on Artificial Intelligence, Singapore},
publisher = {Springer-Verlag},
title = {{On the Practicality of Viewpoint-based Requirements Engineering}},
year = {1998}
}
@inproceedings{jiang08a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08transform.pdf\}},
author = {Jiang, Y and Cukic, B and Menzies, T},
booktitle = {Defects 2008},
title = {{Does Transformation Help?}},
year = {2008}
}
@article{Aggarwal,
author = {Aggarwal, Charu C and Yu, Philip S},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Aggarwal, Yu - Unknown - A Condensation Approach to Privacy Preserving Data Mining.pdf:pdf},
title = {{A Condensation Approach to Privacy Preserving Data Mining}}
}
@article{wiel92,
author = {Wielinga, B J and Schreiber, A T and Breuker, J A},
journal = {Knowledge Acquisition},
pages = {1--162},
title = {{\{KADS\}: a \{M\}odeling \{A\}pproach to \{K\}nowledge \{E\}ngineering.}},
volume = {4},
year = {1992}
}
@article{mann47,
author = {Mann, H B and Whitney, D R},
journal = {Ann. Math. Statist.},
number = {1},
pages = {50--60},
title = {{On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other}},
volume = {18},
year = {1947}
}
@book{booch96,
author = {Booch, G},
publisher = {Addison-Wesley},
title = {{Object Solutions: Managing the Object-Oriented Project}},
year = {1996}
}
@article{poole90b,
author = {Poole, D},
journal = {International Journal of Intelligent Systems},
pages = {521--548},
title = {{A Methodology for Using a Default and Abductive Reasoning System}},
volume = {5},
year = {1990}
}
@inproceedings{green91,
author = {Green, T R G and Petre, M and Bellamy, R K E},
booktitle = {Empirical Studies of Programmers: Fourth Workshop},
pages = {121--146},
title = {{Comprehensibility of Visual and Textual Programs: The Test of Superlativism Against the ``Match-Mismatch'' Conjecture}},
year = {1991}
}
@article{Fulkerson1995a,
author = {Fulkerson, Bill and Michie, D. and Spiegelhalter, D. J. and Taylor, C. C.},
doi = {10.2307/1269742},
file = {:Users/timm/svns/doc/statlog.pdf:pdf},
issn = {00401706},
journal = {Technometrics},
month = nov,
number = {4},
pages = {459},
title = {{Machine Learning, Neural and Statistical Classification}},
url = {http://www.jstor.org/stable/1269742?origin=crossref},
volume = {37},
year = {1995}
}
@article{Druker2010,
author = {Druker, Eric},
file = {:Users/timm/svns/doc/cost/10Druker.pdf:pdf},
number = {January},
pages = {0--27},
title = {{In a nutshell}},
year = {2010}
}
@article{caraca99,
annote = {To appear.},
author = {Caraca-Valente, J P and Gonzalez, L and Morant, J L and Pozas, J},
journal = {International Journal of Human-Computer Studies},
title = {{Knowledge-based Systems Validation: When to Stop Running Test Cases}},
year = {2000}
}
@incollection{lutz03c,
booktitle = {25th Int'l Conf on Software Eng (ICSE'03),Portland, Oregon},
month = may,
title = {{Requirements Discovery During the Testing of Safety-Critical Software}},
year = {2003}
}
@techrepor{kasunic08,
author = {{Kasunic. Mark McCurley. James} and David, Zubrow.},
institution = {Software Engineering Institute, Carnegie Mellon University},
number = {CMU/SEI-2008-TN-028},
title = {{Can You Trust Your Data? Establishing the Need for a Measurement and Analysis Infrastructure Diagnostic}},
year = {2008}
}
@article{me03j,
abstract = {Chung et al. have proposed a graphical model that captures the interdependencies between design alternatives in terms of synergy and trade-offs. This model can assist in identifying quality/risk trade-offs early in the lifecycle of software development, such as architectural design and testing process choices. The Chung et al. method is an analysis framework only: their technique does not include an execution or analysis module. This paper presents a simulation tool developed to analyze such a model, and techniques to facilitate decision making by reducing the space of options worth considering. Our techniques combine Monte Carlo simulations to generate options with a machine learner to determine which option yields the most/least favorable outcome. Experiments based on the above methodology were performed on two case studies, and the results showed that treatment learning successfully pinpointed the key attributes among uncertainties in our test domains. Copyright Â© 2003 John Wiley \& Sons, Ltd.},
author = {Chiang, Eliza and Menzies, Tim},
doi = {10.1002/spip.161},
issn = {1099-1670},
journal = {Software Process: Improvement and Practice},
number = {3â4},
pages = {141--159},
title = {{Simulations for very early lifecycle quality evaluations}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/spip.161/abstract},
volume = {7},
year = {2002}
}
@article{jorgensen09,
author = {J\o rgensen, M and Gruschke, T M},
journal = {Software Engineering, IEEE Transactions on},
number = {3},
pages = {368--383},
title = {{The Impact of Lessons-Learned Sessions on Effort Estimation and Uncertainty Assessments}},
volume = {35},
year = {2009}
}
@inproceedings{KULTUR2008,
address = {New York, NY, USA},
author = {Kultur, Yigit and Turhan, Burak and Bener, Ayse Basar},
booktitle = {SIGSOFT '08/FSE-16: Proceedings of the 16th ACM SIGSOFT International Symposium on Foundations of software engineering},
doi = {http://doi.acm.org/10.1145/1453101.1453148},
isbn = {978-1-59593-995-1},
pages = {330--338},
publisher = {ACM},
title = {{ENNA: software effort estimation using ensemble of neural networks with associative memory}},
year = {2008}
}
@inproceedings{heitmeyer95,
author = {Heitmeyer, C and Labaw, B and Kiskis, D},
booktitle = {International Symposium on Requirements Engineering, York, England , March 26-27},
title = {{Consistency Checking of \{SCR\}-Style Requirements Specifications}},
year = {1995}
}
@inproceedings{zhang06,
author = {Zhang, H and Huo, M and Kitchenham, B and Jeffery, R},
booktitle = {Australian Software Engineering Conference},
title = {{Qualitative Simulation Model for Software Engineering Process}},
year = {2006}
}
@book{busch96,
author = {Buschmann, F and Meunier, R and Rohnert, H and Sommerlad, P and Stal, M},
publisher = {John Wiley \& Sons},
title = {{A System of Patterns: Pattern-Oriented Software Architecture}},
year = {1996}
}
@article{vabu88,
author = {van Harmelen, F and Bundy, A},
journal = {Artificial Intelligence},
pages = {401--412},
title = {{Explanation-Based Generalisation = Partial Evaluation}},
year = {1988}
}
@incollection{hoff97,
author = {Hoffman, R R and Feltovich, P J and Ford, K M},
booktitle = {Expertise in Context},
chapter = {24},
editor = {Feltovich, P J and Ford, K M and Hoffman, R R},
pages = {543--580},
publisher = {MIT PRess},
title = {{A General Framework for Conceiving of Expertise in Expert Systems in Context}},
year = {1997}
}
@article{jackson96a,
author = {Jackson, D and Wing, J},
journal = {Computer},
number = {4},
pages = {21--22},
title = {{Formal Methods Light: Lightweight Formal Methods}},
volume = {29},
year = {1996}
}
@article{dekleer84,
author = {DeKleer, J and Brown, J S},
journal = {Artificial Intelligence},
pages = {7--83},
title = {{A Qualitative Physics Based on Confluences}},
volume = {25},
year = {1984}
}
@article{Kowa88,
author = {Kowalski, R A},
journal = {Communications of the ACM},
month = jan,
number = {1},
pages = {38--43},
title = {{The Early Years of Logic Programming}},
volume = {31},
year = {1988}
}
@inproceedings{sellev90,
author = {Selman, B and Levesque, H J},
booktitle = {\{AAAI\} '90},
pages = {343--348},
title = {{Abductive and \{D\}efault \{R\}easoning: a \{C\}omputational \{C\}ore}},
year = {1990}
}
@article{bert96,
author = {{A. Bertolino}, L Strigini},
journal = {IEEE Transactions on Software Engineering},
number = {2},
pages = {97--108},
title = {{On the Use of Tesability Measures for Dependability Assessment}},
volume = {22},
year = {1996}
}
@phdthesis{davis76,
author = {Davis, R},
school = {Stanford},
title = {{Applications of Meta-Level Knowledge to the Construction, Mainteance and Use of Large Knowledge Bases}},
year = {1976}
}
@misc{knuth84,
author = {Knuth, D E},
institution = {Department of Computer Science, Stanford University},
number = {STAN-CS-84-1027},
title = {{A Torture test for \{TEX\}}},
year = {1984}
}
@article{Song2010,
author = {Song, Qinbao and Jia, Zihan and Shepperd, Martin and Ying, Shi and Liu, Jin},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework.pdf:pdf},
keywords = {machine learning,scheme evaluation,software defect prediction,software defect-proneness prediction},
number = {X},
pages = {1--16},
title = {{A General Software Defect-Proneness Prediction Framework}},
volume = {X},
year = {2010}
}
@book{chung00,
author = {Chung, L and Nixon, B A and Yu, E and Mylopoulos, J},
publisher = {Kluwer Academic Publishers},
title = {{Non-Functional Requirements in Software Engineering}},
year = {2000}
}
@inproceedings{korte08,
author = {Korte, Marcel and Port, Dan},
booktitle = {PROMISE '08: Proceedings of the 4th international workshop on Predictor models in software engineering},
pages = {63--70},
title = {{Confidence in software cost estimation results based on MMRE and PRED}},
year = {2008}
}
@article{gruber93,
author = {Gruber, T R},
journal = {Knowledge Acquisition},
number = {2},
pages = {199--220},
title = {{A Translation Approach to Portable Ontology Specifications}},
volume = {5},
year = {1993}
}
@inproceedings{feather08b,
author = {Feather, M S and Uckun, S and Hicks, K A},
booktitle = {Space Technology and Applications International Forum (STAIF-2008) Albuquerque, USA},
month = feb,
title = {{Technology Maturation of Integrated System Health Management}},
year = {2008}
}
@misc{har98,
author = {Hawryszkiewycz, I T},
booktitle = {In preperation},
title = {{Evolving Workspace Networks for Cooperative Work}},
year = {1998}
}
@article{tosun2010,
author = {Tosun, A and Bener, A and Turhan, B and Menzies, T},
title = {{No Title}}
}
@article{gray06,
author = {Gray, J and Lin, Y and Zhang, J},
journal = {IEEE Computer},
month = feb,
number = {2},
pages = {51--58},
title = {{Automating Change Evolution in Model-Driven Engineering}},
volume = {39},
year = {2006}
}
@article{reggia83,
author = {Reggia, J and Nau, D S and Wang, P Y},
journal = {Int. J. of Man-Machine Studies},
number = {5},
pages = {437--460},
title = {{Diagnostic \{E\}xpert \{S\}ystems \{B\}ased on a \{S\}et \{C\}overing \{M\}odel}},
volume = {19},
year = {1983}
}
@inproceedings{cheng92,
author = {Cheng, P C},
booktitle = {AAAI Spring Symposium on Reasoning with Diagrammatic Representations},
editor = {Narayanan, N H},
pages = {33--38},
title = {{Diagrammatic Reasoning in Scientific Discovery: Modelling Galileo's Kinematic Diagrams}},
year = {1992}
}
@article{lumsden07,
author = {Lumsden, Larry and Strigel, W},
journal = {IEEE Software},
pages = {54--57},
title = {{SE Challenges in Small Software Companies, Point/Counterpoint}}
}
@article{silver92b,
author = {Silverman, B G and Mezher, T M},
journal = {AI Magazine},
pages = {45--62},
title = {{Expert critics in engineering design: lessons learned and research needs}},
year = {1992}
}
@inproceedings{votta93,
author = {Votta, L G},
booktitle = {Proceedings of ACM SIGSOFT Symp. Foundations of Software Engineering, Assoc. for Computing Machinery},
month = dec,
title = {{Does Every Inspection Need a Meeting?}},
year = {1993}
}
@inproceedings{AZZEH2009,
address = {New York, NY, USA},
author = {Azzeh, Mohammad and Neagu, Daniel and Cowling, Peter},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540450},
isbn = {978-1-60558-634-2},
pages = {1--10},
publisher = {ACM},
title = {{Software effort estimation based on weighted fuzzy grey relational analysis}},
year = {2009}
}
@incollection{buch83,
author = {Buchanan, B and Barstow, D and Bechtel, R and Bennet, J and Clancey, W and Kulikowski, C and Mitchell, T M and Waterman, D A},
chapter = {Constructi},
pages = {127--168},
publisher = {Addison-Wesley},
title = {{Building Expert Systems, F. Hayes-Roth and D. Waterman and D. Lenat (eds)}},
year = {1983}
}
@misc{visser05a,
author = {Visser, W},
title = {{Personel communication: Comments on different tools}},
year = {2005}
}
@article{Yoon2010,
author = {Yoon, Kyung-A and Bae, Doo-Hwan},
doi = {10.1016/j.infsof.2009.08.005},
file = {:Users/timm/svns/doc/yoon10.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
month = feb,
number = {2},
pages = {137--151},
title = {{A pattern-based outlier detection method identifying abnormal attributes in software project data}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950584909001256},
volume = {52},
year = {2010}
}
@article{lim94,
author = {Lim, W},
journal = {IEEE Software},
pages = {23--30},
title = {{Effects of reuse on quality, productivity, and economics}},
year = {1994}
}
@phdthesis{edwards96,
author = {Edwards, G},
school = {Computer Science \& Engineering, University of NSW},
title = {{Reflective Expert Systems in Pathology}},
year = {1996}
}
@inproceedings{Zweben1992,
author = {Zweben, S},
booktitle = {Experimental Software Engineering Issues, International Workshop, Rombach and Basili and Selby (Eds.), LNCS 706, Springer-Verlag},
pages = {247--251},
title = {{Effective Use of Measurement and Experimentation in Computing Curricula}},
year = {1992}
}
@book{musa87,
author = {Musa, J and Iannino, A and Okumoto, K},
publisher = {McGraw Hill},
title = {{Software Reliability: Measurement, Prediction, Application}},
year = {1987}
}
@article{Liu2004d,
author = {Liu, H and Motoda, H and Yu, L},
doi = {10.1016/j.artint.2004.05.009},
file = {:Users/timm/svns/doc/Liu04.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {ac,asu,corresponding author,dimensionality reduction,e-mail addresses,edu,feature selection and ranking,h,hliu,jp,learning,leiyu,liu,motoda,osaka-u,sampling,sanken},
month = nov,
number = {1-2},
pages = {49--74},
title = {{A selective sampling approach to active feature selection}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370204000980},
volume = {159},
year = {2004}
}
@inproceedings{jureta08,
author = {Jureta, I J and Mylopoulos, J and Faulkner, S},
booktitle = {International Requirements Engineering, 2008. RE '08. 16th IEEE},
pages = {71--80},
title = {{Revisiting the Core Ontology and Problem in Requirements Engineering}},
year = {2008}
}
@inproceedings{me96e,
author = {Menzies, T J},
booktitle = {Proceedings of the 10th Knowledge Acquisition Workshop for Knowledge-Based Systems, Banff,Canada},
title = {{Assessing Responses to Situated Congition}},
year = {1996}
}
@article{grog92,
author = {Grogono, P and Batarekh, A and Preece, A and Shinghal, R and Suen, C},
journal = {Expert Systems},
pages = {227--239},
title = {{Expert System Evaluation Techniques: A Selected Bibliography.}},
year = {1992}
}
@inproceedings{mittle07,
author = {Mittelmann, H D},
booktitle = {22nd Euorpean Conference on Operational Research},
title = {{Recent Benchmarks of Optimization Software}},
year = {2007}
}
@article{lea94,
author = {Lea, D},
journal = {ACM SIGSOFT Software Engineering Notes},
month = jan,
number = {1},
pages = {39--45},
title = {{Christopher Alexander: An introduction for object-oriented designers}},
volume = {19},
year = {1994}
}
@article{Aha1991,
author = {Aha, D.W. and Kibler, Dennis and Albert, M.K.},
doi = {10.1007/BF00153759},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Aha, Kibler, Albert - 1991 - Instance-based learning algorithms.pdf:pdf},
issn = {0885-6125},
journal = {Machine learning},
keywords = {incremental learning,instance-based concept descriptions,learning theory,supervised concept learning},
month = jan,
number = {1},
pages = {37--66},
publisher = {Springer},
title = {{Instance-based learning algorithms}},
url = {http://www.springerlink.com/index/G4QV6511520X3041.pdf},
volume = {6},
year = {1991}
}
@article{smith97,
author = {Smith, A and Mason, A},
journal = {The Engineering Economist},
number = {2},
pages = {137--161},
title = {{Cost estimation predictive modeling: Regression versus neural network}},
volume = {42},
year = {1997}
}
@book{voas98,
author = {Voas, J and McGraw, G},
isbn = {0-471-18381-4},
publisher = {John Wiley \& Sons},
title = {{Software Fault Injection: Inoculating Programs Against Error}},
year = {1998}
}
@article{beng98,
author = {Benjamins, R and Fensel, D},
journal = {International Journal of Human Computer Studies},
number = {4},
title = {{Special Issue on Problem Solving Methods}},
volume = {49},
year = {1998}
}
@inproceedings{FU09,
address = {New York, NY, USA},
author = {Fu, Yu and Koru, A G\"{u}ne$\backslash$cs and Chen, Zhiyuan and {El Emam}, Khaled},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540443},
isbn = {978-1-60558-634-2},
pages = {1--12},
publisher = {ACM},
title = {{A tree-based approach to preserve the privacy of software engineering data and predictive models}},
year = {2009}
}
@article{compton90,
author = {Compton, P J and Jansen, R},
journal = {Knowledge Acquisition},
pages = {241--257},
title = {{A \{P\}hilosophical \{B\}asis for \{K\}nowledge \{A\}cquisition.}},
volume = {2},
year = {1990}
}
@article{me03j,
author = {Chiang, E and Menzies, T},
journal = {Software Process: Improvement and Practice},
number = {3-4},
pages = {141--159},
title = {{Simulations for very early lifecycle quality evaluations}},
volume = {7},
year = {2003}
}
@book{jones94,
author = {Jones, C},
publisher = {Yourdon Press},
title = {{Assessment and Control of Software Risks}},
year = {1994}
}
@incollection{patel97,
author = {Patel, V L and Ramoni, M F},
booktitle = {Expertise in Context},
chapter = {3},
editor = {Feltovich, P J and Ford, K M and Hoffman, R R},
pages = {67--99},
publisher = {MIT PRess},
title = {{Cognitive Models of Directional Inference in Expert Medical Reasoning}},
year = {1997}
}
@inproceedings{deb98b,
author = {Debenham, J},
booktitle = {Proceedings Tenth International Conference on Software Engineering and Knowledge Engineering SEKE'98, San Francisco, US, June},
title = {{Representing Knowledge Normalisation}},
year = {1998}
}
@article{chandra83,
author = {Chandrasekaran, B},
journal = {AI Magazine},
pages = {9--17},
title = {{Towards a \{T\}axonomy of \{P\}roblem \{S\}olving \{T\}ypes}},
year = {1983}
}
@inproceedings{swart96,
author = {Swartout, B and Gill, Y},
booktitle = {1996 AAAI Spring Symposium on Acquisition, Learning, and Demonstration: Automating Tasks for Users},
title = {{Flexible Knowledge Acquisition Through Explicit Representation of Knowledge Roles}},
year = {1996}
}
@inproceedings{owen01,
author = {Owen, D and Menzies, T},
booktitle = {Proceedings of the First International Workshop on Model-based Requirements Engineering},
title = {{Random Search of AND-OR Graphs Representing Finite-State Models}},
year = {2001}
}
@article{such87,
author = {Suchman, L},
journal = {Artificial Intelligence},
pages = {227--232},
title = {{Book Review of Winograd \& Flores, Understanding Computers and Cognition: A New Foundation for Design}},
volume = {31},
year = {1987}
}
@inproceedings{MENDE2009,
address = {New York, NY, USA},
author = {Mende, Thilo and Koschke, Rainer},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540448},
isbn = {978-1-60558-634-2},
pages = {1--10},
publisher = {ACM},
title = {{Revisiting the evaluation of defect prediction models}},
year = {2009}
}
@book{brooks95,
author = {Brooks, F P},
publisher = {Addison-Wesley},
title = {{The Mythical Man-Month, Anniversary edition}},
year = {1995}
}
@book{knuth92,
author = {Knuth, D},
publisher = {Center for the Study of Language and Information, CLSI},
title = {{Literate Programming}},
year = {1992}
}
@incollection{gut90,
author = {Gutfreund, S H},
booktitle = {Visual Programming Environments: Applications and Issues},
editor = {Glinert, E P},
pages = {25--45},
publisher = {IEEE Computer Society Press Tutorial},
title = {{ManiplIcons in ThinkerToy}},
year = {1990}
}
@article{wilcoxon45,
author = {Wilcoxon, F},
journal = {Biometrics},
pages = {80--83},
title = {{Individual comparisons by ranking methods}},
volume = {1},
year = {1945}
}
@inproceedings{uribe94,
author = {Uribe, Tomas E and Stickel, Mark E},
booktitle = {In Proc. of the 1st International Conference on Constraints in Computational Logics},
pages = {34--49},
publisher = {Springer-Verlag},
title = {{Ordered Binary Decision Diagrams and the Davis-Putnam procedure}},
year = {1994}
}
@article{stukes98,
author = {Stukes, S and Ferens, D},
journal = {Journal of Parametrics},
number = {1},
pages = {77--98},
title = {{Software Cost Model Calibration}},
volume = {18},
year = {1998}
}
@article{simon80,
author = {Larkin, J and McDermott, J and Simon, D P and Simon, H A},
journal = {Science},
pages = {1335--1342},
title = {{Expert and Novice Performance in Solving Physics Problems}},
volume = {208},
year = {1980}
}
@article{bastani93,
author = {Bastani, F and Chen, I},
journal = {International Journal of Software Engineering and Knowledge Engineering},
number = {1},
pages = {99--114},
title = {{Assessment of the Reliability of AI Programs}},
volume = {3},
year = {1993}
}
@article{mili95,
author = {{H. Mili F. Mili}, A Mili},
journal = {IEEE Transactions of Software Engineering},
month = jun,
number = {6},
pages = {528--562},
title = {{Reusing Software: Issues and Research Directions}},
volume = {21},
year = {1995}
}
@article{me99m,
author = {Menzies, T and van Harmelen, F},
journal = {International Journal of Human-Computer Studies, special issue on evaluation of Knowledge Engineering Techniques},
month = oct,
number = {4},
pages = {717--727},
title = {{Editorial: Evaluating Knowledge Engineering Techniques}},
volume = {51},
year = {1999}
}
@inproceedings{me06f,
annote = {Available from $\backslash$url\{http://menzies.us/06deviations.pdf\}},
author = {Menies, T and Lum, K and Hihn, J},
booktitle = {PROMISE, 2006},
title = {{The Deviance Problem in Effort Estimation}},
year = {2006}
}
@article{fagan76,
author = {Fagan, M},
journal = {IBM Systems Journal},
number = {3},
title = {{Design and Code Inspections to Reduce Errors in Program Development}},
volume = {15},
year = {1976}
}
@inproceedings{liu98,
author = {Liu, B and Hsu, W and Ma, Y},
booktitle = {KDD},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/liu98.pdf:pdf},
month = sep,
pages = {80--86},
title = {{Integrating classification and association rule mining}},
year = {1998}
}
@inproceedings{nar95,
author = {Narayanan, N Hari and Suwa, Masaki and Motoda, H},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and {N.H. Narayanan}, B Chandrasekaran},
pages = {501--534},
publisher = {The AAAI Press},
title = {{Behaviour Hypothesis from Schematic Diagrams}},
year = {1995}
}
@book{lim95,
author = {Lim, W C},
publisher = {Prentice Hall},
title = {{Managing Software Reuse}},
year = {1995}
}
@inproceedings{zdrahal94,
author = {Zdrahal, Z and Motta, E},
booktitle = {Proceedings of the Third Japanese Knowledge Acquisition for Knowledge-Based Systems Workshop: \{JKAW\} '94},
editor = {Mizoguchi, R and Motoda, H and Boose, J and Gaines, B and Compton, P},
organization = {Japanese \{AI\} Society},
title = {{An \{I\}n-\{D\}epth \{A\}nalysis of \{P\}ropose \& \{R\}evise \{P\}roblem \{S\}olving \{M\}ethods}},
year = {1994}
}
@inproceedings{SAMI2010,
address = {New York, NY, USA},
author = {Sami, Ashkan and Fakhrahmad, Seyed Mostafa},
booktitle = {SAC '10: Proceedings of the 2010 ACM Symposium on Applied Computing},
doi = {http://doi.acm.org/10.1145/1774088.1774612},
isbn = {978-1-60558-639-7},
pages = {2531--2535},
publisher = {ACM},
title = {{Design-level metrics estimation based on code metrics}},
year = {2010}
}
@inproceedings{clarke89a,
author = {Clark, E M and Long, D E},
booktitle = {Fourth Annual Symposium on Logic in Computer Science},
title = {{Compositional Model Checking}},
year = {1989}
}
@inproceedings{newell72,
author = {Newell, A},
booktitle = {Visual Information Processing},
editor = {Chase, W G},
pages = {283--308},
publisher = {New York: Academic Press},
title = {{You can't play 20 Questions with Nature, and Win}},
year = {1972}
}
@inproceedings{shaw92,
author = {Shaw, M L G and Gaines, B R},
booktitle = {7th Banff Knowledge Acquisition for Knowledge-Based Systems Workshop, Banff, Canada},
pages = {24.1--24.18},
title = {{Repgrid-net: Combining Conceptual Modeling with Electronic Mail to Provide Decision Support}},
year = {1992}
}
@inproceedings{hoos98,
author = {Hoos, H H and Stutzle, T},
booktitle = {Proc. of UAI-98},
title = {{Evaluating Las Vegas Algorithms - Pitfalls and Remedies}},
year = {1998}
}
@inproceedings{me06c,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06bad.pdf\}},
author = {Menzies, T and Allen, D and Orrego, A},
booktitle = {Proceedings of the Machine Learning Algorithms for Surveillance and Event Detection Workshop, ICML'06},
title = {{Bayesian Anomaly Detection (BAD v1.0)}},
year = {2006}
}
@inproceedings{Kocaguneli2009a,
author = {Kocaguneli, Ekrem and Kultur, Y. and Bener, A.B.},
booktitle = {ISSRE '09},
file = {:Users/timm/svns/doc/ekrem09a.pdf:pdf},
title = {{Combining Multiple Learners Induced on Multiple Datasets for Software Effort Prediction}},
url = {http://www.issre2009.org/papers/issre2009\_245.pdf},
year = {2009}
}
@inproceedings{mockus05,
address = {New York, NY, USA},
author = {Mockus, Audris and Zhang, Ping and Li, Paul Luo},
booktitle = {ICSE '05: Proceedings of the 27th international conference on Software engineering},
pages = {225--233},
publisher = {ACM},
title = {{Predictors of customer perceived software quality}},
year = {2005}
}
@book{harrell00,
author = {Harrell, H and Ghosh, L and Bowden, S},
publisher = {McGraw-Hill},
title = {{Simulation Using ProModel}},
year = {2000}
}
@article{hoppe93,
author = {{T. Hoppe}, P Meseguer},
journal = {IEEE Expert},
number = {3},
pages = {48--55},
title = {{VVT Terminology: A Proposal}},
volume = {8},
year = {1993}
}
@inproceedings{macdonell07,
author = {MacDonell, S G and Shepperd, M J},
booktitle = {Empirical Software Engineering and Measurement, ESEM 2007},
pages = {401--409},
title = {{Comparing Local and Global Software Effort Estimation Models -- Reflections on a Systematic Review}},
year = {2007}
}
@inproceedings{leake93,
author = {Leake, D B},
booktitle = {\{IJCAI\} '93},
pages = {24--29},
title = {{Focusing \{C\}onstruction and \{S\}election of \{A\}bductive \{H\}ypotheses}},
year = {1993}
}
@article{bezdek99,
author = {Bezdek, J C and Keller, J M and Krishnapuram, R and Kuncheva, L I and Pal, N R},
journal = {Fuzzy Systems, IEEE Transactions on},
month = jun,
number = {3},
pages = {368--369},
title = {{Will the real iris data please stand up?}},
volume = {7},
year = {1999}
}
@inproceedings{jeff01,
author = {Jeffery, R and Ruhe, M and Wieczorek, I},
booktitle = {Proceedings of the 7th International Software Metrics Symposium},
pages = {16--27},
title = {{Using public domain metrics to estimate software development effort}},
year = {2001}
}
@inproceedings{mich86,
author = {Michalski, I and Mozetic, J and Hong, J and Lavrac, N},
booktitle = {Proceedings of AAAI 1986},
pages = {1041--1045},
title = {{The multi-purpose incremental learning system AQL and its testing application to three medical domains}},
year = {1986}
}
@article{turhan07b,
address = {Los Alamitos, CA, USA},
author = {Turhan, B and Bener, A},
doi = {http://doi.ieeecomputersociety.org/10.1109/QSIC.2007.4},
issn = {1550-6002},
journal = {QSIC 2007: The Seventh International Conference on Quality Software},
pages = {231--237},
publisher = {IEEE Computer Society},
title = {{A Multivariate Analysis of Static Code Attributes for Defect Prediction}},
volume = {0},
year = {2007}
}
@article{webb00a,
author = {{Z. Zheng}, Z and Webb, G},
journal = {Machine Learning},
number = {1},
pages = {53--84},
title = {{Lazy Learning of Bayesian Rules}},
volume = {41},
year = {2000}
}
@inproceedings{me99k,
author = {Menzies, T and Cukic, B},
booktitle = {The Eleventh IEEE International Conference on Tools with Artificial Intelligence. November 9-11, 1999. Chicago IL USA.},
title = {{On the Sufficiency of Limited Testing for Knowledge Based Systems}},
year = {1999}
}
@inproceedings{me03l,
author = {Menzies, T and Singh, H},
booktitle = {Soft Computing in Software Engineering},
editor = {Madravio, M},
publisher = {Springer-Verlag},
title = {{Many Maybes Mean (Mostly) the Same Thing}},
year = {2003}
}
@misc{She02,
author = {Shepperd, M J},
institution = {Bournemouth University, UK},
number = {TR02-08},
title = {{Case-based Reasoning and Software Engineering}},
year = {2002}
}
@book{jones91,
author = {Jones, C},
publisher = {McGraw Hill},
title = {{Applied Software Measurement}},
year = {1991}
}
@article{boehm98,
author = {Boehm, B and Egyed, A and Port, D and Shah, A and Kwan, J and Madachy, R},
journal = {Annals of Software Engineering},
pages = {295--321},
title = {{A Stakeholder Win-Win Approach to Software Engineering Education}},
volume = {6},
year = {1998}
}
@inproceedings{corbet00,
author = {Corbett, J and Dwyer, M B and Hatcliff, J and Laubach, S and Pasareanu, C S and Robby and Zheng, H},
booktitle = {Proceedings ICSE2000, Limerick, Ireland},
pages = {439--448},
title = {{Bandera: Extracting Finite-state Models from Java Source Code}},
year = {2000}
}
@inproceedings{me00q,
author = {Menzies, T and Powell, J and Houle, M E},
booktitle = {ICSE 2001},
file = {::},
title = {{Fast Formal Analysis of Requirements via 'Topoi Diagrams'}},
year = {2001}
}
@book{Maloof2006,
author = {Maloof, M A},
booktitle = {Young},
editor = {Jain, Lakhmi and Wu, Xindong},
pages = {218},
publisher = {Springer Verlag},
title = {{Machine learning and data mining for computer security: methods and applications}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=LGn\_\_F4oFZMC\&amp;oi=fnd\&amp;pg=PR7\&amp;dq=Machine+Learning+and+Data+Mining+for+Computer+Security.+Methods+and+Applications\&amp;ots=ArDVDlXasu\&amp;sig=vK0UzpUUbLimwhpEJ3QvaXOYOF8},
year = {2006}
}
@inproceedings{agesen95,
author = {Agesen, O and Holzle, U},
booktitle = {OOPSLA '95},
pages = {91--107},
title = {{Type Feedback vs Concrete Type Inference: A Comparison of Optimisation Techniques for OO Languages}},
year = {1995}
}
@inproceedings{jalali08,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08keys.pdf\}},
author = {Jalali, O and Menzies, T and Feather, M},
booktitle = {Proceedings of the PROMISE 2008 Workshop (ICSE)},
file = {::},
title = {{Optimizing Requirements Decisions With KEYS}},
year = {2008}
}
@article{mcmonk94,
author = {McCarthy, J C and Monk, A F},
journal = {Collaborative Computing},
pages = {35--60},
title = {{Channels, conversation, co-operation and relevance: all you wanted to know about communication but were afraid to ask}},
volume = {1},
year = {1994}
}
@inproceedings{motta95,
author = {Motta, E and Zdrahal, Z},
booktitle = {Proceedings of the 9th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge-Based Systems Workshop Banff, Canada},
title = {{The Trouble with What: Issues in Method-Independent Task Specifications}},
year = {1995}
}
@inproceedings{cohen97,
author = {Cohen, William W and Devanbu, Prem},
booktitle = {Proc. 14th International Conference on Machine Learning},
pages = {66--74},
publisher = {Morgan Kaufmann},
title = {{A comparative study of inductive logic programming methods for software fault prediction}},
year = {1997}
}
@article{dekleer86a,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {163--196},
title = {{An \{A\}ssumption-\{B\}ased \{TMS\}}},
volume = {28},
year = {1986}
}
@inproceedings{provost98case,
author = {Provost, Foster and Fawcett, Tom and Kohavi, Ron},
booktitle = {Proc. 15th International Conf. on Machine Learning},
pages = {445--453},
publisher = {Morgan Kaufmann, San Francisco, CA},
title = {{The case against accuracy estimation for comparing induction algorithms}},
year = {1998}
}
@inproceedings{fea00,
author = {Feather, M S and Cornford, S L and Larson, T W},
booktitle = {15th IEEE International Conference on Automated Software Engineering, Grenoble, France},
month = sep,
pages = {309--312},
title = {{Combining the Best Attributes of Qualitative and Quantitative Risk Management Tool Support}},
year = {2000}
}
@article{hayes06,
author = {Hayes, Jane Huffman and Dekhtyar, Alex and Sundaram, Senthil Karthikeyan},
journal = {IEEE Trans. Software Eng},
number = {1},
pages = {4--19},
title = {{Advancing Candidate Link Generation for Requirements Tracing: The Study of Methods}},
url = {http://doi.ieeecomputersociety.org/10.1109/TSE.2006.3},
volume = {32},
year = {2006}
}
@inproceedings{BIRD2009,
address = {New York, NY, USA},
author = {Bird, Christian and Bachmann, Adrian and Aune, Eirik and Duffy, John and Bernstein, Abraham and Filkov, Vladimir and Devanbu, Premkumar},
booktitle = {ESEC/FSE '09: Proceedings of the the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering},
doi = {http://doi.acm.org/10.1145/1595696.1595716},
isbn = {978-1-60558-001-2},
pages = {121--130},
publisher = {ACM},
title = {{Fair and balanced?: bias in bug-fix datasets}},
year = {2009}
}
@inproceedings{markosian05,
author = {Markosian, L and Feather, M and Brinza, D and Figueroa, F},
booktitle = {1st \{I\}nternational \{F\}orum on \{I\}ntegrated \{S\}ystem \{H\}ealth \{E\}ngineering and \{M\}anagement in \{A\}erospace, \{Napa\}},
month = nov,
title = {{\{V\&V\} of \{ISHM\} software for space exploration}},
year = {2005}
}
@misc{john96,
annote = {(personal communication)},
author = {Johnson, R},
title = {{No Title}}
}
@misc{cpp06,
booktitle = {Proceedings of the 2006 International Conference of the International Society of Parametric Analysts, Seattle, WA},
title = {{Certified Parametric Practioner Tutorial}},
year = {2006}
}
@misc{gay07,
author = {Gay, G and Menzies, T},
institution = {Lane Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{Under- vs Over- Sampling for C4.5 and Naive Bayes Defect Predictors}},
year = {2007}
}
@inproceedings{rothermel98,
author = {Rothermel, G and Harrold, M J and Ostrin, J and Hong, Christie},
booktitle = {Proceedings of International Conference on Software Maintenance '98},
month = nov,
pages = {34--43},
title = {{An Empirical Study of the Effects of Minimizaton on the Fault-Detection Capabilities of Test Suites}},
year = {1998}
}
@article{clan89a,
author = {Clancey, W},
journal = {Machine Learning},
number = {3/4},
pages = {285--293},
title = {{The knowledge level reinterpreted: Modeling how systems interact}},
volume = {4},
year = {1989}
}
@inproceedings{me09m,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09fssga.pdf\}},
author = {Andrews, Jamie and Menzies, Tim},
booktitle = {PROMISE'09},
title = {{On the Value of Combining Feature Subset Selection with Genetic Algorithms: Faster Learning of Coverage Models}},
year = {2009}
}
@article{Malone1994a,
author = {Malone, Thomas W and Crowston, Kevin},
file = {:Users/timm/svns/doc/malone94.pdf:pdf},
journal = {Computing},
number = {1},
title = {{The Interdisciplinary Study of Coordination}},
volume = {2},
year = {1994}
}
@article{kol91,
author = {Kolodner, J L},
journal = {AI Magazine},
pages = {68},
title = {{Improving \{H\}uman \{D\}ecision \{M\}aking \{T\}hrough \{C\}ase-\{B\}ased \{D\}ecision \{A\}iding}},
year = {1991}
}
@article{Liu2004b,
author = {Liu, H and Motoda, H and Yu, L},
doi = {10.1016/j.artint.2004.05.009},
file = {:Users/timm/svns/doc/Liu04.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {ac,asu,corresponding author,dimensionality reduction,e-mail addresses,edu,feature selection and ranking,h,hliu,jp,learning,leiyu,liu,motoda,osaka-u,sampling,sanken},
month = nov,
number = {1-2},
pages = {49--74},
title = {{A selective sampling approach to active feature selection}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370204000980},
volume = {159},
year = {2004}
}
@article{clancey92,
author = {Clancey, W J},
journal = {Artificial Intelligence},
pages = {1--115},
title = {{Model \{C\}onstruction \{O\}perators}},
volume = {53},
year = {1992}
}
@article{domingos03,
author = {Domingos, Pedro and Hulten, Geoff},
journal = {Journal of Computational and Graphical Statistics},
number = {12},
title = {{A General Framework for Mining Massive Data Streams}},
year = {2003}
}
@article{demillo95,
author = {DeMillo, R A and Mathur, A P and Wong, W E},
journal = {IEEE Transactions on Software Engineering},
month = oct,
number = {10},
pages = {854--861},
title = {{Some Critical Remarks on a Hierarchy of Fault-Detecting Abilities of Test Methods}},
volume = {21},
year = {1995}
}
@inproceedings{dieng93,
author = {Dieng, R and Corby, O and Lapalut, S},
booktitle = {EKAW '93: Knowledge Acquisition for Knowledge-Based Systems: 7th European Workshop},
editor = {Aussenac, N and Boy, G and Gaines, B and {M. Linster}, T.-G. Ganascia and Kodratoff, Y},
pages = {407--426},
title = {{Acquisition of Gradual Knowledge}},
year = {1993}
}
@article{neches91,
author = {Neches, R and Fikes, R and Finin, T and Gruber, T and Patil, R and Senator, T and Swartout., W R},
journal = {AI Magazine},
number = {3},
pages = {16--36},
title = {{Enabling technology for knowledge sharing}},
volume = {12},
year = {1991}
}
@article{brac83,
author = {Brachman, R},
journal = {The \{AI\} Magazine},
month = oct,
pages = {66--73},
title = {{What IS-A Is and Isn't: An Analysis of Taxonomic Links in Semantic Networks}},
year = {1983}
}
@article{Ghinita2011,
author = {Ghinita, Gabriel and Kalnis, Panos and Tao, Yufei},
doi = {10.1109/TKDE.2010.101},
file = {::},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = feb,
number = {2},
pages = {161--174},
title = {{Anonymous Publication of Sensitive Transactional Data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5487522},
volume = {23},
year = {2011}
}
@article{heitmeyer96automated,
author = {Heitmeyer, C L and Jeffords, R D and Labaw, B G},
journal = {ACM Transactions on Software Engineering and Methodology},
month = jul,
number = {3},
pages = {231--261},
publisher = {ACM Press},
title = {{Automated Consistency Checking of Requirements Specifications}},
volume = {5},
year = {1996}
}
@book{dreyfus79,
author = {Dreyfus, H},
publisher = {Freeman},
title = {{What Computers Can't D: A Critique of Artifical Reason}},
year = {1979}
}
@article{Shull1998,
author = {Shull, Forrest},
file = {::},
title = {{Tpi 7057721}},
volume = {267},
year = {1998}
}
@misc{ctc86,
annote = {Vol. 2, No. 3},
howpublished = {Control Theory and Advanced Technology},
month = sep,
title = {{Special Issue on Expert Systems}},
year = {1986}
}
@incollection{ohara97,
author = {O'Hara, K and Shadbolt, N},
booktitle = {Expertise in Context},
chapter = {19},
editor = {Feltovich, P J and Ford, K M and Hoffman, R R},
pages = {449--472},
publisher = {MIT PRess},
title = {{Inerpreting Generic Structures: Expert Systems, Expertise, and Context}},
year = {1997}
}
@misc{me01b,
author = {Menzies, T},
booktitle = {ASERC workshop on Quantiative Software Engineering},
title = {{Applictions of Computational Intelligence to Quantitative Software Engineering}},
year = {2001}
}
@misc{shaw97,
address = {$\backslash$url\{http://Tiger.cpsc.ucalgary.ca/WebGrid/WebGrid.html\}},
author = {Shaw, M},
institution = {Knowledge Systems Institute, University of Calgary},
title = {{WebGrid: a WWW PCP Server}},
year = {1997}
}
@article{okeefe93,
author = {O'Keefe, R M and O'Leary, D E},
journal = {Artificial Intelligence Review},
pages = {3--42},
title = {{Expert system verification and validation: a survey and tutorial}},
volume = {7},
year = {1993}
}
@phdthesis{cooper01a,
author = {Cooper, K},
school = {Department of Electrical and Computer Engineering, The University of British Columbia},
title = {{Assessing Requirements Engineering Languages}},
year = {2001}
}
@inproceedings{pease00,
author = {Pease, A and Chaudhri, V and Lehmann, F and Farquhar, A},
booktitle = {Proceedings of KR-2000},
title = {{Practical Knowledge Representation and the DARPA High Performance Knowledge Bases Project}},
year = {2000}
}
@article{khoshgoftaar03,
address = {Hingham, MA, USA},
author = {Khoshgoftaar, Taghi M and Seliya, Naeem},
doi = {http://dx.doi.org/10.1023/A:1025316301168},
issn = {1382-3256},
journal = {Empirical Softw. Engg.},
number = {4},
pages = {325--350},
publisher = {Kluwer Academic Publishers},
title = {{Analogy-Based Practical Classification Rules for Software Quality Estimation}},
volume = {8},
year = {2003}
}
@inproceedings{JIANG20082,
address = {New York, NY, USA},
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim},
booktitle = {DEFECTS '08: Proceedings of the 2008 workshop on Defects in large software systems},
doi = {http://doi.acm.org/10.1145/1390817.1390822},
isbn = {978-1-60558-051-7},
pages = {16--20},
publisher = {ACM},
title = {{Can data transformation help in the detection of fault-prone modules?}},
year = {2008}
}
@inproceedings{me02n,
author = {Liu, Y and Menzies, T and Cukic, B},
booktitle = {IEEE Tools with AI},
title = {{Data Sniffing - Monitoring of Machine Learning for Online Adaptive Systems}},
year = {2002}
}
@inproceedings{me02c,
author = {Menzies, T and Chiang, E and Feather, M and Hu, Y and Kiper, J D},
booktitle = {Software Engineering with Computational Intelligence},
editor = {Khoshgoftaar, Taghi M},
isbn = {1-4020-7427-1},
publisher = {Kluwer},
title = {{Condensing uncertainty via Incremental Treatment Learning}},
year = {2003}
}
@inproceedings{zhang10,
author = {Zhang, Hongyu and Nelson, Adam and Menzies, Tim},
title = {{Proceedings of PROMISE'10}},
year = {2010}
}
@inproceedings{corn01,
author = {Cornford, S L and Feather, M S and Hicks, K A},
booktitle = {IEEE Aerospace Conference, Big Sky, Montana},
month = mar,
pages = {441--451},
title = {{\{DDP\} A tool for life-cycle risk management}},
year = {2001}
}
@book{glass88,
author = {Glass, L and Mackey, M C},
publisher = {Princeton University Press},
title = {{From Clocks to Chaos}},
year = {1988}
}
@inproceedings{corbet94,
author = {Corbett, J},
booktitle = {Proceedings of the 1994 International Symposium on Software Testing and Analysis (ISSTA)},
title = {{An Empirical Evaluation of Three Methods for Deadlock Analysis of \{ADA\} Tasking Programs}},
year = {1994}
}
@inproceedings{runkel94,
author = {Runkel, J T and Birmingham, W P},
booktitle = {Proceedings of the 8th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge-Based Systems Workshop},
editor = {Gaines, B R and Musen, M},
pages = {42.1--42.28},
title = {{Solving VT by Reuse}},
year = {1994}
}
@article{mann47,
author = {Mann, H B and Whitney, D R},
journal = {Ann. Math. Statist.},
number = {1},
pages = {50--60},
title = {{On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other}},
volume = {18},
year = {1947}
}
@inproceedings{dou95,
author = {Dougherty, James and Kohavi, Ron and Sahami, Mehran},
booktitle = {International Conference on Machine Learning},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Dougherty, Kohavi, Sahami - 1995 - Supervised and unsupervised discretization of continuous features.pdf:pdf},
pages = {194--202},
title = {{Supervised and Unsupervised Discretization of Continuous Features}},
year = {1995}
}
@inproceedings{rieger77,
author = {Rieger, C and Grinberg, M},
booktitle = {IJCAI '77},
pages = {250--256},
title = {{The Declarative Representation and Procedural Simulation of Causality in Physical Mechanisms}},
year = {1977}
}
@article{meseguer92,
author = {Meseguer, P},
journal = {Artificial Intelligence Communications},
number = {3},
pages = {119--135},
title = {{Towards a Conceptual Framework for Expert System Validation}},
volume = {5},
year = {1992}
}
@phdthesis{yun04,
author = {Liu, Alexander Yun-chung},
school = {Graduate School, University of Texas at Austin},
title = {{The Effect of Oversampling and Undersampling on Classifying Imbalanced Text Datasets}},
year = {2004}
}
@inproceedings{swig91,
author = {Swigger, K M and Brazile, R P},
booktitle = {Empirical Studies of Programmers: Fourth Workshop},
editor = {Koenemann-Belliveau, J and Moher, T and Robertson, S},
publisher = {Ablex Publishing Corp},
title = {{An Empirical Study of the Effects of Design/Documentation Formats on Expert System Modifiability}},
year = {1991}
}
@article{offen97,
author = {Offen, R J and Jeffery, R},
journal = {IEEE Software},
pages = {45--53},
title = {{Establishing Software Measurement Programs}},
year = {1997}
}
@book{capers98,
author = {Jones, T C},
publisher = {McGraw-Hill},
title = {{Estimating Software Costs}},
year = {1998}
}
@article{huang06,
author = {Huang, L and Boehm, B},
journal = {Software, IEEE},
number = {5},
pages = {88--95},
title = {{How Much Software Quality Investment Is Enough: A Value-Based Approach}},
volume = {23},
year = {2006}
}
@misc{beed01,
annote = {Available from $\backslash$url\{http://www.agilemanifesto.org/\}},
author = {Et. al., M Beedle},
title = {{Manifesto for Agile Software Development}},
year = {2001}
}
@inproceedings{robles10,
author = {Robles, G},
booktitle = {MSR'10},
title = {{Replicating MSR: A study of the potential replicability of papers published in the Mining Software Repositories Proceedings}},
year = {2010}
}
@inproceedings{park88,
author = {Park, R},
booktitle = {4th COCOMO Users\~{O} Group Meeting},
month = nov,
title = {{The Central Equations of the PRICE Software Cost Model}},
year = {1988}
}
@inproceedings{me01f,
author = {Menzies, T and Hu, Y},
booktitle = {First International Workshop on Model-based Requirements Engineering},
file = {::},
title = {{Reusing models for requirements engineering}},
year = {2001}
}
@article{towell93extracting,
author = {Towell, Geoffrey G and Shavlik, Jude W},
journal = {Machine Learning},
pages = {71--101},
title = {{Extracting Refined Rules from Knowledge-Based Neural Networks}},
url = {citeseer.ist.psu.edu/towell92extracting.html},
volume = {13},
year = {1993}
}
@article{hall03,
author = {Hall, M A and Holmes, G},
file = {:Users/timm/svns/doc/03hall.pdf:pdf},
journal = {IEEE Transactions On Knowledge And Data Engineering},
number = {6},
pages = {1437--1447},
title = {{Benchmarking Attribute Selection Techniques for Discrete Class Data Mining}},
volume = {15},
year = {2003}
}
@article{me03f,
author = {Menzies, T},
journal = {Requirements Engineering},
title = {{Editorial, Requirements Engineering Journal, Special Issue on Model-based Requirements Engineering}},
year = {2003}
}
@article{Fischer2003a,
author = {Fischer, Bernd and Schumann, Johann},
doi = {10.1017/S0956796802004562},
file = {:Users/timm/svns/doc/FISCHER03.pdf:pdf},
issn = {09567968},
journal = {Journal of Functional Programming},
month = may,
number = {3},
pages = {483--508},
title = {{AutoBayes: a system for generating data analysis programs from statistical models}},
url = {http://www.journals.cambridge.org/abstract\_S0956796802004562},
volume = {13},
year = {2003}
}
@misc{ism06,
annote = {Available from $\backslash$url\{http://www.sti.nasa.gov/tto/Spinoff2006/ct\_1.html\}},
author = {Turner, Janelle},
title = {{A Predictive Approach to Eliminating Errors in Software Code}},
year = {2006}
}
@inproceedings{Kohavi1995c,
author = {Kohavi, R.},
booktitle = {International joint Conference on artificial intelligence},
file = {:Users/timm/svns/doc/kohavi95.pdf:pdf},
issn = {1045-0823},
publisher = {Citeseer},
title = {{A study of cross-validation and bootstrap for accuracy estimation and model selection}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.48.529\&amp;rep=rep1\&amp;type=pdf},
volume = {14},
year = {1995}
}
@inproceedings{baile74,
author = {Baile, C A},
booktitle = {Control of Feeding and the Regulation of Energy Balance, FederatedProceedings},
pages = {1166--1175},
title = {{Putative neurotransmitters in the hypothalmus and feeding}},
volume = {33},
year = {1974}
}
@article{mcderm93,
author = {McDermott, J},
journal = {Artificial Intelligence},
pages = {241--247},
title = {{R1 ("XCON") at age 12: lessons from an elementary school achiever}},
volume = {59},
year = {1993}
}
@article{lee98,
author = {Lee, J and Gruninger, M and Jin, Y and Malone, T and Tate, A and Yost, G and other members of the PIF working group},
journal = {Knowledge Engineering Review},
month = feb,
number = {1},
pages = {91--120},
title = {{The PIF Process Interchange Format and framework}},
volume = {13},
year = {1998}
}
@article{ginsberg88,
author = {Ginsberg, A and Weiss, S and Politakis, P},
journal = {Artificial Intelligence},
pages = {197--226},
title = {{Automatic knowledge base refinement for classification systems}},
volume = {35},
year = {1988}
}
@inproceedings{pa94,
author = {Pagnucco, M and Nayak, A C and Foo, N Y},
booktitle = {\{AI\} '94, Australia},
editor = {{C. Zhang}, J Debenham and Lukose, D},
title = {{Abductive \{E\}xpansion: \{A\}bductive \{I\}nference and the \{P\}rocess of \{B\}elief \{C\}hange}},
year = {1994}
}
@inproceedings{cohen97,
author = {Cohen, William W and Devanbu, Prem},
booktitle = {Proc. 14th International Conference on Machine Learning},
pages = {66--74},
publisher = {Morgan Kaufmann},
title = {{A comparative study of inductive logic programming methods for software fault prediction}},
year = {1997}
}
@inproceedings{williams03,
annote = {$\backslash$url\{http://www.cs.cornell.edu/gomes/FILES/backdoors.pdf\}},
author = {Williams, R and Gomes, C P and Selman, B},
booktitle = {Proceedings of IJCAI 2003},
title = {{Backdoors to Typical Case Complexity}},
year = {2003}
}
@inproceedings{me00x,
author = {Menzies, T J},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{SE/KE Reuse Research: Common Themes and Empirical Results}},
year = {2002}
}
@article{me99j,
author = {Menzies, Tim},
journal = {International Journal of Human-Computer Studies, special issue on evaluation of KE techniques},
month = oct,
number = {4},
pages = {783--799},
title = {{Critical Success Metrics: Evaluation at the Business-Level}},
volume = {51},
year = {1999}
}
@inproceedings{fa07,
author = {{J. Falk J. Gladigau}, M Glaï¿½ C Haubelt S Helwig J Keinert M Lukasiewycz T Schlichter T Streichert M Streubï¿½hr and Teich, J},
booktitle = {Proceedings of Design Automation and Test in Europe},
month = apr,
title = {{SystemCoDesigner ï¿½ The System-Level Hardware-Software-Co-Design Tool}},
year = {2007}
}
@book{simon60,
author = {Simon, H A},
publisher = {Prentice Hall},
title = {{The New Science of Management Decision}},
year = {1960}
}
@article{wino87,
author = {Winograd, T and Flores, F},
journal = {Artificial Intelligence},
pages = {250--261},
title = {{On Understanding Computers and Cognition: A New Foundation for Design: A respose to the reviews.}},
volume = {31},
year = {1987}
}
@article{Hand2006a,
archivePrefix = {arXiv},
arxivId = {arXiv:math/0606441v1},
author = {Hand, David J.},
doi = {10.1214/088342306000000060},
eprint = {0606441v1},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Hand - 2006 - Classifier Technology and the Illusion of Progress.pdf:pdf},
issn = {0883-4237},
journal = {Statistical Science},
keywords = {and phrases,empirical com-,error rate,flat maximum effect,lectivity bias,misclas-,population drift,principle of parsimony,problem uncertainty,se-,sification rate,simplicity,supervised classification},
month = feb,
number = {1},
pages = {1--14},
primaryClass = {arXiv:math},
title = {{Classifier Technology and the Illusion of Progress}},
url = {http://projecteuclid.org/Dienst/getRecord?id=euclid.ss/1149600839/},
volume = {21},
year = {2006}
}
@inproceedings{funt92,
author = {Funt, B V},
booktitle = {AAAI Spring Symposium on Reasoning with Diagrammatic Representations},
editor = {Narayanan, N H},
pages = {181},
title = {{Experiential Reasoning}},
year = {1992}
}
@inproceedings{me04a,
author = {Menzies, T and Setamanit, S and Raffo, D},
booktitle = {PROSIM 2004},
title = {{Data Mining from Process Models}},
year = {2004}
}
@inproceedings{crawford94,
author = {Crawford, J and Baker, A},
booktitle = {AAAI '94},
title = {{Experimental Results on the Application of Satisfiability Algorithms to Scheduling Problems}},
year = {1994}
}
@article{harrison04,
author = {Harrison, W},
journal = {IEEE Software},
title = {{Best Practices: Who Says?}},
year = {2004}
}
@phdthesis{davis76,
author = {Davis, R},
school = {Stanford},
title = {{Applications of Meta-Level Knowledge to the Construction, Mainteance and Use of Large Knowledge Bases}},
year = {1976}
}
@article{betta95,
author = {Betta, G and D'Apuzzo, M and Pietrosanto, A},
journal = {IEEE Transactions of Instrumentation and Measurement},
month = dec,
number = {6},
pages = {1016--1109},
title = {{A Knowledge-Based Approach to Instrument Fault Detection and Isolation}},
volume = {44},
year = {1995}
}
@unpublished{spinmanual,
author = {Holzmann, Gerard J},
title = {{\{B\}asic \{SPIN\} \{M\}anual}}
}
@article{tidhar98,
author = {Tidhar, G and Heinze, C and Selvestrel, M},
journal = {Applied Intelligence},
number = {3},
pages = {195--218},
title = {{Flying together: Modelling air mission teams}},
volume = {8},
year = {1998}
}
@inproceedings{dabney06,
annote = {Available from $\backslash$url\{http://promisedata.org/pdf/phil2006DabneyBarberOhi.pdf\}},
author = {Dabney, J B and Barber, G and Ohi, D},
booktitle = {Proceedings of the PROMISE workshop, 2006},
title = {{Predicting Software Defect Function Point Ratios Using a Bayesian Belief Network}},
year = {2006}
}
@article{stroulia00,
annote = {(to appear)},
author = {Stroulia, E and Goel, A K},
journal = {International Journal of Human Computer Studies},
title = {{Evaluating PSMs in Redesign: The AUTOGNOSTIC Experiments}},
year = {2000}
}
@article{kuipers91,
author = {Kuipers, B J and Chiu, C and Molle, D T Dalle and Throop, D R},
journal = {Artificial Intelligence},
pages = {343--379},
title = {{Higher-order derivative constraints in qualitative simulation}},
volume = {51},
year = {1991}
}
@article{olender92,
author = {Olender, K M and Osterweil, L J},
journal = {TOSEM},
number = {2},
pages = {21--52},
title = {{Interprocedural Static Analysis of Sequencing Constraints}},
volume = {1},
year = {1992}
}
@inproceedings{hihn00,
author = {Hihn, J and Habib-agahi, H},
booktitle = {Proceedings of the 22nd Annual Conference of the International Society of Parametric Analysts (ISPA), Noordwijk, Netherlands},
title = {{Identification and Measurement of the Sources of Flight Software Cost Growth}},
year = {2000}
}
@book{coad97,
author = {Coad, P and North, D and Mayfield, M},
publisher = {Prentice Hall},
title = {{Object Models: Strategies, Patterns, and Applications}},
year = {1997}
}
@inproceedings{gokhale97,
author = {Gokhale, S S and Lyu, M R},
booktitle = {Proceedings of the Third ISSAT International Conference on Reliability and Quality in Design, Anaheim, CA},
month = mar,
pages = {31--36},
title = {{Regression Tree Modeling for the Prediction of Software Quality}},
year = {1997}
}
@article{levenson96,
author = {Heimdahl, M P E and Leveson, N},
journal = {IEEE Transactions on Software Engineering},
month = may,
title = {{Completeness and Consistency Analysis of State-Based Requirements}},
year = {1996}
}
@article{minsky91,
author = {Minsky, M},
journal = {Artificial Intelligence},
pages = {371--396},
title = {{Society of \{M\}ind: A \{R\}esponse to \{F\}our \{R\}eviews}},
volume = {48},
year = {1991}
}
@inproceedings{have00b,
author = {Havelund, Klaus},
booktitle = {SPIN Model Checking and Software Verification},
pages = {245--264},
publisher = {Springer-Verlag},
title = {{Using Runtime Analysis to Guide Model Checking of Java Programs}},
year = {2000}
}
@inproceedings{offut89,
author = {Offut, A J},
booktitle = {Proc. Third Symposium on Software Testing, Analysis, and Verification},
pages = {131--140},
publisher = {ACM Press},
title = {{The Coupling Effect: Fact or Fiction?}},
year = {1989}
}
@article{BAKIR2010,
address = {Hingham, MA, USA},
author = {Bakir, Ayse and Turhan, Burak and Bener, Ayse B},
doi = {http://dx.doi.org/10.1007/s11219-009-9081-z},
issn = {0963-9314},
journal = {Software Quality Control},
number = {1},
pages = {57--80},
publisher = {Kluwer Academic Publishers},
title = {{A new perspective on data homogeneity in software cost estimation: a study in the embedded systems domain}},
volume = {18},
year = {2010}
}
@article{kumar92,
author = {Kumar, V},
journal = {AI Magazine},
pages = {32--44},
title = {{Algorithms for Constraint-Satisfaction Problems: A Survery}},
year = {1992}
}
@article{Du2008,
author = {Du, Q. and Fowler, J. E.},
doi = {10.1177/1094342007088380},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Du, Fowler - 2008 - Low-Complexity Principal Component Analysis for Hyperspectral Image Compression.pdf:pdf},
issn = {1094-3420},
journal = {International Journal of High Performance Computing Applications},
month = nov,
number = {4},
pages = {438--448},
title = {{Low-Complexity Principal Component Analysis for Hyperspectral Image Compression}},
url = {http://hpc.sagepub.com/cgi/doi/10.1177/1094342007088380},
volume = {22},
year = {2008}
}
@inproceedings{rich97za,
author = {Richards, D and Menzies, T J},
booktitle = {Third Australian Knowledge Acquisition Workshop, Perth},
editor = {Menzies, T J and Richards, D and Compton, P},
title = {{Extending Knowledge Engineering to Requirements Engineering from Multiple Perspectives}},
year = {1997}
}
@article{compton90,
author = {Compton, P J and Jansen, R},
journal = {Knowledge Acquisition},
pages = {241--257},
title = {{A \{P\}hilosophical \{B\}asis for \{K\}nowledge \{A\}cquisition.}},
volume = {2},
year = {1990}
}
@inproceedings{kerth95,
author = {Kerth, N},
booktitle = {Pattern Languages of Program Design},
editor = {Coplien, J and Schmidt, D},
publisher = {Addison-Wesley},
title = {{Caterpillar's Fate: A Pattern Language for Transformation from Analysis to Design}},
year = {1995}
}
@article{kitch08,
author = {Kitchenham, Barbara},
journal = {Empirical Software Engineering},
pages = {219--221},
title = {{The role of replications in empirical software engineering: a word of warning}},
volume = {13}
}
@inproceedings{deb98a,
author = {Debenham, J},
booktitle = {Proceedings Seventh International Conference on Information Processing and Management of Uncertainty in Knowledge Based Systems IPMU '98, Paris, France, July},
title = {{Managing Knowledge Integrity}},
year = {1998}
}
@article{charniak91,
author = {Charniak, E},
journal = {AI Magazine},
number = {4},
pages = {50--63},
title = {{Bayesian networks without tears}},
volume = {12},
year = {1991}
}
@article{hils92,
author = {Hils, D D},
journal = {Journal of Visual Languages and Computing},
number = {1},
pages = {69--101},
title = {{Visual Languages and Computing Survey}},
volume = {3},
year = {1992}
}
@article{searle82,
annote = {April 29},
author = {Searle, J R},
journal = {The New York Review of Books},
pages = {3--6},
title = {{The Myth of the Computer}},
year = {1982}
}
@article{Lu2006,
author = {Lu, Jingli and Yang, Ying and Webb, G.},
file = {:Users/timm/svns/doc/webb08.pdf:pdf},
journal = {Advanced Data Mining and Applications},
pages = {223--238},
publisher = {Springer},
title = {{Incremental discretization for naive-bayes classifier}},
url = {http://www.springerlink.com/index/e3471527150p1n66.pdf},
year = {2006}
}
@article{singer00backbone,
author = {Singer, Josh and Gent, Ian P and Smaill, Alan},
journal = {Journal of Artificial Intelligence Research},
pages = {235--270},
title = {{Backbone Fragility and the Local Search Cost Peak}},
url = {citeseer.nj.nec.com/singer00backbone.html},
volume = {12},
year = {2000}
}
@inproceedings{me00y,
author = {Menzies, T J and Cukic, B},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
title = {{How Many Tests are Enough?}},
year = {2002}
}
@book{norman89,
author = {Norman, D A},
pages = {257},
publisher = {DoubleDay Currency},
title = {{The Design of Everyday Things}},
year = {1989}
}
@article{metropolis53,
author = {Metropolis, N and Rosenbluth, A W and Rosenbluth, M N and Teller, A H and Teller, E},
journal = {J. Chem. Phys},
pages = {1087--1092},
title = {{Equation of State Calculations by Fast Computing Machines}},
volume = {21},
year = {1953}
}
@article{nus00,
author = {Nuseibeh, B and Easterbrook, S and Russo, A},
journal = {IEEE Computer},
month = apr,
number = {4},
pages = {24--29},
title = {{Leveraging Inconsistency in Software Developoment}},
volume = {33},
year = {2000}
}
@book{boehm91,
author = {Boehm, B},
publisher = {Prentice Hall},
title = {{Software Engineering Economics}},
year = {1981}
}
@inproceedings{rousset88,
author = {Rousset, M C},
booktitle = {Proceedings of the 8th European Conference on Artificial Intelligence (ECAI'88)},
pages = {79--84},
title = {{On the Consistency of Knowledge Bases: the Covadis System}},
year = {1988}
}
@article{fen95a,
author = {Fensel, D},
journal = {The Knowledge Engineering Review},
number = {4},
title = {{Formal Specification Languages in Knowledge and Software Engineering}},
volume = {10},
year = {1995}
}
@inproceedings{parkes97clustering,
author = {Parkes, A J},
booktitle = {\{AAAI\}/\{IAAI\}},
pages = {340--345},
title = {{Clustering at the Phase Transition}},
year = {1997}
}
@misc{breiman84,
annote = {cart algorithm},
author = {Breiman, L and Friedman, J H and Olshen, R A and Stone, C J},
institution = {Wadsworth International, Monterey, CA},
title = {{Classification and Regression Trees}},
year = {1984}
}
@article{avri95,
author = {Avritzer, A and Weyuker, E J},
journal = {IEEE Trans. on Software Engineering},
month = sep,
number = {9},
pages = {705--716},
title = {{The Automatic Generation of Load Test Suites and the Assessment of the Resulting Software}},
volume = {21},
year = {1995}
}
@inproceedings{AZZEH2008,
address = {New York, NY, USA},
author = {Azzeh, Mohammad and Neagu, Daniel and Cowling, Peter},
booktitle = {PROMISE '08: Proceedings of the 4th international workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1370788.1370805},
isbn = {978-1-60558-036-4},
pages = {71--78},
publisher = {ACM},
title = {{Improving analogy software effort estimation using fuzzy feature subset selection algorithm}},
year = {2008}
}
@inproceedings{deb98c,
author = {Debenham, J},
booktitle = {Proceedings Seventh International Conference on Intelligent Systems ICIS'98, Paris, France, July},
title = {{An Integrated Conceptual Model of Knowledge-Based Systems Simplifies Mainteance}},
year = {1998}
}
@inproceedings{hame94,
author = {Haynes, P and Menzies, T J},
booktitle = {Tools '94},
pages = {121--129},
publisher = {Prentice Hall},
title = {{The \{E\}ffects of \{C\}lass \{C\}oupling on \{C\}lass \{S\}ize in \{S\}malltalk \{S\}ystems}},
year = {1994}
}
@inproceedings{BOETTICHER08,
address = {New York, NY, USA},
author = {Boetticher, Gary D and Lokhandwala, Nazim},
booktitle = {PROMISE '08: Proceedings of the 4th international workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1370788.1370797},
isbn = {978-1-60558-036-4},
pages = {33--38},
publisher = {ACM},
title = {{Using correlation and accuracy for identifying good estimators}},
year = {2008}
}
@inproceedings{schnieder98,
author = {Schneider, F and Easterbrook, S M and Callahan, J R and Holzmann, G J},
booktitle = {3rd IEEE International Conference On Requirements Engineering},
title = {{Validating Requirements for Fault Tolerant Systems using Model Checking}},
year = {1998}
}
@inproceedings{meseguer92a,
author = {Meseguer, P},
booktitle = {Proceedings of the 10th European Conference on Artificial Intelligence, ECAI-92},
pages = {840--844},
title = {{Incremental Verification of Rule-Based Expert Systems}},
year = {1992}
}
@misc{web98a,
author = {at UCSD, Hypertext Webster Gateway},
title = {{Definition of ontology}},
year = {1998}
}
@article{Fisher1987,
author = {Fisher, Douglas H.},
doi = {10.1007/BF00114265},
file = {::},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {concept formation,conceptual clustering,incremental learning,inference},
month = sep,
number = {2},
pages = {139--172},
title = {{Knowledge acquisition via incremental conceptual clustering}},
url = {http://www.springerlink.com/index/10.1007/BF00114265},
volume = {2},
year = {1987}
}
@inproceedings{jiang08,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08compare.pdf\}},
author = {Jiang, Y and Cukic, B and Menzies, T and Bartlow, N},
booktitle = {Proceedings of the PROMISE 2008 Workshop (ICSE)},
file = {::},
title = {{Comparing Design and Code Metrics for Software Quality Prediction}},
year = {2008}
}
@article{setamanit07,
author = {Setamanit, S and Wakeland, W and D.Raffo},
journal = {Software Process: Improvement and Practice, (Forthcoming)},
title = {{Using Simulation to Evaluate Global Software Development Task Allocation Strategies}},
year = {2007}
}
@article{bobrow85,
author = {Bobrow, D G},
journal = {IEEE Transactions on Software Engineering},
month = nov,
number = {11},
pages = {1401--1408},
title = {{If Prolog is the Answer, What is the Question? or What it Takes to Support AI Programming Paradigms}},
volume = {11},
year = {1985}
}
@inproceedings{cimatti03,
author = {Cimatti, A and Pecheur, C and Cavada, R},
booktitle = {Proceedings of IJCAI'03, Acapulco, Mexico},
title = {{Formal Verification of Diagnosability via Symbolic Model Checking}},
year = {2003}
}
@inproceedings{shu02,
author = {Shull, F and {ad B. Boehm}, V R Basili and Brown, A W and Costa, P and Lindvall, M and Port, D and Rus, I and Tesoriero, R and Zelkowitz, M V},
booktitle = {Proceedings of 8th International Software Metrics Symposium, Ottawa, Canada},
pages = {249--258},
title = {{What We Have Learned About Fighting Defects}},
year = {2002}
}
@article{shepperd97,
annote = {Available from $\backslash$url\{http://www.utdallas.edu/\~{}rbanker/SE\_XII.pdf\}},
author = {Shepperd, M and Schofield, C},
journal = {IEEE Transactions on Software Engineering},
month = nov,
number = {12},
title = {{Estimating Software Project Effort Using Analogies}},
volume = {23},
year = {1997}
}
@inproceedings{norman86,
author = {Norman, D A},
booktitle = {User Centered System Design},
editor = {Norman, D A and Draper, S W},
publisher = {Hillsdale, NJ: Lawrence Erlbaum Associates},
title = {{Cognitive Engineering}},
year = {1986}
}
@article{me09d,
annote = {Avialable from $\backslash$url\{http://menzies.us/pdf/09ir4pc.pdf\}},
author = {Etzkorn, L and Menzies, T},
journal = {Empirical Software Engineering},
number = {1},
pages = {1--4},
title = {{Editorial, Special issue on information retrieval for program comprehension}},
volume = {14},
year = {2009}
}
@article{mylo99,
author = {Mylopoulos, J and Cheng, L and Yu, E},
journal = {Communications of the ACM},
month = jan,
number = {1},
pages = {31--37},
title = {{From Object-Oriented to Goal-Oriented Requirements Analysis}},
volume = {42},
year = {1999}
}
@article{nii86a,
author = {Nii, H P},
journal = {\{AI\} Magazine},
pages = {38--53},
title = {{Blackboard Systems: The Blackboard Model for Problem Solving And the Evolution of Blackboard Architectures}},
year = {1986}
}
@article{pazzani00,
author = {Pazzani, M J},
journal = {IEEE Intelligent Systems},
pages = {10--13},
title = {{Knowledge discovery from data?}},
year = {2000}
}
@inproceedings{JIANG2009,
address = {New York, NY, USA},
author = {Jiang, Yue and Cukic, Bojan},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540466},
isbn = {978-1-60558-634-2},
pages = {1--10},
publisher = {ACM},
title = {{Misclassification cost-sensitive fault prediction models}},
year = {2009}
}
@article{zlatereva92,
author = {Zlatareva, N},
journal = {International Journal of Expert Systems},
pages = {229--247},
title = {{CTMS: A General Framework for Plausible Reasoning}},
volume = {5},
year = {1992}
}
@inproceedings{rothermel98a,
author = {Rothermel, G and Lixin, L and DuPuis, C and Burnett, M},
booktitle = {International Conference on Software Engineering, Kyoto, Japan},
pages = {198--207},
title = {{What You See Is What You Test: A Methodology for Testing Form-Based Visual Programs}},
year = {1998}
}
@incollection{veld93,
author = {de Velde, W Van},
booktitle = {Second Generation Expert Systems},
editor = {David, J-M. and Krivine, J-P. and Simmons, R},
publisher = {Springer Verlag},
title = {{Issues in Knowledge Level Modeling}},
year = {1993}
}
@misc{sullivan05,
author = {Sullivan, K and Shaw, M and Baldwin, C and Jackson, M},
title = {{Panel, ICSE'05: The Science of Design, May 18}},
year = {2005}
}
@phdthesis{shah93,
author = {Shahsavar, N},
school = {Department of Medical Informatics, Linkoping University, Sweden},
title = {{Design, Implementation and Evaluation of a Knowledge-Based System to Support Ventilator Therapy Management}},
year = {1993}
}
@inproceedings{fayyad97,
author = {Fayyad, U},
booktitle = {Proceedings on Ninth International Conference on Scientific and Statistical Database Management},
pages = {2--11},
title = {{Data mining and knowledge discovery in databases: implications for scientific databases}},
year = {1997}
}
@inproceedings{griesel93,
author = {Griesel, A and Hihn, J and Bruno, K and Tausworthe, R},
booktitle = {Proceedings of the Eighteenth Annual Software Engineering Workshop, Goddard Space Flight Center},
title = {{\{S\}oftware \{F\}orecasting: As it is \{R\}eally \{D\}one: A \{S\}tudy of \{JPL\} \{S\}oftware \{E\}ngineers}},
year = {1993}
}
@inproceedings{joseph98,
author = {Josephson, J R and Chandrasekaran, B and Carroll, M and Iyer, N and Wasacz, B and Rizzoni, G},
booktitle = {AAAI '98},
title = {{Exploration Of Large Design Spaces: an Architecture and Preliminary Results}},
year = {1998}
}
@article{rittel73,
author = {Rittel, H W J and Webber, M M},
journal = {Policy Sciences},
pages = {155--169},
title = {{Dilemmas in a general theory of planning}},
volume = {4},
year = {1973}
}
@inproceedings{pan08,
author = {Pan, H and Zheng, M and Han, X},
booktitle = {International Conference on Computer Science and Software Engineering},
pages = {78--81},
title = {{Particle Swarm-Simulated Annealing Fusion Algorithm and its Application in Function Optimization}},
year = {2008}
}
@incollection{Poole87,
author = {Poole, David and Goebel, Randy and Aleliunas, Romas},
booktitle = {The Knowledge Frontier: Essays in the Representation of Knowledge},
editor = {Cercone, N J and McCalla, G},
pages = {331--352},
publisher = {Springer Verlag},
title = {{Theorist: a logical reasoning system for defaults and diagnosis}},
year = {1987}
}
@article{Quickstart2011a,
author = {Quickstart, A Beamer},
doi = {10.1002/ajmg.a.33889},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Quickstart - 2010 - Table of contents, volume 77, december 2010.pdf:pdf},
issn = {1552-4833},
journal = {American journal of medical genetics. Part A},
month = jan,
number = {1},
pages = {fmi--fmiv},
pmid = {21344620},
title = {{Table of contents, volume 155, number 1, january 2011.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21344620},
volume = {155},
year = {2011}
}
@article{mukho92,
author = {Mukhopadhyay, T and Vicinanza, S S and Prietula, M J},
journal = {MIS Quarterly},
month = jun,
pages = {155--171},
title = {{Examining the Feasibility of a Case-based Reasoning Tool for Software Effort Estimation}},
year = {1992}
}
@incollection{hayes85,
author = {Hayes, P J},
booktitle = {Formal Theories of the Commonsense World},
editor = {Hobbs, J R and Moore, R C},
pages = {1--36},
publisher = {Albex Publishing Corp},
title = {{The Second Naive Physics Manifesto}},
year = {1985}
}
@inproceedings{ayel88,
author = {Ayel, M},
booktitle = {Proceedings of the 8th European Conference on Artificial Intelligence (ECAI'88)},
pages = {220--225},
title = {{Protocols for Consistency Checking in Expert System Knowledge Bases}},
year = {1988}
}
@inproceedings{owen03d,
author = {Owen, David and Menzies, Tim and Heimdahl, Mats and Gao, Jimin},
title = {{Finding \{F\}aults \{Q\}uickly in \{F\}ormal \{M\}odels \{U\}sing \{R\}andom \{S\}earch}},
year = {2004}
}
@misc{bsc99,
author = {Page, Web},
title = {{No Title}}
}
@inproceedings{cold94,
author = {Coldwell, J M and Wrightson, G},
booktitle = {Artificial Intelligence: Sowing the Seeds for the Future; Proceedings of AI '94},
editor = {Zhang, C and Debenham, J and Lukose, D},
pages = {275--282},
publisher = {World Scientific},
title = {{Lemmas and Links in Analystic Tableau}},
year = {1994}
}
@inproceedings{kautz97,
annote = {Available on-line at $\backslash$url\{http://citeseer.ist.psu.edu/168907.html\}},
author = {Kautz, H and Selman, B and Jiang, Y},
booktitle = {The Satisfiability Problem: Theory and Applications, New York, NY},
editor = {Gu, D and Du, J and Pardalos, P},
pages = {573--586},
title = {{A general stochastic approach to solving problems with hard and soft constraints}},
year = {1997}
}
@incollection{fea03b,
author = {Feather, M S and Menzies, T and Connelly, J R},
booktitle = {Proceedings of the 2003 IEEE International Engineering Management Conference (IEMC-2003) on Managing Technologically Driven Organizations; Albany, NY,},
month = nov,
pages = {451--455},
title = {{Identifying Fruitful Connections Between and Among Researchers and Practitioners}},
year = {2003}
}
@inproceedings{me91b,
author = {Menzies, T J},
booktitle = {IJCAI '91 Knowledge Acquisition Workshop},
title = {{Concerning the User of Procedural Construct as a Knowledge Acquisition Technique}},
year = {1991}
}
@article{brooks87,
author = {Brooks, F P},
journal = {IEEE Computer},
number = {4},
pages = {34--42},
title = {{No Silver Bullet: Essence and Accidents of Software Engineering}},
volume = {20},
year = {1987}
}
@inproceedings{langley94,
author = {Langley, P and Sage, S},
booktitle = {Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence},
pages = {399--406},
title = {{Induction of selective Bayesian classifiers}},
year = {1994}
}
@misc{warren83,
author = {Warren, D H D},
institution = {SRI},
month = oct,
number = {Tec. Note 309},
title = {{An Abstract Prolog Instruction Set}},
year = {1983}
}
@inproceedings{SARCIA2009,
address = {Washington, DC, USA},
author = {Sarcia, Salvatore Alessandro and Basili, Victor Robert and Cantone, Giovanni},
booktitle = {ESEM '09: Proceedings of the 2009 3rd International Symposium on Empirical Software Engineering and Measurement},
doi = {http://dx.doi.org/10.1109/ESEM.2009.5316020},
isbn = {978-1-4244-4842-5},
pages = {123--132},
publisher = {IEEE Computer Society},
title = {{Scope error detection and handling concerning software estimation models}},
year = {2009}
}
@inproceedings{deb95b,
author = {Debenham, J},
booktitle = {Proceedings Seventh International Conference on Software Engineering and Knowledge Engineering SEKE'95, Washington, June},
title = {{A Unified Approach to Requirements Specification and Systems Analysis in the Design of Knowledge-Based Systems}},
year = {1995}
}
@book{lewis90,
author = {Lewis, R O},
isbn = {0471570117},
publisher = {Wiley-Interscience},
title = {{Independent Verification and Validation: A Life Cycle Engineering Process for Quality Software}},
year = {1992}
}
@article{Kononenko97,
annote = {Available from $\backslash$url\{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.4740\}},
author = {Kononenko, Igor and Simec, Edvard and Sikonja, Marko Robnik-},
journal = {Applied Intelligence},
pages = {39--55},
title = {{Overcoming the myopia of inductive learning algorithms with RELIEFF}},
volume = {7},
year = {1997}
}
@article{chulani99,
author = {Chulani, S and Boehm, B and Steece, B},
file = {::},
journal = {IEEE Transaction on Software Engineerining},
number = {4},
title = {{Bayesian Analysis of Empirical Software Engineering Cost Models}},
volume = {25},
year = {1999}
}
@inproceedings{chen05,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05/fsscocomo.pdf\}},
author = {Chen, Zhihoa and Menzies, Tim and Port, Dan},
booktitle = {PROMISE'05},
title = {{Feature Subset Selection Can Improve Software Cost Estimation}},
year = {2005}
}
@inproceedings{cukic00,
author = {Cukic, B and Chakrawarthy, D},
booktitle = {Proceedings of the 5th International Symposium on High Assurance Systems Engineering, Albuquerque, NM, November},
title = {{Bayesian Framework for Reliability Assurance of a Deployed Safety Critical System}},
year = {2000}
}
@book{beck00,
author = {Beck, Kent},
isbn = {0-201-61641-6},
publisher = {Addison Wesley},
title = {{Extreme Programming Explained: Embrace Change}},
year = {2000}
}
@article{reel99,
author = {Reel, J S},
journal = {IEEE Computer},
pages = {18--23},
title = {{Critical Success Factors in Software Projects}},
year = {1999}
}
@article{hammill09,
author = {Hamill, M and Goseva-Popstojanova, K},
journal = {Software Engineering, IEEE Transactions on},
number = {4},
pages = {484--496},
title = {{Common Trends in Software Fault and Failure Data}},
volume = {35},
year = {2009}
}
@book{ahern01,
author = {Ahern, D M and Clouse, A and Turner, R},
isbn = {0-201-73500-8},
publisher = {Addison-Wesley},
title = {{CMMI Distilled}},
year = {2001}
}
@inproceedings{crawford96,
author = {Crawford, J and Dvorak, D L and Litman, D J and Mishra, A M and Patel-Schneider, P F},
booktitle = {Thirteenth National Conference on Artificial Intelligence (AAAI-96)},
title = {{Path-Based Rules in Object-Oriented Programming}},
year = {1996}
}
@article{kellner99,
author = {Kellner, M and Madachy, R and Raffo, D},
journal = {Journal of Systems and Software},
number = {2/3},
title = {{Software Process Modeling and Simulation: Why, What, How,}},
volume = {46},
year = {1999}
}
@incollection{leve85,
address = {Palo Alto},
author = {Levesque, H J and Brachman, R J},
booktitle = {Readings in Knowledge Representation},
editor = {Brachmann, R J and Levesque, H J},
isbn = {0-934613-01-X},
pages = {41--70},
publisher = {Morgan Kaufmann},
title = {{A Fundamental Tradeoff in Knowledge Representation and Reasoning (Revised Version)}},
year = {1985}
}
@article{Barrett2008,
address = {New York, New York, USA},
author = {Barrett, Leon and Narayanan, Srini},
doi = {10.1145/1390156.1390162},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Barrett, Narayanan - 2008 - Learning all optimal policies with multiple criteria.pdf:pdf},
isbn = {9781605582054},
journal = {Proceedings of the 25th international conference on Machine learning - ICML '08},
keywords = {pareto},
mendeley-tags = {pareto},
pages = {41--47},
publisher = {ACM Press},
title = {{Learning all optimal policies with multiple criteria}},
url = {http://portal.acm.org/citation.cfm?doid=1390156.1390162},
year = {2008}
}
@inproceedings{crawford96,
author = {Crawford, J and Dvorak, D L and Litman, D J and Mishra, A M and Patel-Schneider, P F},
booktitle = {Thirteenth National Conference on Artificial Intelligence (AAAI-96)},
title = {{Path-Based Rules in Object-Oriented Programming}},
year = {1996}
}
@inproceedings{bark92,
author = {Barker-Plummer, D and Bailin, S C},
booktitle = {AAAI Spring Symposium on Reasoning with Diagrammatic Representations},
editor = {Narayanan, N H},
pages = {102--107},
title = {{Proofs and Pictures: Proving the Diamond Lemma with the GROVER Theorem Proving System}},
year = {1992}
}
@inproceedings{Togelius2009,
annote = {AI Agents for playing Mario},
author = {Togelius, Julian and Karakovskiy, Sergey and Koutnik, Jan and Schmidhuber, Jurgen},
booktitle = {IEEE CIG 2009},
doi = {10.1109/CIG.2009.5286481},
file = {::},
isbn = {978-1-4244-4814-2},
keywords = {input representation,neuroevolution,platform games,super mario bros},
month = sep,
pages = {156--161},
publisher = {Ieee},
title = {{Super mario evolution}},
url = {http://www.ieee-cig.org/cig-2009/Proceedings/proceedings/papers/cig2009\_022e.pdf},
year = {2009}
}
@article{coiera92,
author = {Coiera, E},
journal = {The Knowledge Engineering Review},
pages = {1--23},
title = {{The \{Q\}ualitative \{R\}epresentation of \{P\}hysical \{S\}ystems}},
volume = {7},
year = {1992}
}
@article{Mylopoulos97,
author = {Mylopoulos, J and Borgida, A and Yu, E},
journal = {Automated Software Engineering},
pages = {291--317},
title = {{Representing Software Engineering Knowledge}},
volume = {4},
year = {1997}
}
@inproceedings{hihn91,
author = {Hihn, J M and Habib-agahi, H},
booktitle = {Proceedings of the Thirteenth IEEE International Conference of Software Engineering},
month = may,
title = {{Cost Estimation of Software Intensive Projects: A Survey of Current Practices}},
year = {1991}
}
@inproceedings{druzdel94,
author = {Druzdzel, M J},
booktitle = {Proceedings of the Tenth Annual Conference on Uncertainty in Artificial Intelligence (UAI-94)},
pages = {187--194},
title = {{Some properties of joint probability distributions}},
year = {1994}
}
@misc{tri03,
author = {Rockets, Tripoli},
month = apr,
title = {{Tripoli Rocketry Association. Motor size classifications}},
year = {2003}
}
@article{easter91,
author = {Easterbrook, S},
journal = {Knowledge Acquisition},
pages = {255--289},
title = {{Handling conflicts between domain descriptions with computer-supported negotiation}},
volume = {3},
year = {1991}
}
@article{demsar06,
annote = {Avaliable from $\backslash$url\{http://jmlr.csail.mit.edu/papers/v7/demsar06a.html\}},
author = {Demsar, J},
journal = {Journal of Machine Learning Research},
pages = {1--30},
title = {{Statistical Comparisons of Clasifiers over Multiple Data Sets}},
volume = {7},
year = {2006}
}
@book{ebb85,
author = {Ebbinghaus, H},
publisher = {New York: Dover},
title = {{Memory: A contribution to experimental psychology.}}
}
@book{kol93,
author = {Kolodner, J},
publisher = {Morgan Kaufmann},
title = {{Case-Based Reasoning}},
year = {1993}
}
@inproceedings{etre83,
author = {Etherington, D W and Reiter, R},
booktitle = {\{AAAI\}-83},
pages = {104--108},
title = {{On Inheritance Hierarchies with Exceptions}},
year = {1983}
}
@article{iwasaki93,
author = {Iwasaki, Y and Simon, H A},
journal = {Artificial Intelligence},
pages = {141--146},
title = {{Reprospecitve on "Causality in Device Behavior"}},
volume = {59},
year = {1993}
}
@article{yang98,
author = {J.\~{}Yang and V.\~{}Honavar},
journal = {IEEE Intelligent Systems},
number = {2},
pages = {44--49},
title = {{Feature subset selection using a genetic algorithm}},
volume = {13},
year = {1998}
}
@incollection{reeves94,
author = {Reeves, T C},
booktitle = {Computer education: New Perspectives},
editor = {Wild, M and Kirkpatrick, D},
pages = {219--246},
publisher = {MASTEC},
title = {{Evaluating what really matters in computer-based education}},
year = {1994}
}
@inproceedings{crawford92,
author = {Crawford, J and Farquhar, A and Kuipers, B},
booktitle = {Recent Advances in Qualitative Physics},
editor = {Faltings, B and Struss, P},
publisher = {The MIT Press},
title = {{QPC: A Compiler from Physical Models into Qualitative Differential Equations}},
year = {1992}
}
@article{hatton98,
author = {Hatton, L},
journal = {IEEE Software},
pages = {46--54},
title = {{Does OO Sync with How We Think?}},
year = {1998}
}
@misc{Sayyad-Shirabad+Menzies:2005,
author = {{Sayyad Shirabad}, J and Menzies, T J},
howpublished = {School of Information Technology and Engineering, University of Ottawa, Canada},
title = {{The \{PROMISE\} Repository of Software Engineering Databases.}},
year = {2005}
}
@article{vanHarm96,
author = {van Harmelen, Frank and Aben, Manfred and Ruiz, Fidel and van de Plassche, Joke},
journal = {IEEE Expert},
month = feb,
number = {1},
pages = {56--62},
title = {{Evaluating a formal KBS specification language}},
volume = {11},
year = {1996}
}
@article{bagnall01,
author = {Bagnall, A and {V. Rayward-Smith} and Whittley, I},
journal = {Information and Software Technology},
month = dec,
number = {14},
title = {{The next release problem}},
volume = {43},
year = {2001}
}
@inproceedings{motta01,
author = {Motta, E},
booktitle = {Handbook of Software and Knowledge Engineering (volume 1)},
editor = {Chung, S K},
title = {{The Knowledge Modelling Paradigm in Knowledge Engineering}},
year = {2001}
}
@incollection{steier93,
author = {Steier, D M},
booktitle = {The SOAR Papers},
editor = {Rosenbloom, P S and Laird, J E and Newell, A},
pages = {533--536},
publisher = {MIT Press},
title = {{\{CYPRESS\}-\{SOAR\}: A Case Study in Search and Learning in Algorithm Design}},
volume = {1},
year = {1993}
}
@article{Fischer2003,
author = {Fischer, Bernd and Schumann, Johann},
doi = {10.1017/S0956796802004562},
file = {:Users/timm/svns/doc/FISCHER03.pdf:pdf},
issn = {09567968},
journal = {Journal of Functional Programming},
month = may,
number = {3},
pages = {483--508},
title = {{AutoBayes: a system for generating data analysis programs from statistical models}},
url = {http://www.journals.cambridge.org/abstract\_S0956796802004562},
volume = {13},
year = {2003}
}
@article{ramey94,
annote = {Available from $\backslash$url\{http://tiswww.case.edu/php/chet/bash/rose94.pdf\}},
author = {Ramey, Chet},
title = {{BASH, the Bourne-again Shell}},
year = {1994}
}
@misc{rich05,
author = {Richardson, M and Domingos, Pedro},
booktitle = {Machine learning},
month = feb,
number = {1-2},
title = {{Markov Logic Networks}},
volume = {62},
year = {206}
}
@inproceedings{easterIWSSD96,
author = {Easterbrook, S M},
booktitle = {Eighth International Workshop on Software Specification and Design (IWSSD-8)},
month = mar,
title = {{Learning from Inconsistency}},
year = {1996}
}
@inproceedings{yost94,
author = {Yost, G},
booktitle = {Proceedings of the 8th \{AAAI\}-Sponsored \{B\}anff Knowledge Acquisition for Knowledge-Based Systems Workshop},
editor = {Gaines, B R and Musen, M},
pages = {46.1--46.22},
title = {{Implementing the \{S\}isyphus-93 Task Using \{SOAR\}/\{TAQL\}}},
year = {1994}
}
@inproceedings{RamMe1996,
author = {Ramakrishnan, S and Menzies, T and Hasslinger, M and Bok, P and McCarthy, H and Devakadadcham, B and Moulder, D},
booktitle = {Tools Pacific, 1996},
title = {{On Building an Effective Measurement System for OO Software Process, Product and Resource Tracking}},
year = {1996}
}
@inproceedings{khoshgoftaar01,
author = {Khoshgoftaar, T},
booktitle = {Proceedings of the 12th International Symposium on Software Reliability Engineering, Hong Kong},
month = nov,
pages = {66--73},
title = {{An Application of Zero-Inflated Poisson Regression for Software Fault Prediction}},
year = {2001}
}
@article{jones99,
author = {Jones, Randolph M and Laird, John E and Nielsen, Paul E and Coulter, Karen J and Kenny, Patrick G and Koss, Frank V},
journal = {AI Magazine},
number = {1},
pages = {27--41},
title = {{Automated Intelligent Pilots for Combat Flight Simulation}},
volume = {20},
year = {1999}
}
@article{bieman92,
author = {Bieman, J M and Schultz, J L},
journal = {Software Engineering Journal},
number = {1},
pages = {43--51},
title = {{An empirical evaluation (and specification) of the all-du-paths testing criterion}},
volume = {7},
year = {1992}
}
@article{KORU2009,
address = {Hingham, MA, USA},
author = {Koru, A G\"{u}ne$\backslash$cs and Emam, Khaled El and Zhang, Dongsong and Liu, Hongfang and Mathew, Divya},
doi = {http://dx.doi.org/10.1007/s10664-008-9080-x},
issn = {1382-3256},
journal = {Empirical Softw. Engg.},
number = {5},
pages = {473--498},
publisher = {Kluwer Academic Publishers},
title = {{Theory of relative defect proneness}},
volume = {13},
year = {2008}
}
@inproceedings{kalfoglou99,
author = {{Kalfoglou,Y. and Robertson,D.}},
booktitle = {Proceedings of the 11th International Conference on Software Engineering and Knowledge Engineering, SEKE'99, Kaiserslauten, Germany},
month = jun,
pages = {64--71},
title = {{A Case Study in Applying Ontologies to Augment and Reason about the Correctness of Specifications}},
year = {1999}
}
@article{littlewood97,
author = {Littlewood, B and Wright, D},
journal = {IEEE Transactions on Software Engineering},
month = nov,
number = {11},
pages = {673--683},
title = {{Some Conservative Stopping Rules for the Operational Testing of Safety-Critical Software}},
volume = {23},
year = {1997}
}
@inproceedings{barwise92,
author = {Barwise, J and Etchemendy, J},
booktitle = {AAAI Spring Symposium on Reasoning with Diagrammatic Representations},
pages = {80--84},
title = {{Hyperproof: Logical Reasoning with Diagrams}},
year = {1992}
}
@article{nus94,
author = {Nuseibeh, B and Kramer, J and Finkelstein, A C W},
journal = {IEEE Transactions on Software Engineering},
number = {10},
pages = {760--773},
title = {{A Framework for Expressing the Relationships Between Multiple Views in Requirements Specification}},
volume = {20},
year = {1994}
}
@inproceedings{russo01,
author = {Russo, A},
booktitle = {Handbook of Software and Knowledge Engineering},
editor = {Chung, C K},
title = {{On the Use of Logical Abduction in Software Engineering}},
volume = {1},
year = {2001}
}
@article{dowl84,
author = {Dowling, W F and Gallier, J H},
journal = {Journal of Logic Programming},
pages = {267--284},
title = {{Linear-time Algorithms for Testing the Satisfiability of Propositional Horn Formulae}},
volume = {3},
year = {1984}
}
@inproceedings{chung95,
author = {Chung, L and Nixon, B A},
booktitle = {Proceedings of ICSE '95: the International Conference on Software Engineering},
pages = {25--36},
title = {{Dealing with Non-Functional Requirements: Three Experimental Studies of a Process-Oriented Approach}},
year = {1995}
}
@article{poole93,
author = {Poole, D},
journal = {Artificial Intelligence},
number = {1},
pages = {81--129},
title = {{Probabilistic Horn Abduction and Bayesian Networks}},
volume = {64},
year = {1993}
}
@inproceedings{me97q,
author = {Menzies, T J},
booktitle = {Banff KA '98 workshop.},
title = {{Evaluation Issues with Critical Success Metrics}},
year = {1998}
}
@misc{gent97,
author = {Gent, I P and Grant, S A and MacIntyre, E and Prosser, P and P.Shar and Smith, B M and Walsh, T},
institution = {University of Leeds, School of Computer Studies},
number = {97.27},
title = {{How not to do it}},
year = {1997}
}
@inproceedings{kang95b,
author = {Kang, B H and Compton, P},
booktitle = {Advances in Case-Based Reasoning, Selected Papers from Second European Workshop, EWCBR-94},
editor = {M.Keane and Haton, J P and Manago, M},
pages = {226--239},
publisher = {Springer},
title = {{A Maintenance Approach to Case Based Reasoning}}
}
@inproceedings{cheeseman91,
author = {Cheeseman, P and Kanefsky, B and Taylor, W M},
booktitle = {Proceedings of IJCAI-91},
pages = {331--337},
title = {{Where the Really Hard Problems Are}},
year = {1991}
}
@inproceedings{deb96a,
author = {Debenham, J},
booktitle = {Proceedings 9th International Sympoisum on Methodologies for Intelligent Systems ISMIS '96, Zakopane, Poland, June},
pages = {314--705},
title = {{Knowledge Simplificiation}},
year = {1996}
}
@inproceedings{rich98zb,
author = {Richards, D and Menzies, T J},
booktitle = {Banff Workshop on Knowledge Acquisition},
title = {{Extending the SISYPHUS III Experiment from a Knowledge Engineering Task to a Requirements Engineering Task}},
year = {1998}
}
@article{me97zg,
author = {Menzies, T},
journal = {The Knowledge Engineering Review},
number = {1},
pages = {1--46},
title = {{Knowledge Maintenance: The State of the Art}},
volume = {14},
year = {1999}
}
@inproceedings{Ramakrishnan1995,
author = {Ramakrishnan, S and Menzies, T},
booktitle = {Proceedings SEEP'96, New Zealand},
title = {{An Ongoing Experiment in O-O Software Process and Product Measurements}},
year = {1996}
}
@article{Athitsos2008b,
abstract = {This paper describes BoostMap, a method for efficient nearest neighbor retrieval under computationally expensive distance measures. Database and query objects are embedded into a vector space, in which distances can be measured efficiently. Each embedding is treated as a classifier that predicts for any three objects X, A, B whether X is closer to A or to B. It is shown that a linear combination of such embeddingbased classifiers naturally corresponds to an embedding and a distance measure. Based on this property, the BoostMap method reduces the problem of embedding construction to the classical boosting problem of combining many weak classifiers into an optimized strong classifier. The classification accuracy of the resulting strong classifier is a direct measure of the amount of nearest neighbor structure preserved by the embedding. An important property of BoostMap is that the embedding optimization criterion is equally valid in both metric and non-metric spaces. Performance is evaluated in databases of hand images, handwritten digits, and time series. In all cases, BoostMap significantly improves retrieval efficiency with small losses in accuracy compared to brute-force search. Moreover, BoostMap significantly outperforms existing nearest neighbor retrieval methods, such as Lipschitz embeddings, FastMap, and VP-trees.},
author = {Athitsos, Vassilis and Alon, Jonathan and Sclaroff, Stan and Kollios, George},
doi = {10.1109/TPAMI.2007.1140},
file = {:Users/timm/svns/doc/08boostmap.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Imaging, Three-Dimensional,Imaging, Three-Dimensional: methods,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reproducibility of Results,Sensitivity and Specificity,Subtraction Technique},
month = jan,
number = {1},
pages = {89--104},
pmid = {18000327},
title = {{BoostMap: an embedding method for efficient nearest neighbor retrieval.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18000327},
volume = {30},
year = {2008}
}
@book{Dil84,
author = {Dillon, W and Goldstein, M},
pages = {247--251},
publisher = {Wiley-Interscience},
title = {{Multivariate Analysis: Methods and Applications}},
year = {1984}
}
@book{char87,
author = {Charniak, E and McDermott, D},
pages = {701},
publisher = {Addison-Wesley},
title = {{Introduction to Artificial Intelligence}},
year = {1987}
}
@article{kleijnen97,
author = {Kliijnen, J P C},
journal = {Journal Statistical Computation and Simulation},
number = {1--4},
pages = {111--142},
title = {{Sensitivity Analysis and Related Analyses: a Survey of Statistical Techniques}},
volume = {57},
year = {1987}
}
@book{simon72,
author = {Newell, A and Simon, H A},
publisher = {Prentice-Hall Englewood Cliffs, N.J.},
title = {{Human Problem Solving}},
year = {1972}
}
@article{Manegold2010,
author = {Manegold, S. and Laurent, D. and Lupu, M. and Onose, N. and R\'{e}, C. and Sans, V. and Senellart, P. and Wu, T. and Shasha, D. and Manolescu, I. and Afanasiev, L. and Feng, J. and Gou, G. and Hadjieleftheriou, M. and Harizopoulos, S. and Kalnis, P. and Karanasos, K.},
doi = {10.1145/1815933.1815944},
file = {:Users/timm/svns/doc/manegold09.pdf:pdf},
issn = {01635808},
journal = {ACM SIGMOD Record},
keywords = {repeatability},
mendeley-tags = {repeatability},
month = dec,
number = {3},
pages = {40},
title = {{Repeatability \& workability evaluation of SIGMOD 2009}},
url = {http://portal.acm.org/citation.cfm?doid=1815933.1815944},
volume = {38},
year = {2010}
}
@inproceedings{meseguer91,
author = {Meseguer, P},
booktitle = {Proceedings of the Ninth National Conference on Artificial Intelligence},
pages = {323--328},
title = {{Verification of Multi-Level Rule-Based Expert Systems}},
year = {1991}
}
@article{Zitzler,
author = {Zitzler, Eckart and Laumanns, Marco and Bleuler, Stefan},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zitzler, Laumanns, Bleuler - Unknown - A Tutorial on Evolutionary Multiobjective Optimization.pdf:pdf},
keywords = {pareto},
mendeley-tags = {pareto},
title = {{A Tutorial on Evolutionary Multiobjective Optimization}}
}
@article{me97m,
author = {Menzies, T J and Cohen, R F and Waugh, S and Goss, S},
journal = {IEEE Transactions of Data and Knowledge Engineering},
pages = {1362--1375},
title = {{Applications of Abduction: Testing Very Long Qualitative Simulations}},
year = {2003}
}
@unpublished{goss95,
annote = {In preparation},
author = {Gledhill, J and Goss, S},
title = {{Modeling Situation Awareness}}
}
@inproceedings{forb86,
author = {Forbus, K},
booktitle = {AAAI '86},
pages = {113--117},
title = {{Interpretating Measurements of Physical Systems}},
year = {1986}
}
@article{strike01,
author = {Strike, Kevin and Emam, Khaled El and Madhavji, Nazim H},
journal = {Software Engineering},
number = {10},
pages = {890--908},
title = {{Software Cost Estimation with Incomplete Data}},
url = {citeseer.ist.psu.edu/strike00software.html},
volume = {27},
year = {2001}
}
@inproceedings{me03n,
author = {Menzies, T and Kiper, J and Feather, M},
booktitle = {SEDECS'2003: the 2nd International Workshop on Software Engineering Decision Support (part of SEKE2003)},
month = jun,
title = {{Improved software engineering decision support through automatic argument reduction tools}},
year = {2003}
}
@inproceedings{come96,
author = {Connell, M and Menzies, T J},
booktitle = {Tools Pacific, 1996, Melbourne},
title = {{Quality Metrics: Test Coverage Analysis for Smalltalk}},
year = {1996}
}
@incollection{getner83,
author = {Getner, D and Getner, D R},
chapter = {Flowing Wa},
publisher = {Hillsdale N.J. Erlbarum},
title = {{Mental Models}},
year = {1983}
}
@article{lopez90,
author = {{B. Lopez P. Meseguer}, E Plaza},
journal = {AI Communications},
number = {3},
pages = {119--135},
title = {{Knowledge Based Systems Validation: A State of the Art.}},
volume = {5},
year = {1990}
}
@inproceedings{perkins03,
author = {Perkins, J and Greenberg, A and Sharp, J and Cassard, D and Massey, B},
booktitle = {USENIX 2003},
pages = {245--258},
title = {{Free Software and High-Power Rocketry: The Portland State Aerospace Society}}
}
@article{davis79,
author = {Davis, R},
journal = {Artificial Intelligence},
number = {2},
pages = {121--157},
title = {{Interactive Transfer of Expertise: Acqusiition of New Inference Rules}},
volume = {12},
year = {1979}
}
@misc{lum05scat,
author = {Lum, Karen},
booktitle = {JPL D-26304},
title = {{Software Cost Analysis Tool User Document}},
year = {2005}
}
@inproceedings{Bruegge1994,
author = {Bruegge, B and Coyne, R F},
booktitle = {Software Engineering Education, 7th SEI CSEE Conference, San Antonio, Texas, USA, J L Diaz-Herrera (Ed.), LNCS 750, Springer-Verlag},
month = jan,
pages = {411--428},
title = {{Teaching Iterative and Collaborative Design: Lessons and Directions}},
year = {1994}
}
@article{shepperd94,
author = {Shepperd, M and Ince, D C},
journal = {The Journal of Systems and Software},
month = sep,
number = {3},
pages = {197--210},
title = {{A Critique of Three Metrics}},
volume = {26},
year = {1994}
}
@book{jacobson92,
author = {Jacobson, I and Christerson, M and Jonsson, P and Overgaard, G},
pages = {520},
publisher = {Addison-Wesley},
title = {{Object-Oriented Software Engineering: A Use Case Driven Approach}},
year = {1992}
}
@article{mack92,
author = {Mackworth, A},
journal = {Artificial Intelligence},
pages = {3--20},
title = {{The Logic of Constraint Satisfaction}},
volume = {58},
year = {1992}
}
@article{birnbaum91,
author = {Birnbaum, L},
journal = {Artificial Intelligence},
pages = {57--77},
title = {{Rigor \{M\}ortis: A \{R\}esponse to \{N\}ilsson's '\{L\}ogic and \{A\}rtificial \{I\}ntelligence'}},
volume = {47},
year = {1991}
}
@book{fenton97,
author = {Fenton, N E and Pfleeger, S L},
publisher = {International Thompson Press},
title = {{Software Metrics: A Rigorous \& Practical Approach}},
year = {1997}
}
@article{viola01boosting,
author = {Viola, P and Jones, M},
journal = {Proc. CVPR},
pages = {511--518},
title = {{Rapid object detection using a boosted cascade of simple features}},
volume = {1},
year = {2001}
}
@inproceedings{biere99:bmc,
author = {Biere, A and Cimatti, A and Clarke, E M and Zhu, Y},
booktitle = {In Proceedings of Tools and Algorithms for the Analysis and Construction of Systems},
month = may,
pages = {193207},
title = {{Symbolic model checking without BDDs}},
year = {1999}
}
@phdthesis{greenwald06,
annote = {Available from $\backslash$url\{http://unbox.org/wisp/var/jeremy/Greenwald06Thesis.pdf\}},
author = {Greenwald, J},
school = {Computer Science, Portland State University},
title = {{A Novel Metaheuristic Search Technique: Iterative Treatment Learning}},
year = {2007}
}
@misc{carver03,
author = {Carver, J and Shull, F and Basili, V R},
booktitle = {University of Maryland, Tech Report Number: CS-TR-4441},
month = mar,
title = {{Invstigating the effect of Process Experience on Inspection Effectiveness}},
year = {2003}
}
@inproceedings{cohen95r,
annote = {Available on-line from $\backslash$url\{http://www.cs.cmu.edu/\~{}wcohen/postscript/ml-95-ripper.ps\}},
author = {Cohen, W W},
booktitle = {ICML'95},
pages = {115--123},
title = {{Fast effective rule induction}},
year = {1995}
}
@inproceedings{me02d,
author = {Menzies, T and Owen, D and Cukic, B},
booktitle = {ISSRE 2002},
title = {{Saturation Effects in Testing of Formal Models}},
year = {2002}
}
@misc{kummer00,
author = {Kummer, O},
title = {{The petri nets bibliography; keyword: reliability. $\backslash$url\{http://www.informatik.uni-hamburg.de/TGI/pnbib/keywords/r/reliability.html\}}},
year = {2000}
}
@article{denno03,
author = {Denno, P and Steves, M P and Libes, D and Barkmeyer, E J},
journal = {IEEE Software},
number = {5},
pages = {59--63},
title = {{Model-Drven Integration Using Existing Models}},
volume = {20},
year = {2003}
}
@article{deKleer86d,
author = {DeKleer, J and Brown, J S},
journal = {Artificial Intelligence},
pages = {33--61},
title = {{Theories of Causal Ordering}},
volume = {29},
year = {1986}
}
@article{shum94,
author = {Shum, S Buckingham and Hammond, N},
journal = {International Journal of Human-Computer Studies},
number = {4},
pages = {603--652},
title = {{Argumentation-Based Design Rationale: What Use at What Cost?}},
volume = {40},
year = {1994}
}
@inproceedings{runkel95,
author = {Runkel, J},
booktitle = {Proceedings of the 9th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge-Based Systems Workshop Banff, Canada},
title = {{Analyzing Tasks to Build Reusable Model-Based Tools}},
year = {1995}
}
@inproceedings{top91,
author = {Top, J L and Akkermans, J M},
booktitle = {IJCAI '91},
title = {{Computational and Physical Causality}},
year = {1991}
}
@inproceedings{jenn94,
author = {Jenn, Eric and Arlat, Jean and Rimn, Marcus and Ohlsson, Joakim and Karlsson, Johan},
booktitle = {Proceedings of the 24th International Symposium on Fault Tolerant Computing, (FTCS-24), IEEE, Austin, Texas, USA},
pages = {66--75},
title = {{Fault Injection into VHDL Models: The MEFISTO Tool}},
year = {1994}
}
@article{wick92,
author = {Wick, M R and Thompson, W B},
journal = {Artificial Intelligence},
pages = {33--70},
title = {{Reconstructive Expert System Explanation}},
volume = {54},
year = {1992}
}
@inproceedings{me08f,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ispa.pdf\}},
author = {Hihn, J and Menzies, T and Lum, K and Baker, D and Jalali, O},
booktitle = {ISPA'08: International Society of Parametric Analysis},
title = {{\{2CEE\}, A \{T\}WENTY \{F\}IRST \{C\}ENTURY \{E\}FFORT \{E\}STIMATION \{M\}ETHODOLOGY}},
year = {2008}
}
@misc{yost92,
annote = { Digital Equipment Co., Marlboro, Massachusetts},
author = {Yost, G R},
title = {{Configuring \{E\}levator \{S\}ystems}},
year = {1992}
}
@book{norvig92,
author = {Norvig, P},
pages = {946},
publisher = {Morgan Kaufmann},
title = {{Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp}},
year = {1992}
}
@inproceedings{mozina04,
address = {New York, NY, USA},
author = {Mo\v{z}ina, Martin and Dem\v{s}ar, Janez and Kattan, Michael and Zupan, Bla\v{z}},
booktitle = {PKDD '04: Proceedings of the 8th European Conference on Principles and Practice of Knowledge Discovery in Databases},
isbn = {3-540-23108-0},
pages = {337--348},
publisher = {Springer-Verlag New York, Inc.},
title = {{Nomograms for visualization of naive Bayesian classifier}},
year = {2004}
}
@book{Humphrey1989,
author = {Humphrey, W S},
publisher = {Addison-Wesley, Readings, Mass},
title = {{Managing the Software Process}},
year = {1989}
}
@article{newell93,
author = {Newell, A},
journal = {Artificial Intelligence},
pages = {31--38},
title = {{Reflections on the \{K\}nowledge \{L\}evel}},
volume = {59},
year = {1993}
}
@book{fowler97,
author = {Fowler, M},
publisher = {Addison Wesley},
title = {{Analysis Patterns: Reusable Object Models}},
year = {1997}
}
@article{hinton92,
author = {Hinton, G E},
journal = {Scientific American},
month = sep,
pages = {144--151},
title = {{How Neural Networks Learn from Experience}},
year = {1992}
}
@inproceedings{me99b,
author = {Menzies, T J and Cukic, B},
booktitle = {Submitted to ISSRE-99},
title = {{When You Don't Need to Re-Test the System}},
year = {1999}
}
@misc{compton96a,
annote = {Regarding time interval literal connections.},
author = {Compton, P},
title = {{Personal communication}},
year = {1996}
}
@article{Ag2003,
author = {Ag, Chrysler and Tic, Cicyt and Evanco, William M and Spencer, N and Keppel, H and Brader, D and Brader, M},
file = {:Users/timm/svns/doc/Evanco.pdf:pdf},
journal = {Statistics},
number = {7},
title = {{Comments on â The Confounding Effect of Class Size on the Validity of Object-Oriented Metrics â Comments on â The Confounding Effect of Class Size on the Validity of Object-Oriented Metrics â}},
volume = {29},
year = {2003}
}
@book{leven95,
author = {Leveson, N},
publisher = {Addison-Wesley},
title = {{Safeware System Safety And Computers}},
year = {1995}
}
@article{stefik87,
author = {Stefix, M J and Bobrow, D G},
journal = {Artificial Intelligence},
pages = {220--226},
title = {{Review of Winograd \& Flores, Understanding Computers and Cognition: A New Foundation for Design}},
volume = {31},
year = {1987}
}
@article{dechter85,
address = {New York, NY, USA},
author = {Dechter, Rina and Pearl, Judea},
doi = {http://doi.acm.org/10.1145/3828.3830},
issn = {0004-5411},
journal = {J. ACM},
number = {3},
pages = {505--536},
publisher = {ACM},
title = {{Generalized best-first search strategies and the optimality af A*}},
volume = {32},
year = {1985}
}
@inproceedings{men87a,
author = {Menzies, T J and Markey, B R},
booktitle = {Proceedings of the Third Australian Conference on Expert Systems, May 13-15},
title = {{A Micro-Computer, Rule-Based Prolog Expert-System for Process Control in a Petrochemical Plant}},
year = {1987}
}
@inproceedings{mccarthy93,
author = {McCarthy, J},
booktitle = {IJCAI '93},
pages = {555--560},
title = {{Notes on Formalizing Context}},
year = {1993}
}
@article{dekleer84,
author = {DeKleer, J and Brown, J S},
journal = {Artificial Intelligence},
pages = {7--83},
title = {{A Qualitative Physics Based on Confluences}},
volume = {25},
year = {1984}
}
@inproceedings{me09k,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09irrf.pdf\}},
author = {Gay, G and Haiduc, S and Marcus, A and Menzies, T},
booktitle = {IEEE ICSM'09},
title = {{On the use of Relevance Feedback in IR-based Concept Location}},
year = {2009}
}
@article{compton92,
author = {Compton, P and Edwards, G and Srinivasan, A and Malor, P and Preston, P and Kang, B and Lazarus, L},
journal = {Artificial Intelligence in Medicine},
pages = {47--59},
title = {{Ripple-down-rules: Turning Knowledge Acquisition into Knowledge Maintenance}},
volume = {4},
year = {1992}
}
@book{akao90,
author = {Akao, Y},
publisher = {Productivity Press, Cambridge, Massachusetts},
title = {{Quality Function Deployment}},
year = {1990}
}
@incollection{fea03a,
author = {Feather, M S and Menzies, T and Connelly, J R},
booktitle = {Proceedings of the 2003 Asia-Pacific Software Engineering Conference (APSEC 2003); Chiangmai, Thailand},
month = dec,
title = {{Matching Software Practitioner Needs to Researcher Activities}},
year = {2003}
}
@inproceedings{pearce88,
author = {Pearce, D},
booktitle = {Proc. AAAI-88},
title = {{The Induction of Fault Diagnosis Systems From Qualitative Models}},
year = {1988}
}
@inproceedings{gurp99,
author = {van Gurp, Jilles and Bosch, Jan},
booktitle = {ICT Architectures '99 , Amsterdam},
month = nov,
title = {{Using Bayesian Belief Networks in Assessing Software Designs}},
year = {1999}
}
@book{law00,
author = {Law, A and Kelton, B},
publisher = {McGraw Hill},
title = {{Simulation Modeling and Analysis}},
year = {2000}
}
@article{habib98,
author = {Habib-agahi, H and Malhotra, S and Quirk, J},
journal = {Journal of Parametrics},
month = nov,
pages = {59--71},
title = {{Estimating Software Productivity and Cost for \{NASA\} Projects}},
year = {1998}
}
@article{gutjahr99,
author = {Gutjhar, W J},
journal = {IEEE Transactions on Software Engineering},
number = {5},
pages = {661--674},
title = {{Partition vs. Random Testing: The Influence of Uncertainty}},
volume = {25},
year = {1999}
}
@misc{uml,
annote = {$\backslash$url\{http://www.rational.com/ot/uml/1.0/index.html\}},
author = {Booch, G and Jacobsen, I and Rumbaugh, J},
institution = {Rational},
title = {{Version 1.0 of the Unified Modeling Language}},
year = {1997}
}
@article{me09e,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09nodata.pdf\}},
author = {Menzies, T and Williams, S and Elrawas, O and Baker, D and Boehm, B and Hihn, J and Lum, K and Madachy, R},
file = {::},
journal = {Software Process Improvement and Practice},
month = jul,
number = {4},
pages = {213--225},
title = {{Accurate Estimates Without Local Data?}},
volume = {14},
year = {2009}
}
@book{leach97,
author = {Leach, J},
publisher = {McGraw-Hill},
title = {{Software Reuse: Methods, Models and Costs}},
year = {1997}
}
@inproceedings{huan06,
author = {Cleland-Huang, J and Settimi, R and Zou, X and Solc, P},
booktitle = {RE 2006},
pages = {36--45},
title = {{The Detection and Classification of Non-Functional Requirements with Application to Early Aspects}},
year = {2006}
}
@inproceedings{HAYES2005,
address = {New York, NY, USA},
author = {Hayes, Jane Huffman and Dekhtyar, Alex and Sundaram, Senthil},
booktitle = {MSR '05: Proceedings of the 2005 international workshop on Mining software repositories},
doi = {http://doi.acm.org/10.1145/1083142.1083153},
isbn = {1-59593-123-6},
pages = {1--5},
publisher = {ACM},
title = {{Text mining for software engineering: how analyst feedback impacts final results}},
year = {2005}
}
@article{smith96,
author = {Smith, B and Dyer, M},
journal = {Artificial Intelligence},
number = {1-2},
pages = {155--181},
title = {{Locating the Phase Transition in Binary Constraint Satisfaction Problems}},
volume = {81},
year = {1996}
}
@article{me08a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07ivv.pdf\}},
author = {Menzies, T and Benson, M and Costello, K and Moats, C and Northey, M and Richarson, J},
journal = {Innovations in Systems and Software Engineering},
month = mar,
title = {{Learning Better \{IV\&V\} Practices}},
year = {2008}
}
@article{pazzani97learning,
annote = {Available from$\backslash$url\{citeseer.ist.psu.edu/pazzani97learning.html\}},
author = {Pazzani, Michael J and Billsus, Daniel},
journal = {Machine Learning},
number = {3},
pages = {313--331},
title = {{Learning and Revising User Profiles: The Identification of Interesting Web Sites}},
volume = {27},
year = {1997}
}
@article{musilek00,
address = {New York, NY, USA},
author = {Mus\'{\i}lek, Petr and Pedrycz, Witold and Succi, Giancarlo and Reformat, Marek},
doi = {http://doi.acm.org/10.1145/373975.373984},
issn = {1559-6915},
journal = {SIGAPP Appl. Comput. Rev.},
number = {2},
pages = {24--29},
publisher = {ACM Press},
title = {{Software cost estimation with fuzzy models}},
volume = {8},
year = {2000}
}
@inproceedings{whittle06,
author = {Whittle, J and Jayaraman, P},
booktitle = {IEEE International Conference on Requirements Engineering (RE2006)},
title = {{Generating Hierarchical State Machines from Use Case Charts}},
year = {2006}
}
@inproceedings{yang06,
author = {Yang, Ying and Webb, Geoffrey I and Cerquides, Jes\'{u}s and Korb, Kevin B and Boughton, Janice R and Ting, Kai Ming},
booktitle = {ECML},
pages = {533--544},
title = {{To Select or To Weigh: A Comparative Study of Model Selection and Model Weighing for SPODE Ensembles}},
year = {2006}
}
@article{dekleer86b,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {163--196},
title = {{Extending the ATMS}},
volume = {28},
year = {1986}
}
@article{demillo95,
author = {DeMillo, R A and Mathur, A P and Wong, W E},
journal = {IEEE Transactions on Software Engineering},
month = oct,
number = {10},
pages = {854--861},
title = {{Some Critical Remarks on a Hierarchy of Fault-Detecting Abilities of Test Methods}},
volume = {21},
year = {1995}
}
@incollection{will92,
author = {Williams, Colin P},
booktitle = {Recent Advances in Qualitative Physics},
editor = {Faltings, Boi and Struss, Peter},
pages = {435--450},
publisher = {The MIT Press},
title = {{Analytic Abduction from Qualitative Simulation}},
year = {1992}
}
@misc{addy99,
author = {Addy, E A},
institution = {Software Research Lab, NASA IV\&V Facility, Fairmont, West Virginia},
title = {{A White Paper on Software Risk Assessment}},
year = {1999}
}
@incollection{fischer96,
author = {Fischer, G and Lemke, A C and McCall, R and Morch, A I},
booktitle = {Design Rationale: Concepts, Techniques, and Use},
editor = {Moran, T P and Carroll, J M},
pages = {267--293},
publisher = {Lawerence Erlbaum Associates},
title = {{Making Argumentation Serve Design}},
year = {1996}
}
@misc{womenincs,
author = {Dean, Cornelia},
month = apr,
title = {{Computer Science Takes Steps to Bring Women to the Fold}},
year = {2007}
}
@inproceedings{Blockeel2001,
author = {Blockeel, H. and Struyf, J.},
booktitle = {INTERNATIONAL WORKSHOP on machine learning},
file = {:Users/timm/svns/doc/blockeel01.pdf:pdf},
pages = {11--18},
title = {{Effecient Algorithms for Decision Tree Cross-Validation}},
year = {2001}
}
@inproceedings{lu06,
annote = {Available from $\backslash$url\{http://www.csse.monash.edu/\~{}webb/Files/LuYangWebb06.pdf\}},
author = {Lu, J and Yang, Y and Webb, G I},
booktitle = {Lecture Notes in Computer Science 4093: Proceedings of the Second International Conference on Advanced Data Mining and Applications (ADMA 2006)},
file = {:Users/timm/svns/doc/webb08.pdf:pdf},
pages = {223--238},
title = {{Incremental Discretization for Naive-Bayes Classifier}},
year = {2006}
}
@incollection{preece98,
author = {Preece, A},
booktitle = {Proceedings of the Banff KA workshop, 1998},
title = {{Building the Right System Right: Evaluating V\&V Methods in Knowledge Engineering}},
year = {1998}
}
@inproceedings{men93j,
author = {Menzies, T J and Spurret, R},
booktitle = {Tools Pacific 12},
pages = {213--224},
publisher = {Prentice Hall},
title = {{How to \{E\}dit $\backslash$"it$\backslash$"; or a \{B\}lack-Box \{C\}onstraint \{B\}ased \{F\}ramework for \{U\}ser \{I\}nteraction with \{A\}rbitrary \{S\}tructures}},
year = {1993}
}
@inproceedings{APS93,
author = {Agesen, O and Palsberg, J and Schwartzbach, M},
booktitle = {ECOOP'93, Seventh European Conference on Object-Oriented Programming},
pages = {329--349},
publisher = {Springer-Verlag},
title = {{Analysis of Objects with Dynamic and Multiple Inheritance}},
year = {1993}
}
@misc{preston92,
author = {Preston, P},
title = {{Expert Systems, Knowledge Aquisition and Knowledge Modification}},
year = {1992}
}
@article{Fingerprint2010,
author = {Fingerprint, Integrated Automated},
file = {:Users/timm/svns/doc/IEEESpectrumBeyondCSIRiseofComputationalForensics.pd.pdf:pdf},
journal = {Computing},
keywords = {forensics},
mendeley-tags = {forensics},
title = {{Beyond C . S . I .: The Rise of Computational Forensics}},
year = {2010}
}
@inproceedings{toth91,
author = {Touretzky, J and Thomson, R H and Horty, J F},
booktitle = {\{IJCAI\} '91},
pages = {478--483},
title = {{Skeptic's Menagerie: Conflictor's, Preemptors. Reinstaters, and Zombies in Nonmonotonic Inheritance}},
year = {1991}
}
@book{Bloom1956,
annote = {unread},
author = {Bloom, B},
publisher = {David McKay, New York},
title = {{Taxonomy of Educational Objectives: Handbook I: Cognitive Domain}},
year = {1956}
}
@article{sjoeberg05,
author = {Sjoeberg, D I K and Hannay, J E and Hansen, O and Kampenes, V B and Karahasanovic, A and Liborg, N.-K. and Rekdal, A C},
journal = {IEEE Transactions on Software Engineering},
number = {9},
pages = {733--753},
title = {{A survey of controlled experiments in software engineering}},
volume = {31},
year = {2005}
}
@inproceedings{Kon94,
author = {Kononenko, I},
booktitle = {The Seventh European Conference on Machine Learning},
pages = {pp. 171--182},
publisher = {Springer-Verlag},
title = {{Estimating attributes: Analysis and extensions of relief}},
year = {1994}
}
@book{darden91,
author = {Darden, L},
isbn = {0-19-506797-5},
publisher = {Oxford University Press},
title = {{Theory Change in Science: Strategies from Mendelian Genetics}},
year = {1991}
}
@book{hansen97,
author = {Hansen, G A},
publisher = {Prentice Hall},
title = {{Automating Business Process Reengineering}},
year = {1997}
}
@misc{holzmann99,
author = {Holzmann, G J and Puri, A},
booktitle = {Software Tools for Technology Transfer},
title = {{A Minimized Automaton Representation of Reachable States}},
year = {1999}
}
@incollection{bar83,
author = {Barstow, D R and Aiello, N and Duda, R O and Erman, L D and Forgy, C L and Gorlin, D and Greiner, R D and Lenat, D B and London, P E and McDermott, J and Nii, H Penny and Politakis, P and Reboh, R and Rosenchein, S and Scott, A C and van Melle, W and Weiss, S M},
booktitle = {Building Expert Systems},
chapter = {9},
editor = {Hayes-Roth, F and Waterman, D A and Lenat, D B},
pages = {283--345},
publisher = {Addison-Wesley},
title = {{Languages and Tools for Knowledge Engineering}},
year = {1983}
}
@book{winston84,
author = {Winston, P},
publisher = {Addison-Wesley},
title = {{Artificial Intelligence}},
year = {1984}
}
@article{zhang07,
author = {Zhang, H and Zhang, X},
journal = {IEEE Transactions on Software Engineering},
month = sep,
title = {{Comments on 'Data Mining Static Code Attributes to Learn Defect Predictors'}},
year = {2007}
}
@article{Walkerden1999,
address = {Hingham, MA, USA},
author = {Walkerden, Fiona and Jeffery, Ross},
doi = {http://dx.doi.org/10.1023/A:1009872202035},
issn = {1382-3256},
journal = {Empirical Softw. Engg.},
number = {2},
pages = {135--158},
publisher = {Kluwer Academic Publishers},
title = {{An Empirical Study of Analogy-based Software Effort Estimation}},
volume = {4},
year = {1999}
}
@inproceedings{cordero97,
author = {Cordero, R and Costamagna, M and Paschetta, E},
booktitle = {12th COCOMO Forum},
title = {{A Genetic Algorithm Approach for the Calibration of COCOMO-like Models}},
year = {1997}
}
@book{clancey97b,
author = {Clancey, W J},
publisher = {Cambridge University Press},
title = {{Situated Cognition: On Human Knowledge and Computer Representations}},
year = {1997}
}
@inproceedings{waugh97,
annote = {$\backslash$url\{http://www.cse.unsw.edu.au/\~{}timm/pub/docs\}},
author = {Waugh, S and Menzies, T J and Goss, S},
booktitle = {Advanced Topics in Artificial Intelligence: 10th Australian Joint Conference on AI},
editor = {Sattar, Abdul},
isbn = {3-540-63797-4},
publisher = {Springer-Verlag},
title = {{Evaluating a Qualitative Reasoner}},
year = {1997}
}
@book{BERGE89,
author = {Berge, Claude},
publisher = {North-Holland},
title = {{Hypergraphs}},
year = {1989}
}
@article{brat05,
author = {Brat, G and Drusinsky, D and Giannakopoulou, D and Goldberg, A and Havelund, K and Lowry, M and Pasareanu, C and Venet, A and Washington, R and Visser, W},
journal = {Formal Methods in Systems Design Journal},
month = sep,
title = {{Experimental Evaluation of Verification and Validation Tools on Martian Rover Software}},
year = {2005}
}
@article{dion83,
author = {Dion, R},
journal = {IEEE Software},
month = jul,
pages = {28--35},
title = {{Process Improvement and the Corporate Balance Sheet}},
year = {1993}
}
@article{me08b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ddp.pdf\}},
author = {Feather, M and Cornford, S and Hicks, K and Kiper, J and Menzies, T},
journal = {IEEE Software},
month = may,
title = {{Application of a broad-spectrum quantitative requirements model to early-lifecycle decision making}},
year = {2008}
}
@article{gomez96,
author = {Gomez-Perez, A},
journal = {Expert Systems with Applications},
number = {4},
pages = {519--529},
title = {{Towards a Framework to Verify Knowledge Sharing Technology}},
volume = {11},
year = {1996}
}
@book{saltelli00,
author = {Saltelli, A and Chan, K and Scott, E M},
publisher = {Wiley},
title = {{Sensitivity Analysis}},
year = {2000}
}
@article{zlatereva92b,
author = {Zlatereva, N},
journal = {Artificial Intelligence Review},
title = {{Truth Mainteance Systems and Their Application for Verifying Expert System Knowledge Bases}},
volume = {6},
year = {1992}
}
@article{silver93,
author = {Silverman, B G and Wenig, R G},
journal = {The Knowledge Engineering Review},
number = {4},
pages = {309--328},
title = {{Engineering Expert Critics for Cooperative Systems}},
volume = {8},
year = {1993}
}
@inproceedings{fawcett01,
annote = {Available from $\backslash$url\{http://home.comcast.net/\~{}tom.fawcett/public\_html/papers/ICDM-final.pdf\}},
author = {Fawcett, Tom},
booktitle = {2001 IEEE International Conference on Data Mining (ICDM-01)},
title = {{Using Rule Sets to Maximize ROC Performance}},
year = {2001}
}
@misc{chapman02,
author = {Chapman, Mike and Solomon, Dan},
title = {{The Relationship of Cyclomatic Complexity, Essential Complexity and Error Rates}},
year = {2002}
}
@inproceedings{laird00,
author = {Laird, J and van Lent, M},
booktitle = {AAAI},
title = {{Interactive Computer Games: Human-level AI's Killer Application}},
year = {2000}
}
@inproceedings{hamscher90,
author = {Hamscher, W},
booktitle = {\{AAAI\} Spring Symposium on Automated Abduction},
editor = {O'Rourke, P},
pages = {96--100},
title = {{Explaining \{U\}nexpected \{F\}inancial \{R\}esults}},
year = {1990}
}
@inproceedings{mans91,
author = {Mansuri, Y and Compton, P and Sammut, C},
booktitle = {Australian workshop on knowledge acquisition for knowledge based systems, Pokolbin},
editor = {Boose, J and Debenham, J and Gaines, B and Quinlan, J},
pages = {114--132},
publisher = {University of Technology, Sydney},
title = {{A comparison of a manual knowledge acquisition method and an inductive learning method}},
year = {1991}
}
@article{huang05,
author = {Huang, J and Ling, C},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = mar,
number = {3},
pages = {299--310},
title = {{Using AUC and Accuracy in Evaluating Learning Algorithms}},
volume = {17},
year = {2005}
}
@misc{gent97,
author = {Gent, I P and Grant, S A and MacIntyre, E and Prosser, P and P.Shar and Smith, B M and Walsh, T},
institution = {University of Leeds, School of Computer Studies},
number = {97.27},
title = {{How not to do it}},
year = {1997}
}
@article{stickel92,
author = {Stickel, M E},
journal = {Theoretical Computer Science},
pages = {109--128},
title = {{A Prolog technology theorem prover: a new exposition and implementation in Prolog}},
volume = {104},
year = {1992}
}
@article{me99q,
author = {Menzies, T and Cukic, B},
journal = {IEEE Software},
number = {5},
pages = {107--112},
title = {{When to Test Less}},
volume = {17},
year = {2000}
}
@article{andrews10,
author = {Andrews, James H and Menzies, Tim and Li, Felix C H},
journal = {IEEE Transactions on Software Engineering},
month = mar,
title = {{Genetic Algorithms for Randomized Unit Testing}},
year = {2010}
}
@book{date95,
author = {Date, C J},
publisher = {Addison-Wesley},
title = {{An Introduction to Database Systems}},
volume = {6},
year = {1995}
}
@article{hay96,
author = {Haynes, P and Henderson-Sellers, B},
journal = {American Programmer},
pages = {35--41},
title = {{Cost Estimation of OO Projects: Empirical Observations, Practical Applications}},
year = {1996}
}
@article{Friedman1977,
author = {Friedman, J.H. and Bentley, J.L. and Finkel, R.A.},
file = {:Users/timm/svns/doc/kdTress76.pdf:pdf},
journal = {ACM Transactions on Mathematical Software (TOMS)},
number = {3},
pages = {209--226},
publisher = {ACM},
title = {{An algorithm for finding best matches in logarithmic expected time}},
url = {http://portal.acm.org/citation.cfm?id=355745},
volume = {3},
year = {1977}
}
@article{dijk59,
author = {Dijkstra, E W},
journal = {Numerische Mathematik},
pages = {269--271},
title = {{A note on two problems in connexion with graphs}},
volume = {1},
year = {1959}
}
@incollection{shadbolt97,
author = {Shadbolt, N and O'Hara, K},
booktitle = {Expertise in Context},
chapter = {13},
editor = {Feltovich, P J and Ford, K M and Hoffman, R R},
pages = {315--337},
publisher = {MIT PRess},
title = {{Model-based Expert Systems and the Explanations of Expertise}},
year = {1997}
}
@book{seidman00,
author = {Seidman, C},
publisher = {Microsoft Press},
title = {{Data Mining with Microsoft SQL Server}},
year = {2000}
}
@article{glass99,
author = {Glass, R L},
journal = {Communications of the ACM},
month = apr,
number = {2},
pages = {17--19},
title = {{Inspections Some Surprising Findings}},
volume = {42},
year = {1999}
}
@inproceedings{althoff99a,
author = {Althoff, K.-D. and Nick, M and Tautz, C},
booktitle = {Proc. of the Workshop on Learning Software Organizations (LSO) (in conjunction with the11th International Conference on Software Engineering and Knowledge Engineering, SEKE'99, Kaiserslauten, Germany)},
editor = {Bomarius, F},
month = jun,
pages = {27--44},
title = {{Improving Organizational Memories Through User Feedback}},
year = {1999}
}
@inproceedings{reggia85,
author = {Reggia, J A},
booktitle = {Proceedigns of the Expert Systems in Government Symposium},
pages = {484--489},
title = {{Abductive Inference}},
year = {1985}
}
@incollection{carrol96,
author = {Carrol, J M and Rosson, M B},
booktitle = {Design Rationale: Concepts, Techniques, and Use},
editor = {Moran, T P and Carroll, J M},
pages = {351--372},
publisher = {Lawerence Erlbaum Associates},
title = {{Deliberated Evolution: Stalking the View Matcher in Design Space}},
year = {1996}
}
@article{easter98,
author = {Easterbrook, Steve and Lutz, Robyn R and Covington, Richard and Kelly, John and Ampo, Yoko and Hamilton, David},
journal = {IEEE Transactions on Software Engineering},
pages = {4--14},
title = {{Experiences Using Lightweight Formal Methods for Requirements Modeling}},
year = {1998}
}
@article{feather03,
author = {Feather, Martin and Cornfordi, Steve},
journal = {Requirements Engineering Journal},
number = {4},
pages = {248--265},
publisher = {Springer},
title = {{Quantitative Risk-based Requirements Reasoning}},
volume = {8},
year = {2003}
}
@inproceedings{Fayyad1993,
abstract = {Since most real-world applications of classification learning involve continuous-valued attributes, properly addressing the discretization process is an important problem. This paper addresses the use of the entropy minimization heuristic for discretizing the range of a continuous-valued attribute into multiple intervals. We briefly present theoretical evidence for the appropriateness of this heuristic for use in the binary discretization algorithm used in ID3, C4, CART, and other learning algorithms. The results serve to justify extending the algorithm to derive multiple intervals. We formally derive a criterion based on the minimum description length principle for deciding the partitioning of intervals. We demonstrate via empirical evaluation on several real-world data sets that better decision trees are obtained using the new multi-interval algorithm.},
author = {Fayyad, Usama M and Irani, Keki B},
booktitle = {Thirteenth International Joint Conference on Articial Intelligence},
pages = {1022--1027},
publisher = {Morgan Kaufmann},
series = {13th International Joint Conference on Artificial Intelligence},
title = {{Multi-interval discretization of continuous-valued attributes for classification learning}},
url = {http://trs-new.jpl.nasa.gov/dspace/handle/2014/35171},
volume = {2},
year = {1993}
}
@article{me06a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06qrre.pdf\}},
author = {Menzies, T and Richardson, J},
journal = {IEEE Computer},
month = oct,
title = {{Making Sense of Requirements, Sooner}},
year = {2006}
}
@article{nelson11,
author = {{Adam Nelson Tim Menzies}, Gregory Gay},
journal = {Software- Practice and Experience (to appear)},
title = {{Sharing Experiments Using Open Source Software}},
year = {2011}
}
@inproceedings{bennett00,
author = {Bennett, K H and Rajlich, V},
booktitle = {The Future of Software Engineering},
editor = {Finkelstein, A},
isbn = {ISBN 01-58113-253-0},
pages = {73--87},
publisher = {ACM},
title = {{Software maintenance and evolution: a roadmap}},
year = {2000}
}
@article{Sen,
author = {Sen, Arun and Ramamurthy, K Ram and Sinha, Atish P},
file = {:Users/timm/svns/doc/sen11.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
title = {{IEEE TRANSACTIONS ON SOFTWARE ENGINEERING A Model of Data Warehousing Process Maturity}}
}
@inproceedings{ishida89,
author = {Ishida, Y},
booktitle = {Proceedings of IJCAI '89},
pages = {1174--1179.},
title = {{Using Global Properties for Qualitative Reasoning: A Qualitative System Theory}},
year = {1989}
}
@inproceedings{ng90,
author = {Ng, H T and Mooney, R J},
booktitle = {Working \{N\}otes of the 1990 \{S\}pring \{S\}ymposium on \{A\}utomated \{A\}bduction},
organization = {UC Irvine},
pages = {13--17},
title = {{The \{R\}ole of \{C\}oherence in \{C\}onstructing and \{E\}valuating \{A\}bductive \{E\}xplanations}},
volume = {TR 90-32},
year = {1990}
}
@inproceedings{soloway87,
author = {Soloway, E and Bachant, J and Jensen, K},
booktitle = {\{AAAI\} '87},
pages = {824--829},
title = {{Assessing the Maintainability of XCON-in-RIME: Coping with the Problems of a VERY Large Rule-Base}},
year = {1987}
}
@inproceedings{Basili1992,
author = {Basili, V R},
booktitle = {Experimental Software Engineering Issues: Critical Assessment and Future Directions, International Workshop, Germany, H D Rombach and V R Basili and R W Selby (Eds.), LNCS 706, Springer-Verlag},
pages = {3--12},
title = {{The Experimental Paradigm in Software Engineering}},
year = {1992}
}
@inproceedings{abe06,
author = {Abe, S and O.Mizuno and Kikuno, T and Kikuchi, N and Hirayama, M},
booktitle = {ICSE 2006},
pages = {600--603},
title = {{Estimation of project success using Bayesian classifier}},
year = {2006}
}
@inproceedings{Chaslot2006,
author = {Chaslot, Guillaume and Bakkes, Sander and Szita, Istvan and Spronck, Pieter},
booktitle = {Artificial Intelligence},
file = {:Users/timm/svns/doc/sander08.pdf:pdf},
keywords = {gaming},
mendeley-tags = {gaming},
title = {{Monte-Carlo Tree Search : A New Framework for Game AI Monte-Carlo Tree Search Application to Video Games}},
year = {2006}
}
@inproceedings{shaw88,
author = {Shaw, M L G},
booktitle = {Proceedings of the International Conference on Fifth Generation Computer Systems},
pages = {1259--1266},
title = {{Validation in a Knowledge Acquisition System with Multiple Experts}},
year = {1988}
}
@article{nguyen87,
author = {Nguyen, T A and Perkins, W A and Laffey, T J and Pecora, D},
journal = {AI Magazine},
number = {2},
pages = {69--75},
title = {{Knowledge Base Verification}},
volume = {8},
year = {1987}
}
@inproceedings{bentley90,
author = {Bentley, J L},
booktitle = {Proceedings Proceedings of the 6th Annual Symposium on Computational Geometry, Berkley, California, United States},
pages = {187--197},
title = {{K-d Trees for Semidynamic Point Sets}},
year = {1990}
}
@article{dekleer93,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {63--67},
title = {{A perspective on assumption-based truth maintenance}},
volume = {59},
year = {1993}
}
@book{cohen95,
author = {Cohen, P R},
publisher = {MIT Press},
title = {{Empirical Methods for Artificial Intelligence}},
year = {1995}
}
@inproceedings{bay99,
author = {Bay, S B and Pazzani, M J},
booktitle = {Proceedings of the Fifth International Conference on Knowledge Discovery and Data Mining},
title = {{Detecting Change in Categorical Data: Mining Contrast Sets}},
year = {1999}
}
@inproceedings{LIEBCHEN08,
address = {New York, NY, USA},
author = {Liebchen, Gernot A and Shepperd, Martin},
booktitle = {PROMISE '08: Proceedings of the 4th international workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1370788.1370799},
isbn = {978-1-60558-036-4},
pages = {39--44},
publisher = {ACM},
title = {{Data sets and data quality in software engineering}},
year = {2008}
}
@article{mackworth77,
author = {Mackworth, A K},
journal = {Artificial Intelligence},
pages = {99--118},
title = {{Consistency in \{N\}etworks of \{R\}elations}},
volume = {8},
year = {1977}
}
@book{neilson93,
author = {Nielson, J},
publisher = {Academic Press},
title = {{Usability Engineering}},
year = {1993}
}
@book{Fenton1991,
author = {Fenton, N E},
publisher = {Chapman and Hall, London},
title = {{Software Metrics}},
year = {1991}
}
@article{devedzic99,
author = {Devedzic, V},
journal = {Intelligence (formerly, SIGART)},
pages = {14--24},
title = {{Ontologies: Borrowing from Software Patterns}},
year = {1999}
}
@phdthesis{elrawas08,
annote = {Available from $\backslash$url\{http://unbox.org/wisp/var/ous/thesis/thesis.pdf\}},
author = {El-Rawas, O},
school = {Lane Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{Software Process Control Without Calibration}},
year = {2008}
}
@inproceedings{Daran96,
author = {Daran, M and Thevenod-Fosse, P},
booktitle = {Proc. ISSTA 96},
keywords = {Error propagation,mutation,testing},
pages = {158--171},
title = {{Software Error Analysis: \{A\} Real Case Study Involving Real Faults and Mutations}},
year = {1996}
}
@phdthesis{odberg95,
annote = {408 pages},
author = {Odberg, Erik},
month = feb,
school = {Division of Computer Systems and Telematics, Norwegian Institute of Technology},
title = {{MultiPerspectives: Object Evolution and Schema Modification Management for Object-Oriented Databases}},
year = {1995}
}
@article{kitc01,
author = {Kitchenham, B A and Pickard, L M and MacDonell, S G and Shepperd, M J},
file = {::},
journal = {Software, IEE Proceedings},
number = {3},
pages = {81--85},
title = {{What accuracy statistics really measure}},
volume = {148},
year = {2001}
}
@phdthesis{hu02,
annote = {Masters Thesis},
author = {Hu, Y},
school = {Department of Electrical Engineering, University of British Columbia},
title = {{Treatment Learning: Implementation and Application}},
year = {2003}
}
@article{jackson02,
address = {New York, NY, USA},
author = {Jackson, Daniel},
doi = {http://doi.acm.org.proxy.lib.muohio.edu/10.1145/505145.505149},
issn = {1049-331X},
journal = {ACM Trans. Softw. Eng. Methodol.},
number = {2},
pages = {256--290},
publisher = {ACM Press},
title = {{Alloy: a lightweight object modelling notation}},
volume = {11},
year = {2002}
}
@incollection{hameco95,
author = {Haynes, P and Menzies, T and Cohen, R F},
chapter = {Visualisat},
publisher = {World-Scientific},
title = {{Software Visualization}},
year = {1997}
}
@misc{swiprolog,
author = {Wielemaker, Jan},
title = {{SWI-Prolog}}
}
@book{gleick87,
author = {Gleick, J},
pages = {352},
publisher = {Cardinal},
title = {{Chaos}},
year = {1987}
}
@misc{key03,
annote = {$\backslash$url\{http://www.space-travel.com/reports/Columbia\_\_The\_Legacy\_Of\_Better\_\_Faster\_\_Cheaper.html\}},
author = {Key, Sugarloaf},
month = jul,
title = {{Columbia, The Legacy Of "Better, Faster, Cheaper"?}},
year = {2003}
}
@inproceedings{cukic00,
author = {Cukic, B and Chakrawarthy, D},
booktitle = {Proceedings of the 5th International Symposium on High Assurance Systems Engineering, Albuquerque, NM, November},
title = {{Bayesian Framework for Reliability Assurance of a Deployed Safety Critical System}},
year = {2000}
}
@article{dekleer86a,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {163--196},
title = {{An \{A\}ssumption-\{B\}ased \{TMS\}}},
volume = {28},
year = {1986}
}
@article{silver90,
author = {Silverman, B G},
journal = {AI Magazine},
pages = {60--79},
title = {{Critiquing Human Judgmet Using Knowledge-Acquisition Systems}},
year = {1990}
}
@inproceedings{me06b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06hicss.pdf\}},
author = {Fisher, M S and Menzies, T},
booktitle = {HICSS'06},
title = {{Learning IVV Strategies}},
year = {2006}
}
@article{shavlik91,
author = {Shavlik, J W and Mooney, R L and Towell, G G},
journal = {Machine Learning},
pages = {111--143},
title = {{Symbolic and Neural Learning Algorithms: An Experimental Comparison}},
volume = {6},
year = {1991}
}
@inproceedings{mendes07,
annote = {Available from $\backslash$url\{http://www2007.org/paper326.php\}},
author = {E, Mendes and Dinakaran, G and Mosley, N},
booktitle = {16th International World Wide Web Conference, Banff, Canada, May 8-12},
title = {{How Valuable is it for a Web company to Use a Cross-company Cost Model, Compared to Using Its Own Single-company Model?}},
year = {2007}
}
@article{thelin03,
author = {{Thomas Thelin Per Runeson}, Claes Wohlin},
journal = {IEEE Transactions of Software Engineering},
number = {8},
pages = {687--704},
title = {{An Experimental Comparison of Usage-Based and Checklist-Based Reading}},
volume = {29},
year = {2003}
}
@inproceedings{levy96b,
author = {Levy, A Y and Rousset, M},
booktitle = {AAAI '96},
pages = {577--584},
title = {{The Limits on Combining Recursive Horn Rules with Description Logics}},
year = {1996}
}
@article{reifer79,
author = {Reifer, D J},
journal = {IEEE Transactions on Reliability},
pages = {247--249},
title = {{Software Failure Modes and Effects Analysis}},
year = {1979}
}
@article{glinert84,
author = {Glinert, E P and Tanimoto, S T},
journal = {IEEE Computer},
month = nov,
pages = {7--25},
title = {{Pict: An Interactive Graphical Programming Environment}},
year = {1984}
}
@article{musilek00,
address = {New York, NY, USA},
author = {Mus\'{\i}lek, Petr and Pedrycz, Witold and Succi, Giancarlo and Reformat, Marek},
doi = {http://doi.acm.org/10.1145/373975.373984},
issn = {1559-6915},
journal = {SIGAPP Appl. Comput. Rev.},
number = {2},
pages = {24--29},
publisher = {ACM Press},
title = {{Software cost estimation with fuzzy models}},
volume = {8},
year = {2000}
}
@article{myer90,
author = {Myers, B A},
journal = {Journal of Visual Languages and Computing},
pages = {97--123},
title = {{Taxonomies of visual programming and program visualization}},
volume = {1},
year = {1990}
}
@inproceedings{chee96,
author = {Chee, C L and Jarzabek, S and Ramamoorthy, C V},
booktitle = {SEKE '96: the Eight International Conference of Software Engineering and Knowledge Engineering},
pages = {309--316},
title = {{An Intelligent Process for Formulating and Answering Project Queries}},
year = {1996}
}
@book{reisig82,
author = {Reisig, W},
publisher = {Springer Verlag},
title = {{Petri Nets}},
year = {1982}
}
@article{prab97,
annote = {To appear.},
author = {Prabhaker, S and Goel, A},
journal = {Journal of Artificial Intelligence in Engineering},
title = {{Addressing Incompleteness of Device Models by Adaptable Functional Modelling of Devices for Operating Environments}},
year = {1997}
}
@misc{Norvig2011,
author = {Norvig, Peter},
booktitle = {New York Post},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Norvig - 2011 - The machine age.pdf:pdf},
title = {{The machine age}},
url = {http://www.getcited.org/pub/102527552},
year = {2011}
}
@article{bobrow86,
author = {Bobrow, D G and Mittal, S and Stefik, M J},
journal = {Communications of the ACM},
pages = {880--894},
title = {{Expert Systems: Perils and Promise}},
volume = {29},
year = {1986}
}
@book{anderson85,
author = {Anderson, J R},
publisher = {W.H. Freeman and Company},
title = {{Cognitive Psychology and its Implications}},
year = {1985}
}
@inproceedings{wilson1992,
author = {Wilson, P R},
booktitle = {Proceedings of the 1992 International Workshop on Memory Management},
publisher = {Springer-Verlag},
title = {{Uniprocessor Garbage Collection Techniques}},
year = {1992}
}
@article{ElEmam2001,
author = {{El Emam}, K. and Benlarbi, S. and Goel, N. and Rai, S.N.},
doi = {10.1109/32.935855},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/El Emam et al. - 2001 - The confounding effect of class size on the validity of object-oriented metrics.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
month = jul,
number = {7},
pages = {630--650},
title = {{The confounding effect of class size on the validity of object-oriented metrics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=935855},
volume = {27},
year = {2001}
}
@inproceedings{lang99,
author = {Langley, P and Sage, S},
booktitle = {Proceedings of the Sixteenth International Conference on Machine Learning, Bled, Slovenia},
pages = {220--228},
title = {{Tractable average-case analysis of naive Bayesian classifiers}},
year = {1999}
}
@inproceedings{koru07,
author = {Koru, A G and Zhang, D and Liu, H},
booktitle = {Proceceedings PROMISE'07 (ICSE)},
title = {{Modeling the Effect of Size on Defect Proneness for Open-Source Software}},
year = {2007}
}
@article{dennett82,
annote = {8 June 24},
author = {Dennett, D C},
journal = {The New York Review of Books},
pages = {56--57},
title = {{Letter to the Editor}},
year = {1982}
}
@book{kosko92,
author = {Kosko, B},
publisher = {Prentice-Hall},
title = {{Neural Networks and Fuzzy Systems A Dynamic Systems Approach}},
year = {1992}
}
@article{klein93,
author = {Klein, M},
journal = {IEEE Computer},
number = {1},
pages = {39--47},
title = {{Capturing Design Rationale in Concurrent Engineering Teams}},
volume = {26},
year = {1993}
}
@article{foss05,
author = {Foss, T and Stensrud, E and Kitchenham, B and Myrtveit, I},
journal = {IEEE Transactions on Software Engineering},
month = nov,
number = {11},
pages = {985--995},
title = {{A simulation study of the model evaluation criterion MMRE}},
volume = {29},
year = {2003}
}
@book{pup93,
author = {Puppe, F},
publisher = {Springer-Verlag},
title = {{Systematic Introduction to Expert Systems: Knowledge Representation and Problem-Solving Methods}},
year = {1993}
}
@article{nus01,
author = {Nuseibeh, B A and Easterbrook, S M and Russo, A},
journal = {Journal of Systems and Software},
number = {2},
pages = {171--180},
title = {{Making Inconsistency Respectable in Software Development}},
volume = {58},
year = {2001}
}
@inproceedings{goldberg79,
author = {Goldberg, A},
booktitle = {Courant Computer Science Report, No. 16, New York University, NY},
title = {{On the complexity of the satisfiability problem}},
year = {1979}
}
@misc{ratrose,
annote = {$\backslash$url\{http://www.rational.com\}},
author = {Corporation, Rational Software},
title = {{Rational-Rose}},
year = {1997}
}
@article{wille92,
author = {Wille, R},
journal = {Computers Math. Applic.},
number = {6-9},
pages = {493--515},
title = {{Concept Lattices and Conceptual Knowledge Systems}},
volume = {23},
year = {1992}
}
@book{pree95,
author = {Pree, W},
publisher = {Addison-Wesley},
title = {{Design Patterns for Object-Oriented Software Development}},
year = {1995}
}
@inproceedings{me04e,
author = {Menzies, T and Pecheur, C},
booktitle = {Advances in Computing},
editor = {Zelkowtiz, M},
publisher = {Elsevier},
title = {{Verification and \{V\}alidation and \{A\}rtificial \{I\}ntelligence}},
volume = {65},
year = {2005}
}
@article{jorgensen04a,
author = {Jorgensen, M},
journal = {Journal of Systems and Software},
number = {1-2},
title = {{A Review of Studies on Expert Estimation of Software Development Effort}},
volume = {70},
year = {2004}
}
@incollection{nus97,
author = {Nuseibeh, B},
booktitle = {Proceedings of 8th International Workshop on Software Specification and Design (IWSSD-8)},
pages = {164--169},
publisher = {IEEE CS Press.},
title = {{To Be \{$\backslash$em and\} Not to Be: On Managing Inconsistency in Software Development}},
year = {1997}
}
@article{me97j,
author = {Menzies, T J},
journal = {Software Practice and Experience},
month = dec,
number = {12},
pages = {1457--1478},
title = {{\{O\}\{O\} Patterns: Lessons from Expert Systems}},
volume = {27},
year = {1997}
}
@article{rumel86,
author = {Rumelhart, D E and Hinton, G E and Williams, R J},
journal = {Nature},
number = {323},
pages = {533--536},
title = {{Learning representations by back-propagating errors}},
year = {1986}
}
@misc{me02j,
author = {T.Menzies},
institution = {Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{V and V of adaptive systems}},
year = {2002}
}
@article{clancey91,
author = {Clancey, W},
journal = {Artificial Intelligence},
pages = {241--284},
title = {{Book Review of Israel Rosenfield, The Invention of Memory: A New View of the Brain}},
volume = {50},
year = {1991}
}
@inproceedings{me96l,
author = {Ramakrishnan, S and Menzies, T and Hasslinger, M and Bok, P and Mccarthy, H and Devakadadcham, B and Moulder, D},
booktitle = {Proceedings of Tools-Pacific, Melbourne},
publisher = {Prentice-Hall},
title = {{On Building an Effective Measurement System for OO Software Process}},
year = {1996}
}
@inproceedings{me03d,
author = {Gunnalan, R and T, Menzies and Appukutty, K and A, Srinivasan and Hu, Y},
title = {{Feature Subset Selection with \{TAR2less\}}},
year = {2003}
}
@book{camp70,
author = {Campbell, D T and Stanley, J C},
publisher = {Rand McNally \& Company},
title = {{Experimental and Quasi-Experimental Designs for Research}},
year = {1970}
}
@inproceedings{feig77,
author = {Feigenbaum, E A},
booktitle = {IJCAI '77},
title = {{The Art of Artificial Intelligence: Themes and Case Studies of Knowledge Engineering.}},
year = {1977}
}
@article{brown94,
author = {Brown, T B and Kimura, T D},
journal = {Software- Concepts and Tools},
pages = {34--48},
title = {{Completeness of a Visual Computation Model}},
year = {1994}
}
@article{dekleer86b,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {163--196},
title = {{Extending the ATMS}},
volume = {28},
year = {1986}
}
@unpublished{hod96,
author = {Hodgson, B},
title = {{Personal communication}},
year = {1996}
}
@misc{owl09,
author = {Ciccarese, Paolo},
title = {{Scientific Discourse Relationships Ontology Specification}},
year = {2009}
}
@inproceedings{bradley98refining,
author = {Bradley, Paul S and Fayyad, Usama M},
booktitle = {Proc. 15th International Conf. on Machine Learning},
pages = {91--99},
publisher = {Morgan Kaufmann, San Francisco, CA},
title = {{Refining initial points for \{K\}-\{M\}eans clustering}},
year = {1998}
}
@article{vaab96,
author = {van Harmelen, F and Aben, M},
journal = {International Journal of Human-Computer Studies},
pages = {187--212},
title = {{Structure-Preserving Specification Languages for Knowledge-Based Systems}},
volume = {44},
year = {1996}
}
@book{kan95,
author = {Kan, Stephen H},
publisher = {Addison-Wesley},
title = {{Metrics and Models in Software Quality Engineering}},
year = {2002}
}
@article{boehm99,
author = {B.Boehm and H.In},
journal = {Software Quality Professional},
month = mar,
number = {2},
pages = {38--50},
title = {{Conflict Analysis and Negotiation Aids for Cost-Quality Requirements}},
volume = {1},
year = {1999}
}
@inproceedings{Schikuta1993a,
author = {Schikuta, Erich},
booktitle = {15th Joint. Conf. on Pattern Recognition},
file = {:Users/timm/svns/doc/schikuta93.pdf:pdf},
keywords = {grid clustering},
pages = {101--105},
title = {{GRID -CLUSTERING : A FAST HIERARCHICAL CLUSTERING METHOD FOR VERY LARGE DATA SETS}},
year = {1993}
}
@book{riel96,
author = {Riel, A J},
publisher = {Addison-Wesley},
title = {{Object-Oriented Design Heuristics}},
year = {1996}
}
@inproceedings{martin05,
address = {Washington, DC, USA},
author = {Martin, Cuauhtemoc Lopez and Pasquier, Jerome Leboeuf and Yanez, Cornelio M and Gutierrez, Agustin T},
booktitle = {ENC '05: Proceedings of the Sixth Mexican International Conference on Computer Science},
doi = {http://dx.doi.org/10.1109/ENC.2005.47},
isbn = {0-7695-2454-0},
pages = {113--120},
publisher = {IEEE Computer Society},
title = {{Software Development Effort Estimation Using Fuzzy Logic: A Case Study}},
year = {2005}
}
@inproceedings{patil81,
author = {Patil, R S and Szolovitis, P and Schwartz, W B},
booktitle = {\{IJCAI\} '81},
pages = {893--899},
title = {{Causal \{U\}nderstanding of \{P\}atient \{I\}llness in \{M\}edical \{D\}iagnosis}},
year = {1981}
}
@article{bryant92,
author = {Bryant, R E},
journal = {ACM Computing Surveys},
month = sep,
number = {3},
title = {{Symbolic Boolean Manipulation with Ordered Binary Decision Diagrams}},
volume = {24},
year = {1992}
}
@misc{wilson01,
author = {Wilson-Smith, P},
title = {{Fund managers take fright over \{M\}yners, \{F\}inancial \{N\}ews, \{M\}arch 26}},
year = {2001}
}
@inproceedings{suthers95,
author = {Suthers, D and Weiner, A},
booktitle = {CSCL '95, Computer Supported Cooperative Learning; Bloomington, Indiana, October 17-20},
title = {{Groupware for developing critical discussion skills}},
year = {1995}
}
@book{hump95,
author = {Humphrey, W},
publisher = {McGraw Hill},
title = {{A Discipline for Software Engineering}},
year = {1995}
}
@article{me10d,
author = {Menzies, Tim and Jalali, Omid and Hihn, Jairus and Baker, Dan and Lum, Karen},
file = {::},
journal = {Automated Software Engineering},
month = dec,
number = {4},
title = {{Stable Rankings for Different Effort Models}},
year = {2010}
}
@article{Chandola2009a,
author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
doi = {10.1145/1541880.1541882},
file = {:Users/timm/svns/doc/anomalies09.pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
month = jul,
number = {3},
pages = {1--58},
title = {{Anomaly detection}},
url = {http://portal.acm.org/citation.cfm?doid=1541880.1541882},
volume = {41},
year = {2009}
}
@article{dmcdermott87,
author = {McDermott, D},
journal = {Computational Intelligence},
pages = {151--160},
title = {{A \{C\}ritique of \{P\}ure \{R\}eason}},
volume = {3},
year = {1987}
}
@inproceedings{kamei07,
author = {Kamei, Yasutaka and Monden, Akito and Matsumoto, Shinsuke and Kakimoto, Takeshi and Matsumoto, Ken-ichi},
booktitle = {Empirical Software Engineering and Measurement, 2007. ESEM 2007. First International Symposium on},
pages = {196--204},
title = {{The Effects of Over and Under Sampling on Fault-prone Module Detection}}
}
@inproceedings{wang00,
author = {Wang, K and He, Y and Cheung, D and Chin, F},
booktitle = {10th ACM International Conference on Informationand Knowledge Management (CIKM 2001), Atlanta},
title = {{Mining confident rules without support requirement}},
year = {2001}
}
@book{glas95,
author = {Glasgow, J and Narayanan, H and (eds), B Chandrasekaran},
publisher = {MIT Press},
title = {{Diagrammatic Reasoning : Cognitive and Computational Perspectives}},
year = {1995}
}
@inproceedings{me03g,
author = {{T. Menzies J. Smith}, D Raffo},
title = {{When is Pair Programming Better?}},
year = {2003}
}
@inproceedings{me02o,
author = {Menzies, T and Mason, L},
booktitle = {Third ACM SIGPLAN Workshop on Rule-Based Programming (RULE02) Pittsburgh, PA, October 5},
title = {{Some Prolog Macros for Rule-Based Programming: Why? How?}},
year = {2002}
}
@misc{On,
abstract = {December 7, 2010},
author = {On, Focus},
booktitle = {University of Buffalo},
file = {:Users/timm/svns/doc/HowRareIsThat.pdf:pdf},
keywords = {forensics},
mendeley-tags = {forensics},
title = {{How Rare is that Fingerprint ? Computational Forensics Provides the First Clues}},
url = {http://www.buffalo.edu/news/12073}
}
@incollection{roy94,
annote = {To appear.},
author = {Roy, M and Cruz-Neira, C and Fanti, T De},
chapter = {Cosmic Wor},
publisher = {MIT Press},
title = {{Networks and Virtual Environments of Presence Teleoperators and Virtual Envionrment}},
year = {1994}
}
@article{clancey83,
author = {Clancey, W},
journal = {Artificial Intelligence},
pages = {289--350},
title = {{The Epistomology of Rule-Based Systems: a Framework for Explanation.}},
volume = {27},
year = {1983}
}
@article{michie68,
author = {Michie, D},
journal = {Nature},
pages = {19--22},
title = {{Memo Functions and Machine Learning}},
volume = {218},
year = {1968}
}
@inproceedings{harman04,
address = {Washington, DC, USA},
author = {Harman, Mark and Wegener, Joachim},
booktitle = {ICSE '04: Proceedings of the 26th International Conference on Software Engineering},
isbn = {0-7695-2163-0},
pages = {728--729},
publisher = {IEEE Computer Society},
title = {{Getting Results from Search-Based Approaches to Software Engineering}},
year = {2004}
}
@misc{joseph94,
author = {Josephson, John R and Josephson\~{}(eds), Susan G},
publisher = {Cambridge University Press},
title = {{Abductive Inference Computation, Philosophy, Technology}},
year = {1994}
}
@misc{lee04,
author = {Lee, S C and Santo, A G},
title = {{Tradeoffs in functional allocation between spacecraft autonomy and ground operations: the \{NEAR\} (\{N\}ear \{E\}arth \{A\}steroid \{R\}endezvous) \{E\}xperience, \{J\}ohn \{H\}opkins \{APL\}, \{A\}ugust 9-12, \{U\}tah \{S\}tate \{U\}niversity , \{E\}ccles \{C\}onference \{C\}enter, \{L}}},
year = {2004}
}
@article{kowal75,
author = {Kowalski, R},
journal = {Journal of the Association for Computing Machinery},
month = oct,
number = {4},
pages = {572--595},
title = {{A Proof Procedure Using Connection Graphs}},
volume = {22},
year = {1975}
}
@inproceedings{prakash91,
author = {Prakash, G R and Subramanian, E and Mahabala, H N},
booktitle = {Proceedings of the 12th International Joint Conference on Artificial Intelligence (IJCAI'91)},
pages = {3--8},
title = {{A Methodology for Systematic Verification of OPS5-Based AI Applications}},
year = {1991}
}
@article{plex93,
author = {Plexousakis, D},
journal = {Computational Intelligence},
month = feb,
number = {1},
title = {{Semantical and Ontological Considerations in Telos: a Language for Knowledge Representation}},
volume = {9},
year = {1993}
}
@article{cover67,
author = {Cover, T M and Hart, P E},
journal = {IEEE Transactions on Information Theory},
month = jan,
pages = {21--27},
title = {{Nearest neighbour pattern classification}},
year = {1967}
}
@article{donzelli01,
author = {Donzelli, P and Iazeolla, G},
journal = {Journal of Systems and Software},
month = dec,
number = {3},
title = {{Hybrid Simulation Modelling of the Software Process}},
volume = {59},
year = {2001}
}
@inproceedings{coo04,
author = {Cooper, G and Dash, D and Levander, J and Wong, W-.K. and Hogan, W and {M. Wagner}, M},
booktitle = {Proceedings of the Twentieth Conference of Uncertainty in Artificial Intelligence (UAI-2004)},
pages = {94--103},
title = {{Bayesian biosurveillance of disease outbreaks}},
year = {2004}
}
@article{hamilton91,
author = {{D. Hamilton K. Kelley}, C Culbert},
journal = {Expert Systems with Applications},
pages = {403--410},
title = {{State-of-the-Practice in Knowledge-based System Verification and Validation.}},
volume = {3},
year = {1991}
}
@misc{shum97,
author = {Shum, S Buckingham and Sumner, T},
howpublished = {Knowledge Media Institute, The Open University, Milton Keynes, Technical report KMI-TR-57},
title = {{Publishing, Interpreting and Negotiating Scholarly Hypertexts: Evolution of an Approach and Toolkit}},
year = {1997}
}
@incollection{sch92,
author = {Schreiber, A T and Wielinga, B J and Akkermans, J M},
booktitle = {Formal Methods for Knowledge Modeling in the CommonKADS Methodology: A Compilation (KADS-EE/T1.2/TR/ECN/014/1.0)},
editor = {Balder, J and Akkermans, H},
pages = {53--90},
publisher = {Netherlands Energy Research Foundation},
title = {{Using \{KADS\} to \{A\}nalyse \{P\}roblem \{S\}olving \{M\}ethods}},
year = {1992}
}
@inproceedings{wyatt87,
author = {J., Wyatt},
booktitle = {Lecture Notes in Medical Informatics},
pages = {15--24},
title = {{The evaluation of clinical decision aids: a discussion of methodology used in the ACORN project}},
volume = {33},
year = {1987}
}
@incollection{kit91,
author = {Kitchenham, B and Mellor, P},
booktitle = {Software Metrics},
chapter = {6},
editor = {Fenton, N E},
publisher = {Chapman and Hall, London},
title = {{Data Collection and Analysis}},
year = {1991}
}
@article{franco83,
author = {Franco, J and Paull, M},
journal = {Discrete Applied Math},
pages = {77--87},
title = {{Probabilistic Analysis of the Davis Putnam Procedure for Solving the Satisfiability Problem}},
volume = {5},
year = {1983}
}
@article{seidewitz03,
author = {Seidewitz, Ed},
journal = {IEEE Software},
number = {5},
pages = {26--32},
title = {{What Models Mean}},
volume = {20},
year = {2003}
}
@misc{ford1,
author = {Ford, G},
institution = {Software Engineering Institute Carnegie Mellon University},
number = {SEI-94-TR-011},
title = {{A \{P\}rogress \{R\}eport on \{U\}ndergraduate \{S\}oftware \{E\}ngineering \{E\}ducation}},
year = {1994}
}
@inproceedings{Bird2009a,
author = {Bird, Christian and Nagappan, Nachiappan and Devanbu, Premkumar and Gall, Harald and Murphy, Brendan},
booktitle = {2009 IEEE 31st International Conference on Software Engineering},
doi = {10.1109/ICSE.2009.5070550},
file = {:Users/timm/svns/doc/bird09icse.pdf:pdf},
isbn = {978-1-4244-3453-4},
month = may,
pages = {518--528},
publisher = {Ieee},
title = {{Does distributed development affect software quality? An empirical case study of Windows Vista}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5070550},
year = {2009}
}
@inproceedings{for95,
author = {Forbus, K},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and {N.H. Narayanan}, B Chandrasekaran},
pages = {183--204},
publisher = {The AAAI Press},
title = {{Qualitative Spatial Reasoning: Framework and Frontiers}},
year = {1995}
}
@article{forgy82,
author = {Forgy, C L},
journal = {Artificial Intelligence},
pages = {17--37},
title = {{\{RETE\}: A \{F\}ast \{A\}lgorithm for the \{M\}any \{P\}attern/\{M\}any \{O\}bject \{P\}attern \{M\}atch \{P\}roblem}},
year = {1982}
}
@article{kowa96,
author = {Kowalski, R and Toni, F},
journal = {Artificial Intelligence and Law Journal},
number = {3-4},
pages = {275--296},
title = {{Abstract Argumentation}},
volume = {4},
year = {1996}
}
@inproceedings{deb98a,
author = {Debenham, J},
booktitle = {Proceedings Seventh International Conference on Information Processing and Management of Uncertainty in Knowledge Based Systems IPMU '98, Paris, France, July},
title = {{Managing Knowledge Integrity}},
year = {1998}
}
@article{kuipers93a,
author = {Kuipers, B},
journal = {Artificial Intelligence},
pages = {133--140},
title = {{Qualitative Simulation: then and now}},
volume = {59},
year = {1993}
}
@article{me99r,
annote = {Available from $\backslash$url\{http://menzies.us/desert.html\}},
author = {Menzies, T},
journal = {Automated Software Engineering},
number = {3},
pages = {315--320},
title = {{Desert Island Column}},
volume = {6},
year = {1999}
}
@inproceedings{palmer95,
author = {Palmer, G J and Craw, S},
booktitle = {EUROVAV-95: The Third European Symposium on Validation and Verification of Knowledge-Based Systems},
pages = {201--211},
title = {{Utilising Explanation to Assist the Refinement of Knowledge-Based Systems}},
year = {1995}
}
@book{quinlan92,
annote = {ISBN: 1558602380},
author = {Quinlan, R},
publisher = {Morgan Kaufman},
title = {{C4.5: Programs for Machine Learning}},
year = {1992}
}
@article{gaines92,
author = {Gaines, B},
journal = {\{AI\} Magazine},
pages = {24},
title = {{\{AAAI\} 1992 \{S\}pring \{S\}ymposium \{S\}eries \{R\}eports: \{C\}ognitive \{A\}spects of \{K\}nowledge \{A\}cquisition}},
year = {1992}
}
@article{apswall79,
author = {Apswall, B and Plass, M and Tarjan, R},
journal = {Information Processing Letters},
pages = {121--123},
title = {{A linear-time algorithm for testing the truth of certain quantified Boolean formulas}},
volume = {8},
year = {1979}
}
@article{Leveson94,
author = {Leveson, N G and Heimdahl, M P E and Hildreth, H and Reese, J D},
journal = {IEEE Transactions on Software Engineering},
month = sep,
number = {9},
pages = {684--706},
title = {{Requirements Specification for Process-Control Systems}},
volume = {20},
year = {1994}
}
@article{haag96,
author = {Haag, Stephen and Raja, M K and Schkade, L L},
journal = {Commun. ACM},
number = {1},
pages = {41--49},
title = {{Quality function deployment usage in software development}},
volume = {39},
year = {1996}
}
@article{chandra90,
author = {Chandrasekaran, B},
journal = {\{AI\} Magazine},
pages = {59--71},
title = {{Design Problem Solving: A Task Analysis}},
year = {1990}
}
@inproceedings{deb98c,
author = {Debenham, J},
booktitle = {Proceedings Seventh International Conference on Intelligent Systems ICIS'98, Paris, France, July},
title = {{An Integrated Conceptual Model of Knowledge-Based Systems Simplifies Mainteance}},
year = {1998}
}
@misc{brookes86,
author = {Brookes, C H P},
institution = {Information Systems, University of New South Wales},
number = {11},
title = {{Requirements \{E\}licitation for \{K\}nowledge \{B\}ased \{D\}ecision \{S\}upport \{S\}ystems}},
year = {1986}
}
@book{Sutton1998,
author = {Sutton, R.S. and Barto, A.G.},
booktitle = {Policy},
file = {:Users/timm/svns/doc/sutton98.pdf:pdf},
isbn = {0262193981},
publisher = {The MIT press},
title = {{Reinforcement learning: An introduction}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=CAFR6IBF4xYC\&amp;oi=fnd\&amp;pg=PA3\&amp;dq=Reinforcement+Learning+:+An+Introduction\&amp;ots=e8WUNPbbWC\&amp;sig=9P8h\_oRbAy7uAtVkbWwdFGvz2SQ},
year = {1998}
}
@inproceedings{craw94,
author = {Craw, S and Sleeman, D and Boswell, R and Carbonara, L},
booktitle = {Proceedings of the MLNet Familiarization Workshop on Theory Revision and Restructuring in Machine Learning (ECML-94)},
editor = {Wrobel, S},
pages = {32--34},
title = {{Is knowledge refinement different from theory revision?}},
year = {1994}
}
@article{Barski,
author = {Barski, Conrad},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Barski - 2010 - The Land of Lisp.pdf:pdf},
title = {{Conrad Barski, M.D.}}
}
@incollection{me10e,
author = {Menzies, Tim and Shull, Forrest},
booktitle = {Making Software: What Really Works, and Why We Believe It},
editor = {Oram, A and Wilson, G},
publisher = {O'Reilly},
title = {{The Quest for Convincing Evidence}},
year = {2010}
}
@article{clarke86,
author = {Clarke, E M and Emerson, E A and Sistla, A P},
journal = {ACM Transactions on Programming Languages and Systems},
month = apr,
number = {2},
pages = {244--263},
title = {{Automatic verification of finite-state concurrent systems using temporal logic specifications}},
volume = {8},
year = {1986}
}
@article{mitchell86,
author = {Mitchell, T M and Keller, R M and Kedar-Cabelli, S T},
journal = {Machine Learning},
pages = {47--80},
title = {{Explanation-Based Generalization: A Unifying View}},
volume = {1},
year = {1986}
}
@book{endres03,
author = {{A. Endres H.D}, Rombach},
publisher = {Addison Wesley},
title = {{A Handbook of Software and Systems Engineering: Empirical Observations, Laws and Theories}},
year = {2003}
}
@inproceedings{me97e,
author = {M.Posterma and Wu, X and Menzies, T J},
booktitle = {First Pacific Asia Conference on Knowledge Discovery and Data Mining (PAKDD97)},
title = {{A Tuning Aid for Discretization in Rule Induction}},
year = {1997}
}
@misc{seminal01,
annote = {ISSN:0163-5948},
month = nov,
publisher = {ACM SIGSOFT Software Engineering Notes},
title = {{The SEMINAL workshop: reformulating software engineering as a meta-heuristic search problem}},
volume = {26},
year = {2001}
}
@misc{marick97,
author = {Marick, B},
title = {{The Testing Tools Supplier List $\backslash$url\{http://www.stlabs.com/marick/faqs/tools.htm\}}},
year = {1997}
}
@incollection{CARBONELL-ML2-BOOK,
address = {Los Altos, CA},
author = {Carbonell, J G},
booktitle = {Machine Learning: An Artificial Intelligence Approach, Volume II},
editor = {Michalski, J G Carbonell R S and Mitchell, T M},
pages = {371--392},
publisher = {Morgan Kaufmann},
title = {{Derivational Analogy: \{A\} Theory of Reconstructive Problem Solving and Expertise Acquisition}},
year = {1986}
}
@inproceedings{briand98,
author = {Briand, Lionel C and Emam, Khaled El and Bomarius, Frank},
booktitle = {ICSE},
pages = {390--399},
title = {{COBRA: A Hybrid Method for Software Cost Estimation, Benchmarking, and Risk Assessment}},
year = {1998}
}
@inproceedings{will93,
author = {Williams, M G and Ledder, W A and Buehler, J N and Canning, J T},
booktitle = {Proceedings 1993 IEEE Symposium on Visual Languages},
pages = {371--373},
publisher = {IEEE Comput. Soc. Press.},
title = {{An Empirical Study of Visual Labs}},
year = {1993}
}
@article{takagi05,
author = {Takagi, Y and Mizuno, O and Kikuno, T},
journal = {Empirical Software Engineering},
number = {4},
pages = {495--515},
title = {{An Empirical Approach to Characterizing Risky Software Projects Based on Logistic Regression Analysis}},
volume = {0},
year = {2005}
}
@inproceedings{me92k,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/ai92.pdf\}},
author = {Menzies, T J},
booktitle = {Proceedings of AI '92, Australia},
title = {{Maintaining Procedural Knowledge: Ripple-Down-Functions}},
year = {1992}
}
@article{bals04,
author = {Balsamo, S and Marco, A Di and Inverardi, P and Simeoni, M},
journal = {IEEE Transactions on Software Engineering},
month = may,
number = {5},
title = {{Model-Based Performance Prediction in Software Development: A Survey}},
volume = {30},
year = {2004}
}
@article{scanlon89,
author = {Scanlan, D A},
journal = {IEEE Computer},
number = {5},
pages = {28--36},
title = {{Structured Flowcharts Outperform Psuedocode: an Experimental Comparison}},
volume = {6},
year = {1989}
}
@article{jiang08b,
author = {Jiang, Y and Cukic, B and Ma, Y},
journal = {Empirical Software Engineering},
month = oct,
pages = {561--595},
title = {{Techniques for evaluating fault prediction models}},
year = {2008}
}
@article{feather08,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ddp.pdf\}},
author = {Feather, M and Cornford, S and Hicks, K and Kiper, J and Menzies, T},
journal = {IEEE Software},
title = {{Application of a broad-spectrum quantitative requirements model to early-lifecycle decision making}},
year = {2008}
}
@misc{chiang03,
author = {Chiang, E},
title = {{Learning controllers for nonfunctional requirements}},
year = {2003}
}
@inproceedings{masada08,
address = {Berlin, Heidelberg},
author = {Masada, Tomonari and Kiyasu, Senya and Miyahara, Sueharu},
booktitle = {LKR'08: Proceedings of the 3rd international conference on Large-scale knowledge resources},
isbn = {3-540-78158-7, 978-3-540-78158-5},
pages = {13--26},
publisher = {Springer-Verlag},
title = {{Comparing LDA with pLSI as a dimensionality reduction method in document clustering}},
year = {2008}
}
@article{Saclay,
author = {Saclay, Inria and Sud, U Paris and Orsay, F- and Schoenauer, Marc and Sebag, Mich\`{e}le},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Saclay et al. - Unknown - A Mono Surrogate for Multiobjective Optimization.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {multiobjective optimization,pareto,support vec-,surrogate models},
mendeley-tags = {pareto},
pages = {471--478},
title = {{A Mono Surrogate for Multiobjective Optimization}}
}
@article{heust97,
author = {Van\~{}Heust, G and Schreiber, A Th. and Wielinga, B J},
journal = {International Journal of Human Computer Studies},
pages = {183--292},
title = {{Using explicit ontologies in KBS development}},
volume = {45},
year = {1997}
}
@inproceedings{WATANABE08,
address = {New York, NY, USA},
author = {Watanabe, Shinya and Kaiya, Haruhiko and Kaijiri, Kenji},
booktitle = {PROMISE '08: Proceedings of the 4th international workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1370788.1370794},
isbn = {978-1-60558-036-4},
pages = {19--24},
publisher = {ACM},
title = {{Adapting a fault prediction model to allow inter languagereuse}},
year = {2008}
}
@incollection{newell91,
author = {Newell, A and Yost, G R and Laird, J E and Rosenbloom, P S and Altmann, E},
booktitle = {The Soar Papers},
editor = {Rosenbloom, P S and Laird, J E and Newell, A},
pages = {1321--1359},
publisher = {MIT Press},
title = {{Formulating the \{P\}roblem \{S\}pace \{C\}omputational \{M\}odel}},
volume = {2},
year = {1991}
}
@article{Parnas72,
author = {Parnas, D},
file = {:Users/timm/svns/doc/72parnas.pdf:pdf},
journal = {Communications of the ACM},
month = dec,
number = {12},
pages = {1053--1058},
title = {{On the Criteria to be Used in Decomposing Systems into Modules}},
volume = {5},
year = {1972}
}
@inproceedings{fujita98,
author = {Fujita, M},
booktitle = {Asia and South Pacific - Design Automation Conference},
title = {{Model Checking: Its Basics and Reality}},
year = {1998}
}
@article{preece96,
author = {Preece, A D and Grossner, C and Radhakrishnan, T},
journal = {Int. J. Human-Computer Studies},
pages = {145--169},
title = {{Validating Dynamic Properties of Rule Based Systems}},
volume = {44},
year = {1996}
}
@article{colomb99,
author = {Colomb, R M},
journal = {Artificial Intelligence},
number = {1-2},
pages = {187--209},
title = {{Representation of Propositional Expert Systems as Partial Functions}},
volume = {109},
year = {1999}
}
@article{reiter80,
author = {Reiter, R},
journal = {Artificial Intelligence},
pages = {81--132},
title = {{A \{L\}ogic for \{D\}efault \{R\}easoning}},
volume = {13},
year = {1980}
}
@inproceedings{landi91,
author = {Landi, W and Ryder, B G},
booktitle = {Conference Record of the 18th ACM Symposium on Principles of Programming Languages},
month = jan,
pages = {93--103},
title = {{Pointer-induced aliasing: a problem classification}},
year = {1991}
}
@article{jones98,
author = {Jones, B and Eyres, D and Sthamer, H.-H.},
journal = {ï¿½Computer Journalï¿½},
number = {2},
pages = {98--107},
title = {{A strategy for using genetic algorithms to automate branch and fault-based testing}},
volume = {41},
year = {1998}
}
@inproceedings{emer90,
author = {Emerson, E A},
booktitle = {Handbook of Theoretical Computer Science},
editor = {van Leeuwen, J},
pages = {995--1072},
publisher = {1990},
title = {{Temporal and Model Logic}}
}
@misc{schmann07,
author = {Schumann, J and Gundy-Burlet, K and Menzies, T},
institution = {Computer Science, West Virginia University},
title = {{Learning Predictors \& Controllers for Software Functional Requirements}},
year = {2007}
}
@article{codd:70,
author = {Codd, E F},
journal = {Communications of the ACM},
pages = {377--387},
title = {{A Relational Model of Data for Large Shared Data Banks}},
volume = {13},
year = {1970}
}
@inproceedings{nikora03,
author = {Nikora, A P and Munson, J C},
booktitle = {Ninth International Software Metrics Symposium (METRICS'03)},
title = {{Developing Fault Predictors for Evolving Software Systems}},
year = {2003}
}
@article{warrenDS92,
author = {Warren, D S},
journal = {Communications of the ACM},
month = mar,
pages = {93--101},
title = {{Memoing for Logic Programs}},
volume = {35},
year = {1992}
}
@inproceedings{lokan06,
author = {Lokan, C and Mendes, E},
booktitle = {The ACM-IEEE International Symposium on Empirical Software Engineering, November 21-22, Rio de Janeiro},
title = {{Cross-company and Single-company Effort Models Using the ISBSG Database: a Further Replicated Study}},
year = {2006}
}
@article{Ierusalimschy,
author = {Ierusalimschy, Roberto},
file = {:Users/timm/svns/doc/lua.pdf:pdf},
title = {{Programming in Lua Programming in Lua}}
}
@inproceedings{me00f,
author = {Menzies, T J},
booktitle = {Proceedings of 10th International Workshop on Software Specification and Design (IWSSD-10)},
title = {{The Complexity of TRMCS-like Spiral Specification}},
year = {2000}
}
@article{holzmann97,
author = {Holzmann, G J},
journal = {IEEE Transactions on Software Engineering},
month = may,
number = {5},
pages = {279--295},
title = {{The Model Checker \{SPIN\}}},
volume = {23},
year = {1997}
}
@article{yost93,
author = {Yost, G R},
journal = {IEEE Expert},
month = jun,
pages = {26--34},
title = {{Acquiring Knowledge in Soar}},
year = {1993}
}
@article{brac85,
author = {Brachman, R},
journal = {The \{AI\} Magazine},
pages = {80--93},
title = {{I Lied About the Trees, or Defaults and Definitions in Knowledge Representation}},
year = {1985}
}
@misc{compton95,
author = {Compton, P and Preston, P and Kang, B},
booktitle = {Proceedings of the Banff KA workshop on Knowledge Acquisition for Knowledge-Based Systems},
title = {{The Use of Simulated Experts in Evaluating Knowledge Acquisition}},
year = {1995}
}
@inproceedings{kakas98,
author = {Kakas, A C and Kowalski, R A and Toni, F},
booktitle = {Handbook of Logic in Artificial Intelligence and Logic Programming 5},
editor = {{D.M. Gabbay}, C J Hogger and Robinson, J A},
pages = {235--324},
publisher = {Oxford University Press},
title = {{The Role of Abduction in Logic Programming}},
year = {1998}
}
@book{rubinstein04,
author = {Rubinstein, R Y and Kroese, D P},
publisher = {Springer-Verlag},
title = {{The Cross-Entropy Method: A Unified Approach to Combinatorial Optimization, Monte-Carlo Simulation, and Machine Learning}},
year = {2004}
}
@article{pargas99,
author = {Pargas, R P and Harrold, M J and Peck, R R},
journal = {ï¿½Journal of Software Testing, Verification and Reliabilityï¿½},
pages = {263--282},
title = {{Test-data generation using genetic algorithms}},
volume = {9},
year = {1999}
}
@article{fikes72,
author = {Fikes, Richard E and Hart, Peter E and Nilsson, Nils J},
journal = {Artificial Intelligence},
pages = {251--288},
title = {{Learning and Executing Generalized Robot Plans}},
volume = {3},
year = {1972}
}
@inproceedings{dinv98,
author = {D'Inverno, M and M., Kinny and D., Luck and Wooldridge, M},
booktitle = {Intelligent Agents IV: Proc. of the Fourth International Workshop on Agent Theories. Architectures and Languages, Springer Verlag},
editor = {Singh, A R and M.Wooldridge},
title = {{A formal specification of dMars}},
year = {1998}
}
@book{darden91,
author = {Darden, L},
isbn = {0-19-506797-5},
publisher = {Oxford University Press},
title = {{Theory Change in Science: Strategies from Mendelian Genetics}},
year = {1991}
}
@phdthesis{lee97,
author = {Lee, M},
school = {Computer Science \& Engineering},
title = {{From Multiple Representations to Causal Explanation}},
year = {1997}
}
@inproceedings{rymon94an,
author = {Rymon, R},
booktitle = {Annals of Math. and A.I., special issue on Model-Based Diagnosis},
title = {{An SE-tree-based Prime Implicant Generation Algorithm}},
volume = {11},
year = {1994}
}
@inproceedings{jensen83,
author = {Jensen, R},
booktitle = {5th ISPA Conference},
month = apr,
pages = {88--92},
title = {{An Improved Macrolevel Software Development Resource Estimation Model}},
year = {1983}
}
@inproceedings{sammut92,
author = {Sammut, C and Hurst, S and Kedzier, D and Michie, D},
booktitle = {Ninth International Conference on Machine Learning},
editor = {Sleeman, D},
pages = {385--393},
publisher = {Morgan Kaufmann},
title = {{Learning to Fly}},
year = {1992}
}
@book{salton83introduction,
author = {Salton, G and McGill, M J},
publisher = {McGraw Hill},
title = {{Introduction to Modern Information Retrieval}},
year = {1983}
}
@article{rich07,
author = {Richardson, I and Wangenheim, C},
journal = {IEEE Software},
title = {{Guest Editors' Introduction: Why are Small Software Organizations Different?}},
year = {2007}
}
@misc{Coiera99,
annote = {Technical Report, 1999, to appear},
author = {Coiera, E},
institution = {Hewlett-Packard Laboratories},
title = {{Communication under scarcity of resources}},
year = {1999}
}
@inproceedings{me03c,
author = {Menzies, T and Hu, Y},
booktitle = {IEEE Computer},
month = nov,
title = {{Data Mining for Very Busy People}},
year = {2003}
}
@article{yip91,
author = {Yip, K M},
journal = {Artificial Intelligence},
pages = {179--221},
title = {{Understanding Complex Dynamics by Visual and Symbolic Reasoning}},
volume = {51},
year = {1991}
}
@inproceedings{level89,
author = {Levesque, H},
booktitle = {\{IJCAI\} '89},
pages = {1061--1067},
title = {{A \{K\}nowledge-\{L\}evel \{A\}ccount of \{A\}bduction (\{P\}reliminary \{V\}ersion)}},
volume = {2},
year = {1989}
}
@misc{prevue,
author = {$\backslash$urlhttp://www.pacorp.com, Performance Awareness Corporation},
title = {{preVue-C/S}},
year = {1998}
}
@article{child06,
annote = {Available from $\backslash$url\{http://projects.cis.ksu.edu/docman/view.php/7/129/CALM-Cadena-IEEE-Computer-Feb-2006.pdf\}},
author = {Childs, A and Greenwald, J and Jung, G and Hoosier, M and Hatcliff, John},
journal = {IEEE Computer},
number = {2},
title = {{CALM and Cadena: Metamodeling for Component-Based Product-Line Development}},
volume = {39},
year = {2006}
}
@inproceedings{mebfd92,
author = {Menzies, T J and Black, J and Fleming, J and Dean, M},
booktitle = {The first Conference on Practical Applications of Prolog},
title = {{An Expert System for Raising Pigs}},
year = {1992}
}
@inproceedings{laird83,
author = {Laird, J E and Newell, A},
booktitle = {IJCAI '83},
pages = {771--773},
title = {{A Universal Weak Method: Summary of Results}},
year = {1983}
}
@article{Dishaw19999,
author = {Dishaw, Mark T and Strong, Diane M},
journal = {Information \& Management},
number = {1},
pages = {9--21},
title = {{Extending the technology acceptance model with task-technology fit constructs}},
volume = {36},
year = {1999}
}
@book{jacob97,
author = {{I. Jacobson M. Griss}, P Jonsson},
publisher = {Addison-Wesley},
title = {{Software Reuse: Architecture Process and Organiation for Business Success}},
year = {1997}
}
@article{ambler89,
author = {Ambler, A L and Burnett, M M},
journal = {IEEE Computer},
number = {10},
pages = {9--22},
title = {{Influence of Visual Technology on the Evolution of Language Environments}},
volume = {22}
}
@inproceedings{preece92,
author = {Preece, A D and Shinghal, R},
booktitle = {ECAI '92},
title = {{Verifying Knowledge Bases by Anomaly Detection: An Experience Report}},
year = {1992}
}
@inproceedings{CATAL2009,
address = {London, U.K.},
author = {Catal, C and Sevim, U and Diri, B},
booktitle = {Proceedings of the World Congress on Engineering 2009 Vol I},
title = {{Software Fault Prediction of Unlabeled Program Modules}},
year = {2009}
}
@article{Ling2007,
abstract = {We propose EMD-L1: a fast and exact algorithm for computing the Earth Mover's Distance (EMD) between a pair of histograms. The efficiency of the new algorithm enables its application to problems that were previously prohibitive due to high time complexities. The proposed EMD-L1 significantly simplifies the original linear programming formulation of EMD. Exploiting the L1 metric structure, the number of unknown variables in EMD-L1 is reduced to O(N) from O(N2) of the original EMD for a histogram with N bins. In addition, the number of constraints is reduced by half and the objective function of the linear program is simplified. Formally, without any approximation, we prove that the EMD-L1 formulation is equivalent to the original EMD with a L1 ground distance. To perform the EMD-L1 computation, we propose an efficient tree-based algorithm, Tree-EMD. Tree-EMD exploits the fact that a basic feasible solution of the simplex algorithm-based solver forms a spanning tree when we interpret EMD-L1 as a network flow optimization problem. We empirically show that this new algorithm has an average time complexity of O(N2), which significantly improves the best reported supercubic complexity of the original EMD. The accuracy of the proposed methods is evaluated by experiments for two computation-intensive problems: shape recognition and interest point matching using multidimensional histogram-based local features. For shape recognition, EMD-L1 is applied to compare shape contexts on the widely tested MPEG7 shape data set, as well as an articulated shape data set. For interest point matching, SIFT, shape context and spin image are tested on both synthetic and real image pairs with large geometrical deformation, illumination change, and heavy intensity noise. The results demonstrate that our EMD-L1-based solutions outperform previously reported state-of-the-art features and distance measures in solving the two tasks.},
author = {Ling, Haibin and Okada, Kazunori},
doi = {10.1109/TPAMI.2007.1058},
file = {:Users/timm/svns/doc/earthMoverDistance07.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Computer Simulation,Data Interpretation, Statistical,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Information Storage and Retrieval,Information Storage and Retrieval: methods,Models, Statistical,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reproducibility of Results,Sensitivity and Specificity,Subtraction Technique},
month = may,
number = {5},
pages = {840--53},
pmid = {17356203},
title = {{An efficient Earth Mover's Distance algorithm for robust histogram comparison.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17356203},
volume = {29},
year = {2007}
}
@inproceedings{deb95a,
author = {Debenham, J},
booktitle = {Proceedings Sixth International Conference on Database and Expert Systems Applications DEXA'95, London, September},
title = {{Understanding Expert Systems Maintenance}},
year = {1995}
}
@inproceedings{goel92,
author = {Goel, V},
booktitle = {Proceedings of the AAAI Symposium on Diagrammatic Reasoning Stanford University, March 25-27},
pages = {66--71},
title = {{``Ill-Structured Diagrams'' for Ill-Structured Problems}},
year = {1992}
}
@inproceedings{Xiao2007,
author = {Xiao, Lurong and Hung, E.},
booktitle = {Computational Intelligence and Data Mining, 2007. CIDM 2007. IEEE Symposium on},
file = {:Users/timm/svns/doc/distanceBetweenClusters07.pdf:pdf},
number = {i},
pages = {10--17},
publisher = {IEEE},
title = {{An efficient distance calculation method for uncertain objects}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4221270},
year = {2007}
}
@inproceedings{roth94,
author = {Rothenfluh, T E and Gennari, J H and Erikson, H and Puetra, A R and Tu, W and Musen, M A},
booktitle = {Proceedings of the 8th \{AAAI\}-Sponsored \{B\}anff Knowledge Acquisition for Knowledge-Based Systems Workshop},
editor = {Gaines, B R and Musen, M},
pages = {43.1--43.30},
title = {{Reusable Ontologies, Knowledge-Acquisition Tools and Performance Systems: PROTEGE-\{II\} Solutions to Sisyphus-2}},
year = {1994}
}
@article{journals/ese/KhoshgoftaarS03,
author = {Khoshgoftaar, Taghi M and Seliya, Naeem},
journal = {Empirical Software Engineering},
number = {3},
pages = {255--283},
title = {{Fault Prediction Modeling for Software Quality Estimation: Comparing Commonly Used Techniques}},
url = {http://dx.doi.org/10.1023/A:1024424811345},
volume = {8},
year = {2003}
}
@book{love93,
author = {Love, T},
publisher = {SIG Books Incorporated},
title = {{Object Lessons}},
year = {1993}
}
@inproceedings{curtis00,
author = {Curtis, S A and Mica, J and Nuth, J and Marr, G and Rilee, M and Bhat, M},
booktitle = {International Astronautical Federation, 51st Congress},
month = oct,
title = {{ANTS (Autonomous Nano-Technology Swarm): An Artificial Intelligence Approach to Asteroid Belt Resource Exploration}},
year = {2000}
}
@article{holzman87:scatter,
author = {Holzmann, Gerhard J},
journal = {IEEE Transactions on Software Engineering},
month = jun,
number = {6},
title = {{Automated protocal validation in Argos: Assertion proving and Scatter searching}},
volume = {13},
year = {1987}
}
@inproceedings{catlett91,
author = {Catlett, J},
booktitle = {Australian Workshop on Knowledge Acqusition for Knowledge-Based Systems, Pokolbin},
pages = {53--67},
title = {{Inductive learning from subsets or Disposal of excess training data considered harmful.}},
year = {1991}
}
@inproceedings{me01g,
author = {Menzies, T and Hu, Y},
booktitle = {First International Workshop on Model-based Requirements Engineering},
title = {{Constraining discussions in requirements engineering}},
year = {2001}
}
@article{cope97,
author = {Coplien, J O},
journal = {IEEE Software},
month = jan,
pages = {36--42},
title = {{Idioms and Patterns as Architectural Literature}},
year = {1997}
}
@article{Hughes1990,
author = {Hughes, John},
file = {:Users/timm/svns/doc/hughes90.pdf:pdf},
number = {April 1989},
pages = {98--107},
title = {{Why Functional Programming Matters}},
volume = {32},
year = {1990}
}
@article{Soni2008,
author = {Soni, Bhuman and Hingston, Philip},
doi = {10.1109/IJCNN.2008.4633818},
file = {::},
isbn = {978-1-4244-1820-6},
journal = {IJCNN '08},
month = jun,
pages = {363--369},
publisher = {Ieee},
title = {{Bots trained to play like a human are more fun}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4633818},
year = {2008}
}
@book{norvig03,
address = {Upper Saddle River, NJ, USA},
author = {Russell, Stuart J and Norvig, Peter and Candy, John F and Malik, Jitendra M and Edwards, Douglas D},
isbn = {0-13-103805-2},
pages = {97--104},
publisher = {Prentice-Hall, Inc.},
title = {{Artificial intelligence: a modern approach}},
year = {2003}
}
@book{Strauss1994,
annote = {unread},
author = {Strauss, S H and Ebenau, R G},
publisher = {McGraw Hill},
title = {{Software Inspection Process}},
year = {1994}
}
@inproceedings{kang95a,
author = {Kang, B H and Compton, P and Preston, P},
booktitle = {Proceedings 9th Banff Workshop on Knowledge Acquisition},
title = {{Multiple Classification Ripple Down Rules: Evaluation and Possibilities}},
year = {1995}
}
@inproceedings{men87,
author = {Menzies, T J and Worral, C},
booktitle = {Proceedings of AI '87},
title = {{Worlds in Prolog}},
year = {1987}
}
@article{frued92,
author = {Frueder, E C and Wallace, R J},
journal = {Artificial Intelligence},
pages = {21--70},
title = {{Partial Constraint Satisfaction}},
volume = {58},
year = {1992}
}
@article{giger96,
author = {Gigerenzer, G and Goldstein, D G},
journal = {Psychological Review},
number = {103},
pages = {650--669},
title = {{Reasoning the Fast and Frugal Way: Models of Bounded Rationality}},
year = {1996}
}
@article{Li2009,
author = {Li, Y and Xie, M and Goh, T},
doi = {10.1016/j.jss.2008.06.001},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {analogy based estimation,software cost estimation},
number = {2},
pages = {241--252},
title = {{A study of project selection and feature weighting for analogy based software cost estimation}},
volume = {82},
year = {2009}
}
@article{console91a,
author = {Console, L and Dupre, D T and Torasso, P},
journal = {Journal of Logic Programming},
pages = {661--690},
title = {{On the Relationship Between Abduction and Deduction}},
volume = {1},
year = {1991}
}
@book{mitchell97,
author = {Mitchell, T},
publisher = {McGraw-Hill},
title = {{Machine Learning}},
year = {1997}
}
@inproceedings{RANA2009,
address = {Berlin, Heidelberg},
author = {Rana, Zeeshan Ali and Awais, Mian Muhammad and Shamail, Shafay},
booktitle = {ICIC'09: Proceedings of the Intelligent computing 5th international conference on Emerging intelligent computing technology and applications},
isbn = {3-642-04019-5, 978-3-642-04019-1},
pages = {144--153},
publisher = {Springer-Verlag},
title = {{An FIS for early detection of defect prone modules}},
year = {2009}
}
@article{dolado00,
author = {Dolado, J J},
journal = {IEEE Transactions of Software Engineering},
number = {10},
pages = {1006--1021},
title = {{A validation of the component-based method for software size estimation}},
volume = {26},
year = {2000}
}
@article{koza03,
author = {Koza, J R and Keane, M A and Streeter, M J},
journal = {IEEE Intelligent Systems},
pages = {25--31},
title = {{What's AI Done for Me Lately? Genetic Programming's Human-Competitive Results}},
volume = {18},
year = {2003}
}
@inproceedings{rao95,
author = {Roa, A and Georgeff, M},
booktitle = {Proceedings of the First International Conference on Multi-Agent Systems, San Francisco, CA, June},
title = {{BDI agents: From theory to practice}},
year = {1995}
}
@article{cend87,
author = {Cendrowska, J},
journal = {International Journal of Man-Machine Studies},
number = {4},
pages = {349--370},
title = {{PRISM: An Algorithm for Inducing Modular Rules}},
volume = {27},
year = {1987}
}
@misc{allen90,
author = {{James Allen James Hendler}, Austin Tate},
isbn = {1558601309},
publisher = {Morgan Kaufmann},
title = {{Readings in Planning}},
year = {1990}
}
@incollection{joh83,
author = {Johnson, C K and Jordan, S R},
booktitle = {Building Expert Systems},
chapter = {10},
editor = {Hayes-Roth, F and Waterman, D A and Lenat, D B},
pages = {349--397},
publisher = {Addison-Wesley},
title = {{Emergency Management of Inland Oil and Hazardous Chemical Spills: A Case Study In Knowledge Engineering}},
year = {1983}
}
@misc{ithink94,
author = {Inc., High Performance Software},
title = {{iThink 3.0.5}},
year = {1994}
}
@article{boehm87,
author = {Boehm, B},
journal = {IEEE Software},
number = {5},
title = {{Industrial software metrics top 1O list}},
volume = {4},
year = {1987}
}
@inproceedings{me98e,
author = {Menzies, T J and Waugh, S},
booktitle = {Proceedings Pacific Knowledge Acquisition Workshop, Singapore, November, 1998},
title = {{More Results on the Practical Lower Limits of Test Set Size}},
year = {1998}
}
@inproceedings{cook71,
author = {Cook, S},
booktitle = {Proceedings of the 3rd ACM Symposium on the Theory of Computing},
pages = {151--158},
title = {{The complexity of theorem-proving procedures}},
year = {1971}
}
@article{dieng95,
author = {Dieng, R and Corby, O and Lapalut, S},
journal = {International Journal of Human-Computer Studies},
pages = {465--499},
title = {{Acquisition and Exploitation of Gradual Knowledge}},
volume = {42},
year = {1995}
}
@inproceedings{lutz93,
address = {San Diego, CA},
author = {Lutz, R R},
booktitle = {\{IEEE\} International Symposium on Requirements Engineering},
pages = {126--133},
publisher = {IEEE Computer Society Press},
title = {{Analyzing Software Requirements Errors in Safety-Critical, Embedded Systems}},
year = {1993}
}
@article{genes84,
author = {Genesereth, M R},
journal = {Artificial Intelligence},
pages = {411--436},
title = {{The \{U\}se of \{D\}esign \{D\}escriptions in \{A\}utomated \{D\}iagnosis}},
volume = {24},
year = {1984}
}
@article{hunter98,
author = {Hunter, A and Nuseibeh, B},
journal = {ACM Transactions on Software Engineering and Methodology},
number = {4},
pages = {335--367},
title = {{Managing Inconsistent Specifications: Reasoning, Analysis and Action}},
volume = {7},
year = {1998}
}
@inproceedings{frakes99,
author = {Frakes, W B},
booktitle = {Proceedings of WISR9: The 9th annual workshop on Institutionalizing Software Reuse},
title = {{Domain engineering education}},
year = {1999}
}
@article{waddington03,
author = {Waddington, David and Lardieri, Patrick},
journal = {IEEE Computer},
number = {2},
pages = {28--29},
title = {{Model-Centric Software Development}},
volume = {39},
year = {2006}
}
@article{dunsmore88,
author = {Dunsmore, H E},
journal = {IEEE Software},
month = may,
pages = {96--99},
title = {{Evidence Supports some Truisms, Belies Others. (Some Empirical Results concerning Software Development)}},
year = {1988}
}
@inproceedings{me91c,
author = {Menzies, T J},
booktitle = {Tools 3: Proceedings of the third International Technology of Object-Oriented Languages and; Systems conference},
publisher = {Prentice-Hall},
title = {{Beyond the MVC Triad: Quality Assurance via Interactive Specification Editors}},
year = {1991}
}
@inproceedings{jackson96,
author = {Jackson, D and Jha, S and Damon, C A},
booktitle = {Proc. ACM Conf. on Principles of Programming Languages},
month = jan,
title = {{Faster Checking of Software Specifications By Eliminating Isomorphs}},
year = {1996}
}
@inproceedings{hame93,
author = {Haynes, P and Menzies, T J},
booktitle = {Tools Pacific 1993},
organization = {Prentice Hall},
pages = {75--82},
title = {{C++ is \{B\}etter than \{S\}malltalk?}},
year = {1993}
}
@article{shn08,
author = {Shneiderman, B},
journal = {Science},
month = mar,
number = {7},
pages = {1349--1350},
title = {{Science 2.0}},
volume = {319},
year = {2008}
}
@inproceedings{briand00,
author = {Briand, L C and Langley, T and Wieczorek, I},
booktitle = {Proceedings of the 22nd International Conference on Software Engineering, Limerick, Ireland},
pages = {377--386},
title = {{A replicated assessment and comparison of common software cost modeling techniques}},
year = {2000}
}
@article{rubin92,
author = {Rubin, K S and Goldberg, A},
journal = {Communications of the ACM},
number = {9},
title = {{Object Behavior Analysis}},
volume = {35},
year = {1992}
}
@inproceedings{cheng95,
author = {Cheng, P C and Simon, H A},
booktitle = {Scientific Discovery and Creative Reasoning with Diagrams},
editor = {Smith, S M and Ward, T B and Finke, R A},
pages = {205--228},
publisher = {A Bradford Book},
title = {{The Creative Cognitive Approach}},
year = {1995}
}
@inproceedings{eshghi93,
author = {Eshghi, K},
booktitle = {\{IJCAI\} '93},
pages = {3--8},
title = {{A \{T\}ractable \{C\}lass of \{A\}bductive \{P\}roblems}},
volume = {1},
year = {1993}
}
@book{felt97,
author = {Feltovich, P J and Ford, K M and (eds), R R Hoffman},
publisher = {MIT PRess},
title = {{Expertise in Context}},
year = {1997}
}
@inproceedings{zhang95,
author = {Zhang, Z},
booktitle = {Fourth Asian Test Symposium},
title = {{An Approach to Hierarchy Model Checking via Evaluating CTL Hierarchically}},
year = {1995}
}
@article{me08e,
author = {Menzies, T and Milton, Z and Bener, A and Cukic, B and Gay, G and Jiang, Y and Turhan, B},
file = {::},
journal = {Submitted to IEEE TSE},
title = {{Overcoming Ceiling Effects in Defect Prediction}},
year = {2008}
}
@inproceedings{Abrahamsson2007,
author = {Abrahamsson, Pekka and Moser, Raimund and Pedrycz, Witold and Sillitti, Alberto and Succi, Giancarlo},
booktitle = {Empirical Software Engineering and Measurement, 2007. ESEM 2007. First International Symposium on},
doi = {10.1109/ESEM.2007.16},
file = {::},
isbn = {978-0-7695-2886-1},
issn = {1938-6451},
month = sep,
pages = {344--353},
publisher = {IEEE},
title = {{Effort prediction in iterative software development processesâIncremental versus global prediction models}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4343762},
year = {2007}
}
@inproceedings{nielsen94,
author = {Nielsen, J},
booktitle = {Usability Inspection Methods},
editor = {Nielsen, J and Mack, R L},
publisher = {John Wiley \& Sons},
title = {{Heuristic Evaluation}},
year = {1994}
}
@book{boss94,
annote = {ISBN 1-56881-033-4},
author = {Bossel, H},
publisher = {A.K. Peters Ltd},
title = {{Modeling and Simulations}},
year = {1994}
}
@inproceedings{fen97b,
author = {Fensel, D and Schonegge, A},
booktitle = {Proceedings of the 12th IEEE International Conference on Automated Software Engineering (ASEC-97), Incline Village, Nevada, Nov 3-5},
title = {{Using KIV to Specify and Verify Architecture of Knowledge-Based Systems}},
year = {1997}
}
@inproceedings{bobntim1,
author = {Cohen, R F and Menzies, T J},
booktitle = {Software Education Conference (SRIG-ET'94)},
pages = {71--76},
title = {{Providing \{S\}oftware \{E\}ngineering \{S\}tudents with an \{E\}xperience in "\{B\}ig-\{C\}omputing"}},
year = {1995}
}
@article{me98b,
author = {Menzies, T J},
journal = {International Journal of Human-Computer Studies},
pages = {867--893},
title = {{Towards Situated Knowledge Acquisition}},
volume = {49},
year = {1998}
}
@phdthesis{benj93,
author = {Benjamins, R},
school = {University of Amsterdam},
title = {{Problem Solving Methods for Diagnosis}},
year = {1993}
}
@inproceedings{PORT2008,
address = {New York, NY, USA},
author = {Port, Dan and Korte, Marcel},
booktitle = {ESEM '08: Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
doi = {http://doi.acm.org/10.1145/1414004.1414015},
isbn = {978-1-59593-971-5},
pages = {51--60},
publisher = {ACM},
title = {{Comparative studies of the model evaluation criterions mmre and pred in software cost estimation research}},
year = {2008}
}
@article{ElEmam2001,
author = {{El Emam}, K. and Benlarbi, S. and Goel, N. and Rai, S.N.},
doi = {10.1109/32.935855},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/El Emam et al. - 2001 - The confounding effect of class size on the validity of object-oriented metrics.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
month = jul,
number = {7},
pages = {630--650},
title = {{The confounding effect of class size on the validity of object-oriented metrics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=935855},
volume = {27},
year = {2001}
}
@inproceedings{me05b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05sawtooth.pdf\}},
author = {Menzies, Tim and Orrego, Andres},
title = {{Incremental Discreatization and Bayes Classifiers Handles Concept Drift and Scaled Very Well}},
year = {2005}
}
@inproceedings{pos97,
author = {Pos, A and Akkermans, H and Straatman, R and Wijngaards, N},
booktitle = {Workshop on Problem-Solving Methods for Knowledge-based Systems, IJCAI '97, August 23.},
title = {{Redesign Problem Solving}},
year = {1997}
}
@misc{bsc99,
author = {Page, Web},
title = {{No Title}}
}
@misc{polyspace,
title = {{Polyspace Verifier\^{}\{$\backslash$mbox $\backslash$textregistered\}}},
url = {$\backslash$url\{http://www.di.ens.fr/~cousot/projects/DAEDALUS/synthetic\_summary/POLYSPACE/polyspace-daedalus.htm\}},
year = {2005}
}
@phdthesis{chulani99a,
annote = {Available on-line at $\backslash$url\{http://citeseer.ist.psu.edu/devnani-chulani99bayesian.html\}},
author = {Devnani-Chulani, Sunita},
school = {Graduate School, University of Southern California},
title = {{Bayesian Analysis of Software Cost and Quality Models}},
year = {1999}
}
@article{chandra92,
author = {Chandrasekaran, B and Johnson, T R and Smith, J W},
journal = {Communications of the ACM},
number = {9},
pages = {124--137},
title = {{Task Structure Analysis for Knowledge Modeling}},
volume = {35},
year = {1992}
}
@article{paulk93,
author = {Paulk, M C and Curtis, B and Chrissis, M B and Weber, C V},
file = {::},
journal = {IEEE Software},
month = jul,
number = {4},
pages = {18--27},
title = {{Capability Maturity Model, Version 1.1}},
volume = {10},
year = {1993}
}
@article{okeefe87,
author = {R.M., R M O'Keefe and Balci, O and Smith, E P},
journal = {IEEE Expert},
pages = {81--89},
title = {{Validating Expert System Performance}},
volume = {87},
year = {1987}
}
@article{Abrahamsson2007a,
author = {Abrahamsson, Pekka and Moser, Raimund and Pedrycz, Witold and Sillitti, Alberto and Succi, Giancarlo},
doi = {10.1109/ESEM.2007.16},
file = {::},
isbn = {978-0-7695-2886-1},
journal = {First International Symposium on Empirical Software Engineering and Measurement (ESEM 2007)},
month = sep,
pages = {344--353},
publisher = {Ieee},
title = {{Effort Prediction in Iterative Software Development Processes -- Incremental Versus Global Prediction Models}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4343762},
year = {2007}
}
@incollection{easter07,
author = {Easterbrook, S M and Singer, J and Storey, M and Damian, D},
booktitle = {Guide to Advanced Empirical Software Engineering},
editor = {Shull, F and Singer, J},
publisher = {Springer},
title = {{Selecting Empirical Methods for Software Engineering Research}},
year = {2007}
}
@misc{bse,
author = {Cohen, R F},
title = {{A \{R\}eport on the \{B\}achelor of \{E\}ngineering (\{S\}oftware \{E\}ngineering) \{D\}egree at the \{U\}niversity of \{N\}ewcastle}}
}
@article{cohen98,
author = {Cohen, Paul and Schrag, Robert and Jones, Eric and Pease, Adam and Lin, Albert and Starr, Barbara and Gunning, David and Burke, Murray},
journal = {AI Magazine},
number = {4},
pages = {25--49},
title = {{The DARPA High-Performance Knowledge Bases Project}},
volume = {19},
year = {1998}
}
@inproceedings{ostrand04,
address = {New York, NY, USA},
author = {Ostrand, Thomas J and Weyuker, Elaine J and Bell, Robert M},
booktitle = {ISSTA '04: Proceedings of the 2004 ACM SIGSOFT international symposium on Software testing and analysis},
pages = {86--96},
publisher = {ACM},
title = {{Where the bugs are}},
year = {2004}
}
@book{simon82,
author = {Simon, H A},
publisher = {MIT Press},
title = {{Models of bounded rationality}},
volume = {2},
year = {1982}
}
@inproceedings{me95zb,
author = {Menzies, T J and Compton, P},
booktitle = {Proceedings of the 9th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge Based Systems,},
title = {{The (Extensive) Implications of Evaluation on the Development of Knowledge-Based Systems}},
year = {1995}
}
@inproceedings{drummond03,
author = {Drummond, C and Holte, R C},
booktitle = {Workshop on Learning from Imbalanced Datasets II},
title = {{C4.5, class imbalance, and cost sensitivity: why under-sampling beats over-sampling}},
year = {2003}
}
@article{goldin98,
author = {{D. Goldin S. Venneri}, A Noor},
journal = {Mechanical Engineering},
month = feb,
pages = {62--69},
title = {{A New Frontier in Engineering}},
year = {1998}
}
@inproceedings{port08,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08simrequire.pdf\}},
author = {Port, D and Olkov, A and Menzies, T},
booktitle = {IEEE ASE'08},
title = {{Using Simulation to Investigate Requirements Prioritization Strategies}},
year = {2008}
}
@book{tomah89,
month = nov,
title = {{Tomahawk Nuclear Safety and Certification Program}},
year = {1989}
}
@inproceedings{phipps95,
author = {Phipps, G},
booktitle = {Tools Pacific 18},
pages = {253--264},
title = {{The Structure of Large C++ Programs}},
year = {1995}
}
@phdthesis{easter91b,
author = {Easterbrook, S},
school = {Imperial College of Science Technology and Medicine, University of London},
title = {{Elicitation of Requirements from Multiple Perspectives}},
year = {1991}
}
@inproceedings{WEISS07,
address = {Washington, DC, USA},
author = {Weiss, Cathrin and Premraj, Rahul and Zimmermann, Thomas and Zeller, Andreas},
booktitle = {MSR '07: Proceedings of the Fourth International Workshop on Mining Software Repositories},
doi = {http://dx.doi.org/10.1109/MSR.2007.13},
isbn = {0-7695-2950-X},
pages = {1},
publisher = {IEEE Computer Society},
title = {{How Long Will It Take to Fix This Bug?}},
year = {2007}
}
@inproceedings{coarfa00,
annote = {Availabe from $\backslash$url\{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.3662\}},
author = {Coarfa, Cristian and Demopoulos, Demetrios D and San, Alfonso and Aguirre, Miguel and Subramanian, Devika and Vardi, Moshe Y},
booktitle = {In Principles and Practice of Constraint Programming},
pages = {143--159},
title = {{Random 3-SAT: The plot thickens}},
year = {2000}
}
@article{Gayler2006a,
archivePrefix = {arXiv},
arxivId = {arXiv:math/0606452v1},
author = {Gayler, Ross W.},
doi = {10.1214/088342306000000051},
eprint = {0606452v1},
file = {:Users/timm/svns/doc/gaylor06.pdf:pdf},
issn = {0883-4237},
journal = {Statistical Science},
month = feb,
number = {1},
pages = {19--23},
primaryClass = {arXiv:math},
title = {{Comment: Classifier Technology and the Illusion of ProgressâCredit Scoring}},
url = {http://projecteuclid.org/Dienst/getRecord?id=euclid.ss/1149600841/},
volume = {21},
year = {2006}
}
@article{france03,
author = {France, R and Ghosh, S and Song, E and Kim, D},
journal = {IEEE Software},
number = {5},
pages = {52--58},
title = {{A Metamodeling Approach to Pattern-Based Moel Refractoringt}},
volume = {20},
year = {2003}
}
@inproceedings{sammut86,
author = {Sammut, C and Banerji, R B},
booktitle = {Machine Learning: An Artificial Intelligence Approach},
editor = {Michalski, R S and Carbonell, J G and Mitchell, T M},
pages = {167--192},
publisher = {Los Altos, California: Morgan Kaufmann},
title = {{Learning Concepts by Asking Questions}},
volume = {2},
year = {1986}
}
@misc{boxing,
annote = {$\backslash$url\{http://en.wikipedia.org/wiki/List\_of\_Heavyweight\_Champions\}},
title = {{List of Heavyweight Champions}}
}
@article{chen95,
author = {Chen, I and Tsao, T},
journal = {IEEE Transactions on Reliability},
month = mar,
pages = {54--62},
title = {{A Reliability Model for Real-Time Rule-Based Expert Systems}},
year = {1995}
}
@article{me07d,
annote = {$\backslash$url\{http://menzies.us/pdf/07strange.pdf\}},
author = {Menzies, T and D.Owen and Richardson, J},
journal = {IEEE Computer},
title = {{The Strangest Thing About Software}},
year = {2007}
}
@inproceedings{cox86,
author = {Cox, P T and Pietrzykowski, T},
booktitle = {8th International Conference on Automated Deduction},
pages = {608--621},
publisher = {Springer-Verlag},
title = {{Causes for Events: Their Computation and Applications}},
year = {1986}
}
@inproceedings{zannier06,
author = {{C. Zannier G. Melnik} and Maurer, F},
booktitle = {ICSE'06},
title = {{On the Success of Empirical Studies in the International Conference on Software Engineering}},
year = {2006}
}
@incollection{lutz03c,
booktitle = {25th Int'l Conf on Software Eng (ICSE'03),Portland, Oregon},
month = may,
title = {{Requirements Discovery During the Testing of Safety-Critical Software}},
year = {2003}
}
@inproceedings{Hinneburg1998a,
author = {Hinneburg, A. and Keim, D.A.},
booktitle = {KDD '98},
file = {:Users/timm/svns/doc/hinneburg98.pdf:pdf},
keywords = {Grid cluster},
publisher = {Bibliothek der Universit$\backslash$$\backslash$"at Konstanz},
title = {{An efficient approach to clustering in large multimedia databases with noise}},
url = {http://www.aaai.org/Papers/KDD/1998/KDD98-009.pdf},
year = {1998}
}
@inproceedings{me01e,
author = {Menzies, T and Kiper, J D},
booktitle = {ASE-2001},
title = {{Better reasoning about software engineering activities}},
year = {2001}
}
@misc{pearce00,
author = {Pearce, A and Heinz, C and Goss, S},
booktitle = {AOD technical report, Australian DSTO},
title = {{Meeting plan recognition requirements for real-time air-mission simulations}},
year = {2000}
}
@article{born81,
author = {Borning, A},
journal = {ACM Transactions on Programming Languages and Systems},
month = oct,
number = {4},
pages = {353--387},
title = {{The Programming Language Aspects of ThingLab: a Constraint-Oriented Simulation Laboratory}},
volume = {3},
year = {1981}
}
@misc{leiws,
annote = {$\backslash$url\{http://en.wikipedia.org/wiki/Lennox\_Lewis\}},
title = {{Lennox Lewis}}
}
@article{chang74,
author = {Chang, C L},
journal = {IEEE Trans. on Computers},
pages = {1179--1185},
title = {{Finding Prototypes for Nearest Neighbor Classifiers}},
year = {1974}
}
@book{sch99,
editor = {Schreiber, Guus},
isbn = {0262193000},
publisher = {MIT Press},
title = {{Knowledge Engineering and Management : The CommonKADS Methodology}},
year = {1999}
}
@inproceedings{KAMEI08,
address = {New York, NY, USA},
author = {Kamei, Yasutaka and Keung, Jacky and Monden, Akito and Matsumoto, Ken-ichi},
booktitle = {ESEM '08: Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
doi = {http://doi.acm.org/10.1145/1414004.1414064},
isbn = {978-1-59593-971-5},
pages = {312--314},
publisher = {ACM},
title = {{An over-sampling method for analogy-based software effort estimation}},
year = {2008}
}
@article{hart68,
author = {Hart, P E and Nilsson, N J and Raphael, B},
journal = {IEEE Transactions on Systems Science and Cybernetics},
pages = {100--107},
title = {{A formal basis for the heuristic determination of minimum cost paths}},
volume = {4},
year = {1968}
}
@phdthesis{rela04,
author = {Rela, L},
school = {Department of Information Technology},
title = {{Evolutionary computing in search-based software engineering}},
year = {2004}
}
@inproceedings{jeff88,
author = {Jeffery, D R and Basili, V R},
booktitle = {Proceedings of the 10th International Conference on Software Engineering},
pages = {187--201},
title = {{Validating the TAME Resource Data Model}},
year = {1988}
}
@phdthesis{Muller86,
author = {Muller, H A},
school = {Rice University},
title = {{Rigi - A Model for Software System Construction, Integration, and Evaluation based on Module Interface Specifications}},
year = {1986}
}
@article{bahill95,
author = {Bahill, A T and Bharathan, K and Curlee, R F},
journal = {IEEE Transactions on Systems, Man, and Cybernetics},
month = dec,
number = {12},
pages = {1535--1542},
title = {{How the Testing Techniques for a Decision Support Systems Changed Over Nine Years}},
volume = {25},
year = {1995}
}
@misc{NSB06,
author = {(U.S.), National Science Board},
keywords = {Scientists Employment United States. Engineers Emp},
publisher = {National Science Foundation, National Science Board},
title = {{Science and engineering indicators 2006}}
}
@misc{smythe92,
annote = {Personal communication},
author = {Smythe, G A},
title = {{Concerning errors in the Smythe '87 model.}},
year = {1992}
}
@inproceedings{pople77,
author = {Pople, H E},
booktitle = {IJCAI '77},
pages = {1030--1037},
title = {{The Formation of Composite Hypothess in Diagnositic Problem Soving: An Exercise in Synthetic Reasoning}},
year = {1977}
}
@article{kahn85,
author = {Kahn, G and Nowlan, S and McDermott, J},
journal = {IEEE Trsansactions on Pattern Analysis and Machine Intelligence},
pages = {511--522},
title = {{Strategies for Knowledge Acquisition}},
volume = {Vol. PAMI-},
year = {1985}
}
@article{searle80,
author = {Searle, J R},
journal = {The Behavioral and Brain Sciences},
pages = {417--457},
title = {{Minds, \{B\}rain, and \{P\}rograms}},
volume = {3},
year = {1980}
}
@inproceedings{CMR92,
author = {Consens, M and Mendelzon, A and Ryman, A},
booktitle = {14th International Conference on Software Engineering (Melbourne)},
pages = {11--15},
title = {{Visualizing and Querying Software Structures}},
year = {1992}
}
@book{Mills83,
author = {Mills, H},
publisher = {Little, Brown},
title = {{Software Productivity}},
year = {1983}
}
@article{kitch07,
author = {Kitchenham, B A and Mendes, E and Travassos, G H},
file = {::},
journal = {IEEE Transactions on Software Engineering},
month = may,
pages = {316--329},
title = {{Cross- vs. Within-Company Cost Estimation Studies: A Systematic Review}},
year = {2007}
}
@inproceedings{clarke91,
author = {{H.H. Clarke}, S Brennan},
booktitle = {Perspectives on Socially Shared Cognition},
publisher = {American Psychological Association},
title = {{Grounding in Communication}},
year = {1991}
}
@article{briemann01,
author = {Breimann, L},
journal = {Machine Learning},
month = oct,
pages = {5--32},
title = {{Random Forests}},
year = {2001}
}
@article{Dasarathy1994,
author = {Dasarathy, B.V.},
doi = {10.1109/21.278999},
file = {::},
issn = {00189472},
journal = {IEEE Transactions on Systems, Man, and Cybernetics},
month = mar,
number = {3},
pages = {511--517},
title = {{Minimal consistent set (MCS) identification for optimal nearest neighbor decision systems design}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=278999},
volume = {24},
year = {1994}
}
@misc{codesurfer,
title = {{CodeSurfer\^{}\{$\backslash$mbox $\backslash$textregistered\}}},
url = {$\backslash$url\{http://www.grammatech.com/products/codesurfer\}},
year = {2005}
}
@inproceedings{me03p,
author = {Liu, Yan and Gururajan, Srikanth and Cukic, Bojan and Menzies, Tim and Napolitano, Marcello},
booktitle = {IEEE Tools with AI},
title = {{Validating an Online Adaptive System Using SVDD}},
year = {2003}
}
@article{jones96a,
author = {Jones, B and Sthamer, H.-H. and Eyres, D},
journal = {ï¿½Software Engineering Journalï¿½},
pages = {299--306},
title = {{Automatic structural tsting using genetic algorithms}},
volume = {11},
year = {1996}
}
@inproceedings{glover93tabu,
address = {Oxford, England},
author = {Glover, Fred and Laguna, M},
booktitle = {Modern Heuristic Techniques for Combinatorial Problems},
editor = {Reeves, C},
publisher = {Blackwell Scientific Publishing},
title = {{Tabu Search}},
url = {citeseer.ist.psu.edu/glover97tabu.html},
year = {1993}
}
@misc{murph95a,
author = {Murphy, G C and Notkin, D and Lan, E S C},
institution = {Department of Computer Science \& Engineering, University of Washington},
number = {TR95-8-01},
title = {{An Empirical Study of Static Call Graph Extractors}},
year = {1995}
}
@inproceedings{me09i,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09value.pdf\}},
author = {Green, P and Menzies, T and Williams, S and El-waras, O},
booktitle = {IEEE ASE'09},
title = {{Understanding the Value of Software Engineering Technologies}},
year = {2009}
}
@inproceedings{me01a,
author = {Menzies, T and Cukic, B},
booktitle = {AAAI Stanford Spring Symposium on Model-based Validation of AI Systems},
title = {{Average Case Coverage for Validation of AI Systems}},
year = {2001}
}
@inproceedings{me03i,
author = {Cornford, S L and Feather, M S and Dunphy, J R and Salcedo, J and Menzies, T},
booktitle = {Proceedings of the IEEE Aerospace Conference, Big Sky, Montana},
title = {{Optimizing Spacecraft Design Optimization Engine Development: Progress and Plans}},
year = {2003}
}
@misc{lee04,
author = {Lee, S C and Santo, A G},
title = {{Tradeoffs in functional allocation between spacecraft autonomy and ground operations: the \{NEAR\} (\{N\}ear \{E\}arth \{A\}steroid \{R\}endezvous) \{E\}xperience, \{J\}ohn \{H\}opkins \{APL\}, \{A\}ugust 9-12, \{U\}tah \{S\}tate \{U\}niversity , \{E\}ccles \{C\}onference \{C\}enter, \{L}}},
year = {2004}
}
@book{garey79,
author = {Garey, M R and Johnson, D S},
publisher = {Freeman},
title = {{Computers and Intractability: A Guide to the Theory of NP-Completeness}},
year = {1979}
}
@inproceedings{myers92,
author = {Myers, K L and Konolige, K},
booktitle = {AAAI Spring Symposium on Reasoning with Diagrammatic Representations},
editor = {Narayanan, N H},
pages = {96--101},
title = {{Integrating Analogical and Sentential Resoning for Perception}},
year = {1992}
}
@misc{woller96,
author = {Woller, J},
title = {{The Basics of Monte Carlo Simulations}},
year = {1996}
}
@inproceedings{bricc00,
author = {{G. Bricconi E. Di Nitto}, E Tracanella},
booktitle = {Proceedings of the 10th International Workshop on Software Specification and Design (IWSSD-10), San Diego, USA},
month = nov,
title = {{Issues in analyzing the behavior of event dispatching systems}},
year = {2000}
}
@inproceedings{lowrey98,
author = {Lowry, M and Boyd, M and Kulkarni, D},
booktitle = {Proceedings, ASE'98: Automated Software Engineering},
pages = {322--331},
title = {{Towards a Theory for Integration of Mathematical Verification and Empirical Testing}},
year = {1998}
}
@inproceedings{satoh01,
author = {Satoh, K},
booktitle = {Handbook of Software and Knowledge Engineering},
editor = {Chung, C K},
title = {{Nonmonotonic reasoning and consistency requirements in SE}},
volume = {2},
year = {2001}
}
@article{wallace99,
author = {Wallace, C S and Dowe, D L},
journal = {The Computer Journal},
title = {{Minimum Message Length and Kolmogorov Complexity}},
year = {1999}
}
@inproceedings{CAGLAYAN2009,
address = {Washington, DC, USA},
author = {Caglayan, Bora and Bener, Ayse and Koch, Stefan},
booktitle = {FLOSS '09: Proceedings of the 2009 ICSE Workshop on Emerging Trends in Free/Libre/Open Source Software Research and Development},
doi = {http://dx.doi.org/10.1109/FLOSS.2009.5071357},
isbn = {978-1-4244-3720-7},
pages = {31--36},
publisher = {IEEE Computer Society},
title = {{Merits of using repository metrics in defect prediction for open source projects}},
year = {2009}
}
@article{glass98,
author = {Glass, R L},
journal = {Communciation of the ACM},
number = {12},
title = {{How not to prepare for a consulting assignment and other ugly consultancy truths}},
volume = {41},
year = {1998}
}
@article{dekleer87,
author = {DeKleer, J and Williams, B C},
journal = {Artificial Intelligence},
pages = {97--130},
title = {{Diagnosing \{M\}ultiple \{F\}aults}},
volume = {32},
year = {1987}
}
@article{dijk59,
author = {Dijkstra, E W},
journal = {Numerische Mathematik},
pages = {269--271},
title = {{A note on two problems in connexion with graphs}},
volume = {1},
year = {1959}
}
@article{Hagelb2007,
author = {Hagelb, Johan and Johansson, Stefan J},
file = {::},
journal = {AAIDE (Fourth)},
keywords = {agents,behavior,computer games,disciplinary topics and applications,multi-,swarm intelligence and emergent},
pages = {42--47},
title = {{The Rise of Potential Fields in Real Time Strategy Bots}},
year = {2007}
}
@inproceedings{har97,
author = {Hawryszkiewycz, I T},
booktitle = {Proceedings of the Inaugural Conference of Informatics in Multinational Enterprises, Washington, D.C, OCtober 12-13, 1997},
title = {{A Framework for Strategic Planning for Communications Support}},
year = {1997}
}
@article{kuipers93,
author = {Kuipers, B J},
journal = {Artificial Intelligence},
pages = {125--132},
title = {{Reasoning with Qualitative Models}},
volume = {59},
year = {1993}
}
@article{JIA2009,
address = {Los Alamitos, CA, USA},
author = {Jia, Hao and Shu, Fengdi and Yang, Ye and Li, Qi},
doi = {http://doi.ieeecomputersociety.org/10.1109/ICSM.2009.5306382},
isbn = {978-1-4244-4897-5},
journal = {Software Maintenance, IEEE International Conference on},
pages = {519--522},
publisher = {IEEE Computer Society},
title = {{Data transformation and attribute subset selection: Do they help make differences in software failure prediction?}},
volume = {0},
year = {2009}
}
@article{fink94,
author = {Finkelstein, A and Gabbay, D and Hunter, A and Kramer, J and Nuseibeh, B},
journal = {IEEE Transactions on Software Engineering},
number = {8},
pages = {569--578},
title = {{Inconsistency Handling In Multi-Perspective Specification}},
volume = {20},
year = {1994}
}
@article{Larsen1999b,
address = {New York, New York, USA},
author = {Larsen, Bjornar and Aone, Chinatsu},
doi = {10.1145/312129.312186},
file = {:Users/timm/svns/doc/larsen99.pdf:pdf},
isbn = {1581131437},
journal = {Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '99},
keywords = {clustering,multi-document summarization,text mining},
pages = {16--22},
publisher = {ACM Press},
title = {{Fast and effective text mining using linear-time document clustering}},
url = {http://portal.acm.org/citation.cfm?doid=312129.312186},
year = {1999}
}
@article{pendharkar05,
address = {Piscataway, NJ, USA},
author = {Pendharkar, Parag C and Subramanian, Girish H and Rodger, James A},
doi = {http://dx.doi.org/10.1109/TSE.2005.75},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {7},
pages = {615--624},
publisher = {IEEE Press},
title = {{A Probabilistic Model for Predicting Software Development Effort}},
volume = {31},
year = {2005}
}
@book{bratko01,
author = {Bratko, I},
publisher = {Addison-Wesley},
title = {{Prolog Programming for Artificial Intelligence. (third edition)}},
year = {2001}
}
@article{chen97,
author = {Chen, I},
journal = {IEEE Transactions on Reliability},
number = {1},
pages = {81--87},
title = {{Effect of Parallel Planning on the System Reliability of Real-Time Expert Systems}},
volume = {46},
year = {1997}
}
@book{fen95b,
author = {Fensel, D},
publisher = {Kluwer Academic Publisher},
title = {{The Knowledge Acquisition And Representation Language KARL}},
year = {1995}
}
@inproceedings{edelamp01,
author = {Edelkamp, S and Lafuente, L and Leue, S},
booktitle = {Proc. AAAI Stanford Spring Symposium},
title = {{Protocol Verification with Heuristic Search}},
year = {2001}
}
@inproceedings{lutz99,
author = {Lutz, R and Woodhouse, R},
booktitle = {1st International Software Assurance Certification Conference (ISACC'99)},
title = {{Bi-directional Analysis for Certification of Safety-Critical Software}},
year = {1999}
}
@article{fenton07,
author = {Fenton, Norman E and Neil, Martin and Caballero, Jose Galan},
journal = {IEEE Trans. on Knowl. and Data Eng.},
number = {10},
pages = {1420--1432},
title = {{Using Ranked Nodes to Model Qualitative Judgments in Bayesian Networks}},
volume = {19},
year = {2007}
}
@misc{prevue,
author = {$\backslash$urlhttp://www.pacorp.com, Performance Awareness Corporation},
title = {{preVue-C/S}},
year = {1998}
}
@book{boehm81,
author = {Boehm, B},
publisher = {Prentice Hall},
title = {{Software Engineering Economics}},
year = {1981}
}
@inproceedings{me03k,
author = {Menzies, T and Stefano, J S Di and Chapman, M},
booktitle = {IEEE Metrics '03},
title = {{Learning Early Lifecycle \{IVV\} Quality Indicators}},
year = {2003}
}
@article{kern84,
author = {Kernigham, B W},
journal = {IEEE Transactions on Software Engineering},
pages = {513--518},
title = {{The Unix System and Software Reusability}},
volume = {SE-10},
year = {1984}
}
@article{wallace89,
author = {Wallace, D R and Fujii, R U},
journal = {IEEE Software},
month = may,
pages = {10--17},
title = {{Software Verification and Validation: An Overview}},
year = {1989}
}
@misc{fea03c,
author = {Feather, M S and Menzies, T and Connelly, J R},
booktitle = {Proceedings of the 11th IEEE International Requirements Engineering Conference; Monterey Bay, California},
month = sep,
title = {{Relating Practitioner Needs to Research Activities}},
year = {2003}
}
@article{holte93,
author = {Holte, R C},
file = {::},
journal = {Machine Learning},
pages = {63},
title = {{Very Simple Classification Rules Perform Well on Most Commonly Used Datasets}},
volume = {11},
year = {1993}
}
@inproceedings{me10c,
author = {Kocaguneli, Ekrem and Gay, Gregory and Menzies, Tim and Yang, Ye and Keung, Jacky W},
booktitle = {IEEE ASE'10},
file = {::},
title = {{When to Use Data from Other Projects for Effort Estimation}},
year = {2010}
}
@article{agre90,
author = {Agre, P H},
journal = {Artificial Intelligence},
pages = {369--384},
title = {{Book Review: Lcy A. Scuhman, Plans and Situated Actions: The Problems of Human-Machine Communication}},
volume = {43},
year = {1990}
}
@book{pressman96,
author = {Pressman, R S},
publisher = {McGraw-Hill},
title = {{Software Engineering: A Practitioner's Approach}},
year = {2002}
}
@book{pressman04,
author = {Pressman, R S},
publisher = {McGraw-Hill},
title = {{Software Engineering: A Practitioner's Approach (6th edition)}},
year = {2004}
}
@inproceedings{TOSUN2008,
address = {New York, NY, USA},
author = {Tosun, Ayse and Turhan, Burak and Bener, Ayse},
booktitle = {ESEM '08: Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
doi = {http://doi.acm.org/10.1145/1414004.1414066},
isbn = {978-1-59593-971-5},
pages = {318--320},
publisher = {ACM},
title = {{Ensemble of software defect predictors: a case study}},
year = {2008}
}
@article{bent97,
author = {Bentley, R and Appelt, W and Busbach, U and Hinrichs, E and Kerr, D and Sikkel, K and Trevor, J and Woetzel, G},
journal = {International Journal of Human Computer Studies},
month = jun,
number = {6},
pages = {827--846},
title = {{Basic Support for Cooperative Work on the World Wide Web}},
volume = {46},
year = {1997}
}
@inproceedings{lee96,
author = {Lee, M and Compton, P},
booktitle = {Proceedings of the 3rd World Congress on Expert System (WcES'96)},
title = {{From Heuristic to Causality}},
year = {1996}
}
@article{gaddam07,
author = {Gaddam, S R and Phoha, V V and Balagani, K S},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = mar,
number = {3},
title = {{K-Means+ID3: A Novel Method for Supervised Anomaly Detection by Cascading K-Means Clustering and ID3 Decision Tree Learning Methods}},
volume = {19},
year = {2007}
}
@misc{fenton07b,
author = {Fenton, N},
title = {{Keynote address, PROMISE'07}},
year = {2007}
}
@article{schooff99,
author = {Schooff, R M and Haimes, Y Y},
journal = {IEEE Transactions of Systems, Man, and Cybernetics},
number = {2},
pages = {272--284},
title = {{Dynamic Multistage Software Estimation}},
volume = {29},
year = {1999}
}
@phdthesis{milton08,
author = {Milton, Z A},
school = {West Virginia University},
title = {{WHICH rules}},
year = {2008}
}
@article{stukes99,
author = {Chulani, S and Boehm, B and Steece, B},
journal = {Journal of Parametrics},
number = {2},
pages = {175--188},
title = {{From Multiple Regression to Bayesian Analysis for Calibrating \{COCOMO\} \{II\}}},
volume = {15},
year = {1999}
}
@book{deb98e,
author = {Debenham, J},
publisher = {Springer-Verlag},
title = {{Knowledge Engineering: Unifying Knowledge Base and Database Design}},
year = {1998}
}
@article{darwiche02,
annote = {Available from $\backslash$url\{ww.jair.org/media/989/live-989-2063-jair.pdf\}},
author = {Darwiche, A and Marquis, P},
journal = {Journal of Artifical Intelligence Research},
pages = {229--264},
title = {{A Knowledge Compulation Map}},
volume = {17},
year = {2002}
}
@inproceedings{fea02a,
author = {Feather, M S and Menzies, T},
booktitle = {IEEE Joint Conference On Requirements Engineering ICRE'02 and RE'02, 9-13th September, University of Essen, Germany},
file = {::},
title = {{Converging on the Optimal Attainment of Requirements}},
year = {2002}
}
@misc{standish95,
title = {{The \{S\}tandish \{G\}roup \{R\}eport: \{C\}haos}},
year = {1995}
}
@article{char94,
author = {Charniak, E and Shimony, S E},
journal = {Artificial Intelligence},
pages = {345--374},
title = {{Cost-based abduction and MAP explanation}},
year = {1994}
}
@article{Lua,
author = {Lu, Jingli and Yang, Ying and Webb, Geoffrey I},
file = {:Users/timm/svns/doc/webb08.pdf:pdf},
journal = {Learning},
title = {{Incremental Discretization for Na\"{\i}ve-Bayes Classifier}}
}
@misc{me01d,
author = {Menzies, T and Kiper, J D},
file = {::},
title = {{Machine Learning for Requirements Engineering}},
year = {2001}
}
@article{Wong2009,
author = {Wong, W. Eric and Tse, T.H. and Glass, Robert L. and Basili, Victor R. and Chen, T.Y.},
doi = {10.1016/j.jss.2009.06.018},
file = {:Users/timm/svns/doc/wong10.pdf:pdf},
issn = {01641212},
journal = {Journal of Systems and Software},
month = aug,
number = {8},
pages = {1370--1373},
title = {{An assessment of systems and software engineering scholars and institutions (2002â2006)}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0164121209001265},
volume = {82},
year = {2009}
}
@misc{jorgensen05,
author = {Jorgensen, M and Shepperd, M},
month = jan,
title = {{A Systematic Review of Software Development Cost Estimation Studies}},
year = {2007}
}
@article{Buse,
author = {Buse, Raymond P L and Zimmermann, Thomas},
file = {::},
title = {{Information Needs for Software Development Analytics}}
}
@inproceedings{hori98,
author = {Hori, M and Yoshida, T},
booktitle = {Submitted to the Banff KA workshop, 1998.},
title = {{Measuring the evolution of a knowledge library: Assessment study}},
year = {1998}
}
@article{boehm01,
author = {Boehm, B and Basili, V R},
journal = {IEEE Software},
month = jan,
pages = {135--137},
title = {{Software Defect Reduction Top 10 list}},
year = {2001}
}
@book{der96,
author = {Deransart, P and Ed-Dbali, A and Cervoni, L},
publisher = {Sprunger},
title = {{Prolog: The Standard}},
year = {1996}
}
@inproceedings{JALALI2007,
address = {Washington, DC, USA},
author = {Jalali, Omid and Menzies, Tim and Baker, Dan and Hihn, Jairus},
booktitle = {PROMISE '07: Proceedings of the Third International Workshop on Predictor Models in Software Engineering},
doi = {http://dx.doi.org/10.1109/PROMISE.2007.3},
isbn = {0-7695-2954-2},
pages = {7},
publisher = {IEEE Computer Society},
title = {{Column Pruning Beats Stratification in Effort Estimation}},
year = {2007}
}
@inproceedings{kar96,
author = {Karsenty, Laurent},
booktitle = {CHI '96: Electronic Proceedings $\backslash$url\{http://www.acm.org/sigchi/chi96/proceedings/papers/Karsenty/lk\_txt.htm\}},
editor = {Bilger, Ralf and Guest, Steve and Taube, Michael J},
title = {{An Empirical Evaluation of Design Rationale Documents}},
year = {1996}
}
@article{clarke03,
author = {Clarke, J and Dolado, J J and Harman, M and Hierons, R and Jones, B and Lumkin, M and Mitchell, B and Mancoridis, S and Rees, K and Roper, M and Shepperd, M},
journal = {ï¿½IEE Proceedings-Softwareï¿½},
number = {3},
pages = {161--175},
title = {{Reformulating software engineering as a search problem}},
volume = {150},
year = {2003}
}
@article{nich94,
author = {Nicholson, A E and Brady, J M},
journal = {IEEE Transactions on Systems, Man, and Cybernetics},
number = {11},
pages = {1593--1610},
title = {{Dynamic belief networks for discrete monitoring}},
volume = {24},
year = {1994}
}
@inproceedings{pelanek04,
author = {Pelanek, R},
booktitle = {Proceedings SPIN'04 Workshop},
title = {{Typical Structural Properties of State Spaces}},
year = {2004}
}
@misc{bobntim2,
author = {Cohen, R F and Menzies, T},
number = {TR95-20},
title = {{Reverse Engineering a Software Engineering Curriculum}},
year = {1995}
}
@book{bergadano95,
author = {Bergadano, F and Gunetti, D},
publisher = {The MIT Press},
title = {{Inductive Logic Programming: From Machine Learning to Software Engineering}},
year = {1995}
}
@inproceedings{terps93,
author = {Terpstra, P and van Heijst, G and Wielinga, B and Shadbolt, N},
booktitle = {Second Generation Expert Systems},
editor = {$\backslash$etal, M Davis},
publisher = {Springer-Verlag},
title = {{Knowledge Acquisition Support Through Generalised Directive Models}},
year = {1993}
}
@inproceedings{breuker94,
author = {Breuker, J},
booktitle = {8th European Knowledge Acquisition Workshop, EKAW '94},
pages = {118--136},
title = {{Components of \{P\}roblem \{S\}olving and \{T\}ypes of \{P\}roblems}},
year = {1994}
}
@article{paris96,
author = {Paris, C and Vander-Linden, K},
journal = {IEEE Computer},
month = jul,
title = {{DRAFTER: An Interactive Support Tool for Writing Multilingual Manuals}},
year = {1996}
}
@article{poole90a,
author = {Poole, D},
journal = {International Journal of Intelligent Systems},
pages = {521--548},
title = {{A \{M\}ethodology for \{U\}sing a \{D\}efault and \{A\}bductive \{R\}easoning \{S\}ystem}},
volume = {5},
year = {1990}
}
@inproceedings{steels94,
author = {Steels, L},
booktitle = {Proceedings of the Third Japanese Knowledge Acquisition for Knowledge-Based Systems Workshop, JKAW '94},
editor = {Mizoguchi, R and Motoda, H and Boose, J and Gaines, B and Compton, P},
pages = {65--71},
title = {{How \{C\}an we \{M\}ake \{F\}urther \{P\}rogress in \{K\}nowledge \{A\}cquisition?}},
year = {1994}
}
@article{sullivan03,
author = {(ed), Kevin Sullivan},
title = {{Preliminary Report, NSF Workshop on the Science of Design: Software and Software-Intensive Systems}},
year = {2003}
}
@inproceedings{zimmermann09,
author = {{T. Zimmermann N. Nagappan}, H Gall E Giger and Murphy, B},
booktitle = {ESEC/FSE'09},
month = aug,
title = {{Cross-Project Defect Prediction}},
year = {2009}
}
@article{Meda2010a,
abstract = {When designing a business workflow, it is customary practice to create the control flow structure first and to ensure its correctness. Information about the flow of data is introduced subsequently into the workflow and its correctness is independently verified. Improper specification of data requirements of tasks and XOR splits can cause problems such as wrong branching at XOR splits and the failure of tasks to execute. Here we present a graph traversal algorithm called GTforDF for detecting data flow errors in both nested and unstructured workflows, and illustrate its operation on realistic examples. Two of these have interconnected loops and are free of control flow errors, and the third one is an unstructured loop-free workflow. Our approach extends and generalizes data flow verification methods that have been recently proposed. It also makes use of the concept of corresponding pairs lately introduced in control flow verification. It thus has the potential for development into a unified algorithmic procedure for the concurrent detection of control flow and data flow errors. The correctness of the algorithm has been proved theoretically. It has also been tested experimentally on many examples.},
author = {Meda, Hema S. and Sen, Anup Kumar and Bagchi, Amitava},
issn = {1936-1955},
journal = {Journal of Data and Information Quality (JDIQ)},
keywords = {Corresponding pair,Data flow errors,Workflow management,pareto},
mendeley-tags = {pareto},
number = {1},
title = {{On Detecting Data Flow Errors in Workflows}},
url = {http://portal.acm.org/citation.cfm?id=1805286.1805290},
volume = {2},
year = {2010}
}
@phdthesis{WEILAI93,
address = {Callaghan, New South Wales, Australia, 2308},
author = {Lai, W},
month = jun,
school = {Department of Computer Science, University of Newcatle},
title = {{Building Interactive Diagram Applications}},
year = {1993}
}
@inproceedings{me04d,
author = {Owen, D and Menzies, T},
booktitle = {IEEE Transactions on Software Engineering (in preperation)},
title = {{Random Serial World Generation}},
year = {2004}
}
@inproceedings{raffo05c,
author = {Raffo, D and Menzies, T},
booktitle = {Proceedings of the 6th International Workshop on Software Process Simulation Modeling (ProSim'05)},
title = {{Evaluating the Impact of a New Technology Using Simulation: The Case for Mining Software Repositories}},
year = {2005}
}
@inproceedings{HATA08,
address = {New York, NY, USA},
author = {Hata, Hideaki and Mizuno, Osamu and Kikuno, Tohru},
booktitle = {MSR '08: Proceedings of the 2008 international working conference on Mining software repositories},
doi = {http://doi.acm.org/10.1145/1370750.1370772},
isbn = {978-1-60558-024-1},
pages = {89--98},
publisher = {ACM},
title = {{An extension of fault-prone filtering using precise training and a dynamic threshold}},
year = {2008}
}
@article{smythe87,
author = {Smythe, G A},
journal = {Exp. Clin. Endocrinol. (Life Sci. Adv.)},
pages = {141--144},
title = {{Hypothalamic noradrenergic activation of stress-induced adrenocorticotropin (\{ACTH\}) release: Effects of acute and chronic dexamethasone pre-treatment in the rat}},
year = {1987}
}
@article{shn08,
author = {Shneiderman, B},
journal = {Science},
month = mar,
number = {7},
pages = {1349--1350},
title = {{Science 2.0}},
volume = {319},
year = {2008}
}
@article{reiter87,
author = {Reiter, R},
journal = {Artificial Intelligence},
pages = {57--96},
title = {{A \{T\}heory of \{D\}iagnosis from \{F\}irst \{P\}rinciples}},
volume = {32},
year = {1987}
}
@article{reich95,
author = {Reich, Y},
journal = {International Journal of Human-Computer Studies},
number = {1},
pages = {3--30},
title = {{Measuring the Value of Knowledge}},
volume = {42},
year = {1995}
}
@article{chandra86,
author = {Chandrasekaran, B},
journal = {IEEE Expert},
pages = {23--30},
title = {{Generic Tasks in Knowledge-Based Reasoning: High-Level Building Blocks for Expert System Design}},
year = {1986}
}
@inproceedings{althoff99,
author = {Althoff, K-D. and Birk, A and Hartkopf, S and Muller, W and Nick, M and Surmann, D and Tautz, C},
booktitle = {Proceedings of the 11th International Conference on Software Engineering and Knowledge Engineering, SEKE'99, Kaiserslauten, Germany},
month = jun,
pages = {10--19},
title = {{Managing Software Engineering Experience for Comprehensive Reuse}},
year = {1999}
}
@inproceedings{Kohavi1995b,
author = {Kohavi, R.},
booktitle = {International joint Conference on artificial intelligence},
file = {:Users/timm/svns/doc/kohavi95.pdf:pdf},
issn = {1045-0823},
publisher = {Citeseer},
title = {{A study of cross-validation and bootstrap for accuracy estimation and model selection}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.48.529\&amp;rep=rep1\&amp;type=pdf},
volume = {14},
year = {1995}
}
@book{Alpaydin2004,
author = {Alpaydin, Ethem},
publisher = {MIT Press},
title = {{Introduction to Machine Learning}},
year = {2004}
}
@inproceedings{harr92,
author = {Harrison, W},
booktitle = {International Workshop on Experiment Software Engineering: Critical Assessment and Future Directions},
editor = {{H. Dieter Rombach V.R. Basili}, R W Selby},
pages = {107--111},
title = {{Towards Well-Defined, Shareable Product Data}},
year = {1992}
}
@article{mantyla09,
annote = {Available from $\backslash$url\{http://sequoia.cs.byu.edu/files/reser2010/proceedings/Mantyla\%20-\%20Rethinking\%20Replication.pdf\}},
author = {{Mika V. Mï¿½ntylï¿½ Casper Lassenius} and Vanhanen, Jari},
journal = {First International Workshop on Replication in Empirical Software Engineering Research, ICSE'09},
title = {{Rethinking Replication in Software Engineering: Can We See the Forest for the Trees?}},
year = {2009}
}
@inproceedings{Hinneburg1998b,
author = {Hinneburg, A. and Keim, D.A.},
file = {:Users/timm/svns/doc/hinneburg98.pdf:pdf},
publisher = {Bibliothek der Universit$\backslash$$\backslash$"at Konstanz},
title = {{An efficient approach to clustering in large multimedia databases with noise}},
url = {http://www.aaai.org/Papers/KDD/1998/KDD98-009.pdf},
year = {1998}
}
@misc{bse,
author = {Cohen, R F},
title = {{A \{R\}eport on the \{B\}achelor of \{E\}ngineering (\{S\}oftware \{E\}ngineering) \{D\}egree at the \{U\}niversity of \{N\}ewcastle}}
}
@article{AZZEH2010,
address = {Hingham, MA, USA},
author = {Azzeh, Mohammad and Neagu, Daniel and Cowling, Peter I},
doi = {http://dx.doi.org/10.1007/s10664-009-9113-0},
issn = {1382-3256},
journal = {Empirical Softw. Engg.},
number = {1},
pages = {60--90},
publisher = {Kluwer Academic Publishers},
title = {{Fuzzy grey relational analysis for software effort estimation}},
volume = {15},
year = {2010}
}
@misc{jackson97,
author = {Jackson, B and Griggs, J and Costello, K and Solomon, D},
title = {{Systems level definition of IV\&V}},
year = {2006}
}
@inproceedings{pecheur02,
author = {Nelson, S and Pecheur, C},
booktitle = {Second Goddard Workshop on Formal Aspects of Agent-Based Systems (FAABS II), Greenbelt, MD},
month = oct,
title = {{Formal Verification of a Next-Generation Space Shuttle}},
volume = {2699},
year = {2002}
}
@misc{kremer98,
annote = {To appear},
author = {Kremer, R},
howpublished = {KAW'98: Eleventh Workshop on Knowledge Acquisition, Modeling and Management, Voyager Inn, Banff, Alberta, Canada},
title = {{Visual Languages for Knowledge Representation}},
year = {1998}
}
@article{dietterich97,
author = {Dietterich, T G},
journal = {AI Magazine},
number = {4},
pages = {97--136},
title = {{Machine Learning Research: Four Current Directions}},
volume = {18},
year = {1997}
}
@article{ElEmam2001,
author = {{El Emam}, K. and Benlarbi, S. and Goel, N. and Rai, S.N.},
doi = {10.1109/32.935855},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/El Emam et al. - 2001 - The confounding effect of class size on the validity of object-oriented metrics.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
month = jul,
number = {7},
pages = {630--650},
title = {{The confounding effect of class size on the validity of object-oriented metrics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=935855},
volume = {27},
year = {2001}
}
@inproceedings{zhang06,
author = {Zhang, H and Huo, M and Kitchenham, B and Jeffery, R},
booktitle = {Australian Software Engineering Conference},
title = {{Qualitative Simulation Model for Software Engineering Process}},
year = {2006}
}
@article{chill92,
author = {Chillarege, R and Bhandari, I S and Chaar, J K and Halliday, M J and Moebus, D S and Ray, B K and Wong, M.-Y.},
journal = {IEEE Transactions on Software Engineering},
month = nov,
number = {11},
pages = {943--956},
title = {{Orthogonal Defect Classification--A Concept for In-Process Measurements}},
volume = {18},
year = {1992}
}
@inproceedings{Buntine1999,
author = {Buntine, W. and Fischer, B. and Pressburger, T.},
booktitle = {Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining},
file = {:Users/timm/svns/doc/Buntine99.pdf:pdf},
isbn = {1581131437},
publisher = {ACM},
title = {{Towards automated synthesis of data mining programs}},
url = {http://portal.acm.org/citation.cfm?id=312286},
year = {1999}
}
@article{brantley02,
annote = {Available from $\backslash$url\{http://www.dau.mil/pubs/images/download.gif\}},
author = {{M.W. Brantley}, W J McFadden and Davis, Mark J},
journal = {Acquisition Review Quarterly},
title = {{Expanding the trade space: an analysis of requirements tradeoffs affecting system design}},
year = {2002}
}
@incollection{maclean96,
author = {MacLean, A and Young, R M and Bellotti, V and Moran, T P},
booktitle = {Design Rationale: Concepts, Techniques, and Use},
editor = {Moran, T P and Carroll, J M},
pages = {53--106},
publisher = {Lawerence Erlbaum Associates},
title = {{Questions, options and criteria: Elements of design space analysis}},
year = {1996}
}
@inproceedings{domingos00mining,
author = {Domingos, P and Hulten, G},
booktitle = {Knowledge Discovery and Data Mining},
pages = {71--80},
title = {{Mining high-speed data streams}},
url = {citeseer.ist.psu.edu/domingos00mining.html},
year = {2000}
}
@book{hamscher92,
author = {Hamscher, W and Console, L and DeKleer, J},
publisher = {Morgan Kaufmann},
title = {{Readings in Model-Based Diagnosis}},
year = {1992}
}
@article{renn89,
author = {Rennels, G D and Shortliffe, E H and Stockdale, F E and Miller, P L},
journal = {AI Magazine},
pages = {49--57},
title = {{A Computational Model of Reasoning from the Clinical Literature}},
year = {1989}
}
@inproceedings{nusmv,
author = {Cimatti, A and Clarke, E and Giunchiglia, E and Giunchiglia, F and Pistore, M and Roveri, M and Sebastiani, R and Tacchella, A},
booktitle = {\{P\}roc. \{I\}nternational \{C\}onference on \{C\}omputer-\{A\}ided \{V\}erification},
title = {{\{N\}u\{SMV\} \{V\}ersion 2: \{A\}n \{O\}pen\{S\}ource \{T\}ool for \{S\}ymbolic \{M\}odel \{C\}hecking}},
year = {2002}
}
@inproceedings{arisholm06,
author = {Arisholm, E and Briand, L},
booktitle = {5th ACM-IEEE International Symposium on Empirical Software Engineering (ISESE), Rio de Janeiro, Brazil, September 21-22},
title = {{Predicting Fault-prone Components in a Java Legacy System}},
year = {2006}
}
@article{graves00,
annote = {Available on-line at $\backslash$url\{www.niss.org/technicalreports/tr80.pdf\}},
author = {Graves, Todd L and Karr, Alan F and Marron, J S and Siy, Harvey P},
journal = {IEEE Trans. Software Eng.},
number = {7},
pages = {653--661},
title = {{Predicting Fault Incidence Using Software Change History}},
volume = {26},
year = {2000}
}
@inproceedings{me08g,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08severis.pdf\}},
author = {Menzies, T and Marcus, A},
booktitle = {ICSM'08},
title = {{Automated Severity Assessment of Software Defect Reports}},
year = {2008}
}
@misc{me07c,
annote = {$\backslash$url\{http://promisedata.org/repository\}},
author = {Boetticher, G and Menzies, T and Ostrand, T},
institution = {West Virginia University, Lane Department of Computer Science and Electrical Engineering},
title = {{The \{PROMISE\} \{R\}epository of \{E\}mpirical \{S\}oftware \{E\}ngineering \{D\}ata}},
year = {2007}
}
@inproceedings{rish01,
author = {Rish, E},
booktitle = {IJCAI-01 workshop on Empirical Methods in AI},
title = {{An empirical study of the naive Bayes classifier}},
year = {2001}
}
@article{ack67,
author = {Ackoff, R L},
journal = {Management Science},
month = dec,
pages = {319--331},
title = {{Management \{M\}isinformation \{S\}ystems}},
year = {1967}
}
@inproceedings{sjoberg07,
author = {Sjoberg, D and {aand B. Anda}, T Byba and Hannay, J},
booktitle = {Guide to Advanced Empirical Software Engineering},
editor = {{F. Shull J. Singer} and Sjoberg, D},
pages = {312--336},
publisher = {Spring},
title = {{Building Theories in Software Engineering}},
year = {2007}
}
@article{jarv88,
author = {Jarvenpaa, S L and Dickson, G W},
journal = {Communications of the ACM},
number = {6},
pages = {764--774},
title = {{Graphics and Managerial Decision Making: Research Based Guidelines}},
volume = {31}
}
@article{born86,
author = {Borning, A H},
journal = {Human-Computer Interaction},
number = {4},
pages = {269--295},
title = {{Graphically Defining New Building Blocks in ThingLab}},
volume = {2},
year = {1986}
}
@article{DH88,
author = {Harel, D},
journal = {Communications of the ACM},
number = {5},
pages = {514--530},
title = {{On visual formalisms}},
volume = {31},
year = {1988}
}
@article{man95,
author = {Manley, R},
journal = {American Programmer},
pages = {17--18},
title = {{\{TAURUS\}: How I Lived to Tell the Tale}},
year = {1995}
}
@inproceedings{cruz93,
author = {Cruz-Neira, C and Sandin, D and DeFanti, T},
booktitle = {Proceedings of SIGGRAPH '93, ACM SIGGRAPH},
month = aug,
pages = {135--142},
title = {{Surround-Screen Projection-Based Virtual Reality: The Design and Implementation of the CAVE}},
year = {1993}
}
@article{kim08,
author = {Kim, Sunghun and Whitehead, James and Zhang, Yi},
journal = {IEEE TSE},
pages = {181--196},
title = {{Classifying Software Changes: Clean or Buggy?}},
year = {2008}
}
@article{Li2009a,
author = {Li, Y and Xie, M and T., Goh},
journal = {Empirical Software Engineering},
pages = {603--643},
title = {{A study of the non-linear adjustment for analogy based software cost estimation}},
year = {2009}
}
@book{busch96,
author = {Buschmann, F and Meunier, R and Rohnert, H and Sommerlad, P and Stal, M},
publisher = {John Wiley \& Sons},
title = {{A System of Patterns: Pattern-Oriented Software Architecture}},
year = {1996}
}
@inproceedings{boehm96,
author = {Boehm, B},
booktitle = {IEEE Software},
month = mar,
title = {{Aims for Indentifying Conflicts Among Quality Requirements}},
year = {1996}
}
@inproceedings{LI08,
address = {New York, NY, USA},
author = {Li, Jingzhou and Ruhe, Guenther},
booktitle = {PROMISE '08: Proceedings of the 4th international workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1370788.1370803},
isbn = {978-1-60558-036-4},
pages = {55--62},
publisher = {ACM},
title = {{Multi-criteria decision analysis for customization of estimation by analogy method AQUA+}},
year = {2008}
}
@inproceedings{basili02,
author = {Basili, V and McGarry, F and Pajerski, R and Zelkowitz, M},
booktitle = {Proceedings of the 24th International Conference on Software Engineering (ICSE) 2002, Orlando, Florida},
title = {{Lessons Learned from 25 Years of Process Improvement: The Rise and Fall of the \{NASA\} Software Engineering Laboratory}},
year = {2002}
}
@article{dennett95,
author = {Dennett, D C},
journal = {The New York Review of Books},
month = dec,
pages = {83},
title = {{'The Mystery of Consciousness': An Exchange}},
year = {1995}
}
@misc{me02b,
author = {Houle, M and Menzies, T and Powell, J},
booktitle = {IEEE Transactions on Software Engineering (submitted)},
title = {{A Fast Search for Temporal Properties of Requirements}},
year = {2002}
}
@inproceedings{queen67,
author = {MacQueen, J B},
booktitle = {Proceedings of 5th Berkeley Symposium on Mathematical Statistics and Probability},
pages = {281--297},
title = {{Some Methods for classification and Analysis of Multivariate Observations}},
year = {1967}
}
@inproceedings{polyak98b,
author = {Polyak, S and Lee, J and Gruninger, M and Menzel, C},
booktitle = {Proceedings of Workshop on Applications of Ontologies and Problem Solving Methods, ECAI'98, Brighton, England},
editor = {Gomez-Perez, A and Benjamins, R},
month = aug,
title = {{Applying the Process Interchange Format(PIF) to a Supply Chain Process Interoperability Scenario}},
year = {1998}
}
@article{Du2008,
author = {Du, Q. and Fowler, J. E.},
doi = {10.1177/1094342007088380},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Du, Fowler - 2008 - Low-Complexity Principal Component Analysis for Hyperspectral Image Compression.pdf:pdf},
issn = {1094-3420},
journal = {International Journal of High Performance Computing Applications},
month = nov,
number = {4},
pages = {438--448},
title = {{Low-Complexity Principal Component Analysis for Hyperspectral Image Compression}},
url = {http://hpc.sagepub.com/cgi/doi/10.1177/1094342007088380},
volume = {22},
year = {2008}
}
@inproceedings{elkan93,
address = {Menlo Park, California},
author = {Elkan, Charles},
booktitle = {Proceedings of the Eleventh National Conference on Artificial Intelligence},
editor = {Fikes, Richard and Lehnert, Wendy},
pages = {698--703},
publisher = {AAAI Press},
title = {{The Paradoxical Success of Fuzzy Logic}},
year = {1993}
}
@inproceedings{gers87,
author = {Gerstendorfer, M and Rohr, G},
booktitle = {Human-Computer Interaction - \{INTERACT\} '87},
pages = {6 pages},
title = {{Which Task in Which Representation on What Kind of Interface}},
year = {1987}
}
@article{Athitsos2008a,
abstract = {This paper describes BoostMap, a method for efficient nearest neighbor retrieval under computationally expensive distance measures. Database and query objects are embedded into a vector space, in which distances can be measured efficiently. Each embedding is treated as a classifier that predicts for any three objects X, A, B whether X is closer to A or to B. It is shown that a linear combination of such embeddingbased classifiers naturally corresponds to an embedding and a distance measure. Based on this property, the BoostMap method reduces the problem of embedding construction to the classical boosting problem of combining many weak classifiers into an optimized strong classifier. The classification accuracy of the resulting strong classifier is a direct measure of the amount of nearest neighbor structure preserved by the embedding. An important property of BoostMap is that the embedding optimization criterion is equally valid in both metric and non-metric spaces. Performance is evaluated in databases of hand images, handwritten digits, and time series. In all cases, BoostMap significantly improves retrieval efficiency with small losses in accuracy compared to brute-force search. Moreover, BoostMap significantly outperforms existing nearest neighbor retrieval methods, such as Lipschitz embeddings, FastMap, and VP-trees.},
author = {Athitsos, Vassilis and Alon, Jonathan and Sclaroff, Stan and Kollios, George},
doi = {10.1109/TPAMI.2007.1140},
file = {:Users/timm/svns/doc/08boostmap.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Imaging, Three-Dimensional,Imaging, Three-Dimensional: methods,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reproducibility of Results,Sensitivity and Specificity,Subtraction Technique},
month = jan,
number = {1},
pages = {89--104},
pmid = {18000327},
title = {{BoostMap: an embedding method for efficient nearest neighbor retrieval.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18000327},
volume = {30},
year = {2008}
}
@inproceedings{me08c,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08icsp.pdf\}},
author = {Menzies, T and Elrawas, O and Barry, B and Madachy, R and Hihn, J and Baker, D and Lum, K},
booktitle = {International Conference on Software Process},
title = {{Accurate Estimates without Calibration}},
year = {2008}
}
@article{rosen92,
author = {Rosenblum, L J and Brown, B E},
journal = {IEEE Computer Graphics and Applications},
number = {4},
pages = {18--71},
title = {{Special Issue on Visualization}},
volume = {12}
}
@inproceedings{davies94,
author = {Davies, P},
booktitle = {ECAI '94},
title = {{Planning and Expert Systems}},
year = {1994}
}
@inproceedings{me96i,
author = {Menzies, T J},
booktitle = {Proceedings of the Eighth International Conference on Software Engineering and Knowledge Engineering},
isbn = {0-9641699-3-2},
publisher = {Knowledge Systems Institute, Skokie, Illinois, USA},
title = {{Visual Programming, Knowledge Engineering, and Visual Programming}},
year = {1996}
}
@inproceedings{albrecht79,
author = {Albrecht, A J},
booktitle = {Proceedings of the Joint SHARE, GUIDE, and IBM Application Development Symposium, Monterey, California, October 14-17, IBM Corporation},
pages = {83--92},
title = {{Measuring Application Development Productivity}},
year = {1979}
}
@inproceedings{boose92,
author = {Boose, J H and Bradshaw, J M and Koszareck, J L and Shema, D B},
booktitle = {Proceedings of the 7th Knowledge Acquisition for Knowledge-Based Systems Workshop},
editor = {Gaines, B R and Musen, M A and Boose, J R},
pages = {2.1----2.22},
title = {{Knowledge \{A\}cquisition \{T\}echniques for \{G\}roup \{D\}ecision \{S\}upport}},
year = {1992}
}
@article{antoniol02,
author = {Antoniol, G and Canfora, G and Casazza, G and Lucia, A De and Merlo, E},
journal = {IEEE Transactions on Software Engineering},
month = oct,
number = {10},
pages = {970--983},
title = {{Recovering Traceability Links between Code and Documentation}},
volume = {28},
year = {2002}
}
@inproceedings{schn01,
author = {Schneidewind, N F},
booktitle = {Proceedings of the 7th International Software Metrics Symposium, London},
month = apr,
pages = {328--337},
title = {{Investigation of Logistic Regression as a Discriminant of Software Quality}},
year = {2001}
}
@inproceedings{me02g,
author = {Menzies, Tim and Lutz, Robyn and Mikulski, Carmen},
booktitle = {SEKE03},
title = {{Better Analysis of Defect Data at \{NASA\}}},
year = {2003}
}
@article{Larsen1999c,
address = {New York, New York, USA},
author = {Larsen, Bjornar and Aone, Chinatsu},
doi = {10.1145/312129.312186},
file = {:Users/timm/svns/doc/larsen99.pdf:pdf},
isbn = {1581131437},
journal = {Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '99},
keywords = {clustering,multi-document summarization,text mining},
pages = {16--22},
publisher = {ACM Press},
title = {{Fast and effective text mining using linear-time document clustering}},
url = {http://portal.acm.org/citation.cfm?doid=312129.312186},
year = {1999}
}
@article{me99c,
author = {Menzies, T},
journal = {Submitted to AAAI-99},
title = {{Simpler, Faster Abductive Validation}},
year = {1999}
}
@inproceedings{zelkowitz01,
address = {Washington, DC, USA},
author = {Zelkowitz, Marvin V and Rus, Ioana},
booktitle = {ICSE '01: Proceedings of the 23rd International Conference on Software Engineering},
isbn = {0-7695-1050-7},
pages = {349--357},
publisher = {IEEE Computer Society},
title = {{Understanding \{IV\&V\} in a safety critical and complex evolutionary environment: the NASA space shuttle program}},
year = {2001}
}
@inproceedings{kabas90,
author = {Kakas, A C and Mancrella, P},
booktitle = {ECAI-90},
title = {{Generalized Stable Models: A Semantics for Abduction}},
year = {1990}
}
@inproceedings{me96f,
author = {Menzies, T J and Goss, S},
booktitle = {Proceedings PKAW '96: Pacific Knowledge Acquisition Workshop and Monash University Department of Software Development Technical Report TR96-15},
title = {{Vague Models and Their Implications for the KBS Design Cycle}},
year = {1996}
}
@article{koru08,
author = {Koru, A G and Emam, K El and Zhang, D and Liu, H and Mathew, D},
journal = {Empirical Software Engineering},
month = oct,
pages = {473--498},
title = {{Theory of relative defect proneness: Replicated Studies on the Functional Form of the Size-Defect Relationship}},
year = {2008}
}
@inproceedings{me92n,
author = {Menzies, T J and Compton, P and Mahidadia, A},
booktitle = {Communicating Scientific and Technical Knowledge, an AAAI '92 workshop},
title = {{Communicating Research Models of Human Physiology using Qualitative Compartmental Modeling}},
year = {1992}
}
@inproceedings{cai05,
address = {New York, NY, USA},
author = {Cai, Yuanfang and Sullivan, Kevin J},
booktitle = {ASE '05: Proceedings of the 20th IEEE/ACM international Conference on Automated software engineering},
doi = {http://doi.acm.org.proxy.lib.muohio.edu/10.1145/1101908.1101962},
isbn = {1-59593-993-4},
pages = {329--332},
publisher = {ACM Press},
title = {{Simon: modeling and analysis of design space structures}},
year = {2005}
}
@article{boehm00a,
author = {Boehm, B},
journal = {IEEE Software},
pages = {14--17},
title = {{Safe and Simple Software Cost Analysis}},
year = {2000}
}
@inproceedings{chai02bayesian,
annote = {Available from $\backslash$url\{citeseer.ist.psu.edu/chai02bayesian.html\}},
author = {Chai, K and Ng, H and Chieu, H},
booktitle = {Proceedings of SIGIR-02, 25th ACM International Conference on Research and Development in Information Retrieval},
editor = {Beaulieu, M and BaezaYates, R and Myaeng, S H and Jarvelin, K},
pages = {97--104},
title = {{Bayesian online classifiers for text classification and filtering}},
year = {2002}
}
@inproceedings{akhavi93,
author = {Akhavi, M and Wilson, W},
booktitle = {Proceedings of the 5th Software Engineering Process Group National Meeting (Held at Costa Mesa, California, April 26 - 29)},
publisher = {Software engineering Institute, Carnegie Mellon University},
title = {{Dynamic Simulation of Software Process Models}},
year = {1993}
}
@misc{do178b,
annote = {December 1},
author = {RTCA, I N C},
title = {{RTCA DO178B: Software Considerations in Airborned Systems and Equipment Consideration}},
year = {1992}
}
@book{for93,
author = {Forbus, K D and DeKleer, J},
publisher = {The MIT Press},
title = {{Building Problem Solvers}},
year = {1993}
}
@article{clarkeng89,
author = {Clark, P and Ng, T},
journal = {Machine Learning},
pages = {261--283},
title = {{The CN2 Induction Algorithm}},
volume = {3},
year = {1989}
}
@inproceedings{beck89,
author = {Beck, K and Cunnignham, W},
booktitle = {Proceedings OOPSLA '89, ACM SIGPLAN Notices},
number = {October},
pages = {1--6},
title = {{A Laboratory for Teaching Object-Oriented Thinking}},
volume = {24},
year = {1989}
}
@article{me00o,
author = {Menzies, T and Althoff, K D and Kalfoglou, Y and Motta, E},
journal = {International Journal of Software Engineering and Knowledge Engineering},
month = aug,
number = {4},
title = {{Issues with Meta-Knowledge}},
volume = {10},
year = {2000}
}
@misc{lowry99,
author = {Lowry, M},
title = {{Personnel communication}},
year = {1999}
}
@inproceedings{owen2b,
author = {Owen, D and Cukic, B and Menzies, T},
booktitle = {7th IEEE International Symposium on High Assurance Systems Engineering},
pages = {119},
title = {{An Alternative to Model Checking: Verification by Random Search of AND-OR Graphs Representing Finite-State Models}},
volume = {1},
year = {2002}
}
@article{colomb98,
author = {Colomb, R M},
journal = {Artificial Intelligence},
number = {1-2},
pages = {187--209},
title = {{Representation of Propositional Expert Systems as Partial Functions}},
volume = {109},
year = {1999}
}
@misc{TheMendeleySupportTeam2010,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {::},
keywords = {Mendeley,how-to,user manual},
pages = {1--14},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2010}
}
@book{gleick87,
author = {Gleick, J},
pages = {352},
publisher = {Cardinal},
title = {{Chaos}},
year = {1987}
}
@inproceedings{me00r,
author = {Menzies, T and Easterbrook, S and Nuseibeh, B and Waugh, S},
booktitle = {Submitted for journal review},
title = {{Validating Inconsistent Requirements Models using Graph-based Abduction}},
year = {2001}
}
@article{kakas00aclp,
author = {Kakas, Antonis C and Michael, A and Mourlas, C},
journal = {Journal of Logic Programming},
number = {1-3},
pages = {129--177},
title = {{\{ACLP\}: Abductive Constraint Logic Programming}},
volume = {44},
year = {2000}
}
@misc{bobntim2,
author = {Cohen, R F and Menzies, T},
number = {TR95-20},
title = {{Reverse Engineering a Software Engineering Curriculum}},
year = {1995}
}
@misc{spear00,
title = {{No Title}}
}
@article{kah82,
author = {Kahneman, D and Tversky, A},
journal = {Scientific American},
pages = {136--142},
title = {{The Psychology of Preferences}},
volume = {246},
year = {1982}
}
@article{brieman96,
author = {Brieman, L},
journal = {Machine Learning},
number = {2},
pages = {123--140},
title = {{Bagging predictors}},
volume = {24},
year = {1996}
}
@inproceedings{Muns91,
author = {Munson, J C and Khoshgoftaar, T M},
booktitle = {Proceedings of the International Symposium on Software Reliability Engineering, Austin, TX},
month = may,
title = {{The Use of Software Complexity Metrics in Software Reliability Modeling}},
year = {1991}
}
@book{tansley93,
author = {Tansley, D S W and Hayball, C C},
pages = {528},
publisher = {Prentice-Hall},
title = {{Knowledge-Based Systems Analysis and Design}},
year = {1993}
}
@inproceedings{QWFENG95,
author = {Feng, Q W and Cohen, R F and Eades, P},
booktitle = {Proc. of the First International Conference on Computing and Combinatorics (COCOON95)},
publisher = {Springer-Verlag},
series = {Lecture Notes in Computer Science},
title = {{How to Draw a Planar Clustered Graph}},
year = {1995}
}
@inproceedings{me00e,
author = {Menzies, T and Sinsel, E},
booktitle = {Proceedings ASE 2000},
title = {{Practical Large Scale What-if Queries: Case Studies with Software Risk Assessment}},
year = {2000}
}
@inproceedings{me98f,
author = {Menzies, T J and Waugh, S},
booktitle = {Proceedings, Pacific Rim Conference on Artificial Intelligence, Singapore},
publisher = {Springer-Verlag},
title = {{On the Practicality of Viewpoint-based Requirements Engineering}},
year = {1998}
}
@book{bratko89,
author = {Bratko, I and Mozetic, I and Lavrac, N},
publisher = {MIT Press},
title = {{KARDIO: a Study in Deep and Qualitative Knowledge for Expert Systems}},
year = {1989}
}
@inproceedings{eickel96,
author = {Eickelmann, N S and Richardson, D J},
booktitle = {Proccesings, International Conference on Software Engineering},
pages = {353--364},
title = {{An Evaluation of Software Test Environment Architectures}},
year = {1996}
}
@inproceedings{Basson1993,
annote = {unread},
author = {Basson, H and Haton, M C and Derniame, J C},
booktitle = {Proceedings of Software Quality Management, Elsevier Science and CMP, Southampton},
pages = {807--818},
title = {{Use of quality characteristics graphs for a knowledge-based assistance in software quality management}},
year = {1993}
}
@book{boehm00b,
author = {Boehm, Barry and Horowitz, Ellis and Madachy, Ray and Reifer, Donald and Clark, Bradford K and Steece, Bert and Brown, A Winsor and Chulani, Sunita and Abts, Chris},
publisher = {Prentice Hall},
title = {{Software Cost Estimation with Cocomo II}},
year = {2000}
}
@inproceedings{horgan96,
address = {McGraw-Hill},
author = {Horgan, J and Mathur, A},
booktitle = {The Handbook of Software Reliability Engineering},
editor = {Lyu, M R},
pages = {531--565},
title = {{Software Testing and Reliability}},
year = {1996}
}
@inproceedings{me01h,
author = {Menzies, T and Hu, Y},
booktitle = {Agent Technology from a Formal Perspective},
editor = {Rouff, C and Hinchey, M and Rash, J and Truszkowski, W and Gordon-Spears, D},
isbn = {1-85233-947-0},
publisher = {Springer},
title = {{Agents in a Wild World}},
year = {2006}
}
@article{Mendes2007,
address = {Piscataway, NJ, USA},
annote = {Member-Kitchenham, Barbara A.},
author = {Kitchenham, Barbara and Mendes, Emilia and Travassos, Guilherme H},
doi = {http://dx.doi.org/10.1109/TSE.2007.1001},
file = {::},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {5},
pages = {316--329},
publisher = {IEEE Press},
title = {{Cross versus Within-Company Cost Estimation Studies: A Systematic Review}},
volume = {33},
year = {2007}
}
@book{byrn99,
editor = {Baeza-Yates, R A and Ribeiro-Neto, B},
publisher = {Addison-Wesley},
title = {{Modern Information Retrieval}},
year = {1999}
}
@inproceedings{budgen09,
author = {{D. Budgen P. Brereton}, B Kitchenham},
booktitle = {33rd Annual IEEE Software Engineering Workshop 2009 (SEW-33), Skï¿½vde, Sweden},
title = {{Is Evidence Based Software Engineering mature enough for Practice \& Policy?}},
year = {2009}
}
@article{Fayyad1996,
author = {Fayyad, Usama and Piatetsky-shapiro, Gregory and Smyth, Padhraic},
file = {:Users/timm/svns/doc/fayyad06.pdf:pdf},
journal = {AI Magazine},
pages = {37--54},
title = {{From Data Mining to Knowledge Discovery in Databases}},
year = {1996}
}
@book{clocksin87,
author = {Clocksin, W F and Mellish, C S},
publisher = {Springer-Verlag},
title = {{Programming in Prolog (third edition)}},
year = {1987}
}
@inproceedings{Milic2004,
author = {Milic, Drazen and Wohlin, Claes},
booktitle = {Euromicro},
keywords = {control,effort estimation,estimation process,software project,software project management},
title = {{Distribution Patterns of Effort Estimations}},
year = {2004}
}
@inproceedings{Child2005a,
author = {Child, Christopher and Stathis, Kostas},
booktitle = {Computational Logic in Multi-Agent Systems},
file = {:Users/timm/svns/doc/child04.pdf:pdf},
pages = {105--113},
publisher = {Springer},
title = {{The Apriori Stochastic Dependency Detection (ASDD) Algorithm for Learning Stochastic Logic Rules}},
url = {http://www.springerlink.com/index/CBJHWJPRCF60HPQ0.pdf},
year = {2005}
}
@misc{Misue93,
author = {Misue, K and Sugiyama, K},
institution = {ISIS, Fujitsu Laboratories},
number = {IIAS-RR-93-3E},
title = {{An overview of diagram based idea organizer: D-ABDUCTOR}},
year = {1993}
}
@article{deKleer86,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {163--196},
title = {{An \{A\}ssumption-\{B\}ased \{TMS\}}},
volume = {28},
year = {1986}
}
@book{alex64,
author = {Alexander, C},
publisher = {Harvard University Press},
title = {{Notes on Synthesis of Form}},
year = {1964}
}
@article{boning94,
author = {Boning, D S and Mozumder, P K},
journal = {IEEE Transactions on Semiconductor Manufacturing},
month = may,
number = {2},
pages = {233--244},
title = {{DOE/Opt: a system for design of experiments, response surface modeling, and optimization using process and device simulation}},
volume = {7},
year = {1994}
}
@misc{coker03,
annote = {Available from $\backslash$url\{http://www.jcrocket.com/altimeters.shtml\}},
author = {Coker, John},
title = {{John Coker's Rocket Pages: Altimeter Comparison}},
year = {2003}
}
@article{me89zb,
author = {Menzies, T J},
journal = {AI Expert},
title = {{Domain-Specific Knowledge Representations}},
year = {1989}
}
@article{will00,
author = {Williams, L and Kessler, R R and Cunningham, W and Jeffries, R},
journal = {IEEE Software},
title = {{Strengthening the Case for Pair-Programming}},
year = {2000}
}
@inproceedings{motta99,
author = {Motta, E and Fensel, D and Gaspari, M and Benjamins, A},
booktitle = {Proceedings of SEKE '99},
title = {{Specifications of Knowledge Components for Reuse}},
year = {1999}
}
@article{Saclay,
author = {Saclay, Inria and Sud, U Paris and Orsay, F- and Schoenauer, Marc and Sebag, Mich\`{e}le},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Saclay et al. - Unknown - A Mono Surrogate for Multiobjective Optimization.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {multiobjective optimization,pareto,support vec-,surrogate models},
mendeley-tags = {pareto},
pages = {471--478},
title = {{A Mono Surrogate for Multiobjective Optimization}}
}
@misc{compton95,
author = {Compton, P and Preston, P and Kang, B},
booktitle = {Proceedings of the Banff KA workshop on Knowledge Acquisition for Knowledge-Based Systems},
title = {{The Use of Simulated Experts in Evaluating Knowledge Acquisition}},
year = {1995}
}
@book{morari86,
author = {Morari, M and McAvoy, T J},
publisher = {A Cache Publication},
title = {{Chemical Process Control: CPC III}},
year = {1986}
}
@article{myrtveit05,
author = {Myrtveit, Ingunn and Stensrud, Erik and Shepperd, Martin},
journal = {IEEE Transactions on Software Engineerining},
month = may,
number = {5},
pages = {380--391},
title = {{Reliability and Validity in Comparative Studies of Software Prediction Models}},
volume = {31},
year = {2005}
}
@misc{reaction03,
annote = {Available from $\backslash$url\{http://www.rrs.org/Projects/Launches/Space\_Shot/space\_shot.html\}},
author = {Research, Reaction},
title = {{Reaction Research Society Space Shot}},
year = {2003}
}
@phdthesis{pande96,
author = {Pande, H D},
school = {Gradaute School- New Brunswick. Rutgers, The State University of New Jersey},
title = {{Compile Time Analysis of C and C++ Systems}},
year = {1996}
}
@article{Ona,
author = {On, Focus},
file = {:Users/timm/svns/doc/HowRareIsThat.pdf:pdf},
journal = {Search},
title = {{How Rare is that Fingerprint ? Computational Forensics Provides the First Clues}}
}
@article{regan04,
author = {Regan, Patrick and Hamilton, Scott},
journal = {IEEEComputer},
number = {1},
pages = {59--68},
title = {{NASA's Mission Reliable}},
volume = {37},
year = {2004}
}
@inproceedings{me05e,
author = {Menzies, T and Richardson, J},
booktitle = {COCOMO forum, 2005},
title = {{XOMO: Understanding Development Options for Autonomy}},
year = {2005}
}
@inproceedings{basili94,
author = {Basili, V R and Caldiera, G and Rombach, H D},
booktitle = {Encyclopedia of Software Engineering, volume 1},
editor = {Marciniak, J J},
pages = {469Â476},
publisher = {John Wiley \& Sons},
title = {{Experience Factory}},
year = {1994}
}
@inproceedings{me97b,
author = {Menzies, T J and Mahidadia, A},
booktitle = {Workshop on Problem-Solving Methods for Knowledge-based Systems, IJCAI '97, August 23.},
title = {{Ripple-Down Rationality: A Framework for Maintaining PSMs}},
year = {1997}
}
@article{duda85,
author = {Duda, R O and Hart, P E and Reboh, R},
journal = {Artificial Intelligence},
pages = {359--360},
title = {{Letter to the Editor}},
volume = {26},
year = {1985}
}
@inproceedings{me96m,
author = {Menzies, Tim},
booktitle = {Proceedings of the ECAI '96 workshop on Modelling Conflicts in AI},
title = {{Expert Systems Inference = Modeling Conflicts}},
year = {1996}
}
@inproceedings{BOETTICHER2009,
address = {New York, NY, USA},
author = {Boetticher, Gary D},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540458},
isbn = {978-1-60558-634-2},
pages = {1--5},
publisher = {ACM},
title = {{From software engineer to day trader in 3 easy steps: a comparison of software engineering (SE) data mining with financial data mining}},
year = {2009}
}
@book{tecuci98,
author = {Tecuci, G},
publisher = {Academic Press},
title = {{Building Intelligent Agents: An Apprenticeship Multistrategy Learning Theory, Methodology, Tool and Case Studies}},
year = {1998}
}
@inproceedings{yann01,
author = {Kalgoglou, Y},
booktitle = {Handbook of Software and Knowledge Engineering (volume 1)},
editor = {Chung, S K},
title = {{Ontologies in Software Design}},
year = {2001}
}
@article{brown85,
author = {Brown, M B and Sedgewick, R},
journal = {IEEE Software},
month = jan,
pages = {28--39},
title = {{Techniques for Algorithm Animation}},
year = {1985}
}
@article{mintz75,
author = {Mintzberg, H},
journal = {Harvard Business Review},
pages = {29--61},
title = {{The \{M\}anager's \{J\}ob: \{F\}olklore and \{F\}act}},
year = {1975}
}
@inproceedings{boett01,
author = {Boetticher, G},
booktitle = {Second International Workshop on Soft Computing Applied to Software Engineering, Enschade, NL},
title = {{An Assessment of Metric Contribution in the Construction of a Neural Network-Based Effort Estimator}},
year = {2001}
}
@misc{swiprolog,
author = {Wielemaker, Jan},
title = {{SWI-Prolog}}
}
@inproceedings{bradley98scaling,
annote = {Available from $\backslash$url\{http://citeseer.ist.psu.edu/bradley98scaling.html\}},
author = {Bradley, Paul S and Fayyad, Usama M and Reina, Cory},
booktitle = {Knowledge Discovery and Data Mining},
pages = {9--15},
title = {{Scaling Clustering Algorithms to Large Databases}},
year = {1998}
}
@article{NicDaeid2005,
abstract = {Over the last 20 years there has been an increasing interest in the development of robust systems, both analytical and statistical, to enable the linkage of seizures of illicit drug to each other. Much of this work has concentrated on the analysis of synthetic drugs, such as amphetamine and its analogues. In recent years, the analysis of both organic and elemental impurities as well as isotope ratios has advanced the usefulness of the techniques available. The application of specific chemometric methods to the derived analytical data has begun to provide the possibility of robust methods by which the resultant information can be interrogated.},
author = {{Nic Da\'{e}id}, Niamh and Waddell, Ruth J H},
doi = {10.1016/j.talanta.2005.05.018},
file = {:Users/timm/svns/doc/nic05.pdf:pdf},
issn = {1873-3573},
journal = {Talanta},
keywords = {chemometrics,drug analysis,forensic analysis},
month = aug,
number = {2},
pages = {280--5},
pmid = {18970168},
title = {{The analytical and chemometric procedures used to profile illicit drug seizures.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18970168},
volume = {67},
year = {2005}
}
@article{dieng95,
author = {Dieng, R and Corby, O and Lapalut, S},
journal = {International Journal of Human-Computer Studies},
pages = {465--499},
title = {{Acquisition and Exploitation of Gradual Knowledge}},
volume = {42},
year = {1995}
}
@book{Bache1994,
annote = {unread},
author = {Bache, R and Bazzana, G},
publisher = {McGraw-Hill},
title = {{Software Metrics for Product Assessment}},
year = {1994}
}
@article{kemerer87,
author = {Kemerer, C F},
file = {::},
journal = {Communications of the ACM},
month = may,
number = {5},
pages = {416--429},
title = {{An Empirical Validation of Software Cost Estimation Models}},
volume = {30},
year = {1987}
}
@inproceedings{pavl03,
author = {Pavlovic, D and Smith, D R},
booktitle = {UNU/IIST 10th Anniversary Colloquium, Formal Methods at the Crossroads: From Panaea to Foundational Support},
publisher = {Springer-Verlag},
title = {{Software Development by Refinement}},
year = {2003}
}
@article{have00,
author = {Havelund, K and Pressburger, T},
journal = {International Journal on Software Tools for Technology Transfer},
month = apr,
number = {4},
title = {{Model Checking Java Programs Using Java PathFinder}},
volume = {2},
year = {2000}
}
@misc{hig96,
annote = {CMU/SEI-96-TR-012 },
author = {Higuera, R P and Haimes, Y Y},
institution = {Software Engineering Institute},
month = jun,
title = {{Software Risk Management}},
year = {1996}
}
@inproceedings{me97d,
author = {Postema, M and Menzies, T J and Wu, X},
booktitle = {The Joint Pacific Asia Conference on Expert Systems/Singapore International Conference on Intelligent Systems. (PACES/SPICIS '97)},
title = {{A Decision Support Tool for Tuning Parameters in a Machine Leraning Algorithm}},
year = {1997}
}
@inproceedings{cass00,
author = {Cass, A G and Lerner, B Staudt and McCall, E K and Osterweil, L J and Jr., Stanley M Sutton and Wise, A},
booktitle = {Proceedings of the 22nd International Conference on Software Engineering (ICSE 2000)},
month = jun,
pages = {754--757},
title = {{Little-JIL/Juliette: A Process Definition Language and Interpreter}},
year = {2000}
}
@article{fea03,
author = {Feather, M S and Cornford, S L},
journal = {Requirements Engineering Journal},
title = {{Quantitative Risk-based Requirements Reasoning}},
year = {2003}
}
@misc{On,
abstract = {December 7, 2010},
author = {On, Focus},
booktitle = {University of Buffalo},
file = {:Users/timm/svns/doc/HowRareIsThat.pdf:pdf},
keywords = {forensics},
mendeley-tags = {forensics},
title = {{How Rare is that Fingerprint ? Computational Forensics Provides the First Clues}},
url = {http://www.buffalo.edu/news/12073}
}
@misc{hulten02mining,
annote = {Available from $\backslash$url\{citeseer.ist.psu.edu/hulten02mining.html\}},
author = {Hulten, G and Domingos, P},
pages = {525--531},
title = {{Mining complex models from arbitrarily large databases in constant time}},
year = {2002}
}
@misc{persist97,
address = {http://www.persistence.com/},
institution = {Persistence Software Inc.},
title = {{Persistence: A Relational Mapping and Caching Tool}}
}
@misc{kendall01,
author = {Kendall, Graham},
title = {{Tutorial notes on the history of AI}},
year = {2001}
}
@inproceedings{schn97,
author = {Schneidewind, N F},
booktitle = {Proceedings of the 8th International Symposium on Software Reliability Engineering, Albuquerque, New Mexico},
month = nov,
pages = {402--415},
title = {{Software Metrics Model for Integrating Quality Control and Prediction}},
year = {1997}
}
@book{rump88,
author = {Rump, S M},
publisher = {Academic Press},
title = {{Reliability in Computing. The Role of Interval Methods in Scientific Computing}},
year = {1988}
}
@misc{heeger98,
author = {Heeger, D},
title = {{Signal Detection Theory}},
year = {1998}
}
@misc{lutz03b,
annote = {(submitted)},
author = {Lutz, R and Mikulski, Carmen},
title = {{Empirical Analysis of Safety-Critical Anomalies During Operations}},
year = {2003}
}
@article{weyeuker08,
author = {Weyuker, E J and Ostrand, T J and Bell, R M},
journal = {Empirical Software Engineering},
month = oct,
title = {{Do too many cooks spoil the broth? Using the number of developers to enhance defect prediction models}},
year = {2008}
}
@inproceedings{fenton07a,
annote = {Available from $\backslash$url\{http://promisedata.org/pdf/mpls2007FentonNeilMarshHeartyRadlinskiKrause.pdf\}},
author = {Fenton, Norman and Neil, Martin and Marsh, William and Hearty, Peter and Radlinski, Lukasz and Krause, Paul},
booktitle = {PROMISE'09},
title = {{Project Data Incorporating Qualitative Factors for Improved Software Defect Prediction}},
year = {2007}
}
@book{brac85,
address = {Palo Alto},
author = {Brachmann, R J and Levesque, H J},
isbn = {0-934613-01-X},
publisher = {Morgan Kaufmann},
title = {{Readings in Knowledge Representation}},
year = {1985}
}
@misc{beohm06a,
annote = {Keynote address, CSEET'06},
author = {Boehm, B},
title = {{Educating Students in Value-Based Design and Development}},
year = {2006}
}
@book{kuhn62,
author = {Kuhn, T},
publisher = {Cambridge Press},
title = {{The Structure of Scientific Revolutions}},
year = {1962}
}
@article{poole88,
author = {Poole, D},
journal = {Artificial Intelligence},
pages = {27--47},
title = {{A Logical Framework for Default Reasoning}},
volume = {36},
year = {1988}
}
@article{lam98,
author = {van Lamsweerde, A and Willemet, L},
journal = {IEEE Transactions on Software Engineering, Special Issue on Scenario Management},
month = nov,
title = {{Inferring Declarative Requirements Specifications from Operational Scenarios}},
year = {1998}
}
@book{Meyer1988,
author = {Meyer, B},
publisher = {Prentice-Hall,Hemel Hemstead},
title = {{Object-oriented Software Construction}},
year = {1988}
}
@inproceedings{gerth95,
author = {Gerth, R and Peled, D and Vardi, M and Wolper, P},
booktitle = {Proc. PSTV 1995 Conference, Warsaw, Poland},
title = {{Simple on-the-fly automatic verification of linear temporal logic}},
year = {1995}
}
@article{Onb,
author = {On, Focus},
file = {:Users/timm/svns/doc/HowRareIsThat.pdf:pdf},
journal = {Search},
title = {{How Rare is that Fingerprint ? Computational Forensics Provides the First Clues}}
}
@book{ull:88a,
author = {Ullman, J D},
publisher = {Computer Science Press},
title = {{Principles of Database and Knowledge-base Systems}},
year = {1988}
}
@inproceedings{me05a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05safewhen.pdf\}},
author = {Menzies, Tim and Chen, Zhihao and Port, Dan and Hihn, Jairus},
booktitle = {Proceedings, PROMISE workshop, ICSE 2005},
title = {{Simple Software Cost Estimation: Safe or Unsafe?}},
year = {2005}
}
@inproceedings{green82,
author = {Greenspan, S J and Mylopoulos, J},
booktitle = {International Conference on Software Engineering},
pages = {225--234},
title = {{Capturing More World Knowledge in the Requirements Specification}},
year = {1982}
}
@article{vera93b,
author = {Vera, A H and Simon, H A},
journal = {Cognitive Science},
pages = {117--133},
title = {{Situated Action: Reply to William Clancey}},
volume = {17},
year = {1993}
}
@inproceedings{cold94,
author = {Coldwell, J M and Wrightson, G},
booktitle = {Artificial Intelligence: Sowing the Seeds for the Future; Proceedings of AI '94},
editor = {Zhang, C and Debenham, J and Lukose, D},
pages = {275--282},
publisher = {World Scientific},
title = {{Lemmas and Links in Analystic Tableau}},
year = {1994}
}
@inproceedings{raffo94,
author = {Raffo, D M},
booktitle = {Proceedings of CASCON 94, held in Toronto, Ontario, Canada, Oct.31-Nov.3},
publisher = {IBM Canada Ltd. Laboratory, Center for Advanced Studies; and National Research Council for Canada},
title = {{Capturing Software Process and Product Characteristics in Process Models Using Task Element Decomposition}},
year = {1994}
}
@misc{raffo95,
annote = {Ph.D. thesis, Manufacturing and Operations Systems},
author = {Raffo, D M},
institution = {Graduate School of Industrial Administration, Carnegie Mellon University, Pittsburgh, Pennsylvania},
month = may,
title = {{Modeling Software Processes Quantitatively and Assessing the Impact of Potential Process Changes of Process Performance}},
year = {1996}
}
@inproceedings{zlatareva93,
author = {Zlatareva, N},
booktitle = {IJCAI '93 workshop on Validation, Verification and Test of KBs Chambery, France},
pages = {67--77},
title = {{Distributed Verification and Automated Generation of Test Cases}},
year = {1993}
}
@inproceedings{HECKMAN2008,
address = {New York, NY, USA},
author = {Heckman, Sarah and Williams, Laurie},
booktitle = {ESEM '08: Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
doi = {http://doi.acm.org/10.1145/1414004.1414013},
isbn = {978-1-59593-971-5},
pages = {41--50},
publisher = {ACM},
title = {{On establishing a benchmark for evaluating static analysis alert prioritization and classification techniques}},
year = {2008}
}
@article{Barrett2008,
address = {New York, New York, USA},
author = {Barrett, Leon and Narayanan, Srini},
doi = {10.1145/1390156.1390162},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Barrett, Narayanan - 2008 - Learning all optimal policies with multiple criteria.pdf:pdf},
isbn = {9781605582054},
journal = {Proceedings of the 25th international conference on Machine learning - ICML '08},
keywords = {pareto},
mendeley-tags = {pareto},
pages = {41--47},
publisher = {ACM Press},
title = {{Learning all optimal policies with multiple criteria}},
url = {http://portal.acm.org/citation.cfm?doid=1390156.1390162},
year = {2008}
}
@article{deKleer86d,
author = {DeKleer, J and Brown, J S},
journal = {Artificial Intelligence},
pages = {33--61},
title = {{Theories of Causal Ordering}},
volume = {29},
year = {1986}
}
@inproceedings{me09f,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09bfc.pdf\}},
author = {Menzies, T and El-Rawas, O and Hihn, J and Boehm, B},
booktitle = {PROMISE'09},
title = {{Can We Build Software Faster and Better and Cheaper?}},
year = {2009}
}
@book{hof81,
author = {Hofstader, D R and Dennett, D C},
title = {{The Mind's I}},
year = {1981}
}
@article{Mendes2003,
author = {Mendes, Emilia and Watson, Ian D and Triggs, Chris and Mosley, Nile and Counsell, Steve},
journal = {Empirical Software Engineering},
number = {2},
pages = {163--196},
title = {{A Comparative Study of Cost Estimation Models for Web Hypermedia Applications}},
volume = {8},
year = {2003}
}
@inproceedings{don99,
author = {Dondossola, G},
booktitle = {Validation and Verication of Knowledge Based Systems: Theory, Tools and Practice},
editor = {Vermesan, A and Coenen, F},
isbn = {0-7923-8645-0},
pages = {113--130},
publisher = {Kluwer Academic Publishing, Utrecht, Netherlands},
title = {{Formal Method for Engineering and Certification of Safety-Critical Knowledge Based Systems}},
year = {1999}
}
@inproceedings{owen02a,
author = {Owen, D and Menzies, T and Cukic, B},
booktitle = {IEEE Conference on Automated Software Engineering (ASE '02)},
title = {{What Makes Finite-State Models more (or less) Testable?}},
year = {2002}
}
@article{shults97,
author = {Shults, B and Kuipers, B},
journal = {Artificial Intelligence},
pages = {91--129},
title = {{Proving properties of continuous systems: qualitative simulation and temporal logic}},
volume = {92},
year = {1997}
}
@misc{1012,
author = {IEEE-1012},
title = {{\{IEEE\} Standard 1012-2004 for Software Verification and Validation}},
year = {1998}
}
@inproceedings{cai98,
author = {Cai, C H and Fu, A W C and Cheng, C H and Kwong, W W},
booktitle = {Proceedings of International Database Engineering and Applications Symposium (IDEAS 98)},
month = aug,
title = {{Mining Association Rules with Weighted Items}},
year = {1998}
}
@inproceedings{bhar97,
author = {Bharadwaj, Ramesh and Heitmeyer, Constance},
booktitle = {Proc. First ACM SIGPLAN Workshop on Automatic Analysis of Software},
month = jan,
title = {{Verifying \{SCR\} Requirements Specifications Using State Exploration}},
year = {1997}
}
@inproceedings{quinlan82,
author = {Quinlan, J R},
booktitle = {Machine Learning},
title = {{Learning Efficient Classification Procedures and Thier Application to Chess End-Games}},
year = {1982}
}
@article{mcderm81,
author = {McDermott, J},
journal = {AI Magazine},
number = {2},
pages = {21--29},
title = {{R1's formative years}},
volume = {2},
year = {1981}
}
@article{clancey93,
author = {Clancey, W},
journal = {Cognitive Science},
pages = {87--116},
title = {{Situated \{A\}ction: \{A\} \{N\}europsychological \{I\}nterpretation (\{R\}esponse to \{V\}era and \{S\}imon)}},
volume = {17},
year = {1993}
}
@article{konoligue92,
author = {Konoligue, K},
journal = {Artificial Intelligence},
pages = {255--272},
title = {{Abduction versus \{C\}losure in \{C\}ausal \{T\}heories}},
volume = {53},
year = {1992}
}
@article{mack85,
author = {Mackworth, A K and Frueder, E C},
journal = {Artificial Intelligence},
pages = {65--74},
title = {{The Complexity of Some Polynomial Network Consistency Algorithms for Constraint Satisfaction Problems}},
volume = {25},
year = {1985}
}
@inproceedings{lum06,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06ispa.pdf\}},
author = {Lum, K and Hihn, J and Menzies, T},
booktitle = {ISPA Conference Proceedings},
title = {{Sudies in Software Cost Model Behavior: Do we Really Understand Cost Model Performance?}},
year = {2006}
}
@misc{clancey96,
annote = {Personal communcaition},
author = {Clancey, W},
title = {{No Title}},
year = {1996}
}
@inproceedings{back91,
address = {San Mateo, CA},
author = {B\"{a}ck, Thomas and Hoffmeister, Frank and Schwefel, Hans-Paul},
booktitle = {Proceedings of the Fourth International Conference on Genetic Algorithms},
editor = {Belew, Rick and Booker, Lashon},
pages = {2--9},
publisher = {Morgan Kaufman},
title = {{A survey of evolution strategies}},
year = {1991}
}
@inproceedings{Litt95,
author = {Littlewood, B and Wright, D},
booktitle = {Proceedings of the 25th Conference on Fault Tolerant Computing (FTCS 25), Pasadena, CA, July},
title = {{Stopping Rules for the Operational Testing of Safety Critical Software}},
year = {1995}
}
@article{Fingerprint2010a,
author = {Fingerprint, Integrated Automated},
file = {:Users/timm/svns/doc/IEEESpectrumBeyondCSIRiseofComputationalForensics.pd.pdf:pdf},
journal = {Computing},
keywords = {forensics},
mendeley-tags = {forensics},
title = {{Beyond C . S . I .: The Rise of Computational Forensics}},
year = {2010}
}
@incollection{casady96,
author = {Casady, G},
booktitle = {Design Rationale: Concepts, Techniques, and Use},
editor = {Moran, T P and Carroll, J M},
pages = {351--372},
publisher = {Lawerence Erlbaum Associates},
title = {{Rationale in Practice: templates for Capturing and Applying Design Expertise}},
year = {1996}
}
@inproceedings{KULTUR2008,
address = {New York, NY, USA},
author = {Kultur, Yigit and Turhan, Burak and Bener, Ayse Basar},
booktitle = {SIGSOFT '08/FSE-16: Proceedings of the 16th ACM SIGSOFT International Symposium on Foundations of software engineering},
doi = {http://doi.acm.org/10.1145/1453101.1453148},
isbn = {978-1-59593-995-1},
pages = {330--338},
publisher = {ACM},
title = {{ENNA: software effort estimation using ensemble of neural networks with associative memory}},
year = {2008}
}
@inproceedings{ashoh09,
address = {New York, NY, USA},
author = {Ashok, B and Joy, Joseph and Liang, Hongkang and Rajamani, Sriram K and Srinivasa, Gopal and Vangala, Vipindeep},
booktitle = {ESEC/FSE '09: Proceedings of the the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering},
isbn = {978-1-60558-001-2},
pages = {373--382},
publisher = {ACM},
title = {{DebugAdvisor: a recommender system for debugging}},
year = {2009}
}
@inproceedings{TOSUN2009,
address = {New York, NY, USA},
author = {Tosun, Ayse and Turhan, Burak and Bener, Ayse},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540446},
isbn = {978-1-60558-634-2},
pages = {1--9},
publisher = {ACM},
title = {{Validation of network measures as indicators of defective modules in software systems}},
year = {2009}
}
@inproceedings{Quinlan1993,
author = {Quinlan, J.R.},
booktitle = {Proceedings of the Tenth International Conference on Machine Learning},
file = {:Users/timm/svns/doc/quinlan93.pdf:pdf},
pages = {236--243},
publisher = {Citeseer},
title = {{Combining instance-based and model-based learning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.34.6358\&amp;rep=rep1\&amp;type=pdf},
year = {1993}
}
@inproceedings{gautier93,
author = {Gautier, Patrice O and Gruber, Thomas R},
booktitle = {AAAI-93},
pages = {264--270},
title = {{Generating Explanations of Device Behavior Using Compositional Modeling and Causal Ordering}},
year = {1993}
}
@misc{compton94,
annote = {regarding the status of the PIERS system},
author = {Compton, P},
title = {{Personal communication}},
year = {1994}
}
@article{rum94,
author = {Rumbaugh, J},
journal = {JOOP},
pages = {8--23},
title = {{\{G\}etting \{S\}tarted: \{U\}sing \{U\}se \{C\}ases to \{C\}apture \{R\}equirements}},
year = {1994}
}
@article{weil92,
author = {Wielinga, B J and Schreiber, A T and Breuker, J A},
journal = {Knowledge Acquisition},
pages = {1--162},
title = {{\{KADS\}: a \{M\}odeling \{A\}pproach to \{K\}nowledge \{E\}ngineering.}},
volume = {4},
year = {1992}
}
@inproceedings{me96b,
annote = {Available from $\backslash$url\{http:/menzies.us/pdf/96ok.pdf\}},
author = {Menzies, T J},
booktitle = {ECAI '96},
title = {{On the Practicality of Abductive Validation}},
year = {1996}
}
@article{ragland95,
author = {Ragland, B},
journal = {Crosstalk},
number = {3},
title = {{Measure, Metric or Indicator: What's the Difference?}},
volume = {8},
year = {1995}
}
@inproceedings{harel95,
author = {Harel, D},
booktitle = {Diagrammatic Reasoning},
chapter = {8},
editor = {Glasgow, J and {N.H. Narayanan}, B Chandrasekaran},
pages = {235--271},
publisher = {The AAAI Press},
title = {{On Visual Formalisms}},
year = {1995}
}
@article{harrold98,
author = {Harrold, M J and Jones, J A and Rothermel, G},
journal = {Empirical Software Engineering},
pages = {203--211},
title = {{Empirical Studies of Control Dependence Graph Size for C Programs}},
volume = {3},
year = {1998}
}
@misc{john96,
annote = {(personal communication)},
author = {Johnson, R},
title = {{No Title}}
}
@misc{pisces,
author = {Technlogies, Reliable Sotware},
title = {{PiSCES Automatic Test Case Generator $\backslash$url\{http://www.rstcorp.com/tools.html\#pisces\}}},
year = {1997}
}
@article{Watson2007,
author = {Watson, Hugh J and Wixom, Barbara H},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Watson, Wixom - 2007 - The Current State of Business Intelligence.pdf:pdf},
journal = {IEEE Computer},
pages = {96--99},
title = {{The Current State of Business Intelligence}},
year = {2007}
}
@inproceedings{curtis00,
author = {Curtis, S A and Mica, J and Nuth, J and Marr, G and Rilee, M and Bhat, M},
booktitle = {International Astronautical Federation, 51st Congress},
month = oct,
title = {{ANTS (Autonomous Nano-Technology Swarm): An Artificial Intelligence Approach to Asteroid Belt Resource Exploration}},
year = {2000}
}
@inproceedings{garre05,
author = {Garre, M and {J.J. Cuadrado-Gallego}, M Sicilia and Charro, M and Rodriguez, D},
booktitle = {27th International Conference on Information Technology Interfaces. ITI 2005, Dubrovnik, Croatia},
title = {{Segmented Parametric Software Estimation Models: Using the EM algorithm with the ISBSG 8 database}},
year = {2005}
}
@inproceedings{mockus09,
annote = {Available from $\backslash$url\{http://sequoia.cs.byu.edu/files/reser2010/proceedings/Mockus\%20-\%20Experiences\%20from.pdf\}},
author = {{Audris Mockus Bente Anda} and Sjoberg, Dag I K},
booktitle = {First International Workshop on Replication in Empirical Software Engineering Research, ICSE'09},
title = {{Experiences from Replicating a Case Study to Investigate Reproducibility of Software Development}},
year = {2009}
}
@inproceedings{WAGNER2009,
address = {New York, NY, USA},
author = {Wagner, Stefan},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540447},
isbn = {978-1-60558-634-2},
pages = {1--9},
publisher = {ACM},
title = {{A Bayesian network approach to assess and predict software quality using activity-based quality models}},
year = {2009}
}
@inproceedings{mcluskey87,
author = {McCluskey, T L},
booktitle = {IJCAI'87},
pages = {331--333},
title = {{Combining Weak Learning Heuristics in General Problem Solvers}},
year = {1987}
}
@book{simon69,
author = {Simon, H},
publisher = {MIT Press},
title = {{The Science of the Artificial}},
year = {1969}
}
@inproceedings{nich92,
author = {Nicholson, A E and Brady, J M},
booktitle = {Proc. of the 10th European Conf. on Artificial Intelligence (ECAI-92)},
title = {{The data association problem when monitoring robot vehicles using dynamic belief networks}},
year = {1992}
}
@inproceedings{owen04a,
annote = {Tech report, Computer Science, West Virginia University},
author = {Owen, David and Menzies, Tim},
title = {{Experiments with LURCH}},
year = {2004}
}
@article{shull00b,
author = {Shull, F and Lanubile, F and Basili, V R},
journal = {IEEE Transactions of Software Engineering},
number = {11},
pages = {1101--1118},
title = {{Investigating Reading Techniques for Object-Oriented Framework Learning}},
volume = {26},
year = {2000}
}
@article{console91,
author = {Console, L and Torasso, P},
journal = {Computational Intelligence},
pages = {133--141},
title = {{A \{S\}pectrum of \{D\}efinitions of \{M\}odel-\{B\}ased \{D\}iagnosis}},
volume = {7},
year = {1991}
}
@incollection{buch84a,
author = {Buchanan, B G and Shortliffe, E H},
chapter = {10. Uncert},
pages = {209--232},
publisher = {Addison Wesley},
title = {{Rule-Based Expert Systems: The MYCIN Experiments of the Stanford Heuristic Programming Project}},
year = {1984}
}
@book{pad74,
author = {Paulo, L and Arbib, M A},
publisher = {W.B. Saunders},
title = {{System Theory}},
year = {1974}
}
@misc{orourke90,
annote = {September 27, 1990},
author = {O'Rourke, P},
institution = {University of California, Irvine, CA.},
number = {90-32},
title = {{Working Notes of the 1990 Spring Symposium on Automated Abduction}},
year = {1990}
}
@book{rakitin01,
author = {Rakitin, S R},
isbn = {1-58053-296-9},
publisher = {Artech House},
title = {{Software Verification and Validation for Practitioners and Managers, Second Edition}},
year = {2001}
}
@incollection{mich90,
author = {Michalski, R S},
booktitle = {Reading in Knowledge Acquisition and Learning},
editor = {Buchanan, B G and Wilkins, D C},
pages = {7--38},
publisher = {Morgan Kaufmann},
title = {{Toward a Unified Theory of Learning}},
year = {1993}
}
@article{dwyer98,
author = {Dwyer, M B and Avrunin, G S and Corbett, J C},
journal = {Proceeding of the 2nd Workshop on Formal Methods in Software Practice},
pages = {7--15},
title = {{Patterns in Property SPecifications for Finite-state Verification}},
year = {1998}
}
@article{smythe89,
author = {Smythe, G A},
journal = {The Endocrine Pancreas},
publisher = {Raven Press},
title = {{Brain-hypothalmus, \{P\}ituitary and the \{E\}ndocrine \{P\}ancreas}},
year = {1989}
}
@article{lees96,
author = {Lee, S and O'Keefe, R M},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = feb,
number = {1},
pages = {173--178},
title = {{The Effect of Knowledge Representation Schemes on Maintainability of Knowledge-Based Systems}},
volume = {8},
year = {1996}
}
@article{vandebrug86,
author = {de Brug, A Van and Bachant, J and McDermott, J},
journal = {IEEE Expert},
pages = {33--39},
title = {{The \{T\}aming of \{R1\}}},
year = {1986}
}
@incollection{porter80,
author = {Porter, M F},
booktitle = {Readings in Information Retrieval, San Francisco: Morgan Kaufmann},
editor = {Jones, K Sparck and Willet, P},
isbn = {1-55860-454-4},
title = {{An algorithm for suffix stripping}},
year = {1997}
}
@article{Browman1999,
author = {Browman, Howard I.},
file = {::},
issn = {0885-6125},
journal = {Mar. Ecol. Prog. Ser.},
pages = {301--309},
publisher = {Springer},
title = {{Negative results}},
url = {http://www.springerlink.com/index/N7K33668Q00G5105.pdf},
volume = {191},
year = {1999}
}
@inproceedings{me04h,
author = {Menzies, T and Port, D and Chen, Z and Hihn, J and Stukes, S},
booktitle = {Proceedings, ICSE},
file = {::},
title = {{Validation Methods for Calibrating Software Effort Models}},
year = {2005}
}
@article{agre93,
author = {Agre, P H},
journal = {Cognitive Science},
pages = {61--69},
title = {{The Symbolic WorldView: Reply to Vera and Simon}},
volume = {17},
year = {1993}
}
@article{yildiz06,
author = {Yildiz, O T and Alpaydin, E},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {3},
pages = {392--402},
title = {{Ordering and Finding the Best of K>2 Supervised Learning Algorithms}},
volume = {28},
year = {2006}
}
@article{NicDaeid2005,
abstract = {Over the last 20 years there has been an increasing interest in the development of robust systems, both analytical and statistical, to enable the linkage of seizures of illicit drug to each other. Much of this work has concentrated on the analysis of synthetic drugs, such as amphetamine and its analogues. In recent years, the analysis of both organic and elemental impurities as well as isotope ratios has advanced the usefulness of the techniques available. The application of specific chemometric methods to the derived analytical data has begun to provide the possibility of robust methods by which the resultant information can be interrogated.},
author = {{Nic Da\'{e}id}, Niamh and Waddell, Ruth J H},
doi = {10.1016/j.talanta.2005.05.018},
file = {:Users/timm/svns/doc/nic05.pdf:pdf},
issn = {1873-3573},
journal = {Talanta},
keywords = {chemometrics,drug analysis,forensic analysis},
month = aug,
number = {2},
pages = {280--5},
pmid = {18970168},
title = {{The analytical and chemometric procedures used to profile illicit drug seizures.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18970168},
volume = {67},
year = {2005}
}
@misc{spohrer84,
author = {Spohrer, J C and Riesbeck, C K},
institution = {Yale University},
number = {YALEU/DCS/RR-308},
title = {{Reasoning-driven Memory Modifications in the Economics Domain.}},
year = {1984}
}
@article{purv83,
author = {Purvey, R and Farrell, J and Klose, P},
journal = {ACM Tans Office Inf. Syst.},
number = {1},
pages = {3--34},
title = {{The Design of Star's Records Processing: Data processing for the noncomputer professional}},
volume = {1},
year = {1983}
}
@book{sha83,
address = {Cambridge, Massachusetts},
author = {Shapiro, E Y},
pages = {232},
publisher = {MIT Press},
title = {{Algorithmic program debugging}},
year = {1983}
}
@article{Bojarski2010,
author = {Bojarski, Slawomir and Congdon, Clare Bates},
file = {::},
journal = {IEEE Computational Intelligence and Games},
pages = {83--90},
title = {{REALM : A Rule-Based Evolutionary Computation Agent that Learns to Play Mario}},
url = {http://game.itu.dk/cig2010/proceedings/papers/cig10\_011CP\_125.pdf},
year = {2010}
}
@article{free90,
author = {Freeman-Benson, B N and Maloney, J and Borning, A},
journal = {Communications of the ACM},
pages = {54--63},
title = {{An Incremental Constraint Solver}},
volume = {33},
year = {1990}
}
@inproceedings{deb95b,
author = {Debenham, J},
booktitle = {Proceedings Seventh International Conference on Software Engineering and Knowledge Engineering SEKE'95, Washington, June},
title = {{A Unified Approach to Requirements Specification and Systems Analysis in the Design of Knowledge-Based Systems}},
year = {1995}
}
@inproceedings{ginsberg88a,
author = {Ginsberg, A},
booktitle = {Proceedings of the Seventh National Conference on Artificial Intelligence (AAAI'88),},
pages = {585--589},
title = {{Knowledge-Base Reduction: A New Approach to Checking Knowledge Bases for Inconsistency \& Redundancy}},
year = {1988}
}
@inproceedings{green91,
author = {Green, T R G and Petre, M and Bellamy, R K E},
booktitle = {Empirical Studies of Programmers: Fourth Workshop},
pages = {121--146},
title = {{Comprehensibility of Visual and Textual Programs: The Test of Superlativism Against the ``Match-Mismatch'' Conjecture}},
year = {1991}
}
@article{sch94,
author = {Schreiber, A T H and Wielinga, B and Akkermans, J M and Velde, W Van De and de Hoog, R},
journal = {IEEE Expert},
number = {6},
pages = {28--37},
title = {{CommonKADS. A Comprehensive Methodology for KBS Development}},
volume = {9},
year = {1994}
}
@inproceedings{men92s,
author = {Menzies, T J and Compton, P and Feldman, B and Toft, T},
booktitle = {Proceedings of the AAAI Symposium on Diagrammatic Reasoning Stanford University, March 25-27},
title = {{Qualitative Compartmental Modeling}},
year = {1992}
}
@inproceedings{slezak92,
author = {Slezak, P},
booktitle = {AAAI Spring Symposium on Reasoning with Diagrammatic Representations},
editor = {Narayanan, N H},
pages = {12--17},
title = {{The "Philosphical" Case Against Visual Images: a "Crucial" Experiment}},
year = {1992}
}
@article{vienneau95,
author = {Vienneau, R},
journal = {Journal of Parametrics},
month = apr,
pages = {18--36},
title = {{The Present Value of Software Maintenance}},
year = {1995}
}
@inproceedings{me90,
author = {Menzies, T J},
booktitle = {Proceedings \{AI\} '90},
title = {{Isa Object Part-of Knowledge Representation?}},
year = {1990}
}
@article{Manolescu2008,
author = {Manolescu, I. and Shasha, D. and Afanasiev, L. and Arion, A. and Dittrich, J. and Manegold, S. and Polyzotis, N. and Schnaitter, K. and Senellart, P. and Zoupanos, S.},
doi = {10.1145/1374780.1374791},
file = {:Users/timm/svns/doc/manolescu08.pdf:pdf},
issn = {01635808},
journal = {ACM SIGMOD Record},
keywords = {repeatability},
month = mar,
number = {1},
pages = {39},
title = {{The repeatability experiment of SIGMOD 2008}},
url = {http://portal.acm.org/citation.cfm?doid=1374780.1374791},
volume = {37},
year = {2008}
}
@article{Zitzler1999,
author = {Zitzler, E. and Thiele, L.},
doi = {10.1109/4235.797969},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zitzler, Thiele - 1999 - Multiobjective evolutionary algorithms a comparative case study and the strength Pareto approach.pdf:pdf},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {pareto},
mendeley-tags = {pareto},
number = {4},
pages = {257--271},
title = {{Multiobjective evolutionary algorithms: a comparative case study and the strength Pareto approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=797969},
volume = {3},
year = {1999}
}
@article{erik95,
author = {Eriksson, H and Shahar, Y and Tu, S W and Puerta, A R and Musen, M A},
journal = {Artificial Intelligence},
number = {2},
pages = {293--326},
title = {{Task Modeling with Reusable Problem-Solving Methods}},
volume = {79},
year = {1995}
}
@inproceedings{pecheur00,
author = {Pecheur, Charles and Simmons, Reid},
booktitle = {Proceedings of First Goddard Workshop on Formal Approaches to Agent-Based Systems},
month = apr,
pages = {5--7},
title = {{From Livingstone to SMV: Formal Verification for Autonomous Spacecrafts}},
year = {2000}
}
@inproceedings{tallis98,
author = {Tallis, M},
booktitle = {Banff KAW '98 workshop.},
title = {{A Script-Based Approach to Modifying Knowledge-Based Systems}},
year = {1998}
}
@book{gardner00,
author = {Gardner, Karen M and Rush, Alexander R and Crist, Michael and Konitzer, Rober and Odell, James J and Teegarden, Bobbin and Konitzer, Robert},
isbn = {0521649986},
month = jun,
publisher = {Cambridge University Press},
title = {{Cognitive Patterns: Problem-Solving Frameworks for Object Technology}},
year = {1998}
}
@article{gick80,
author = {Gick, M L and Holyoak, K J},
journal = {Cognitive Psychology},
pages = {306--355},
title = {{Analogic Problem Solving}},
volume = {12},
year = {1980}
}
@phdthesis{yost92a,
author = {Yost, G R},
school = {Computer Science, Carnegie Mellon},
title = {{TAQL: A Problem Space Tool for Expert System Development}},
year = {1992}
}
@inproceedings{zowghi96,
author = {Zowghi, D and Ghose, A and Peppas, P},
booktitle = {Proceedings of the 4th Pacific Rim International Conference on Artificial Intelligence (PRICAI96), Cairns, Australia, August},
title = {{A Framework for Reasoning about Requirements Evolution}},
year = {1996}
}
@inproceedings{pressburger06,
annote = {Available from $\backslash$url\{http://ti.arc.nasa.gov/m/tech/rse/publications/papers/IEEE06/infuse.pdf\}},
author = {Pressburger, T and Hinchey, M and Feather, M S and Markosian, L},
booktitle = {IEEE International Conference on Space Mission Challenges for Information Technology},
title = {{Infusing Software Engineering Technology into Practice at NASA}},
year = {2006}
}
@article{clancey89,
author = {Clancey, W},
journal = {IEEE Expert},
pages = {9--23},
title = {{Viewing Knowledge Bases as Qualitative Models}},
year = {1989}
}
@inproceedings{crawford92,
author = {Crawford, J and Farquhar, A and Kuipers, B},
booktitle = {Recent Advances in Qualitative Physics},
editor = {Faltings, B and Struss, P},
publisher = {The MIT Press},
title = {{QPC: A Compiler from Physical Models into Qualitative Differential Equations}},
year = {1992}
}
@inproceedings{koe95,
author = {Koedinger, K R and Anderson, J R},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and {N.H. Narayanan}, B Chandrasekaran},
pages = {577--625},
publisher = {The AAAI Press},
title = {{Abstract Planning and Conceptual Chunks}},
year = {1995}
}
@misc{budgen06,
annote = {Keynote address, CSEET'06},
author = {Budgen, D},
title = {{No Title}},
year = {2006}
}
@book{glass97,
author = {Glass, R L},
isbn = {013673443X},
publisher = {Pearson Education},
title = {{Software Runaways: Lessons Learned from Massive Software Project Failures}},
year = {1997}
}
@inproceedings{laurent92,
author = {Laurent, J P},
booktitle = {Proceedings of the 10th European Conference on Artificial Intelligence, ECAI-92, Vienna, Austria},
pages = {829--834},
title = {{Proposals for a valid terminology in KBS Validation}},
year = {1992}
}
@incollection{lee96a,
author = {Lee, J and Lai, K},
booktitle = {Design Rationale: Concepts, Techniques, and Use},
editor = {Moran, T P and Carroll, J M},
pages = {21--52},
publisher = {Lawerence Erlbaum Associates},
title = {{What's in Design Rationale?}},
year = {1996}
}
@misc{Norvig2011,
author = {Norvig, Peter},
booktitle = {New York Post},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Norvig - 2011 - The machine age.pdf:pdf},
title = {{The machine age}},
url = {http://www.getcited.org/pub/102527552},
year = {2011}
}
@misc{jones08,
annote = {Available from $\backslash$url\{http://www.di.univaq.it/ase2008/docs/ASE-08-slides.pdf\}},
author = {Jones, C B},
title = {{Reflections on, and predictions for, support systems for the development of programs, \{K\}eynote address, \{IEEE\} \{ASE\}}},
year = {2008}
}
@inproceedings{comp98,
author = {Compton, P and Ramadan, Z and Preston, P and Le-Gia, T and V.Chellen and Mulholland, M and Hibbert, D B and Haddad, P R and Kang, B},
booktitle = {Banff Workshop on Knowledge Acquisition},
title = {{A Trade-off Between Domain Knowledge and Problem-Solving Method Power,}},
year = {1998}
}
@inproceedings{me97o,
author = {Menzies, T J and Cohen, R F and Waugh, S},
booktitle = {Banff KAW '98 workshop.},
title = {{Evaluating Conceptual Qualitative Modeling Languages}},
year = {1998}
}
@book{forr61,
author = {Forrester, J W},
publisher = {Pegasus Communications},
title = {{Industrial Dynamics}},
year = {1961}
}
@misc{clancey96,
annote = {Personal communcaition},
author = {Clancey, W},
title = {{No Title}},
year = {1996}
}
@article{frankl95,
author = {Frankl, P G and Weyuker, E J},
journal = {IEEE Transactions on Software Engineering},
month = oct,
number = {10},
pages = {861--863},
title = {{Reply to "Some Critical Remarks on a Hierarchy of Fault-Detecting Abilities of Test Methods"}},
volume = {21},
year = {1995}
}
@book{paulk95,
author = {Paulk, M C and Weber, C V and Curtis, B and Chriss, M B},
publisher = {Addison-Wesley},
title = {{The Capability Maturity Model: Guidelines for Improving the Software Process}},
year = {1995}
}
@inproceedings{TOSUN20092,
address = {Washington, DC, USA},
author = {Tosun, Ayse and Bener, Ayse},
booktitle = {ESEM '09: Proceedings of the 2009 3rd International Symposium on Empirical Software Engineering and Measurement},
doi = {http://dx.doi.org/10.1109/ESEM.2009.5316006},
isbn = {978-1-4244-4842-5},
pages = {477--480},
publisher = {IEEE Computer Society},
title = {{Reducing false alarms in software defect prediction by decision threshold optimization}},
year = {2009}
}
@article{Ali2006,
author = {Ali, S and Smith, K},
doi = {10.1016/j.asoc.2004.12.002},
file = {:Users/timm/svns/doc/On learning algorithm selection for classification (1).pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing},
keywords = {algorithm selection,classification,no free lunch theorem},
month = jan,
number = {2},
pages = {119--138},
title = {{On learning algorithm selection for classification}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1568494605000049},
volume = {6},
year = {2006}
}
@inproceedings{MIZUNO2007,
address = {New York, NY, USA},
author = {Mizuno, Osamu and Kikuno, Tohru},
booktitle = {ESEC-FSE '07: Proceedings of the the 6th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering},
doi = {http://doi.acm.org/10.1145/1287624.1287683},
isbn = {978-1-59593-811-4},
pages = {405--414},
publisher = {ACM},
title = {{Training on errors experiment to detect fault-prone software modules by spam filter}},
year = {2007}
}
@inproceedings{me92l,
author = {Menzies, T and Mahidadia, A and Compton, P},
booktitle = {Proceedings of the 7th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge-Based Systems Workshop},
title = {{Using Causality as a Generic Knowledge Representation, or Why and How Centralised Knowledge Servers Can Use Causality}},
year = {1992}
}
@article{vera93a,
author = {Vera, A H and Simon, H A},
journal = {Cognitive Science},
pages = {77--86},
title = {{Situated Action: A Response to Reviewers}},
volume = {17},
year = {1993}
}
@book{putnam92,
author = {Putnam, L and Myers, W},
publisher = {Yourdon Press Computing Series},
title = {{Measures for Excellence}},
year = {1992}
}
@article{kuipers86,
author = {Kuipers, B},
journal = {Artificial Intelligence},
pages = {229--338},
title = {{Qualitative Simulation}},
volume = {29},
year = {1986}
}
@inproceedings{grove95,
author = {Grove, D and Dean, J and Garnett, C and Chambers, C},
booktitle = {OOPSLA '95},
pages = {108--123},
title = {{Profile Guided Reciever Class Prediction}},
year = {1995}
}
@article{will91,
author = {Williams, B C and DeKleer, J},
journal = {Artificial Intelligence},
pages = {1--9},
title = {{Qualitative Reasoning about Physical Systems: a Return to Roots}},
volume = {51},
year = {1991}
}
@inproceedings{dambrosio93,
author = {D'Ambrosio, Bruce},
booktitle = {UAI'93},
title = {{Incremental Probabilistic Inference}},
year = {1983}
}
@book{tour86,
author = {Touretzky, J},
publisher = {Morgan Kaufmann},
title = {{The Mathematics of Inheritance}},
year = {1986}
}
@article{richards03,
author = {Richards, Debbie},
journal = {Requirements Engineering},
title = {{Merging Individual Conceptual Models of Requirements}}
}
@article{DeMil78,
author = {DeMillo, R and Lipton, R and Sayad, F},
journal = {IEEE Computer},
month = apr,
number = {4},
pages = {34--41},
title = {{Hints on Test Data Selection: Help for the Practising Programmer}},
volume = {11},
year = {1987}
}
@misc{ss1,
title = {{SpaceShipOne: Soaring Toward Tomorrow, A Space.com special report}},
year = {2004}
}
@article{morasca99,
author = {Morasca, S and Ruhe, Gunther},
journal = {International Journal of Software Engineering and Knowledge Engineering},
month = oct,
title = {{Guest editors' introduction of the Special issue on Knowledge Discovery from Software Engineering Data}},
year = {1999}
}
@book{davis02,
author = {Davis, J and Fensel:q, D and {van Harmelen (eds.)}, F},
publisher = {John Wiley},
title = {{Towards the Semantic Web: Ontology-Driven Knowledge Management}},
year = {2002}
}
@inproceedings{brouck03,
author = {Bouckaert, Remco},
booktitle = {ICML'03},
file = {::},
title = {{Choosing between two learning algorithms based on calibrated tests}},
year = {2003}
}
@article{hayes97a,
author = {Hayes, C C and Parzen, M I},
journal = {IEEE Transactions of Knowledge and Data Engineering},
number = {6},
pages = {838--847},
title = {{QUEN: An Achivement Test for Knowledge-Based Systems}},
volume = {9},
year = {1997}
}
@article{lessmann09,
author = {Lessmann, S and Baesens, B and Mues, C and Pietsch, S},
file = {::},
journal = {IEEE Transactions on Software Engineering},
title = {{Benchmarking classification models for software defect prediction: A proposed framework and novel findings}},
year = {2008}
}
@article{lutz04,
author = {Lutz, Robyn R and Mikulski, Ines Carmen},
journal = {IEEE Trans. Software Eng},
number = {3},
pages = {172--180},
title = {{Empirical Analysis of Safety-Critical Anomalies During Operations}},
url = {http://csdl.computer.org/comp/trans/ts/2004/03/e0172abs.htm},
volume = {30},
year = {2004}
}
@misc{me00c,
author = {Menzies, Tim and Cukic, Bojan and Singh, Harhsinder},
month = apr,
title = {{Agents Talking Faster}},
year = {2000}
}
@article{tarjan81,
author = {Tarjan, R E},
journal = {Journal of the Association for Computing Machinery},
month = jul,
number = {3},
pages = {594--614},
title = {{Fast Algorithms for Solving Path Problems}},
volume = {28},
year = {1981}
}
@book{rosen93,
author = {Rosenbloom, P S and Laird, J E and Newell, A},
institution = {The MIT Press},
publisher = {The MIT Press},
title = {{The SOAR Papers}},
year = {1993}
}
@article{steels90,
author = {Steels, L},
journal = {\{AI\} Magazine},
pages = {29--49},
title = {{Components of \{E\}xpertise}},
volume = {11},
year = {1990}
}
@inproceedings{me08fh,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08antares.pdf\}},
author = {Gundy-Burlet, K and Schumann, J and Menzies, T and Barrett, T},
booktitle = {9th International Symposium on Artifical Intelligence, Robotics and Automation in Space},
title = {{Parametric Analysis of ANTARES Re-entry Guidance Algorithms Using Advanced Test Generation and DAta Analysis}},
year = {2008}
}
@misc{price-s,
author = {NJ, PRICE Systems L L C Mt. Laurel},
title = {{Your Guide to PRICE-S: Estimating Cost and Schedule of Software Development and Support}},
year = {1998}
}
@inproceedings{owen06a,
author = {{D. Owen}, D Desovski and Cukic, B},
booktitle = {ISSRE 06},
title = {{Effectively Combining Software Verification Strategies: Understanding Different Assumptions}},
year = {2006}
}
@inproceedings{me95a,
author = {Menzies, T J},
booktitle = {Australian Cognitive Science Society, 3rd Conference},
title = {{Situated \{S\}emantics is a \{S\}ide-\{E\}ffect of the \{C\}omputational \{C\}omplexity of \{A\}bduction}},
year = {1995}
}
@inproceedings{me03m,
author = {Menzies, T and Ammar, K and Nikora, A and Stefano, Justin Di},
booktitle = {Tech report, Computer Science, Portland State University},
title = {{How Simple is Software Defect Detection?}},
year = {2004}
}
@inproceedings{khos02z,
address = {Los Alamitos, CA, USA},
author = {Khoshgoftaar, T M and Geleyn, E and Nguyen, L and Bullard, L},
booktitle = {IEEE Symposium on High Assurance Software Engineering},
doi = {http://doi.ieeecomputersociety.org/10.1109/HASE.2002.1173102},
issn = {1530-2059},
pages = {51},
publisher = {IEEE Computer Society},
title = {{Cost-Sensitive Boosting In Software Quality Modeling}},
volume = {00},
year = {2002}
}
@inproceedings{ram94,
author = {Ramakrishnan, S},
booktitle = {Proceedings of the \{F\}irst \{I\}nternational \{C\}onference on \{S\}oftware \{T\}esting, \{R\}eliability and \{Q\}uality \{A\}ssurance (STRQA 1994)},
title = {{Quality \{F\}actors for \{R\}esource \{A\}llocations \{P\}roblems - \{L\}inking \{D\}omain \{A\}nalysis and \{O\}bject-\{O\}riented \{S\}oftware \{E\}ngineering}},
year = {1994}
}
@book{neuman95,
author = {Neumann, Peter G},
isbn = {0-201-55805-X},
publisher = {ACM Press / Addison Wesley},
title = {{Computer-Related Risks}},
year = {1995}
}
@inproceedings{Dum98,
author = {Dumais, S and Platt, J and Heckerman, D and Sahami, M},
booktitle = {The International Conference on Information and Knowledge Management},
pages = {pp. 148--155},
title = {{Inductive learning algorithms and representations for text categorization}},
year = {1998}
}
@book{Barski2010,
author = {Barski, Conrad},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Barski - 2010 - The Land of Lisp.pdf:pdf},
publisher = {NoStrach Press},
title = {{The Land of Lisp}},
year = {2010}
}
@inproceedings{willzh96,
author = {Williams, G J and Huang, Z},
booktitle = {Proceedings PKAW '96: Pacific Knowledge Acquisition Workshop},
title = {{A Case Study in Knowledge Acquisition for Insurance Risk Assessment using a KDD Methodology}},
year = {1996}
}
@article{Liu2004,
author = {Liu, H and Motoda, H and Yu, L},
doi = {10.1016/j.artint.2004.05.009},
file = {:Users/timm/svns/doc/Liu04.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {ac,asu,corresponding author,dimensionality reduction,e-mail addresses,edu,feature selection and ranking,h,hliu,jp,learning,leiyu,liu,motoda,osaka-u,sampling,sanken},
month = nov,
number = {1-2},
pages = {49--74},
title = {{A selective sampling approach to active feature selection}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370204000980},
volume = {159},
year = {2004}
}
@inproceedings{MORASCA2009,
address = {New York, NY, USA},
author = {Morasca, Sandro},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540465},
isbn = {978-1-60558-634-2},
pages = {1--10},
publisher = {ACM},
title = {{Building statistically significant robust regression models in empirical software engineering}},
year = {2009}
}
@book{clarke99,
address = {\{C\}ambridge, \{MA\}},
author = {Clarke, E and Grumberg, Orna and Peled, Doron A},
publisher = {\{MIT\} \{P\}ress},
title = {{\{M\}odel \{C\}hecking}},
year = {1999}
}
@inproceedings{garm95,
author = {Gardin, F and Meltzer, B},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and {N.H. Narayanan}, B Chandrasekaran},
pages = {669--688},
publisher = {The AAAI Press},
title = {{Analogical Representations of Naive Physics}},
year = {1995}
}
@article{kotonya92,
author = {Kotonya, G and Sommerville, I},
journal = {IEE Software Engineering Journal},
pages = {375--387},
title = {{Viewpoints for Requirements Definition}},
volume = {7},
year = {1992}
}
@book{ocs-book-96,
editor = {Jampel, M and Freuder, E and Maher, M},
month = aug,
number = {1106},
publisher = {Springer},
series = {LNCS},
title = {{Over-Constrained Systems}},
year = {1996}
}
@book{kelton02,
author = {Kelton, D and Sadowski, R and Sadowski, D},
publisher = {McGraw-Hill},
title = {{Simulation with Arena, second edition}},
year = {2002}
}
@article{doyle79,
author = {Doyle, J},
journal = {Artificial Intelligence},
pages = {231--272},
title = {{A Truth Maintenance System}},
volume = {12},
year = {1979}
}
@article{Quickstart2011,
author = {Quickstart, A Beamer},
doi = {10.1002/ajmg.a.33931},
issn = {1552-4833},
journal = {American journal of medical genetics. Part A},
month = feb,
number = {2},
pages = {fmi--fmiv},
pmid = {21271636},
title = {{Table of contents, volume 155, number 2, february 2011.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21271636},
volume = {155},
year = {2011}
}
@misc{mmcarthy00,
author = {McCarthy, J},
title = {{Lessons from the \{L\}ighthill \{F\}lap}},
year = {2000}
}
@article{Dietterich2008,
author = {Dietterich, Thomas G. and Domingos, Pedro and Getoor, Lise and Muggleton, Stephen and Tadepalli, Prasad},
doi = {10.1007/s10994-008-5079-1},
file = {:Users/timm/svns/doc/mlTheNext10years.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {dietterich,editors,g,hendrik blockeel,inductive logic programming,jude shavlik,learning,p,relational learning,statistical relational,structured machine learning,t,tadepalli},
month = aug,
number = {1},
pages = {3--23},
title = {{Structured machine learning: the next ten years}},
url = {http://www.springerlink.com/index/10.1007/s10994-008-5079-1},
volume = {73},
year = {2008}
}
@inproceedings{fea01,
author = {Feather, M and In, H and Kiper, J and Kurtz, J and Menzies, T},
booktitle = {ECE UBC tech report},
title = {{First Contract: Better, Earlier Decisions for Software Projects}},
year = {2001}
}
@book{davi91,
author = {Davison, A},
publisher = {The PARLOG Group, Dept. of Computing, Imperial College, London},
title = {{Design Issues for Logic-Programming-based Object-Oriented Languages}},
year = {1991}
}
@inproceedings{me03o,
author = {Menzies, T and Gunnalan, R and Appukutty, K and A, Srinivasan and Hu, Y},
booktitle = {International Journal on Artificial Intelligence Tools (IJAIT), to appear},
title = {{Learning Tiny Theories}},
year = {2005}
}
@article{dekleer86c,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {197--224},
title = {{Problem Solving with the ATMS}},
volume = {28},
year = {1986}
}
@misc{herb94,
author = {Herbsleb, James and Carleton, Anita and Rozum, James and Siegel, Jane and Zubrow, David},
institution = {Software Engineering Institute, Carnegie Mellon University},
month = aug,
title = {{Benefits of CMM-Based Software Process Improvement: Initial Results}},
year = {1994}
}
@article{preece92b,
author = {Preece, A D and Shinghal, R and Batarekh, A},
journal = {Expert Systems with Applications},
number = {2},
pages = {421--436},
title = {{Verifying expert systems: a logical framework and a practical tool}},
volume = {5},
year = {1992}
}
@misc{bsc99,
author = {Page, Web},
title = {{No Title}}
}
@inproceedings{tosun10,
author = {Tosun, A and Bener, A and Kale, R},
booktitle = {Twenty-Second IAAI Conference on Artificial Intelligence},
title = {{AI-Based Software Defect Predictors: Applications and Benefits in a Case Study}},
year = {2010}
}
@article{darke96,
author = {Darke, P and Shanks, G},
journal = {Requirements Engineering},
number = {2},
pages = {88--105},
title = {{Stakeholder Viewpoints in Requirements Definition: A Framework for Understanding Viewpoint Development Approaches}},
volume = {1},
year = {1996}
}
@article{rissanen78,
author = {Rissanen, J},
journal = {Automatica},
pages = {465--471},
title = {{Modeling by shortest data description}},
volume = {14},
year = {1978}
}
@incollection{iwasaki89,
author = {Iwasaki, Y},
booktitle = {The Handbook of Artificial Intelligence},
editor = {{A. Barr}, P R Cohen and Feigenbaum, E A},
pages = {323--413},
publisher = {Addison Wesley},
title = {{Qualitative Physics}},
volume = {4},
year = {1989}
}
@inproceedings{me07g,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07fix.pdf\}},
author = {Menzies, T and Elrawas, O and Baker, D and Hihn, J and Lum, K},
booktitle = {International Workshop on Living with Uncertainty (an ASE'07 co-located event)},
title = {{On the Value of Stochastic Abduction (if you fix everything, you lose fixes for everything else)}},
year = {2007}
}
@inproceedings{Basili01cebase,
author = {Basili, Victor and Tesoriero, Roseanne and Costa, Patricia and Lindvall, Mikael and Rus, Ioana and Shull, Forrest and Zelkowitz, Marvin},
booktitle = {in Profes (Product Focused Software Process Improvement},
pages = {110--125},
title = {{Building an Experience Base for Software Engineering: A report on the first CeBASE eWorkshop}},
year = {2001}
}
@inproceedings{duda76,
author = {Duda, R and Hart, P and Nilsson, N},
booktitle = {Technical Report 124, Artificial Intelligence Center, SRI International},
title = {{Subjective bayesian methods for rule-based inference systems}},
year = {1976}
}
@article{Zitzler1999,
author = {Zitzler, E. and Thiele, L.},
doi = {10.1109/4235.797969},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zitzler, Thiele - 1999 - Multiobjective evolutionary algorithms a comparative case study and the strength Pareto approach.pdf:pdf},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {pareto},
mendeley-tags = {pareto},
number = {4},
pages = {257--271},
title = {{Multiobjective evolutionary algorithms: a comparative case study and the strength Pareto approach}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=797969},
volume = {3},
year = {1999}
}
@misc{coker03,
annote = {Available from $\backslash$url\{http://www.jcrocket.com/altimeters.shtml\}},
author = {Coker, John},
title = {{John Coker's Rocket Pages: Altimeter Comparison}},
year = {2003}
}
@inproceedings{Alm91,
author = {Almuallim, H and Dietterich, T G},
booktitle = {The Ninth National Conference on Artificial Intelligence},
pages = {pp. 547--552},
publisher = {AAAI Press},
title = {{Learning with Many Irrelevant Features}},
year = {1991}
}
@article{wilson97a,
author = {Wilson, D R and Martinez, T R},
journal = {Journal of Artificial Intelligence Research},
pages = {1--34},
title = {{Improved Heterogeneous Distance Functions}},
volume = {6},
year = {1997}
}
@misc{parkes99lifted,
author = {Parkes, A},
title = {{Lifted Search Engines for Satisfiability}},
url = {citeseer.nj.nec.com/parkes99lifted.html},
year = {1999}
}
@book{modelchecking,
address = {\{C\}ambridge, \{MA\}},
author = {Clarke, Edmund A and Grumberg, Orna and Peled, Doron A},
publisher = {\{MIT\} \{P\}ress},
title = {{\{M\}odel \{C\}hecking}},
year = {1999}
}
@article{selman96knowledge,
author = {Selman, Bart and Kautz, Henry},
journal = {Journal of the ACM},
number = {2},
pages = {193--224},
title = {{Knowledge compilation and theory approximation}},
volume = {43},
year = {1996}
}
@inproceedings{fouche92,
author = {Fouche, P and Kuipers, B},
booktitle = {Recent Advances in Qualitative Physics},
editor = {Faltings, B and Struss, P},
pages = {263--278},
publisher = {The MIT Press},
title = {{An Assessment of Current Qualitative Simulation Techniques}},
year = {1992}
}
@inproceedings{me09n,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09ourmine.pdf\}},
author = {Gay, G and Menzies, T and Cukic, B and Turhan, Burak},
booktitle = {PROMISE'09},
title = {{How to Build Repeatable Experiments}},
year = {2009}
}
@inproceedings{rymon93setree,
author = {Rymon, Ron},
booktitle = {International Conference on Machine Learning},
pages = {268--275},
title = {{An \{SE\}-tree based Characterization of the Induction Problem}},
year = {1993}
}
@article{boehm88,
author = {Boehm, B and Papaccio, P},
journal = {IEEE Trans. on Software Engineering},
month = oct,
number = {10},
pages = {1462--1477},
title = {{Understanding and controlling software costs}},
volume = {14},
year = {1988}
}
@article{tambe90,
author = {Tambe, M and Newell, A and Rosenbloom, P S},
journal = {Machine Learning},
number = {3},
pages = {299--348},
title = {{The Problem of Expensive Chunks and its Solution by Restricting Expressiveness}},
volume = {5},
year = {1990}
}
@book{moran96,
author = {Moran, T P and Carroll, J M},
publisher = {Lawerence Erlbaum Associates},
title = {{Design Rationale: Concepts, Techniques, and Use}},
year = {1996}
}
@inproceedings{vante97,
author = {van Harmelen, F and ten Teije, Annette},
booktitle = {European Symposium on the Validation and Verification of Knowledge Based Systems, Leuven, Belgium},
title = {{Validation and Verification of Conceptual Models of Diagnosis}},
year = {1997}
}
@book{puccia85,
author = {Levins, R and Puccia, C J},
pages = {259},
publisher = {Harvard University Press, Cambridge, Mass.},
title = {{Qualitative Modeling of Complex Systems: An Introduction to Loop Analysis and Time Averaging}},
year = {1985}
}
@article{Leigh,
author = {Leigh, Ryan and Louis, Sushil J and Miles, Chris},
file = {::},
journal = {CIG 2007},
keywords = {a,genetic algorithms,pathfinding},
title = {{Using a Genetic Algorithm to Explore A * -like Pathfinding Algorithms}}
}
@article{boehmturner03,
author = {Boehm, B and Turner, R},
journal = {IEEE Computer},
month = jun,
number = {6},
pages = {57--66},
title = {{Using risk to balance agile and plan-driven methods}},
volume = {36},
year = {2003}
}
@book{filman04,
author = {Filman, R E},
publisher = {Addison-Wesley, Boston},
title = {{Aspect-Oriented Software Development}},
year = {2004}
}
@article{buntine98,
author = {Buntime, W},
journal = {IEEE Intelligent Systems},
pages = {9--15},
title = {{Will Domain-Specific Code Syhthsis Become a Silver Bullet?}},
year = {1998}
}
@article{sand89,
author = {Sanderson, P M and Verhapge, A G and Fuld, R B},
journal = {Ergonomics},
number = {11},
pages = {1343--1372},
title = {{State-space and Verbal Protocol Methods for Studying the Human Operator in Process Control}},
volume = {32},
year = {1989}
}
@article{demillo78,
author = {DeMillo, R A and Lipton, R J and Sayward, F G},
journal = {Computer},
keywords = {mutation,testing},
number = {4},
pages = {34--41},
title = {{Hints on Test Data Selection: Help for the Practicing Programmer}},
volume = {11},
year = {1978}
}
@inproceedings{MORAN2009,
address = {London, U.K.},
author = {Moran, Stuart and He, Yulan and Liu, Kecheng},
booktitle = {Proceedings of the World Congress on Engineering 2009 Vol I},
title = {{An Empirical Framework for Automatically Selecting the Best Bayesian Classifier}},
year = {2009}
}
@article{Rubner1998,
author = {Rubner, Y. and Tomasi, C. and Guibas, L.J.},
doi = {10.1109/ICCV.1998.710701},
file = {:Users/timm/svns/doc/earthMoverDistance.pdf:pdf},
isbn = {81-7319-221-9},
journal = {Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)},
pages = {59--66},
publisher = {Narosa Publishing House},
title = {{A metric for distributions with applications to image databases}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=710701},
year = {1998}
}
@article{Webb2000,
author = {Webb, GI},
file = {:Users/timm/svns/doc/webb00.pdf:pdf},
journal = {Machine learning},
keywords = {aggregation,bagging,boosting,decision committee,decision tree,wagging},
pages = {159--197},
title = {{Multiboosting: A technique for combining boosting and wagging}},
url = {http://www.springerlink.com/index/G7K410V232R15363.pdf},
volume = {39},
year = {2000}
}
@inproceedings{CHEN2005,
address = {New York, NY, USA},
author = {Chen, Zhihao and Menzies, Tim and Port, Dan and Boehm, Barry},
booktitle = {PROMISE '05: Proceedings of the 2005 workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1083165.1083171},
isbn = {-159593-125-2},
pages = {1--6},
publisher = {ACM},
title = {{Feature subset selection can improve software cost estimation accuracy}},
year = {2005}
}
@article{chechik03,
author = {Checkik, M and Devereux, Benet and Gurfinkel, Arie and Easterbrook, Steve},
journal = {ACM Transactions on Software Engineering and Methodology (to appear)},
title = {{Multi-Valued Symbolic Model-Checking}},
year = {2003}
}
@article{MALHOTRA2010,
address = {New York, NY, USA},
author = {Malhotra, Ruchika and Kaur, Arvinder and Singh, Guru Gobind},
doi = {http://doi.acm.org/10.1145/1764810.1764825},
issn = {0163-5948},
journal = {SIGSOFT Softw. Eng. Notes},
number = {3},
pages = {1--6},
publisher = {ACM},
title = {{Application of machine learning methods for software effort prediction}},
volume = {35},
year = {2010}
}
@misc{nasa91,
author = {NASA},
howpublished = {Software \{T\}echnology \{B\}ranch, \{l\}yndon \{B\}. \{J\}ohnson \{S\}pace \{C\}enter},
title = {{\{CLIPS\} \{R\}eference \{M\}anual}},
year = {1991}
}
@book{fowler99,
address = {Boston, MA, USA},
author = {Fowler, Martin},
isbn = {0-201-48567-2},
keywords = {evolution refactoring software},
publisher = {Addison-Wesley},
title = {{Refactoring: Improving the Design of Existing Code}},
year = {1999}
}
@inproceedings{ceruti00,
author = {Ceruti, M and Anken, C and Lin, A and Rubin, S},
booktitle = {Proceedings of IEEE Systems Man and Cybernetics},
title = {{Applications of High-Performance Knowledge-Based Technology}},
year = {2000}
}
@article{kohavi97,
author = {Kohavi, Ron and John, George H},
journal = {Artificial Intelligence},
number = {1-2},
pages = {273--324},
title = {{Wrappers for Feature Subset Selection}},
url = {citeseer.nj.nec.com/kohavi96wrappers.html},
volume = {97},
year = {1997}
}
@inproceedings{marcus03,
author = {Marcus, A and Maletic, J},
booktitle = {Proceedings of the Twenty-Fifth International Conference on Software Engineering},
title = {{Recovering Documentation-to-Source Code Traceability Links using Latent Semantic Indexing}},
year = {2003}
}
@misc{me98g,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/99ab.pdf\}},
author = {Menzies, T and Waugh, S},
title = {{Abduction: Experiments and Implications}},
year = {1999}
}
@inproceedings{heitmeyer95,
author = {Heitmeyer, C and Labaw, B and Kiskis, D},
booktitle = {International Symposium on Requirements Engineering, York, England , March 26-27},
title = {{Consistency Checking of \{SCR\}-Style Requirements Specifications}},
year = {1995}
}
@misc{me97i,
author = {Menzies, T},
howpublished = {Asian-Pacific Workshop on Intelligent Software Engineering},
title = {{Applications of Abduction: A Unified Framework for Software and Knowledge Engineering}},
year = {1998}
}
@article{compton92,
author = {Compton, P and Edwards, G and Srinivasan, A and Malor, P and Preston, P and Kang, B and Lazarus, L},
journal = {Artificial Intelligence in Medicine},
pages = {47--59},
title = {{Ripple-down-rules: Turning Knowledge Acquisition into Knowledge Maintenance}},
volume = {4},
year = {1992}
}
@inproceedings{wino75,
author = {Winograd, T},
booktitle = {Readings in Knowledge Representation},
pages = {185--210},
publisher = {Morgan Kaufman},
title = {{Frame Representations and the Declarative/Procedural Controversy}},
year = {1975}
}
@article{gaines95,
author = {Gaines, B R and Shaw, M L G},
journal = {The Knowledge Engineering Review},
title = {{Knowledge Acquisition Tools based on Personal Construct Psychology}},
year = {1993}
}
@book{brooks75,
author = {Brooks, F P},
publisher = {Addison-Wesley},
title = {{The Mythical Man-Month, Anniversary edition}},
year = {1975}
}
@book{hof80,
author = {Hofstadter, D R},
pages = {777},
publisher = {Penguin Books},
title = {{G\"{o}del, Escher, Bach: An Eternal Golden Braid}},
year = {1980}
}
@article{cohen98,
author = {Cohen, Paul and Schrag, Robert and Jones, Eric and Pease, Adam and Lin, Albert and Starr, Barbara and Gunning, David and Burke, Murray},
journal = {AI Magazine},
number = {4},
pages = {25--49},
title = {{The DARPA High-Performance Knowledge Bases Project}},
volume = {19},
year = {1998}
}
@book{raymond01,
author = {Raymond, E S and Young, B},
isbn = {0596001088},
publisher = {O'Reilly \& Associates},
title = {{The Cathedral and the Bazaar: Musings on Linux and Open Source by an Accidental Revolutionary}},
year = {2001}
}
@article{arthur99,
author = {Arthur, J D and Groner, M K and Hayhurst, K J and Holloway, C M},
journal = {IEEE Computer},
month = oct,
pages = {79--83},
title = {{Evaluating the Effectiveness of Independent Verification and Validation}},
year = {199}
}
@inproceedings{lam00,
author = {van Lamsweerde, A},
booktitle = {Proceedings ICSE2000, Limmerick, Ireland},
pages = {5--19},
title = {{Requirements Engineering in the Year 00: A Research Perspective}},
year = {2000}
}
@article{Valente99,
author = {Valente, A and Russ, T and MacGrecor, R and Swartout, W},
journal = {IEEE Intelligent Systems},
month = jan,
number = {1},
pages = {27--36},
title = {{Building and (Re)Using an Ontology for Air Campaign Planning}},
volume = {14},
year = {1999}
}
@article{benj95,
author = {Benjamins, R},
journal = {International Journal of Expert Systems: Research \& Applications},
number = {2},
pages = {93--120},
title = {{Problem-Solving Methods for Diagnosis and their Role in Knowledge Acquisition}},
volume = {8},
year = {1995}
}
@article{basili99,
author = {Basili, V R and Shull, F and Lanubile, F},
journal = {IEEE Transactions on Software Engineering},
number = {4},
pages = {456--473},
title = {{Building Knowledge through Families of Experiments}},
volume = {25},
year = {1999}
}
@inproceedings{ritthoff01,
annote = {Available from $\backslash$url\{http://ls2-www.cs.uni-dortmund.de/\~{}fischer/publications/YaleLLWA01.pdf\}},
author = {Ritthoff, O and Klinkenberg, R and Fischer, S and Mierswa, I and Felske, S},
booktitle = {LLWA 01 - Tagungsband der GI-Workshop-Woche, Dortmund, Germany},
month = oct,
pages = {84--92},
title = {{YALE: Yet Another Learning Environment}},
year = {2001}
}
@inproceedings{kind92,
author = {Kindfield, A C H},
booktitle = {Proceedings of the AAAI Symposium on Diagrammatic Reasoning Stanford University, March 25-27},
pages = {41--46},
title = {{Expert Diagrammatic Reasoning in Biology}},
year = {1992}
}
@inproceedings{murph95b,
author = {Murphy, G C and Notkin, D},
booktitle = {ACM SIGSOFT Symposium on the Foundations of Software Engineering (FSE '95)},
title = {{Software Reflexion Models: Bridging the Gap Between Source and High-Level Models}},
year = {1995}
}
@article{brown06,
author = {Brown, A W and Iyengar, S and Johnston, S},
journal = {IBM Systems Journal},
number = {3},
pages = {463--480},
title = {{A Rational approach to model-driven development}},
volume = {45},
year = {2006}
}
@inproceedings{zdrahal96,
author = {Zdrahal, Z and Motta, E},
booktitle = {10th Banff Knowledge Acquisition for Knowledge-Based Systems Workshop, November 9-14, 1996, Banff, Canada},
title = {{Improving Conpetence by Intergrating Case-Based Reasoning and Heuristic Search}},
year = {1996}
}
@inproceedings{me00w,
author = {Menzies, T J},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{Knowledge Elicitation: the State of the Art}},
year = {2002}
}
@article{Du2008a,
author = {Du, Q. and Fowler, J. E.},
doi = {10.1177/1094342007088380},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Du, Fowler - 2008 - Low-Complexity Principal Component Analysis for Hyperspectral Image Compression.pdf:pdf},
issn = {1094-3420},
journal = {International Journal of High Performance Computing Applications},
month = nov,
number = {4},
pages = {438--448},
title = {{Low-Complexity Principal Component Analysis for Hyperspectral Image Compression}},
url = {http://hpc.sagepub.com/cgi/doi/10.1177/1094342007088380},
volume = {22},
year = {2008}
}
@inproceedings{fen97,
author = {Fensel, D and Schoenegge, A},
booktitle = {Workshop on Problem-Solving Methods for Knowledge-based Systems, IJCAI '97, August 23.},
title = {{Hunting for Assumptions as Developing Method for Problem-Solving Methods}},
year = {1997}
}
@misc{seer-sem,
annote = {$\backslash$url\{http://www1.jsc.nasa.gov/bu2/PCEHHTML/pceh225.htm\}},
author = {of USA, DoD},
title = {{Parametric Cost Estimating Handbook, second Edition}},
year = {1999}
}
@book{bratko90,
author = {Bratko, I},
publisher = {Addison-Wesley},
title = {{Prolog Programming for Artificial Intelligence. (second edition)}},
year = {1990}
}
@article{Bird2009b,
annote = {Social metrics stuff.},
author = {Bird, Christian and Nagappan, Nachiappan and Gall, Harald and Murphy, Brendan and Devanbu, Premkumar},
doi = {10.1109/ISSRE.2009.17},
file = {:Users/timm/svns/doc/bird09.pdf:pdf},
isbn = {978-1-4244-5375-7},
journal = {2009 20th International Symposium on Software Reliability Engineering},
month = nov,
pages = {109--119},
publisher = {Ieee},
title = {{Putting It All Together: Using Socio-technical Networks to Predict Failures}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5362091},
year = {2009}
}
@phdthesis{acree80,
author = {Acree, A T},
school = {School of Information and Computer Science, Georgia Institute of Technology},
title = {{On Mutations}},
year = {1980}
}
@inproceedings{cunn95,
author = {Cunningham, W},
booktitle = {Pattern Languages of Program Design},
editor = {Coplien, J and Schmidt, D},
publisher = {Addison-Wesley},
title = {{The CHECKS Pattern Language of Information Integrity}},
year = {1995}
}
@inproceedings{john95,
annote = {Available from $\backslash$url\{http://citeseer.ist.psu.edu/john95estimating.html\}},
author = {John, G H and Langley, P},
booktitle = {Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence Montreal, Quebec: Morgan Kaufmann},
pages = {338--345},
title = {{Estimating continuous distributions in Bayesian classifiers}},
year = {1995}
}
@inproceedings{oates97,
annote = {Available from $\backslash$url\{http://www.cs.umbc.edu/\~{}oates/publications.html\}},
author = {Oates, Tim and Jensen, David},
booktitle = {Proc. 14th International Conference on Machine Learning},
pages = {254--262},
publisher = {Morgan Kaufmann},
title = {{The effects of training set size on decision tree complexity}},
year = {1997}
}
@article{gabow76,
author = {Gabow, H N and Maheshwari, S N and Osterweil, L},
journal = {IEEE Trans. Software Engrg},
pages = {227--231},
title = {{On Two Problems in the Generation of Program Test Paths}},
volume = {SE-2},
year = {1976}
}
@article{Bates1994,
annote = {Bates says there is an overlap between AI and (Disney) Character animation with regards to modelling and learning emotion in intelligence.},
author = {Bates, Joseph},
file = {::},
journal = {Communciation of the ACM},
keywords = {animation,art,arti cial intelligence,believable agents,believable characters,emotion},
number = {April},
title = {{The Role of Emotion in Believable Agents Joseph Bates}},
url = {http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.8186},
year = {1994}
}
@article{LIU2007,
address = {USA},
author = {Liu, Yi and Yao, Jenq-Foung and Williams, Gita and Adkins, Gerald},
issn = {1937-4771},
journal = {J. Comput. Small Coll.},
number = {5},
pages = {55--61},
publisher = {Consortium for Computing Sciences in Colleges},
title = {{Studying software metrics based on real-world software systems}},
volume = {22},
year = {2007}
}
@article{reed74,
author = {Reed, S and Ernst, G and Banerji, R},
journal = {Cognitive Psychology},
number = {3},
pages = {436--450},
title = {{The Role of Analogy in Transfer Between Similar Problem States}},
volume = {6},
year = {1974}
}
@article{quinlan86,
author = {Quinlan, R},
journal = {Machine Learning},
pages = {81--106},
title = {{Induction of Decision Trees}},
volume = {1},
year = {1986}
}
@book{tcp,
author = {Stevens, W Richard},
publisher = {\{A\}ddison-\{W\}esley},
title = {{\{TCP/IP\} \{I\}llustrated, \{V\}olume 1: \{T\}he \{P\}rotocols}},
year = {1994}
}
@misc{smith93,
author = {Smith, B},
month = dec,
title = {{The Phase Transition in Constraint Satisfaction Problems: A Closer Look at the Mushy Region}},
year = {1993}
}
@inproceedings{me97p,
author = {Menzies, T J},
booktitle = {The Second Australian Workshop on Requirements Engineering (AWRE'97)},
title = {{Qualitative Causal Diagrams for Requirements Engineering}},
year = {1997}
}
@inproceedings{Peters2015,
author = {Peters, Fayola and Menzies, Tim and Layman, Lucas},
booktitle = {ICSE'15},
title = {{LACE2: Better Privacy-Preserving Data Sharing for Cross Project Defect Prediction}},
year = {2015}
}
@article{ERDOGMUS2008,
address = {Los Alamitos, CA, USA},
author = {Erdogmus, Hakan},
doi = {http://doi.ieeecomputersociety.org/10.1109/MS.2008.81},
issn = {0740-7459},
journal = {IEEE Software},
pages = {4--7},
publisher = {IEEE Computer Society},
title = {{The Infamous Ratio Measure}},
volume = {25},
year = {2008}
}
@article{Guyon2003,
author = {Guyon, Isabelle and Elisseefi, Andre},
doi = {10.1162/153244303322753616},
editor = {Kaelbling, Leslie Pack},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - r d V a a.pdf:pdf},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {bioinformatics,clustering,computational biology,feature selection,gene expression,genomics,information retrieval,information theory,microarray,model selection,pat-,proteomics,qsar,space dimensionality reduction,statistical testing,support vector machines,tern discovery,text classi\o cation,variable selection,wrappers,\o lters},
month = oct,
number = {7-8},
pages = {1157--1182},
title = {{An Introduction to Variable and Feature Selection}},
url = {http://www.crossref.org/jmlr\_DOI.html},
volume = {3},
year = {2003}
}
@article{conk88,
author = {Conklin, J E and Begeman, M L},
journal = {ACM Transactions on Office Information Systems},
pages = {303--331},
title = {{gIBIS: A Hypertext Tool for Exploratory Policy Discussion}},
volume = {6},
year = {1988}
}
@inproceedings{me04b,
author = {Menzies, T and Di\~{}Stefano, Justin S and Cunanan, Chris and Chapman, Robert (Mike)},
booktitle = {IEEE Transactions Software Engineering (in preperation)},
title = {{The Business Case for Defect Logging}},
year = {2004}
}
@book{uml13,
author = {Booch, G and Jacobsen, I and Rumbaugh, J},
publisher = {Addison Wesley},
title = {{The Unified Modeling Language User Guide}},
year = {1999}
}
@article{evanco03,
author = {Evanco, William M},
journal = {IEEE Transactions on Software Engineering},
month = jul,
pages = {670--672},
title = {{Comments on 'The Confounding Effect of Class Size on the Validity of Object-Oriented Metrics$\backslash$'}},
year = {2003}
}
@inproceedings{deb98b,
author = {Debenham, J},
booktitle = {Proceedings Tenth International Conference on Software Engineering and Knowledge Engineering SEKE'98, San Francisco, US, June},
title = {{Representing Knowledge Normalisation}},
year = {1998}
}
@article{uschold96,
author = {Uschold, M and Gruninger, M},
journal = {The Knowledge Engineering Review},
number = {2},
pages = {93--136},
title = {{Ontologies: Principles, Methods, and Applications}},
volume = {11},
year = {1996}
}
@phdthesis{funt76,
author = {Funt, B V},
publisher = {University of British Columbia},
title = {{WHISPER: a Computer Implementation Using Analogues in Reasoning.}},
year = {1976}
}
@article{vera93,
author = {Vera, A H and Simon, H A},
journal = {Cognitive Science},
pages = {7--48},
title = {{Situated \{A\}ction: A \{S\}ymbolic \{I\}nterpretation}},
volume = {17},
year = {1993}
}
@article{weiss78,
author = {Weiss, S M and Kulikowski, C A and Amarel, S},
journal = {Artificial Intelligence},
title = {{A \{M\}odel-\{B\}ased \{M\}ethod for \{C\}omputer-\{A\}ided \{M\}edical \{D\}ecision-\{M\}aking}},
volume = {11},
year = {1978}
}
@article{Webb2000a,
author = {Webb, Geoffrey I},
file = {:Users/timm/svns/doc/webb00.pdf:pdf},
journal = {Computing},
keywords = {aggregation,bagging,boosting,decision committee,decision tree,wagging},
pages = {159--197},
title = {{MultiBoosting : A Technique for Combining Boosting and Wagging}},
volume = {39},
year = {2000}
}
@inproceedings{me09l,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09irrf.pdf\}},
author = {Cukic, B and Menzies, T and Jiang, Y},
booktitle = {IEEE ISSRE'09},
title = {{Variance analysis in software fault prediction models}},
year = {2009}
}
@article{me06e,
annote = {Available on-line at $\backslash$url\{http://menzies.us/pdf/06costs.pdf\}},
author = {Menzies, T and Hihn, J},
journal = {IEEE Software},
title = {{Evidence-Based Cost Estimation for Better Quality Software}},
year = {2006}
}
@inproceedings{rittel72,
author = {Rittel, H W J},
booktitle = {Design Methods Group 5th Anniversary Report: DMG Occasional Paper, 1, 5-10.},
title = {{Second generation design methods}},
year = {1972}
}
@article{domingos97optimality,
author = {Domingos, Pedro and Pazzani, Michael J},
journal = {Machine Learning},
number = {2-3},
pages = {103--130},
title = {{On the Optimality of the Simple Bayesian Classifier under Zero-One Loss}},
url = {citeseer.ist.psu.edu/domingos97optimality.html},
volume = {29},
year = {1997}
}
@inproceedings{me99g,
author = {Menzies, T and Michael, C C},
booktitle = {SEKE '99, June 17-19, Kaiserslautern, Germany.},
title = {{Fewer Slices of PIE: Optimising Mutation Testing via Abduction}},
year = {1999}
}
@article{me10a,
author = {Menzies, T J and Multon, Z and Turhan, B and Cukic, B and Jiang, Y and Bener, A},
file = {::},
journal = {Automated Software Engineering},
title = {{Defect Prediction from Static Code Features: Current Results, Limitations, New Approaches}},
year = {2010}
}
@article{fenton99,
author = {Fenton, N E and Neil, M},
file = {::},
journal = {IEEE Transactions on Software Engineering},
number = {5},
pages = {675--689},
title = {{A Critique of Software Defect Prediction Models}},
volume = {25},
year = {1999}
}
@article{hulten03,
annote = {Available from $\backslash$url\{http://www.cs.washington.edu/homes/ghulten/papers/genframe-jcgs.pdf\}},
author = {Hulten, G and Domingos, P},
journal = {Journal of Computational and Graphical Statistics},
title = {{A General Framework for Mining Massive Data Streams}},
volume = {12},
year = {2003}
}
@misc{wang93,
author = {Wang, P},
institution = {Center for Research on Concepts and Cognition, Indiana University, Bloomington, Indiana,},
title = {{From Inheritance Relation to Non-Axiomatic Logic}},
year = {1993}
}
@misc{IEEE90,
publisher = {\{IEEE\}, New York},
title = {{\{IEEE\} Glossary of Software Engineering Terminology, \{ANSI/IEEE\} Standard 610.12}},
year = {1990}
}
@misc{me09h,
author = {Menzies, T and Mizuno, O and Takagi, Y and Kikuno, Y},
booktitle = {Journal of Software Engineering and Applications},
month = nov,
pages = {221--236},
title = {{Explanation vs Performance in Data Mining: A Case Study with Predicting Runaway Projects}},
year = {2009}
}
@article{boehm02,
author = {Boehm, B},
journal = {IEEE Computer},
pages = {2--7},
title = {{Get Ready for Agile Methods}},
year = {2002}
}
@misc{schw02,
author = {Schwaber, Ken},
title = {{No Title}},
year = {2002}
}
@misc{me99e,
annote = {in preperation},
author = {Menzies, T and Cukic, B},
howpublished = {NASA/WVU IVV tech report},
month = mar,
title = {{Experiments with an Average-Case Model of Reachability}},
year = {1999}
}
@article{frank02,
author = {Franklin, D},
journal = {Time Magazine},
month = dec,
title = {{Data Miners: New software instantly connects key bits of data that once eluded teams of researchers}},
year = {2002}
}
@inproceedings{pople73,
author = {Pople, H E},
booktitle = {IJCAI '73},
pages = {147--152},
title = {{On the mechanization of abductive logic.}},
year = {1973}
}
@incollection{linster92a,
author = {Linster, M},
booktitle = {Knowledge Acquisition for Knowledge-Based Systems},
editor = {Aussenac, N and Boy, G and Gaines, B and Linser, M and Ganascia, J.-G. and Kordratoff, Y},
pages = {159--182},
publisher = {Springer-Verlag},
title = {{A review of Sisyphus 91 and 92: Models of Problem-Solving Knowledge}},
year = {1992}
}
@inproceedings{gil97,
author = {Gil, Y and Tallis, M},
booktitle = {Proceedings of the Fourteenth National Conference on Artificial Intelligence (AAAI-97)},
title = {{A Script-Based Approach to Modifying Knowledge Bases}},
year = {1997}
}
@incollection{dechter-constraint,
author = {Dechter, Rina},
booktitle = {MIT Encyclopedia of the Cognitive Sciences (MITECS)},
month = jan,
publisher = {John Wiley and Sons.},
title = {{Constraint satisfaction}},
year = {1998}
}
@article{Pfleeger1990,
author = {Pfleeger, S L and McGowan, C},
journal = {Journal of Systems and Software},
month = jul,
pages = {255--261},
title = {{Software Metrics in a Process Maturity Framework}},
volume = {12},
year = {1990}
}
@article{parnas76,
author = {Parnas, D},
journal = {IEEE Transactions on Software Engineering},
month = mar,
title = {{On the design and development of program families}},
year = {1976}
}
@article{caraca00,
annote = {To appear.},
author = {Caraca-Valente, J P and Gonzalez, L and Morant, J L and Pozas, J},
journal = {International Journal of Human-Computer Studies},
title = {{Knowledge-based Systems Validation: When to Stop Running Test Cases}},
year = {2000}
}
@article{voas92,
author = {Voas, J M},
journal = {IEEE Transactions of Software Engineering},
month = aug,
number = {2},
pages = {717--727},
title = {{PIE: A Dynamic Failure-Based Technique}},
volume = {18},
year = {1992}
}
@inproceedings{me00a,
author = {Menzies, T and Sinsel, E and Kurtz, T},
booktitle = {Workshop on Intelligent Software Engineering, an ICSE workshop, and NASA/WVU Software Research Lab, Fairmont, WV, Tech report \# NASA-IVV-99-027},
keywords = {COCOMO-II,Keywords: Machine learning,Monte-Carlo simulations,decision support systems,effort estimation,risk assessment},
title = {{Learning to Reduce Risks with COCOMO-II}},
year = {2000}
}
@inproceedings{ammar97,
author = {Ammar, H H and Nikzadeh, T and Dugan, J B},
booktitle = {Proceedings of the International Symposium on Software Metrics},
month = nov,
publisher = {IEEE Computer Society},
title = {{A Methodology for Risk Assessment of Functional Specification of Software Systems Using Colored Petri Nets}},
year = {1997}
}
@article{gray97,
author = {Gray, A and MacDonnell, S},
journal = {Information and Software Technology},
title = {{A Comparison of Techniques for Developing Predictive Models of Software Metrics}},
volume = {39},
year = {1997}
}
@article{noy97,
author = {Noy, N F and Hafner, C D},
journal = {AI Magazines},
pages = {53--74},
title = {{The State of the Art in Ontology Design: A Survey and Comparative Review}},
year = {1997}
}
@incollection{emmerich98,
annote = {Available $\backslash$url\{eprints.ucl.ac.uk/937/1/10.6\_chapter2v2.pdf\}},
author = {Emmerich, W and Finkelstein, A and Fuggetta, A and Montangero, C and Derniame, J},
booktitle = {J.C. Derniame and B.A. Kaba and D. Wastell},
editor = {{Software Process: Principles Methodology}, Technology Lecture Notes in Computer Science},
pages = {15--25},
publisher = {Springer Verlag},
title = {{Software process: standards, assessments and improvements}},
volume = {1500},
year = {1998}
}
@inproceedings{KORU2005,
address = {New York, NY, USA},
author = {Koru, A G\"{u}nes and Liu, Hongfang},
booktitle = {PROMISE '05: Proceedings of the 2005 workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1083165.1083172},
isbn = {-159593-125-2},
pages = {1--5},
publisher = {ACM},
title = {{An investigation of the effect of module size on defect prediction using static measures}},
year = {2005}
}
@inproceedings{koed92,
author = {Koedinger, K R},
booktitle = {Proceedings of the AAAI Symposium on Diagrammatic Reasoning Stanford University, March 25-27},
pages = {154--159},
title = {{Emergent Properties and Structural Constraints: Advantages of Diagrammatic Representations for Reasoning and Learning}},
year = {1992}
}
@misc{warrenDS94,
author = {Warren, D S},
title = {{Personal Communication}},
year = {1994}
}
@incollection{gross93,
author = {Grossner, C and Preece, A and Chander, P Gokul and Radhakrishnan, T and Suen., C},
booktitle = {Proc. 11th National Conference on Artificial Intelligence (AAAI-93)},
pages = {704--709},
publisher = {MIT Press},
title = {{Exploring the Structure of Rule Based Systems}},
year = {1993}
}
@article{harel90,
author = {Harel, D},
journal = {IEEE Transactions on Software Engineering},
month = apr,
number = {4},
pages = {403--414},
title = {{STATEMATE: A Working Environment for the Development of Complex Reactive Systems}},
volume = {16},
year = {1990}
}
@inproceedings{boutif06,
author = {Bouktif, S and Sahraoui, H and Antoniol, G},
booktitle = {GECCO '06: Proceedings of the 8th annual conference on Genetic and evolutionary computation},
pages = {1893--1900},
title = {{Simulated annealing for improving software quality prediction}},
year = {2006}
}
@article{marcus89,
author = {Marcus, S and McDermott, J},
journal = {Artificial Intelligence},
pages = {1--37},
title = {{\{SALT\}: A \{K\}nowledge \{A\}cquisition \{L\}anguage for \{P\}ropose-and-\{R\}evise \{S\}ystems}},
volume = {39},
year = {1989}
}
@article{devedzic99,
author = {Devedzic, V},
journal = {Intelligence (formerly, SIGART)},
pages = {14--24},
title = {{Ontologies: Borrowing from Software Patterns}},
year = {1999}
}
@inproceedings{Kohavi1995,
author = {Kohavi, R.},
booktitle = {International joint Conference on artificial intelligence},
file = {:Users/timm/svns/doc/kohavi95.pdf:pdf},
issn = {1045-0823},
publisher = {Citeseer},
title = {{A study of cross-validation and bootstrap for accuracy estimation and model selection}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.48.529\&amp;rep=rep1\&amp;type=pdf},
volume = {14},
year = {1995}
}
@inproceedings{me95c,
author = {Menzies, T J},
booktitle = {Proceedings of AI '95, Australia},
publisher = {World-Scientific},
title = {{\{L\}imits to \{K\}nowledge \{L\}evel-\{B\} \{M\}odeling (and \{KADS\})}},
year = {1995}
}
@inproceedings{alvarez-data,
author = {Alvarez, J L and Mata, J and Riquelme, Jose C and Ramos, I},
booktitle = {ICEIS'2003: Fifth International Conference on Enterprise Information Systems},
title = {{A Data Mining Method to Support Decision Making in Software Development Projects}},
url = {citeseer.ist.psu.edu/alvarez03data.html},
year = {2003}
}
@inproceedings{clancy97,
author = {Clancy, D J and Kuipers, B K},
booktitle = {AAAI-97},
title = {{Model Decomposition and Simulation: A component based qualitative simulation algorithm}},
year = {1997}
}
@article{jorg04,
author = {Jorgensen, M},
journal = {Journal of Systems and Software},
number = {1-2},
pages = {37--60},
title = {{A Review of Studies on Expert Estimation of Software Development Effort}},
volume = {70},
year = {2004}
}
@book{olle91,
author = {Olle, T W and Hagelstein, J and MacDonald, I G and Rolland, C and Sol, H K and Assche, F J M Van and Verrijn-Stuart, A A},
publisher = {Addison-Wesley},
title = {{Information Systems Methodologies: A Framework for Understanding}},
year = {1991}
}
@article{madachy97,
author = {Madachy, R},
journal = {IEEE Software},
month = may,
number = {3},
pages = {51--59},
title = {{Heuristic Risk Assessment Using Cost Factors}},
volume = {14},
year = {1997}
}
@inproceedings{khoshgoftaar99,
author = {Khoshgoftaar, T M and Allen, E B},
booktitle = {Recent Advances in Reliability and Quality Engineering},
chapter = {15},
editor = {Pham, H},
pages = {247--270},
publisher = {World Scientific},
title = {{Model Software Quality with Classification Trees}},
year = {2001}
}
@misc{sisti94,
annote = {CMU/SEI-94-TR-19},
author = {Sisti, F J and Joseph, S},
institution = {Software Engineering Institute},
month = dec,
title = {{Software Risk Evaluation Method, Version 1}},
year = {1994}
}
@inproceedings{me04g,
author = {Menzies, T and DiStefano, J and Orrego, A and Chapman, R},
booktitle = {Proceedings, workshop on Predictive Software Models, Chicago},
title = {{Assessing Predictors of Software Defects}},
year = {2004}
}
@inproceedings{cunn95,
author = {Cunningham, W},
booktitle = {Pattern Languages of Program Design},
editor = {Coplien, J and Schmidt, D},
publisher = {Addison-Wesley},
title = {{The CHECKS Pattern Language of Information Integrity}},
year = {1995}
}
@misc{compton96a,
annote = {Regarding time interval literal connections.},
author = {Compton, P},
title = {{Personal communication}},
year = {1996}
}
@inproceedings{wu93,
author = {Wu, X},
booktitle = {Proceedings of the 21st ACMl Computer Science Conference},
pages = {168--175},
title = {{The HCV induction algorithm.}},
year = {1993}
}
@article{laird86,
author = {Laird, P S and {J. E.}, Rosenbloom and Newell, A},
journal = {Machine Learning},
number = {1},
pages = {11--46},
title = {{Chunking in \{SOAR\}: The Anatomy of a General Learning Mechanism}},
volume = {1},
year = {1986}
}
@inproceedings{reiss89,
author = {Reiss, S P and Meyers, S and Duby, C},
booktitle = {Proceedings of the Second Annual Symposium on User Interface Software and Technology},
month = nov,
pages = {149--157},
title = {{Using GELO to Visualize Software Systems}},
year = {1989}
}
@article{greeno93,
author = {Greeno, J G and Moore, J L},
journal = {Cognitive Science},
pages = {49--59},
title = {{Situativity and Symbols: Response to Vera and Simon}},
volume = {17},
year = {1993}
}
@article{SM91,
author = {Sugiyama, K and Misue, K},
journal = {IEEE Transactions on Systems, Man and Cybernetics},
number = {4},
pages = {876--892},
title = {{Visualization of structural information: Automatic drawing of compound digraphs}},
volume = {21},
year = {1991}
}
@inproceedings{andrews07,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07ase-nighthawk.pdf\}},
author = {Andrews, J H and Li, F C H and Menzies, T},
booktitle = {IEEE ASE'07},
title = {{Nighthawk: A Two-Level Genetic-Random Unit Test Data Generator}},
year = {2007}
}
@misc{cocomoII,
annote = {$\backslash$url\{http://sunset.usc.edu/COCOMOII/cocomox.html\#downloads\}},
author = {Abts, C and Clark, B and Devnani-Chulani, S and Horowitz, E and Madachy, R and Reifer, D and Selby, R and Steece, B},
institution = {Center for Software Engineering, USC,},
title = {{\{COCOMO II\} Model Definition Manual}},
year = {1998}
}
@incollection{Amarel86,
address = {Los Altos, CA},
author = {Amarel, S},
booktitle = {Machine Learning: An Artificial Intelligence Approach: Volume II},
editor = {Michalski, R S and Carbonell, J G and Mitchell, T M},
pages = {499--569},
publisher = {Kaufmann},
title = {{Program Synthesis as a Theory Formation Task: Problem Representations and Solution Methods}},
year = {1986}
}
@inproceedings{me02l,
author = {Stefano, J S Di and Menzies, T},
booktitle = {Proceedings, IEEE Tools with AI, 2002},
title = {{Machine Learning for Software Engineering: Case Studies in Software Reuse}},
year = {2002}
}
@article{Hand2007c,
abstract = {Data mining is the discovery of interesting, unexpected or valuable structures in large datasets. As such, it has two rather different aspects. One of these concerns large-scale, 'global' structures, and the aim is to model the shapes, or features of the shapes, of distributions. The other concerns small-scale, 'local' structures, and the aim is to detect these anomalies and decide if they are real or chance occurrences. In the context of signal detection in the pharmaceutical sector, most interest lies in the second of the above two aspects; however, signal detection occurs relative to an assumed background model, therefore, some discussion of the first aspect is also necessary. This paper gives a lightning overview of data mining and its relation to statistics, with particular emphasis on tools for the detection of adverse drug reactions.},
author = {Hand, David J},
file = {:Users/timm/svns/doc/hand01.pdf:pdf},
issn = {0114-5916},
journal = {Drug safety : an international journal of medical toxicology and drug experience},
keywords = {Adverse Drug Reaction Reporting Systems,Adverse Drug Reaction Reporting Systems: organizat,Databases, Factual,Drug Industry,Humans,Information Systems,Information Systems: organization \& administration,Product Surveillance, Postmarketing},
month = jan,
number = {7},
pages = {621--2},
pmid = {17604416},
title = {{Principles of data mining.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17604416},
volume = {30},
year = {2007}
}
@article{agnew93,
author = {Agnew, N M and Ford, K M and Hayes, P J},
journal = {International Journal of Expert Systems},
title = {{Expertise in Context: Personally Constructed, Socially elected, and Reality-Relevant?}},
volume = {7},
year = {1993}
}
@book{goldberg00,
author = {Goldberg, D E},
publisher = {Addison-Wesley},
title = {{Genetic Algorithms in Search, Optimization, and Machine Learning}},
year = {1989}
}
@phdthesis{acree80,
author = {Acree, A T},
school = {School of Information and Computer Science, Georgia Institute of Technology},
title = {{On Mutations}},
year = {1980}
}
@misc{purify,
author = {$\backslash$urlhttp://www.pureatria.com/products, Pure Atria},
title = {{Purify}}
}
@book{Witten05,
address = {Los Altos, US},
author = {Witten, Ian H and Frank, Eibe},
publisher = {Morgan Kaufmann},
title = {{Data mining. 2nd edition}},
year = {2005}
}
@article{Manegold2010b,
author = {Manegold, S. and Laurent, D. and Lupu, M. and Onose, N. and R\'{e}, C. and Sans, V. and Senellart, P. and Wu, T. and Shasha, D. and Manolescu, I. and Afanasiev, L. and Feng, J. and Gou, G. and Hadjieleftheriou, M. and Harizopoulos, S. and Kalnis, P. and Karanasos, K.},
doi = {10.1145/1815933.1815944},
file = {:Users/timm/svns/doc/manegold09.pdf:pdf},
issn = {01635808},
journal = {ACM SIGMOD Record},
month = dec,
number = {3},
pages = {40},
title = {{Repeatability \& workability evaluation of SIGMOD 2009}},
url = {http://portal.acm.org/citation.cfm?doid=1815933.1815944},
volume = {38},
year = {2010}
}
@article{wong95,
author = {Wong, W E and Mathur, A P},
journal = {The Journal of Systems and Software},
month = dec,
number = {3},
pages = {185--196},
title = {{Reducing the Cost of Mutation Testing: An Empirical Study}},
volume = {31},
year = {1995}
}
@misc{althoff98,
author = {Althoff, K and Bomarius, F and Tautz, C},
title = {{Using case-based reasoning technology to build learning organizations}},
year = {1998}
}
@article{hori00,
annote = {(to appear)},
author = {Hori, M},
journal = {International Journal of Human Computer Studies},
title = {{Stability of a Domain-Oriented Component Library: An Explanatory Case Study}},
year = {2000}
}
@incollection{bannon93,
author = {Bannon, L J and Bodker, S},
chapter = {Beyond the},
publisher = {Cambridge University Press},
title = {{Designing Interaction}},
year = {1993}
}
@article{Ahn1997a,
author = {Ahn, H.K. and Mamoulis, Nikos and Wong, H.M.},
file = {:Users/timm/svns/doc/Ahn01.pdf:pdf},
journal = {Lecture COMP630c,âSpatial, Image and Multimedia Databasesâ, University of Science and Technology, Clearwater Bay, Hong Kong},
keywords = {Grid cluster},
publisher = {Citeseer},
title = {{A survey on multidimensional access methods}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.19.192\&amp;rep=rep1\&amp;type=pdf},
year = {1997}
}
@book{hof81,
author = {Hofstader, D R and Dennett, D C},
title = {{The Mind's I}},
year = {1981}
}
@article{stark93,
author = {Stark, M},
journal = {J. Systems Software},
pages = {163--169},
title = {{Impacts of \{O\}bject-\{O\}riented \{T\}echnologies: Seven Years of \{S\}oftware \{E\}ngineering}},
volume = {23},
year = {1993}
}
@book{sterman00,
author = {Sterman, H},
publisher = {Irwin McGraw-Hill},
title = {{Business Dynamics: Systems Thinking and Modeling for a Complex World}},
year = {2000}
}
@inproceedings{me03r,
author = {Geletko, Dustin and Menzies, Tim},
booktitle = {28th Annual NASA Goddard Software Engineering Workshop (SEW'03)},
month = dec,
title = {{Model-Based Software Testing via Incremental Treatment Learning}},
year = {2003}
}
@article{Speil2002,
author = {Speil, Christopher},
file = {:Users/timm/svns/doc/texinfo.pdf:pdf},
journal = {Linux Gazette},
title = {{Writing Documentation , Part IV : Texinfo}},
year = {2002}
}
@book{glinert90a,
editor = {Glinert, E P},
publisher = {IEEE Computer Society Press},
title = {{Visual Programming Environments: Paradigms and Systems}},
year = {1990}
}
@article{hailpern06,
author = {B. hailpern and P. tarr},
journal = {ibm systems journal},
number = {3},
pages = {451--461},
title = {model-driven develpment: the good, the bad, and the ugly},
volume = {45},
year = {2006}
}
@article{aamodt94,
author = {Aamodt, A and Plaza, E},
file = {::},
journal = {AI Communications},
month = mar,
number = {1},
pages = {39--59},
title = {{Case-based reasoning; Foundational issues, methodological variations, and system approaches}},
volume = {7},
year = {1994}
}
@misc{wilke96,
author = {Wilke, W and Vollrath, I and Altho, K and Bergmann, R},
booktitle = {Adaptation in Case Based Reasoning: A Workshop at ECAI 1996 in Budapes},
title = {{A Framework for Learning Adaptation Knowledge Based on Knowledge Light Approaches}},
year = {1996}
}
@inproceedings{kanovich91,
author = {Kanovich, M I},
booktitle = {Theoretical Aspects of Comptuer Software, September, 1991, Sendai, Japan},
title = {{Effecient Program Synthesis: Semantics, Logic, Complexity}},
year = {1991}
}
@article{gregor02,
annote = {Available from $\backslash$url\{http://dl.acs.org.au/index.php/ajis/article/viewPDFInterstitial/439/399?ads=\}},
author = {Gregor, S},
journal = {Australasian Journal of Information Systems},
month = dec,
title = {{Design Theory in Information Systems}},
year = {2002}
}
@article{davis79,
author = {Davis, R},
journal = {Artificial Intelligence},
number = {2},
pages = {121--157},
title = {{Interactive Transfer of Expertise: Acqusiition of New Inference Rules}},
volume = {12},
year = {1979}
}
@misc{ithink94,
author = {Inc., High Performance Software},
title = {{iThink 3.0.5}},
year = {1994}
}
@inproceedings{Buntine1999a,
author = {Buntine, W. and Fischer, B. and Pressburger, T.},
booktitle = {Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining},
file = {:Users/timm/svns/doc/Buntine99.pdf:pdf},
isbn = {1581131437},
publisher = {ACM},
title = {{Towards automated synthesis of data mining programs}},
url = {http://portal.acm.org/citation.cfm?id=312286},
year = {1999}
}
@book{kelly55,
author = {Kelly, G A},
publisher = {Norton},
title = {{The Psychology of Persona] Constructs. Volume 1: A Theory of Personality. Volume 2: Clinical Diagnosis and Psychotherapy}},
year = {1955}
}
@inproceedings{clark93,
author = {Clark, P and Matwin, S},
booktitle = {Proceedings of the Tenth International Machine Learning Conference, ML-93},
editor = {Utgoff, P},
organization = {Department of Computer Science, Ottawa University, Canada},
pages = {49--56},
title = {{Using Qualitative Models to Guide Inductive Learning}},
year = {1993}
}
@incollection{roa95,
annote = {slides},
author = {Roa, A},
title = {{Review of Agent-Oriented Systems: Research Issues and Commercial Applications}},
year = {1995}
}
@article{schreiber96,
author = {Schreiber, A Th. and Birmingham, W P},
journal = {International Journal of Human-Computer Studies},
number = {3/4},
title = {{The Sisyphus-VT initiative}},
volume = {44},
year = {1996}
}
@misc{cock00,
address = {Cagliari, Sardinia, Italy},
author = {Cockburn, Alistair and Williams, Laurie},
booktitle = {Proceedings of the First International Conference on Extreme Programming and Flexible Processes in Software Engineering (\{XP2000\})},
month = jun,
title = {{The Costs and Benefits of Pair Programming}},
url = {citeseer.nj.nec.com/cockburn00costs.html},
year = {2000}
}
@inproceedings{me00t,
author = {Menzies, T and Singh, H},
booktitle = {2nd International Workshop on Soft Computing applied to Software Engineering (Netherlands), February},
title = {{Many Maybes Mean (Mostly) the Same Thing}},
year = {2001}
}
@inproceedings{kohavi96,
author = {Kohavi, R and Sommerfield, D and Dougherty, J},
booktitle = {Tools with AI 1996},
title = {{Data Minining using MLC++: A Machine Learning Library in C++}},
year = {1996}
}
@inproceedings{thumm09,
address = {Washington, DC, USA},
author = {Thummalapenta, Suresh and Xie, Tao},
booktitle = {ICSE '09: Proceedings of the 31st International Conference on Software Engineering},
doi = {http://dx.doi.org/10.1109/ICSE.2009.5070548},
isbn = {978-1-4244-3453-4},
pages = {496--506},
publisher = {IEEE Computer Society},
title = {{Mining exception-handling rules as sequence association rules}},
year = {2009}
}
@book{halstead77,
author = {Halstead, M H},
publisher = {Elsevier},
title = {{Elements of Software Science}},
year = {1977}
}
@article{Fikes99,
author = {Fikes, R and Farquhar, A},
journal = {IEEE Intelligent Systems},
month = mar,
number = {2},
pages = {73--79},
title = {{Distributed Repositories of Highly Expressive Reusable Ontologies}},
volume = {14},
year = {1999}
}
@book{popper63,
author = {Popper, K R},
publisher = {Routledge and Kegan Paul},
title = {{Conjectures and Refutations,}},
year = {1963}
}
@inproceedings{me99a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/99re.pdf\}},
author = {Menzies, T J and Easterbrook, S and Nuseibeh, Bashar and Waugh, Sam},
booktitle = {RE '99},
title = {{An Empirical Investigation of Multiple Viewpoint Reasoning in Requirements Engineering}},
year = {1999}
}
@article{hall00,
author = {Hall, G A and Munson, J C},
journal = {Journal of Systems and Software},
pages = {111--118},
title = {{Software evolution: code delta and code churn}},
year = {2000}
}
@inproceedings{balbo95,
author = {S, Balbo},
booktitle = {Proceddings of the 6th International Conference on HCI, Pacificon Yokohama (Japan)},
editor = {Anzi, Y and Ogawa, K},
title = {{Software Tools for Evaluating the Usability of User Interfaces}},
year = {1995}
}
@article{ren07,
author = {Ren, J and Taylor, R N},
journal = {Communications of the ACM},
month = jun,
pages = {81--85},
title = {{Automatic and Versatile Publications Ranking for Research Instituions and Scholars}},
year = {2007}
}
@article{bratko95,
author = {Bratko, I and Muggleton, S},
journal = {Communications of the ACM},
number = {11},
pages = {65--70},
title = {{Applications of Inductive Logic Programming}},
volume = {38},
year = {1995}
}
@article{marcus87,
author = {Marcus, S and Stout, J and McDermott, J},
journal = {AI Magazine},
pages = {41--58},
title = {{\{VT\}: An \{E\}xpert \{E\}levator \{D\}esigner \{T\}hat \{U\}ses \{K\}nowledge-\{B\}ased \{B\}acktracking}},
year = {1987}
}
@article{vard88,
author = {Vardi, M Y},
journal = {IEEE Software},
month = mar,
pages = {80--85},
title = {{The Universal-Relation Rata Model for Logical Independence}},
year = {1988}
}
@incollection{me95g,
author = {Menzies, T J},
booktitle = {Proceedings of the Melbourne Workshop on Intelligent Decision Support},
publisher = {Department of Information Systems, Monash University, Melbourne},
title = {{Applications of Abduction: Intelligent Decision Support Systems}},
year = {1996}
}
@article{easter96,
author = {Easterbrook, S and Nuseibeh, B},
journal = {BCS/IEE Software Engineering Journal},
month = jan,
pages = {31--43},
title = {{Using Viewpoints for Inconsistency Management}},
year = {1996}
}
@article{harman01,
author = {Harman, M and Jones, B F},
journal = {Journal of Information and Software Technology},
month = dec,
pages = {833--839},
title = {{Search-based software engineering}},
volume = {43},
year = {2001}
}
@article{morisio02,
author = {Morisio, M and {M. Ezran} and Tully, C},
journal = {IEEE Transactions on Software Engineering},
number = {4},
pages = {340--357},
title = {{Success and failure factors in software reuse}},
volume = {28},
year = {2002}
}
@misc{boehm09a,
annote = {Keynote address, PROMISE'09},
author = {Boehm, B},
title = {{No Title}},
year = {2009}
}
@inproceedings{wise00,
author = {Wise, A and Cass, A G and Lerner, B Staudt and McCall, E K and Osterweil, L J and {S.M. Sutton}, Jr.},
booktitle = {Proceedings of the Automated Software Engineering Conference (ASE 2000) Grenoble, France.},
month = sep,
title = {{Using Little-JIL to Coordinate Agents in Software Engineering}},
year = {2000}
}
@misc{stukes91,
author = {Stukes, S and Apgar, H},
month = mar,
title = {{Applications Oriented Software Data Collection: Software Model Calibration Report, \{TR\}-9007/549-1, Management Consulting and Research}},
year = {1991}
}
@article{schmidt06,
author = {Schmidt, D C},
journal = {IEEE Computer},
month = feb,
number = {2},
pages = {25--31},
title = {{Model-Driven Engineering}},
volume = {39},
year = {2006}
}
@inproceedings{dieng93,
author = {Dieng, R and Corby, O and Lapalut, S},
booktitle = {EKAW '93: Knowledge Acquisition for Knowledge-Based Systems: 7th European Workshop},
editor = {Aussenac, N and Boy, G and Gaines, B and {M. Linster}, T.-G. Ganascia and Kodratoff, Y},
pages = {407--426},
title = {{Acquisition of Gradual Knowledge}},
year = {1993}
}
@book{pearl84,
address = {Boston, MA, USA},
author = {Pearl, Judea},
isbn = {0-201-05594-5},
publisher = {Addison-Wesley Longman Publishing Co., Inc.},
title = {{Heuristics: intelligent search strategies for computer problem solving}},
year = {1984}
}
@inproceedings{Child2005,
author = {Child, Christopher and Stathis, Kostas},
booktitle = {Computational Logic in Multi-Agent Systems},
file = {:Users/timm/svns/doc/child04.pdf:pdf},
pages = {105--113},
publisher = {Springer},
title = {{The Apriori Stochastic Dependency Detection (ASDD) Algorithm for Learning Stochastic Logic Rules}},
url = {http://www.springerlink.com/index/CBJHWJPRCF60HPQ0.pdf},
year = {2005}
}
@article{Fulkerson1995b,
author = {Fulkerson, Bill and Michie, D. and Spiegelhalter, D. J. and Taylor, C. C.},
doi = {10.2307/1269742},
file = {:Users/timm/svns/doc/statlog.pdf:pdf},
issn = {00401706},
journal = {Technometrics},
month = nov,
number = {4},
pages = {459},
title = {{Machine Learning, Neural and Statistical Classification}},
url = {http://www.jstor.org/stable/1269742?origin=crossref},
volume = {37},
year = {1995}
}
@article{raffo05b,
author = {Raffo, D and Menzies, T},
journal = {Journal of Information, Software and Technology},
month = dec,
number = {15},
pages = {1009--1017},
title = {{Software project management using PROMPT: A hybrid metrics, modeling and utility framework}},
volume = {47},
year = {2005}
}
@inproceedings{myers81,
author = {Myers, E},
booktitle = {Conference Record of the Eighth Annual Symposium on Principles of Programming Languages},
month = jan,
title = {{A precise inter-procedural data flow algorithm}},
year = {1981}
}
@article{me97a,
author = {Menzies, T J and Compton, P},
journal = {Artificial Intelligence in Medicine},
pages = {145--175},
title = {{Applications of Abduction: Hypothesis Testing of Neuroendocrinological Qualitative Compartmental Models}},
volume = {10},
year = {1997}
}
@article{leveson91,
author = {Leveson, N and Cha, S and Shimall, T},
journal = {IEEE Software},
month = jul,
number = {7},
pages = {48--59},
title = {{Safety Verification of \{ADA\} Programs using software fault trees}},
volume = {8},
year = {1991}
}
@book{CASEV,
annote = {Volumes I and II},
author = {Inc, Silicon Graphics},
publisher = {Silicon Graphics Inc},
title = {{\{CASEV\}ision/workshop user's guide}},
year = {1992}
}
@misc{fen97a,
annote = {$\backslash$url\{http://www.aifb.uni-karlsruhe.de/WBS/dfe/dlfl/summary.html\}},
author = {{D. Fensel M.-C. Rousset}, S Decker},
howpublished = {to appear in Data and Knowledge Engineering},
title = {{Workshop on Comparing Description and Frame Logics}},
year = {1997}
}
@inproceedings{me02f,
author = {Menzies, Tim and Raffo, David and Setamanit, Siri-on and Hu, Ying and Tootoonian, Sina},
booktitle = {Proceedings of IEEE ASE 2002},
file = {::},
title = {{Model-based Tests of Truisms}},
year = {2002}
}
@inproceedings{Thompson99:nimbus-proto,
author = {Thompson, Jeffrey M and Heimdahl, Mats Per Erik},
booktitle = {\{IEEE\} International Workshop on Rapid System Prototyping},
pages = {172--177},
title = {{An Integrated Development Environment for Prototyping Safety Critical Systems}},
url = {citeseer.nj.nec.com/thompson99integrated.html},
year = {1999}
}
@inproceedings{iwasaki88,
author = {Iwasaki, Y},
booktitle = {Proceedings of AAAI '88},
pages = {313--318},
title = {{Causal Ordering in a Mixed Structure}},
year = {1988}
}
@inproceedings{lee92,
author = {Lee, M and Compton, P and Jansen, B},
booktitle = {Proceedings of the Second Japan Knowledge Acquisition for Knowledge-Based Systems Workshop, Kobe, Japan},
pages = {357--370},
title = {{Modelling with Context-Dependant Causality}},
year = {1992}
}
@inproceedings{MAIR2005,
address = {New York, NY, USA},
author = {Mair, Carolyn and Shepperd, Martin and J\o rgensen, Magne},
booktitle = {PROMISE '05: Proceedings of the 2005 workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1083165.1083166},
isbn = {-159593-125-2},
pages = {1--6},
publisher = {ACM},
title = {{An analysis of data sets used to train and validate cost prediction systems}},
year = {2005}
}
@incollection{gas83,
author = {Gaschnig, J and Klahr, P and Pople, H and Shortliffe, E and Terry, A},
booktitle = {Building Expert Systems},
chapter = {8},
editor = {Hayes-Roth, F and Waterman, D A and Lenat, D B},
pages = {241--280},
publisher = {Addison-Wesley},
title = {{Evaluation of Expert Systems: Issues and Case Studies}},
year = {1983}
}
@incollection{zeitz97,
author = {Zeitz, C M},
booktitle = {Expertise in Context},
chapter = {2},
editor = {Feltovich, P J and Ford, K M and Hoffman, R R},
pages = {43--65},
publisher = {MIT PRess},
title = {{Some Concrete Advantages of Abstraction: How Experts' representations Facilitate Reasoning}},
year = {1997}
}
@misc{purify,
author = {$\backslash$urlhttp://www.pureatria.com/products, Pure Atria},
title = {{Purify}}
}
@article{avri96,
author = {Avritzer, A and Ros, J P and Weyuker, E J},
journal = {IEEE Software},
month = sep,
pages = {76--82},
title = {{Reliability of Rule-Based Systems}},
year = {1996}
}
@book{Walden1995,
annote = {unread},
author = {Walden, K and Nerson, J-M},
publisher = {Prentice-Hall, Englewood Cliffs, New Jersey},
title = {{Seamless Object-Oriented Software Architecture}},
year = {1995}
}
@inproceedings{cohen99,
author = {Cohen, P and Chaudhri, V and Pease, A and Schrag, R},
booktitle = {AAAI'99},
title = {{Does Prior Knowledge Facilitate the Development of Knowledge-based Systems?}},
year = {1999}
}
@incollection{dechter-constraint,
author = {Dechter, Rina},
booktitle = {MIT Encyclopedia of the Cognitive Sciences (MITECS)},
month = jan,
publisher = {John Wiley and Sons.},
title = {{Constraint satisfaction}},
year = {1998}
}
@inproceedings{me98c,
author = {Menzies, T J and Waugh, S},
booktitle = {Proceedings of the Australian AI '98 conference},
publisher = {World-Scientific},
title = {{Lower Limits on the Size of Test Data Sets}},
year = {1998}
}
@phdthesis{Whalen00:ms-thesis,
author = {{M.P. Whalen}},
school = {University of Minnesota},
title = {{A Formal Semantics for RSML}},
year = {2000}
}
@article{me03e,
author = {Menzies, T},
journal = {IEEE Intelligent Systems},
title = {{21\^{}\{st\} century \{AI\}: proud, not smug}},
year = {2003}
}
@article{gama00,
author = {Gama, J},
journal = {Intelligent Data Analysis},
pages = {475--488},
title = {{Iterative Bayes}},
year = {2000}
}
@inproceedings{preston93,
author = {Preston, P and Edwards, G and Compton, P},
booktitle = {Second World Congress on Expert Systems},
editor = {Leibowitz, J},
title = {{A 1600 \{R\}ule \{E\}xpert \{S\}ystem \{W\}ithout \{K\}nowledge \{E\}ngineers.}},
year = {1993}
}
@inproceedings{compton93,
author = {Compton, P and Kang, B and Preston, P and Mulholland, M},
booktitle = {European Knowledge Acquisition Workshop},
title = {{Knowledge Acquisition Without Analysis}},
year = {1993}
}
@inproceedings{nach08,
author = {Nagappan, N and Murphy, B and V, Basili},
booktitle = {ICSE'08},
title = {{The Influence of Organizational Structure on Software Quality: An Empirical Case Study}},
year = {2008}
}
@article{aguilar01,
author = {Aguilar-Ruiz, J and Ramos, I and Riquelme, J C and Toro, M},
journal = {Information and Software Technology},
month = dec,
number = {14},
pages = {875--882},
title = {{An evolutionary approach to estimating software development projects}},
volume = {43},
year = {2001}
}
@inproceedings{mull02,
author = {M\"{u}ller, Matthias M and Padberg, Frank},
booktitle = {Proceedings of the Fourth International Workshop on Economics-Driven Software Engineering Research (EDSER)},
title = {{Extreme Programming from an Engineering Economics Viewpoint}},
year = {2002}
}
@inproceedings{jiang07,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07issre.pdf\}},
author = {Jiang, Y and Cukic, B and Menzies, T},
booktitle = {ISSRE'07},
title = {{Fault Prediction using Early Lifecycle Data}},
year = {2007}
}
@book{davis02,
author = {Davis, J and Fensel:q, D and {van Harmelen (eds.)}, F},
publisher = {John Wiley},
title = {{Towards the Semantic Web: Ontology-Driven Knowledge Management}},
year = {2002}
}
@inproceedings{li07,
author = {Li, J and Ruhe, G},
booktitle = {Proceedings, PROMISE'07 workshop on Repeatable Experiments in Software Engineering},
title = {{Decision Support Analysis for Software Effort Estimation by Analogy}},
year = {2007}
}
@inproceedings{me92m,
author = {Mahidadia, A J and Compton, P and Menzies, T J and Sammut, C and Smythe, G A},
booktitle = {AI '92, Horbart, Australia},
publisher = {World-Scientific},
title = {{Inventing Causal Qualitative Models: A Tool for Experimental Research}},
year = {1992}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@incollection{burg95,
author = {Burgett, J and Ohman, B},
booktitle = {OOPSLA'95 Appendum to the Proceedings},
pages = {138--142},
publisher = {Association for Computing Machinery},
title = {{Experiences with Object-Based Software Development Effort Estimates and Associated Metrics}},
year = {1995}
}
@inproceedings{vanlamsweerde98integrating,
author = {van Lamsweerde, Axel and Letier, Emmanuel},
booktitle = {Proceedings of the\~{}20th\~{}International Conference on Software Engineering},
pages = {53--62},
publisher = {IEEE Computer Society Press},
title = {{Integrating Obstacles in Goal-Driven Requirements Engineering}},
year = {1998}
}
@phdthesis{reggia81,
author = {Reggia, J A},
school = {University of Maryland},
title = {{Knowledge-Based Decision Support Systems: Development Through KMS}},
year = {1981}
}
@inproceedings{will96,
author = {Williams, B C and Nayak, P P},
booktitle = {Proceedings, AAAI '96},
pages = {971--978},
title = {{A Model-Based Approach to Reactive Self-Configuring Systems}},
year = {1996}
}
@inproceedings{pand97,
author = {Nayak, P Pandurang and Williams, Brian C},
booktitle = {Proceedings of AAAI-97},
title = {{Fast Context Switching in Real-time Propositional Reasoning}},
year = {1997}
}
@misc{mendonca99,
author = {Mendonca, M and Sunderhaft, N L},
month = sep,
title = {{Mining Software Engineering Data: A Survey}},
year = {1999}
}
@article{Chandola2009,
author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
doi = {10.1145/1541880.1541882},
file = {:Users/timm/svns/doc/anomalies09.pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
month = jul,
number = {3},
pages = {1--58},
title = {{Anomaly detection}},
url = {http://portal.acm.org/citation.cfm?doid=1541880.1541882},
volume = {41},
year = {2009}
}
@article{Khanna2010a,
abstract = {The clinical use of information technology in the dental profession has increased substantially in the past 10 to 20 years. In most developing countries an insufficiency of medical and dental specialists has increased the mortality of patients suffering from various diseases. Employing technology, especially artificial intelligence technology, in medical and dental application could reduce cost, time, human expertise and medical error. This approach has the potential to revolutionise the dental public health scenario in developing countries. Clinical decision support systems (CDSS) are computer programs that are designed to provide expert support for health professionals. The applications in dental sciences vary from dental emergencies to differential diagnosis of orofacial pain, radiographic interpretations, analysis of facial growth in orthodontia to prosthetic dentistry. However, despite the recognised need for CDSS, the implementation of these systems has been limited and slow. This can be attributed to lack of formal evaluation of the systems, challenges in developing standard representations, cost and practitioner scepticism about the value and feasibility of CDSS. Increasing public awareness of safety and quality has accelerated the adoption of generic knowledge based CDSS. Information technology applications for dental practice continue to develop rapidly and will hopefully contribute to reduce the morbidity and mortality of oral and maxillofacial diseases and in turn impact patient care.},
author = {Khanna, Sunali},
file = {:Users/timm/svns/doc/millington09.pdf:pdf},
issn = {0020-6539},
journal = {International dental journal},
keywords = {Artificial Intelligence,Decision Making, Computer-Assisted,Decision Support Systems, Clinical,Dentistry,Fuzzy Logic,Humans,Knowledge Bases,Neural Networks (Computer),User-Computer Interface},
month = aug,
number = {4},
pages = {269--72},
pmid = {20949757},
title = {{Artificial intelligence: contemporary applications and future compass.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20949757},
volume = {60},
year = {2010}
}
@inproceedings{taylor05,
author = {Taylor, B J and Darrah, M A},
booktitle = {IJCNN '05: Proceedings. 2005 IEEE International Joint Conference on Neural Networks},
pages = {2915--2920},
title = {{Rule extraction as a formal method for the verification and validation of neural networks}},
volume = {5},
year = {2005}
}
@inproceedings{dekhtyar04,
author = {Dekhtyar, A and Hayes, J Huffman and Menzies, T},
booktitle = {International Workshop on Mining Software Repositories (submitted)},
title = {{Text is Software Too}},
year = {2004}
}
@misc{boehm03,
author = {Boehm, B},
title = {{Personnel communication}},
year = {2003}
}
@article{mccabe76,
author = {McCabe, T J},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
month = dec,
number = {4},
pages = {308--320},
title = {{A Complexity Measure}},
volume = {2},
year = {1976}
}
@phdthesis{budd80,
author = {Budd, T A},
school = {Yale University},
title = {{Mutation analysis of programs test data}},
year = {1980}
}
@inproceedings{mitchell92hard,
address = {Menlo Park, California},
author = {Mitchell, David G and Selman, Bart and Levesque, Hector J},
booktitle = {Proceedings of the Tenth National Conference on Artificial Intelligence},
editor = {Rosenbloom, Paul and Szolovits, Peter},
pages = {459--465},
publisher = {AAAI Press},
title = {{Hard and Easy Distributions for \{SAT\} Problems}},
year = {1992}
}
@article{cour83,
author = {Courtney, R E and Gustafson, D A},
journal = {Software Engineering Journal},
month = jan,
pages = {5--11},
title = {{Shotgun Correlations in Software Measures}},
year = {1983}
}
@article{Harman2010c,
author = {Harman, Mark and McMinn, Phil},
doi = {10.1109/TSE.2009.71},
file = {:Users/timm/svns/doc/harmanTSE10.pdf:pdf},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
month = mar,
number = {2},
pages = {226--247},
title = {{A Theoretical and Empirical Study of Search-Based Testing: Local, Global, and Hybrid Search}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5342440},
volume = {36},
year = {2010}
}
@misc{griener98,
author = {Greiner, C and Hawryszkiewycz, I T and Rose, T and Fliedner, T M},
howpublished = {In preperation},
title = {{Capturing Knowledge for Planning: An Application in Global Health Planning}},
year = {1998}
}
@article{slaughter98,
author = {{S. Slaughter}, D Harter and Krishnan, M},
journal = {Communications of the ACM},
month = aug,
pages = {67--73},
title = {{Evaluating the Cost of Software Quality}},
year = {1998}
}
@inproceedings{drummond09,
annote = {Available on-line at $\backslash$url\{http://www.site.uottawa.ca/\~{}cdrummon/pubs/ICMLws09.pdf\}},
author = {Drummond, Chris},
booktitle = {Proceedings of the Twenty-Sixth International Conference on Machine Learning: Workshop on Evaluation Methods for Machine Learning IV},
title = {{Replicability is not reproducibility: Nor is it good science}},
year = {2009}
}
@inproceedings{fischer89,
author = {Fischer, G and McCall, R and Morch, A},
booktitle = {CHI '89},
title = {{Design environments for constructive and argumentative design}},
year = {1989}
}
@inproceedings{kirsopp02,
author = {Kirsopp, C and Shepperd, M},
booktitle = {Proc. of 22nd SGAI International Conference on Knowledge-Based Systems and Applied Artificial Intelligence, Cambridge, UK},
title = {{Case and Feature Subset Selection in Case-Based Software Project Effort Prediction}},
year = {2002}
}
@article{me06d,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06coseekmo.pdf\}},
author = {Menzies, Tim and Chen, Zhihao and Hihn, Jairus and Lum, Karen},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Menzies et al. - 2006 - Selecting Best Practices for Effort Estimation.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
month = nov,
title = {{Selecting Best Practices for Effort Estimation}},
year = {2006}
}
@inproceedings{Guerrieri99,
author = {Guerrieri, E},
booktitle = {Proceedings of WISR9: The 9th annual workshop on Institutionalizing Software Reuse},
title = {{Reuse success - when and how?}},
year = {1999}
}
@inproceedings{me04c,
author = {Menzies, T and Di\~{}Stefano, Justin S and Cunanan, Chris and Chapman, Robert (Mike)},
booktitle = {International Workshop on Mining Software Repositories},
title = {{Mining Repositories to Assist in Project Planning and Resource Allocation}},
year = {2004}
}
@inproceedings{decu95,
author = {DeCuyper, J and Keymeulen, D and Steels, L},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and {N.H. Narayanan}, B Chandrasekaran},
pages = {731--752},
publisher = {The AAAI Press},
title = {{A Hybrid Architecture for Modeling Liquid Behavior}},
year = {1995}
}
@inproceedings{MENZIES2005,
address = {New York, NY, USA},
author = {Menzies, Tim and Port, Dan and Chen, Zhihao and Hihn, Jairus},
booktitle = {PROMISE '05: Proceedings of the 2005 workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1083165.1083170},
file = {::},
isbn = {-159593-125-2},
pages = {1--6},
publisher = {ACM},
title = {{Simple software cost analysis: safe or unsafe?}},
year = {2005}
}
@misc{me99d,
annote = {In preperation},
author = {Menzies, T and Cukic, B},
howpublished = {NASA/WVU IVV tech report.},
month = mar,
title = {{An Average-Case Model of Reachability}},
year = {1999}
}
@article{forbus84,
author = {Forbus, K},
journal = {Artificial Intelligence},
pages = {85--168},
title = {{Qualitative Process Theory}},
volume = {24},
year = {1984}
}
@article{yann00,
author = {Kalfoglou, Y and Menzies, T and Althoff, K F and Motta, E},
journal = {The Knowledge Engineering Review},
month = dec,
number = {4},
title = {{Meta-Knowledges in systems design: panacea... or undelivered promise?}},
volume = {15},
year = {2000}
}
@article{vell87,
author = {Vellino, A},
journal = {Artificial Intelligence},
pages = {213--261},
title = {{Book Review of Winograd \& Flores, Understanding Computers and Cognition: A New Foundation for Design}},
volume = {31},
year = {1987}
}
@article{provost99survey,
author = {Provost, Foster J and Kolluri, Venkateswarlu},
journal = {Data Mining and Knowledge Discovery},
number = {2},
pages = {131--169},
title = {{A Survey of Methods for Scaling Up Inductive Algorithms}},
volume = {3},
year = {1999}
}
@incollection{fenton00,
author = {Fenton, N E and Neil, M},
booktitle = {Software metrics: A roadmap},
editor = {Finkelstein, A},
publisher = {ACM Press, New York},
title = {{Software Metrics: A Roadmap}},
year = {2000}
}
@misc{koru08a,
annote = {Available from $\backslash$url\{http://promisedata.org/?p=30\}},
author = {Koru, G},
title = {{Errors in LOC counts}}
}
@book{der96,
author = {Deransart, P and Ed-Dbali, A and Cervoni, L},
publisher = {Sprunger},
title = {{Prolog: The Standard}},
year = {1996}
}
@misc{davis00,
annote = {Space.com, 13 March 2000. Available from $\backslash$url\{http://www.space.com/businesstechnology/business/spear\_report\_000313.html\}.},
author = {David, L},
title = {{NASA report: Too Many Failures with Faster, Better, Cheaper}}
}
@article{Liu2004c,
author = {Liu, H and Motoda, H and Yu, L},
doi = {10.1016/j.artint.2004.05.009},
file = {:Users/timm/svns/doc/Liu04.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {ac,asu,corresponding author,dimensionality reduction,e-mail addresses,edu,feature selection and ranking,h,hliu,jp,learning,leiyu,liu,motoda,osaka-u,sampling,sanken},
month = nov,
number = {1-2},
pages = {49--74},
title = {{A selective sampling approach to active feature selection}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370204000980},
volume = {159},
year = {2004}
}
@article{krueger92,
author = {Krueger, C W},
journal = {ACM Computing Surveys},
number = {2},
pages = {131--183},
title = {{Software reuse}},
volume = {24},
year = {1992}
}
@inproceedings{bey06,
annote = {Available from $\backslash$url\{http://hunch.net/\~{}jl/projects/cover\_tree/cover\_tree.html\}},
author = {Beygelzimer, A and Kakade, S and Langford, J},
booktitle = {ICML'06},
file = {::},
title = {{Cover Trees for Nearest Neighbor}},
year = {2006}
}
@article{basili88,
author = {Basili, V R and Rombach, H D},
journal = {IEEE Transactions on Software Engineering},
month = jun,
number = {6},
pages = {758--773},
title = {{The TAME project: towards improvement-oriented software environments}},
volume = {14},
year = {1988}
}
@misc{lum03handbook,
author = {Lum, Karen and Bramble, Michael and Hihn, Jairus and Hackney, John and Khorrami, Mori and Monson, Erik},
title = {{Handbook for Software Cost Estimation}},
url = {http://ceh.nasa.gov/downloadfiles/Web Links/cost\_hb\_public-6-5.pdf},
year = {2003}
}
@article{ElEmam2001,
author = {{El Emam}, K. and Benlarbi, S. and Goel, N. and Rai, S.N.},
doi = {10.1109/32.935855},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/El Emam et al. - 2001 - The confounding effect of class size on the validity of object-oriented metrics.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
month = jul,
number = {7},
pages = {630--650},
title = {{The confounding effect of class size on the validity of object-oriented metrics}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=935855},
volume = {27},
year = {2001}
}
@book{breuker94a,
author = {Breuker, J and {de Velde (eds)}, W Van},
publisher = {IOS Press, Netherlands},
title = {{The CommonKADS Library for Expertise Modelling}},
year = {1994}
}
@article{tian03,
author = {Tian, Liang and Noore, Afzel},
issn = {0094-2898},
journal = {Proceedings of the 35th Southeastern Symposium on System Theory},
pages = {232--236},
title = {{Multistage Software Estimation}},
year = {2003}
}
@article{Wettschereck1997,
author = {Wettschereck, D. and Aha, D.W. and Mohri, T.},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Wettschereck, Aha, Mohri - 1997 - A review and empirical evaluation of feature weightng methods for a class of lazy learning algorithms.pdf:pdf},
issn = {0269-2821},
journal = {Artificial Intelligence Review},
keywords = {cbr,feature selection,instance,weighting},
number = {1},
pages = {273--314},
publisher = {Springer},
title = {{A review and empirical evaluation of feature weightng methods for a class of lazy learning algorithms}},
url = {http://www.springerlink.com/index/R1323574686528KT.pdf},
volume = {11},
year = {1997}
}
@inproceedings{orrego09,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09reuse.pdf\}},
author = {Orrego, A and Menzies, T and El-Rawas, O},
booktitle = {International Conference on Software Process},
title = {{On the Relative Merits of Software Reuse}},
year = {2009}
}
@inproceedings{evertsz91,
author = {Evertsz, R},
booktitle = {Proceedings of the 12th International Joint Conference on Artificial Intelligence (IJCAI'91)},
pages = {22--27},
title = {{The Automatic Analysis of Rule-based System Based on their Procedural Semantics}},
year = {1991}
}
@misc{curtis95,
author = {Curtis, W},
month = may,
title = {{Building a Cost-Benefit Case for Software Process Improvement, Notes from Tutorial given at the Seventh \{S\}oftware \{E\}ngineering \{P\}rocess \{G\}roup \{C\}onference, \{B\}oston, \{M\}\{A\},}},
year = {1995}
}
@article{by88,
author = {Bylander, T},
journal = {IEEE Transactions on Systems, Man, and Cybernetics},
number = {2},
pages = {252--263},
title = {{A Critique of Qualitative Simulation from a Consolidation Viewpoint}},
volume = {18},
year = {1988}
}
@book{glass02,
author = {Glass, Robert},
isbn = {0321117425},
publisher = {Addison-Wesley},
title = {{Facts and Falllacies of Software Engineering}},
year = {2002}
}
@article{burn94,
author = {Burnett, M and Baker, M},
journal = {Journal of Visual Languages and Computing,},
month = sep,
pages = {287--300},
title = {{A Classification System for Visual Programming Languages}},
year = {1994}
}
@article{aikins83,
author = {Aikins, Janice S},
journal = {Artificial Intelligence},
number = {2},
pages = {163--210},
title = {{Prototypical Knowledge for Expert Systems}},
volume = {20},
year = {1983}
}
@book{kaplan96,
author = {Kaplan, R S and Norton, D P},
publisher = {Harvard Business School Press. Boston},
title = {{The Balanced Scorecard: Translating Strategy into Action}},
year = {1996}
}
@inproceedings{FERNANDES2010,
address = {New York, NY, USA},
author = {Fernandes, Paulo and Lopes, Lucelene and Ruiz, Duncan D A},
booktitle = {SAC '10: Proceedings of the 2010 ACM Symposium on Applied Computing},
doi = {http://doi.acm.org/10.1145/1774088.1774300},
isbn = {978-1-60558-639-7},
pages = {1002--1009},
publisher = {ACM},
title = {{The impact of random samples in ensemble classifiers}},
year = {2010}
}
@incollection{hayes77,
author = {Hayes, J R and Simon, H A},
booktitle = {Cognitive Theory},
editor = {Costellan, N J and Pisoni, D B and Potts, G R},
pages = {21--41},
publisher = {Hillsdale N.J. Erlbaum},
title = {{Psychological Differences Among Problem Isomorphs}},
volume = {2},
year = {1977}
}
@article{mccon00,
author = {McConnell, Steve},
journal = {IEEE Software},
title = {{The Best Influences on Software Engineering}},
year = {2000}
}
@book{booch94,
author = {Booch, G},
publisher = {Benjamin/ Cummings},
title = {{\{O\}bject-\{O\}riented \{D\}esign with \{A\}pplications (second edition)}},
year = {1994}
}
@article{hor90,
author = {Horwitz, S and {T. Reps} and Binkley, D},
journal = {ACM Transactions on Programming Languages and Systems},
month = jan,
number = {12},
pages = {26--60},
title = {{Interprocedural slicing using dependence graphs}},
volume = {1},
year = {1990}
}
@book{laguna04,
author = {Laguna, M and Marklund, J},
publisher = {Pearson Prenctice Hall},
title = {{Business Process Modeling, Simulation, and Design}},
year = {2004}
}
@article{lutz03,
author = {Lutz, R and Mikulski, Carmen},
journal = {Journal of Systems and Software},
title = {{Operational Anomalies as a Cause of Safety-Critical Requirements Evolution}},
year = {2003}
}
@article{m-ilp-91,
author = {Muggleton, S},
journal = {New Generation Computing},
pages = {295--318},
title = {{Inductive Logic Programming}},
volume = {8},
year = {1991}
}
@article{campbell82,
author = {Campbell, A N and Hollister, V F and Duda, R O and Hart, P E},
journal = {Science},
pages = {927--929},
title = {{Recognition of a \{H\}idden \{M\}aterial \{D\}eposit by and \{A\}rtificially \{I\}ntelligent \{P\}rogram}},
volume = {217},
year = {1982}
}
@article{nii86b,
author = {Nii, H P},
journal = {\{AI\} Magazine},
month = aug,
pages = {82--106},
title = {{Blackboard Systems: Blackboard Application Systems, Blackboard Systems from a Knowledge Engineering Perspective}},
year = {1986}
}
@article{Grosan2010a,
author = {Grosan, Crina and Abraham, Ajith},
doi = {10.1016/j.ins.2009.12.018},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Grosan, Abraham - 2010 - Approximating Pareto frontier using a hybrid line search approach.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {pareto},
mendeley-tags = {pareto},
month = jul,
number = {14},
pages = {2674--2695},
title = {{Approximating Pareto frontier using a hybrid line search approach}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0020025509005489},
volume = {180},
year = {2010}
}
@article{benj98,
annote = {To appear},
author = {Benjamins, R and Fensel, D and Chandrasekaran, B},
journal = {International Journal of Human-Computer Studies},
title = {{PSMs do IT! -- Summary of track on Sharable and Reusable Problem-Solving Methods of the 10th KAW'96, Banff, Canada}},
year = {1998}
}
@inproceedings{feather06a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06rev.pdf\}},
author = {Feather, M and Cornford, S and Kiper, J and Menzies, T},
booktitle = {First International Workshop on Requirements Engineering Visualization},
title = {{Experiences using Visualization Techniques to Present Requirements, Risks to Them, and Options for Risk Mitigation}},
year = {2006}
}
@misc{compton94,
annote = {regarding the status of the PIERS system},
author = {Compton, P},
title = {{Personal communication}},
year = {1994}
}
@inproceedings{green94,
author = {Greenspan, S and Mylopoulos, J and Borgida, A},
booktitle = {International Conference on Software Engineering},
pages = {135--147},
title = {{On Formal Requirements Modeling Languages: RML Revisited}},
year = {1994}
}
@article{KULTUR2009,
address = {Amsterdam, The Netherlands, The Netherlands},
author = {Kultur, Yigit and Turhan, Burak and Bener, Ayse},
doi = {http://dx.doi.org/10.1016/j.knosys.2009.05.001},
issn = {0950-7051},
journal = {Know.-Based Syst.},
number = {6},
pages = {395--402},
publisher = {Elsevier Science Publishers B. V.},
title = {{Ensemble of neural networks with associative memory (ENNA) for estimating software development costs}},
volume = {22},
year = {2009}
}
@book{gof95,
author = {Gamma, E and Helm, R and Johnson, R and Vlissides, J},
publisher = {Addison-Wesley},
title = {{Design Patterns: Elements of Reusable Object-Oriented Software}},
year = {1995}
}
@inproceedings{Gu97,
author = {Gu, Jun and Purdom, Paul W and Franco, John and Wah, Benjamin W},
booktitle = {DIMACS Series in Discrete Mathematics and Theoretical Computer Science},
pages = {19--152},
publisher = {American Mathematical Society},
title = {{Algorithms for the Satisfiability (SAT) Problem: A Survey}},
year = {1997}
}
@inproceedings{me00u,
author = {Menzies, T and Singh, H},
booktitle = {AI'2001: the Fourteenth Canadian Conference on Artificial Intelligence, June 7-9, Ottawa, Canada},
title = {{How \{AI\} can help \{SE\}; or: Randomized Search Not Considered Harmful}},
year = {2001}
}
@misc{standish01,
title = {{The \{S\}tandish \{G\}roup \{R\}eport: \{C\}haos 2001}},
year = {2001}
}
@inproceedings{motta96,
author = {Motta, E and Zdrahal, Z},
booktitle = {Proceedings of the 10th Banff Knowledge Acquisition for Knowledge-Based System Workshop},
title = {{Parametric Design Problem Solving}},
year = {1996}
}
@article{loggia89,
author = {Ramsey, C Loggia and Basili, V R},
journal = {IEEE Transactions on Software Engineering},
pages = {747--759},
title = {{An Evaluation for Expert Systems for Software Engineering Management}},
volume = {15},
year = {1989}
}
@misc{grey03,
author = {Grey, W and Katircioglu, K and Bagchi, S and Shi, D and Gallego, G and Seybold, D and Stefanis, S},
booktitle = {IBM Systems Journal},
number = {3},
title = {{An analytic approach for quantifying the value of e-business initiatives}},
volume = {42},
year = {2003}
}
@book{cormen90,
annote = {ISBN: 0262031418},
author = {Cormen, T E and Leiserson, C E and Rivest, R L},
publisher = {MIT Press},
title = {{Introduction to Algorithms}},
year = {1990}
}
@article{Kirsopp2002,
author = {Kirsopp, C and Shepperd, M},
doi = {10.1049/ip-sen},
journal = {IEEE Proc.},
number = {5},
title = {{Making inferences with small numbers of training sets}},
volume = {149},
year = {2002}
}
@inproceedings{darden90,
author = {Darden, L},
booktitle = {Computational Models of Scientific Discovery and Theory Formation},
editor = {Sharager, J and Langley, P},
publisher = {Morgan Kaufmann Publishers Inc.},
title = {{Diagnosing and Fixing Faults in Theories}},
year = {1990}
}
@inproceedings{shu86,
author = {Shu, N C},
booktitle = {Visual Languages},
editor = {Chang, S K and Ligomenides, P A},
pages = {11--34},
title = {{Visual Programming Languages: A Perspective and a Dimensional Analysis}},
year = {1986}
}
@article{simon86,
author = {Iwasaki, Y and Simon, H A},
journal = {Artificial Intelligence},
pages = {3--31},
title = {{Causality in Device Behaviour}},
volume = {29},
year = {1986}
}
@inproceedings{hayes05,
author = {Hayes, J H and Chemannoor, I and Surisetty, V and Andrews, A},
booktitle = {Proceedings of European Dependable Computing Conference (EDCC), Budapest, Hungary},
month = apr,
title = {{Fault Links:Exploring the Relationship Between Module and Fault Types}},
year = {2005}
}
@inproceedings{keim99,
author = {Keim, G A and Shazeer, N and Littman, M L and Agarwal, S and Cheves, C M and Fitzgerald, J and Grosland, J and Jiang, F and Pollard, S and Weinmeister, K},
booktitle = {Proceedings of the Sixteenth National Conference on Artificial Intelligence (AAAI-99)},
pages = {710--717},
title = {{Proverb: The probabilistic cruciverbalist}},
year = {1999}
}
@inproceedings{mah94,
author = {Mahihadia, A and Sammut, C and Compton, P},
booktitle = {Artificial Intelligence: Sowing the Seeds for the Future; Proceedings of AI'94},
publisher = {World Scientific},
title = {{Applying Inductive Logic Programming to Causal Qualitative Models in Neuroendocrinology}},
year = {1994}
}
@article{me96a,
author = {Menzies, T J},
journal = {International Journal of Human Computer Studies},
pages = {305--355},
title = {{Applications of Abduction: Knowledge Level Modeling}},
volume = {45},
year = {1996}
}
@inproceedings{fea99,
author = {Feather, M and Smith, B},
booktitle = {Proceedings of the Fourteenth IEEE International Conference on Automated Software Engineering (ASE-99), Cocoa Beach, Florida},
month = oct,
pages = {63--72},
title = {{Automatic Generation of Test Oracles: From Pilot Studies to Applications}},
year = {1999}
}
@article{SURE83,
author = {Supowit, K J and Reingold, E M},
journal = {Acta Informatica},
pages = {377--392},
title = {{The Complexity of Drawing Trees Nicely}},
volume = {18},
year = {1983}
}
@book{Grady1992,
author = {Grady, R B},
publisher = {Prentice-Hall, Englewood Cliffs},
title = {{Practical Software Metrics for Project Management and Process Improvement}},
year = {1992}
}
@incollection{shalin97,
author = {Shalin, V L and Geddes, N D and Bertram, D and Szczepkowski, M A and Dubois, D},
booktitle = {Expertise in Context},
chapter = {9},
editor = {Feltovich, P J and Ford, K M and Hoffman, R R},
pages = {195--217},
publisher = {MIT PRess},
title = {{Expertise in Dynamic, Physical Task Domains}},
year = {1997}
}
@article{mitchell06,
author = {Mitchell, B S and Mancoridis, S},
journal = {IEEE Transactions on Software Engineering},
month = mar,
number = {3},
pages = {193--208},
title = {{On the Automatic Modularization of Software Systems Using the Bunch Tool}},
volume = {32},
year = {2006}
}
@inproceedings{me88,
annote = {Adelaide, Australia},
author = {Menzies, T J and Dean, M and Black, J and Fleming, J},
booktitle = {AI '88},
title = {{Combining Heuristics with Simulation Models: An Expert System for the Optimal Management of Pig}},
year = {1988}
}
@article{denne95,
author = {Dennebouy, Y and Andersson, M and Auddino, A and Dupont, Y and Fontana, E and Gentile, M and Spaccapietra, S},
journal = {Journal of Visual Languages and Computing},
pages = {73--99},
title = {{Super: Visual Interfaces for Object and Relationship Data Models}},
year = {1995}
}
@article{ropp00,
author = {Ropponen, J and Lyytinen, K},
journal = {IEEE Transactions on Software Engineering},
pages = {98--112},
title = {{Components of software development risk: how to address them? A project manager survey}},
year = {2000}
}
@inproceedings{han99,
author = {Han, K and Veloso, M},
booktitle = {Proceedings of the Sixteenth Interntional Joint Conference on Artificial Intelligence. Workshop on Team Behaviour and Plan Recognition},
pages = {47--52},
title = {{Automated robot behaviour recognition applied to robot soccer}},
year = {1999}
}
@inproceedings{me07,
author = {Menzies, T and Hu, Y},
booktitle = {Artificial Intelligence Review},
file = {::},
title = {{Just Enough Learning (of Association Rules): The \{TAR2\} Treatment Learner}},
year = {2007}
}
@inproceedings{iwasaki95,
author = {Iwasaki, Y},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and Narayanan, H and Chandrasekaran, B},
pages = {657--668},
publisher = {MIT Press},
title = {{Problem Solving with Diagrams}},
year = {1995}
}
@misc{gibson06,
author = {Gibson, D L and Goldenson, D R and Kost, K},
institution = {Software Engineering Institute},
title = {{Performance Results of CMMI-Based Process Improvement}},
year = {2006}
}
@inproceedings{lud88,
author = {Ludolph, F and Chow, Y and Ingalls, D and Wallace, S and Doyle, K},
booktitle = {IEEE Proceedings Workshop on Visual Languages},
pages = {222--230},
title = {{The Fabrik Programming Environment}},
year = {1988}
}
@inproceedings{SUNDARAM2005,
address = {New York, NY, USA},
author = {Sundaram, Senthil Karthikeyan and Hayes, Jane Huffman and Dekhtyar, Alexander},
booktitle = {PROMISE '05: Proceedings of the 2005 workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1083165.1083169},
isbn = {-159593-125-2},
pages = {1--6},
publisher = {ACM},
title = {{Baselines in requirements tracing}},
year = {2005}
}
@inproceedings{hori97,
author = {Hori, M and Yoshida, T},
booktitle = {Workshop on Problem-Solving Methods for Knowledge-based Systems, IJCAI '97, August 23.},
title = {{Domain-oriented library of scheduling methods: Design Principle and real-life application}},
year = {1997}
}
@book{lewis93,
author = {Lewis, C and Rieman, J},
publisher = {University of Colorado},
title = {{Task-Centred User Interface Design}},
year = {1993}
}
@article{tosun2010,
author = {Tosun, A and Bener, A and Turhan, B and Menzies, T},
title = {{No Title}}
}
@book{greenfield04,
author = {Greenfield, Jack and Short, Keith},
publisher = {Wiley Publishing, Indianapolis, IN},
title = {{Software factories : assembling applications with patterns, models, frameworks, and tools}},
year = {2004}
}
@misc{wu95b,
author = {Wu, X},
institution = {Department of Software Development, Monash University},
number = {95-1},
title = {{Noise handling with extension matrixes}},
year = {1995}
}
@inproceedings{me99f,
author = {Menzies, T and Cukic, B},
booktitle = {Proceedings, AAAI '99 workshop on Intelligent Software Engineering, Orlando, Florida},
month = jul,
title = {{Intelligent Testing can be Very Lazy}},
year = {1999}
}
@inproceedings{asano00,
author = {Asano, T and Williamson, D P},
booktitle = {SODA '00: 11th Annual ACM Symposium of Discrete Algorithms},
pages = {96--115},
title = {{Improved approximation algorithms for MAX SAT}},
year = {2000}
}
@article{song06,
address = {Piscataway, NJ, USA},
author = {Song, Qinbao and Shepperd, Martin and Cartwright, Michelle and Mair, Carolyn},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {2},
pages = {69--82},
publisher = {IEEE Press},
title = {{Software Defect Association Mining and Defect Correction Effort Prediction}},
volume = {32},
year = {2006}
}
@inproceedings{me00v,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/00vp.pdf\}},
author = {Menzies, T},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{Evaluation Issues for Visual Programming Languages}},
year = {2002}
}
@inproceedings{me03a,
author = {Menzies, T and Stefano, J Di and Ammar, K and McGill, K and Callis, P and Chapman, R and J, Davis},
booktitle = {IEEE Metrics'03},
title = {{When Can We Test Less?}},
year = {2003}
}
@inproceedings{tidhar99,
author = {Tidar, G and Heinze, C and Goss, S and Murray, G and Appla, D and Lloyd, I},
booktitle = {Proc. of Eleventh Innovative Applications of Artificial Intelligence Conference, American Association of Artificial Intelligence},
title = {{Using intelligent agents in military simulations or 'using agents intelligently.'}},
year = {1999}
}
@article{iwasaki86a,
author = {Iwasaki, Y and Simon, H},
journal = {Artificial Intelligence},
pages = {63--72},
title = {{Theories of Causal Ordering: Reply to deKleer and Brown}},
volume = {29},
year = {1986}
}
@article{miller83,
author = {Miller, P L},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = sep,
number = {5},
pages = {449--461},
title = {{ATTENDING: critiquing a physcian's management plan}},
year = {1983}
}
@misc{sinha02,
annote = {Available from $\backslash$url\{http://www.exu.ilstu.edu/spin/presentations/Prabhuus\_presentation.pdf\}},
author = {Sinha, P},
title = {{Worldwide Implementation of the CMM and its Impact on the U.S. Software Development Community, SEI Software Process Improvement Network, June 6, Bradley University Student Center Peoria, Illinois}},
year = {2002}
}
@misc{soft02,
author = {Ciolkowski, M and Laitenberger, O and Rombach, D and Shull, F and Perry, D},
booktitle = {Proceedings of the 2003 International Conference on Software Enginereing},
pages = {641--642},
title = {{Software Inspections, Reviews \& Walkthroughs, an ICSE 2002 IMPACT Presentations}},
year = {2002}
}
@article{Bentley1975,
author = {Bentley, Jon Louis},
doi = {10.1145/361002.361007},
file = {:Users/timm/svns/doc/bentleyKDtree75.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = sep,
number = {9},
pages = {509--517},
title = {{Multidimensional binary search trees used for associative searching}},
url = {http://portal.acm.org/citation.cfm?doid=361002.361007},
volume = {18},
year = {1975}
}
@book{basset97,
author = {Bassett, P G},
publisher = {Yourdon Press},
title = {{Framing Software Reuse}},
year = {1997}
}
@article{Cha2007,
author = {Cha, Sung-hyuk},
file = {:Users/timm/svns/doc/distance07.pdf:pdf},
keywords = {distance,histogram,probability density function},
number = {4},
title = {{Comprehensive Survey on Distance / Similarity Measures between Probability Density Functions}},
volume = {1},
year = {2007}
}
@article{simons99,
author = {Simons, D J and Chabris, C F},
journal = {Perception},
pages = {1059--1074},
title = {{Gorillas in our Midst: Sustained Inattentional Blindless for Dynamic Events Perception}},
volume = {28},
year = {1999}
}
@misc{Coiera96,
annote = {Technical Report HPL-96-65, May, 1996},
author = {Coiera, E},
institution = {Hewlett-Packard Laboratories},
title = {{Communication in Organisations}},
year = {1996}
}
@article{ramesh92,
author = {Ramesh, B and Dhar, V},
journal = {IEEE Transactions on Software Engineering},
month = jun,
number = {6},
pages = {498--510},
title = {{Supporing Systems Development by Capturing Deliberations During Requirements Engineering}},
volume = {18},
year = {1992}
}
@inproceedings{mizuno00,
author = {Mizuno, O and Kikuno, T and Takagi, Y and Sakamoto, K},
booktitle = {ICSE 2000},
title = {{Characterization of risky projects based on project managers evaluation}},
year = {2000}
}
@book{verm99,
author = {Vermesan, A and Coenen, F},
isbn = {0-7923-8645-0},
publisher = {Kluwer Academic Publishing, Utrecht, Netherlands},
title = {{Validation and Verication of Knowledge Based Systems: Theory, Tools and Practice}},
year = {1999}
}
@article{aamod94,
author = {Aamodt, A and Plaza, E},
file = {::},
journal = {Artificial Intellegence Communications},
pages = {39--59},
title = {{Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches}},
volume = {7},
year = {1994}
}
@misc{blazy99,
author = {Blazy, L B},
month = mar,
title = {{\{O\}\{S\}\{M\}\{A\} Software Assurance Program Level 1 Technical Program Plan, Ames Research Center - Code \{I\}\{T\} Software Independent Verification \& Validation Facility \{F\}airmont, \{W\}est \{V\}irginia}},
year = {1999}
}
@article{adams92,
author = {{Dennis A. Adams}, R Ryan Nelson and Todd, Peter A},
journal = {MIS Quarterly},
number = {2},
pages = {227--247},
title = {{Perceived Usefulness, Ease of Use, and Usage of Information Technology: A Replication}},
volume = {16},
year = {1992}
}
@article{pasquini96,
author = {Pasquini, A and A, N Crespo and Matrella, P},
journal = {IEEE Transactions on Reliability},
number = {4},
pages = {531--540},
title = {{Sensitivity of Reliability-Growth Models to Pperational Profile Errors vs Testing Accuracy}},
volume = {45},
year = {1996}
}
@article{toh04,
author = {Toh, K and Yau, W and Jiang, X},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
month = feb,
pages = {224--233},
title = {{A Reduced Multivariate Polynomial Model for Multimodal Biometrics and Classifiers Fusion}},
year = {2004}
}
@article{raffo99,
author = {Raffo, D M and Vandeville, J V and Martin, R},
journal = {Journal of Systems and Software},
month = apr,
number = {2/3},
title = {{Software Process Simulation to Achieve Higher CMM Levels}},
volume = {46},
year = {1999}
}
@inproceedings{raffo04,
author = {Raffo, D and Nayak, U and Setamanit, S and Wakeland, W},
booktitle = {Proceedings of the International Workshop on Software Process Simulation and Modeling (ProSim'04), Held in conjunction with the International Conference of Software Engineering (ICSE), Held in Edinburgh, Scotland},
month = may,
title = {{Using Software Process Simulation Models to Assess the Impact of \{IV\&V\} Activities}},
year = {2004}
}
@misc{me09c,
author = {Gundy-Burlet, K and Schumann, J and Menzies, T and Barrett, T},
booktitle = {AIAA Aerospace, 2009},
title = {{Parametric Analysis of a Hover Test Vehicle Using Advanced Test Generation and Data Analysis}},
year = {2009}
}
@misc{raffo05,
author = {Raffo, D},
title = {{Personnel communication}},
year = {2005}
}
@misc{budgen06,
annote = {Keynote address, CSEET'06},
author = {Budgen, D},
title = {{No Title}},
year = {2006}
}
@inproceedings{waugh98,
author = {Waugh, S and Blogs, J and Menzies, T},
booktitle = {Proceedings of the Australain AI '98 conference},
title = {{The Temporal Qualitative Compartmental Modeling Language}},
year = {1998}
}
@inproceedings{hui04,
author = {Hui, Y C and Prakash, E C and Chaudhari, N S},
booktitle = {TENCON 2004. 2004 IEEE Region 10 Conference},
isbn = {0-7803-8560-8},
pages = {306--309},
title = {{Game AI: artificial intelligence for 3D path finding}},
volume = {2},
year = {2004}
}
@article{zlatereva94,
author = {Zlatereva, N and Preece, A},
journal = {Expert Systems with Applications},
pages = {151--167},
title = {{State of the Art in Automated Validation of Knowledge-Based Systems}},
volume = {7},
year = {1994}
}
@inproceedings{madachy94,
author = {Madachy, R},
booktitle = {Proceedings Ninth Knowledge-Based Software Engineering Conference},
pages = {172--178},
title = {{Knowledge-based risk assessment and cost estimation}},
year = {1994}
}
@article{Zadeh1973a,
author = {Zadeh, L A},
journal = {IEEE Transactions on Systems, Man and Cybernetics},
month = jan,
number = {1},
pages = {28--44},
title = {{Outline of a New Approach to the Analysis of Complex Systems and Decision Processes}},
volume = {SMC-3},
year = {1973}
}
@book{demarco87,
address = {New York, NY, USA},
author = {DeMarco, Tom and Lister, Timothy},
isbn = {0-932633-05-6},
publisher = {Dorset House Publishing Co., Inc.},
title = {{Peopleware: productive projects and teams}},
year = {1987}
}
@inproceedings{antoniol05,
author = {Antoniol, G and Gueheneuc, Yann-Gael},
booktitle = {ICSM 2005},
pages = {357--366},
title = {{Feature Identification: A Novel Approach and a Case Study}},
year = {2005}
}
@inproceedings{frank03,
author = {Frank, Eibe and Hall, Mark and Pfahringer, Bernhard},
booktitle = {Proceedings of the Conference on Uncertainty in Artificial Intelligence},
pages = {249--256},
publisher = {Morgan Kaufmann},
title = {{Locally weighted naive Bayes}},
year = {2003}
}
@article{lapu91,
author = {Lalonde, W and Pugh, J},
journal = {Journal of Object-Oriented Programming},
month = jan,
pages = {57--62},
title = {{Subclassing $\backslash$neq subtyping $\backslash$neq Is-a}},
year = {1991}
}
@article{clancey85,
author = {Clancey, W},
journal = {Artificial Intelligence},
pages = {289--350},
title = {{Heuristic \{C\}lassification}},
volume = {27},
year = {1985}
}
@inproceedings{yang02,
annote = {Available from $\backslash$url\{http://www.csse.monash.edu/\~{}webb/Files/YangWebb03.pdf\}},
author = {Yang, Y and Webb, G},
booktitle = {Proceedings of the 7th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2003)},
title = {{Weighted Proportional k-Interval Discretization for Naive-Bayes Classifiers}},
year = {2003}
}
@incollection{paris89,
author = {Paris, C L},
booktitle = {User Models in Dialog Systems},
editor = {Kobsa, A and Wahlster, W},
pages = {200--232},
publisher = {Springer-Verlag},
title = {{The \{U\}se of \{E\}xplicit \{U\}ser \{M\}odels in a \{G\}eneration \{S\}ystem for \{T\}ailoring \{A\}nswers to the \{U\}ser's \{L\}evel of \{E\}xpertise}},
year = {1989}
}
@misc{spear00,
annote = {www.nasawatch.com/congress/2000/03.22.00.spear.pdf},
author = {Spear, Tony},
month = mar,
title = {{Testimony on NASA FBC Task before the Subcommittee on Science, Technology, and Space}},
year = {2000}
}
@inproceedings{hirata94,
annote = {Also in \{$\backslash$em Machine Intelligence\} 14},
author = {Hirata, K},
booktitle = {Proceedings of the Fourteenth International Machine Learning Workshop, ML-14},
pages = {16},
title = {{A \{C\}lassification of \{A\}bduction: \{A\}bduction for \{L\}ogic \{P\}rogramming}},
year = {1994}
}
@article{paulk99,
author = {Paulk, M},
month = jun,
number = {3},
pages = {19--29},
title = {{ASQ Software Quality Professional}},
volume = {1},
year = {1999}
}
@inproceedings{levy96,
author = {Levy, A Y and Rousset, M},
booktitle = {AAAI '96},
title = {{Verification of knowledge bases using containnment checking}},
year = {1996}
}
@inproceedings{me05d,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05learncost.pdf\}},
author = {Menzies, T and Port, D and Chen, Z and Hihn, J and Stukes, S},
booktitle = {IEEE ASE, 2005},
title = {{Specialization and Extrapolation of Induced Domain Models: Case Studies in Software Effort Estimation}},
year = {2005}
}
@article{silver92a,
author = {Silverman, B G},
journal = {IEEE Expert},
month = apr,
pages = {18--25},
title = {{Building a Better Critic: Recent Empirical Results}},
year = {1992}
}
@misc{me09g,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09keys2.pdf\}},
author = {Gay, G and Menzies, T and Jalali, O and Mundy, G and Gilkerson, B and Feather, M and Kiper, J},
booktitle = {Automated Software Engineering},
number = {1},
pages = {87--116},
title = {{Finding robust solutions in requirements models}},
volume = {17},
year = {2010}
}
@inproceedings{raffo99a,
author = {Raffo, D and Kellner, M},
booktitle = {Elements of Software Process Assessment and Improvement},
editor = {Emam, K El and Madhavji, N},
publisher = {IEEE Computer Society},
title = {{Impact of Potential Process Changes: A Quantitative Approach to Process Modeling}},
year = {199}
}
@article{chang90,
author = {Chang, C L and Combs, J B and Stachowitz, R A},
journal = {Expert Systems with Applications},
number = {3},
pages = {217--230},
title = {{Report on the Expert Systems Validation Associate (EVA)}},
volume = {1},
year = {1990}
}
@book{booch96,
author = {Booch, G},
publisher = {Addison-Wesley},
title = {{Object Solutions: Managing the Object-Oriented Project}},
year = {1996}
}
@article{swan90,
author = {Swanson, D R},
journal = {Bull Med Libr Assoc},
pages = {29--37},
title = {{Medical Knowledge as a Potential Source of New Knowledge}},
volume = {78},
year = {1990}
}
@article{Haaga04,
author = {Haaga, John and Commission., Appalachian Regional and Bureau., Population Reference},
keywords = {Educational attainment Appalachian Region.},
pages = {24 p.},
publisher = {Appalachian Regional Commission : Population Reference Bureau},
title = {{Educational attainment in Appalachia}},
year = {2004}
}
@misc{musc00,
author = {{N. Muscettola}, NASA Ames Research Center},
title = {{Personal communication}},
year = {2000}
}
@article{tiang95,
author = {Tian, J and Zelkowitz, M V},
journal = {IEEE Transaction on Software Engineering},
month = aug,
number = {8},
pages = {641--649},
title = {{Complexity Measure Evaluation and Selection}},
volume = {21},
year = {1995}
}
@article{denne95,
author = {Dennebouy, Y and Andersson, M and Auddino, A and Dupont, Y and Fontana, E and Gentile, M and Spaccapietra, S},
journal = {Journal of Visual Languages and Computing},
pages = {73--99},
title = {{Super: Visual Interfaces for Object and Relationship Data Models}},
year = {1995}
}
@article{Manegold2010a,
author = {Manegold, S. and Laurent, D. and Lupu, M. and Onose, N. and R\'{e}, C. and Sans, V. and Senellart, P. and Wu, T. and Shasha, D. and Manolescu, I. and Afanasiev, L. and Feng, J. and Gou, G. and Hadjieleftheriou, M. and Harizopoulos, S. and Kalnis, P. and Karanasos, K.},
doi = {10.1145/1815933.1815944},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Manegold et al. - 2010 - Repeatability \& workability evaluation of SIGMOD 2009(2).pdf:pdf},
issn = {01635808},
journal = {ACM SIGMOD Record},
month = dec,
number = {3},
pages = {40},
title = {{Repeatability \& workability evaluation of SIGMOD 2009}},
url = {http://portal.acm.org/citation.cfm?doid=1815933.1815944},
volume = {38},
year = {2010}
}
@article{bachant84,
author = {Bachant, J and McDermott, J},
journal = {\{AI\} Magazine},
pages = {21--32},
title = {{\{R1\} \{R\}evisited: \{F\}our \{Y\}ears in the \{T\}renches}},
year = {1984}
}
@inproceedings{gent95,
author = {Gent, I and MacIntyre, E and Prosser, P and Walsh, T},
booktitle = {International Conference on Principles and Practice of Constraint Programming},
title = {{Scaling Effects in CSP Phase Transistion}},
year = {1995}
}
@article{ross85,
author = {Ross, D T},
journal = {IEEE Computer},
pages = {25--34},
title = {{Applications and Extensions of SADT}},
volume = {18},
year = {1985}
}
@book{glinert90b,
editor = {Glinert, E P},
publisher = {IEEE Computer Society Press},
title = {{Visual Programming Environments: Applications and Issues}},
year = {1990}
}
@article{demillo78,
author = {DeMillo, R A and Lipton, R J and Sayward, F G},
journal = {Computer},
keywords = {mutation,testing},
number = {4},
pages = {34--41},
title = {{Hints on Test Data Selection: Help for the Practicing Programmer}},
volume = {11},
year = {1978}
}
@article{Strouthidis2010b,
abstract = {To evaluate the reproducibility of the Heidelberg retina tomograph (HRT) Glaucoma Probability Score (GPS) and assess its potential for monitoring progression.},
author = {Strouthidis, Nicholas G and Demirel, Shaban and Asaoka, Ryo and Cossio-Zuniga, Claudio and Garway-Heath, David F},
doi = {10.1016/j.ophtha.2009.09.036},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Strouthidis et al. - 2010 - The Heidelberg retina tomograph Glaucoma Probability Score reproducibility and measurement of progression.pdf:pdf},
issn = {1549-4713},
journal = {Ophthalmology},
keywords = {Adult,Aged,Aged, 80 and over,Diagnostic Techniques, Ophthalmological,Disease Progression,Female,Glaucoma, Open-Angle,Glaucoma, Open-Angle: diagnosis,Glaucoma, Open-Angle: physiopathology,Humans,Intraocular Pressure,Intraocular Pressure: physiology,Male,Middle Aged,Observer Variation,Ocular Hypertension,Ocular Hypertension: diagnosis,Ocular Hypertension: physiopathology,Probability,Reproducibility of Results,Sensitivity and Specificity,Tomography,Tomography: methods,Visual Fields,Visual Fields: physiology,Young Adult},
month = apr,
number = {4},
pages = {724--9},
pmid = {20045564},
title = {{The Heidelberg retina tomograph Glaucoma Probability Score: reproducibility and measurement of progression.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20045564},
volume = {117},
year = {2010}
}
@phdthesis{huang06a,
annote = {Available from $\backslash$url\{http://csse.usc.edu/csse/TECHRPTS/PhD\_Dissertations/files/Huang\_Dissertation.pdf\}},
author = {Huang, L},
school = {Department of Computer Science, University of Southern California},
title = {{Software Quality Analysis: A Value-Based Approach}},
year = {2006}
}
@article{dekleer93,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {63--67},
title = {{A perspective on assumption-based truth maintenance}},
volume = {59},
year = {1993}
}
@inproceedings{malin07,
author = {Malin, J T and Throop, D R},
booktitle = {IEEE Aerospace Conference},
month = mar,
title = {{Basic Concepts and Distinctions for an Aerospace Ontology of Functions, Entities and Problems}},
year = {2007}
}
@inproceedings{me08d,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ceiling.pdf\}},
author = {Menzies, T and Turhan, B and Bener, A and Gay, G and Cukic, B and Jiang, Y},
booktitle = {Proceedings of PROMISE 2008 Workshop (ICSE)},
file = {::},
title = {{Implications of Ceiling Effects in Defect Predictors}},
year = {2008}
}
@book{karolak96,
author = {Karolak, D},
publisher = {IEEE Computer Society Press},
title = {{Software Engineering Risk Management}},
year = {1996}
}
@article{dekleer87,
author = {DeKleer, J and Williams, B C},
journal = {Artificial Intelligence},
pages = {97--130},
title = {{Diagnosing \{M\}ultiple \{F\}aults}},
volume = {32},
year = {1987}
}
@article{furnkranz05,
address = {Hingham, MA, USA},
author = {F\"{u}rnkranz, Johannes and Flach, Peter A},
doi = {http://dx.doi.org/10.1007/s10994-005-5011-x},
issn = {0885-6125},
journal = {Machine Learning},
number = {1},
pages = {39--77},
publisher = {Kluwer Academic Publishers},
title = {{ROC 'n' rule learning: towards a better understanding of covering algorithms}},
volume = {58},
year = {2005}
}
@article{jorgensen05a,
author = {Jorgensen, M},
journal = {IEEE Software},
number = {3},
title = {{Practical Guidelines for Expert Judgment Based-Software-Effort Estimation}},
volume = {22},
year = {2005}
}
@inproceedings{deb96a,
author = {Debenham, J},
booktitle = {Proceedings 9th International Sympoisum on Methodologies for Intelligent Systems ISMIS '96, Zakopane, Poland, June},
pages = {314--705},
title = {{Knowledge Simplificiation}},
year = {1996}
}
@misc{me99i,
annote = {NASA IVV Facility Technical Report},
author = {Menzies, T and Houle, M E and Powell, J},
title = {{RAPTURE/SP2: Efficient Testing of Temporal Properties Without Search Space Explosion}},
year = {1999}
}
@inproceedings{mink75,
author = {Minsky, M},
booktitle = {The Psychology of Computer Vision},
organization = {McGraw-Hill},
title = {{A Framework for Representing Knowledge}},
year = {1975}
}
@inproceedings{fecosm89b,
author = {Feldman, B and Compton, P and Smythe, G},
booktitle = {Proceedings of the Joint Australian Conference on Artificial Intelligence, \{AI\} '89},
pages = {319--331},
title = {{Towards \{H\}ypothesis \{T\}esting: JUSTIN, \{P\}rototype \{S\}ystem \{U\}sing \{J\}ustification in \{C\}ontext}},
year = {1989}
}
@inproceedings{michael97,
author = {Michael, C C},
booktitle = {Proceedings of the 12th Annual Confererence on Computer Assurance (COMPASS '97) Gaithersburg, MD},
title = {{On the Uniformity of Error Propagation in Software}},
year = {1997}
}
@article{fenton02,
address = {Los Alamitos, CA, USA},
author = {Fenton, Norman and Krause, Paul and Neil, Martin},
doi = {http://doi.ieeecomputersociety.org/10.1109/MS.2002.1020298},
issn = {0740-7459},
journal = {IEEE Software},
number = {4},
pages = {116--122},
publisher = {IEEE Computer Society},
title = {{Software Measurement: Uncertainty and Causal Modeling}},
volume = {19},
year = {2002}
}
@book{Sutton1998,
author = {Sutton, R.S. and Barto, A.G.},
booktitle = {Policy},
file = {:Users/timm/svns/doc/sutton98.pdf:pdf},
isbn = {0262193981},
publisher = {The MIT press},
title = {{Reinforcement learning: An introduction}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=CAFR6IBF4xYC\&amp;oi=fnd\&amp;pg=PA3\&amp;dq=Reinforcement+Learning+:+An+Introduction\&amp;ots=e8WUNPbbWC\&amp;sig=9P8h\_oRbAy7uAtVkbWwdFGvz2SQ},
year = {1998}
}
@article{motta98,
author = {Motta, E and Zdrahal, Z},
journal = {International Journal of Human Computer Studies},
pages = {437--470},
title = {{A library of problem-solving components based on the intergration of the search paradigm with task and method ontologies.}},
volume = {49},
year = {1998}
}
@book{booch91,
author = {Booch, G},
publisher = {Benjamin/ Cummings},
title = {{Object-Oriented Design with Applications}},
year = {1991}
}
@article{me09b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ccwc.pdf\}},
author = {Turhan, B and Menzies, T and Bener, A and Distefano, J},
file = {::},
journal = {Empirical Software Engineering},
number = {2},
pages = {278--290},
title = {{On the Relative Value of Cross-Company and Within-Company Data for Defect Prediction}},
volume = {68},
year = {2009}
}
@inproceedings{Gangemi98,
author = {Gangemi, A and Pisanelli, D and Steve, G},
booktitle = {Proceedings of the 1st International Conference on Formal Ontology in Information Systems, FOIS'98, Trento, Italy},
editor = {Guarino, N},
month = jun,
pages = {163--178},
title = {{Ontology Integration: Experiences with Medical Terminologies}},
year = {1998}
}
@article{poole93g,
author = {Poole, D},
journal = {Artificial Intelligence},
number = {1},
pages = {81--129},
title = {{Probabilistic \{Horn\} Abduction and \{Bayesian\} Networks}},
volume = {64},
year = {1993}
}
@inproceedings{kautz96,
address = {Menlo Park},
author = {Kautz, Henry and Selman, Bart},
booktitle = {Proceedings of the Thirteenth National Conference on Artificial Intelligence and the Eighth Innovative Applications of Artificial Intelligence Conference},
isbn = {0-262-51091-X},
pages = {1194--1201},
publisher = {AAAI Press / MIT Press},
title = {{Pushing the Envelope: Planning, Propositional Logic and Stochastic Search}},
year = {1996}
}
@article{lanubile97,
author = {Lanubile, F and Visaggio, G},
journal = {The Journal of Software and Systems},
pages = {225--234},
title = {{Evaluating Predictive Quality Models Derived from Software Measures: Lessons Learned}},
volume = {38},
year = {1997}
}
@misc{powell99,
author = {Powell, J D},
title = {{A Graph Theoretic Approach to Assessing Tradeoffs on Memory Usage for Model Checking,}},
year = {1999}
}
@inproceedings{burch90,
author = {Burch, J R and Clark, E M},
booktitle = {Fifth Annual IEEE Symposium on Logic in Computer Science},
title = {{Symbolic Model Checking: 10\^{}\{20\} States and Beyond}},
year = {1990}
}
@inproceedings{Rushby:Tutorial,
address = {Bad Herrenalb, Germany},
author = {{S. Owre} and {J.M. Rushby} and {N. Shankar} and {M.K. Srivas}},
booktitle = {Proc. 2nd International Conference on Theorem Provers in Circuit Design (TPCD94)},
editor = {{T. Kropf} and {R. Kumar}},
pages = {258--279},
publisher = {Springer-Verlag},
title = {{A Tutorial on Using \{PVS\} for Hardware Verification}},
url = {citeseer.nj.nec.com/owre95tutorial.html},
volume = {901},
year = {1994}
}
@article{poole90b,
author = {Poole, D},
journal = {International Journal of Intelligent Systems},
pages = {521--548},
title = {{A Methodology for Using a Default and Abductive Reasoning System}},
volume = {5},
year = {1990}
}
@misc{me95i,
author = {Menzies, T J and Taylor, A},
institution = {Department of Software Development, Monash University},
number = {TR95-36},
title = {{Abduction and Memoing}},
year = {1995}
}
@misc{ang93,
author = {Angele, J},
howpublished = {Infix, St. Augustin},
title = {{Operationalisierung des Models der Expertise mit KARL Operationalisierung des Models der Expertise mit KARL}},
year = {1993}
}
@inproceedings{edwards95,
author = {Edwards, G},
booktitle = {Poster, Australian AI '95},
title = {{New Paradigms in Expert Systems in Health Care}},
year = {1995}
}
@article{pugh90,
author = {Pugh, W},
journal = {Communications of the ACM},
number = {6},
pages = {668--676},
title = {{Skip Lists: a Probabilistic Alternative to Balanced Trees}},
volume = {33},
year = {1990}
}
@misc{12207,
isbn = {0-7381-0428-0, SS94581},
title = {{ISO/IEC 12207 Standard for Information Technology - Software Lifecycle Process}},
year = {1998}
}
@inproceedings{webb00,
author = {Webb, G},
booktitle = {Proceeding of KDD-2000 Boston, MA},
title = {{Efficient search for association rules}},
year = {2000}
}
@article{king02,
author = {King, J and Diaz, M},
journal = {CROSSTALK},
month = mar,
title = {{How \{CMM\} Impacts Quality, Productivity, Rework, and the Bottom Line}},
year = {2002}
}
@misc{wu95a,
author = {Wu, X},
title = {{ARC application for initial support in 1996.}},
year = {1995}
}
@article{ntafos01,
author = {Ntafos, S C},
journal = {IEEE Transactions on Software Engineering},
month = oct,
number = {10},
title = {{On Comparisons of Random, Partition, and Propositional Partition Testing}},
volume = {27},
year = {2001}
}
@inproceedings{MA2007,
address = {Washington, DC, USA},
author = {Ma, Yan and Cukic, Bojan},
booktitle = {PROMISE '07: Proceedings of the Third International Workshop on Predictor Models in Software Engineering},
doi = {http://dx.doi.org/10.1109/PROMISE.2007.1},
isbn = {0-7695-2954-2},
pages = {1},
publisher = {IEEE Computer Society},
title = {{Adequate and Precise Evaluation of Quality Models in Software Engineering Studies}},
year = {2007}
}
@incollection{harman07,
author = {Harman, Mark},
booktitle = {Future of Software Engineering, ICSE'07},
title = {{The Current State and Future of Search Based Software Engineering}},
year = {2007}
}
@article{kirkpatrick83,
author = {Kirkpatrick, S and Gelatt, C D and Vecchi, M P},
journal = {Science, Number 4598, 13 May 1983},
pages = {671--680},
title = {{Optimization by Simulated Annealing}},
url = {citeseer.nj.nec.com/kirkpatrick83optimization.html},
volume = {220, 4598},
year = {1983}
}
@article{mi90,
author = {Mi, P and Scacchi, W},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = sep,
pages = {283--294},
title = {{A Knowledge-Based Environment for Modeling and Simulation Software Engineering Processes}},
year = {1990}
}
@book{alex77,
author = {Alexander, C and Ishikawa, S and Silverstein, S and Jacobsen, I and Fiksdahl-King, I and Angel, S},
publisher = {Oxford University Press},
title = {{A Pattern Language}},
year = {1977}
}
@article{sieg95,
author = {Siegelmann, Hava T and Sontag, Eduardo D},
journal = {Journal of Computer and System Sciences},
number = {1},
pages = {132--150},
title = {{On the Computational Power of Neural Nets}},
volume = {50},
year = {1995}
}
@book{stutzke05,
author = {Strutzke, R},
publisher = {Addison Wesley},
title = {{Estimating Software-Intensive Systems: Products, Projects and Processes}},
year = {2005}
}
@article{lang83,
author = {Langlotx, C P and Shortliffe, E H},
journal = {International Journal of Man-Machine Studies},
number = {5},
pages = {479--496},
title = {{Adapating a consultatation system to critique user plans}},
volume = {19}
}
@incollection{stamper94,
author = {Stamper, R},
booktitle = {Requirements Engineering: Social and Technical Issues},
editor = {Jirotka, M and Goguen, J A},
pages = {107--139},
publisher = {Academic Press},
title = {{Social Norms in Requirements Analysis: an outline of MEASUR}},
year = {1994}
}
@article{fagan86,
author = {Fagan, M},
journal = {IEEE Trans. on Software Engineering},
month = jul,
pages = {744--751},
title = {{Advances in software inspections}},
year = {1986}
}
@inproceedings{ohara93,
author = {O'Hara, K and Shadbolt, N},
booktitle = {\{IJCAI\} '93},
pages = {188--193},
title = {{\{AI\} \{M\}odels as a \{V\}ariety of \{P\}sychological \{E\}xplanation}},
volume = {1},
year = {1993}
}
@article{frankl93,
author = {Frankl, P G and Weiss, S N},
journal = {IEEE Transactions on Software Engineering},
month = aug,
number = {8},
pages = {774--787},
title = {{An Experimental Comparison of the Effectiveness of Branch Testing and Data Flow Testing}},
volume = {19},
year = {1993}
}
@book{walpole72,
author = {Walpole, R E and Myers, R H},
edition = {2},
publisher = {Collier Macmillion},
title = {{Probability and Statistics for Engineers ad Scientists}},
year = {1972}
}
@inproceedings{poole90,
author = {Poole, D},
booktitle = {Working Notes of the 1990 Spring Symposium on Automated Abduction.},
editor = {O'Rourke, P},
organization = {UC Irvine},
pages = {106--110},
title = {{Hypo-\{D\}eductive \{R\}easoning for \{A\}bduction, \{D\}efault \{R\}easoning, and \{D\}esign}},
volume = {TR 90-32},
year = {1990}
}
@inproceedings{ceruti00,
author = {Ceruti, M and Anken, C and Lin, A and Rubin, S},
booktitle = {Proceedings of IEEE Systems Man and Cybernetics},
title = {{Applications of High-Performance Knowledge-Based Technology}},
year = {2000}
}
@misc{burge96,
author = {Burge, A R},
title = {{Test and Evaluation, Based on Metrics, Measures, Thresholds, and Indicators}},
year = {1996}
}
@inproceedings{kal04,
author = {{M. Kalinowski}, G H Travassos},
booktitle = {IEEE ASE 2004},
pages = {46--55},
title = {{Computational Framework for Supporting Software Inspections}},
year = {2004}
}
@inproceedings{poole89,
author = {Poole, D},
booktitle = {IJCAI '89},
pages = {1304--1310},
title = {{Normality and \{F\}aults in \{L\}ogic-\{B\}ased \{D\}iagnosis}},
year = {1989}
}
@article{zloof81,
author = {Zloof, M M},
journal = {Computer},
month = may,
pages = {13--22},
title = {{QBE/OBE: A Language for Office and Business Automation}},
year = {1981}
}
@misc{boehm04,
annote = {Available from $\backslash$url\{http://ase-conferences.org/ase/past/ase2004/download/KeynoteBoehm.pdf\}},
author = {Boehm, B},
title = {{Automating Value-Based Software Engineering, \{K\}eynote address to \{IEEE\} \{ASE\}}},
year = {2004}
}
@inproceedings{BRODER2008,
address = {New York, NY, USA},
author = {Broder, Andrei and Ciaramita, Massimiliano and Fontoura, Marcus and Gabrilovich, Evgeniy and Josifovski, Vanja and Metzler, Donald and Murdock, Vanessa and Plachouras, Vassilis},
booktitle = {CIKM '08: Proceeding of the 17th ACM conference on Information and knowledge management},
doi = {http://doi.acm.org/10.1145/1458082.1458216},
isbn = {978-1-59593-991-3},
pages = {1003--1012},
publisher = {ACM},
title = {{To swing or not to swing: learning when (not) to advertise}},
year = {2008}
}
@inproceedings{zhang07,
author = {Zhang, Y and Harman, M and Mansouri, S A},
booktitle = {In ACM Genetic and Evolutionary Computation Conference (GECCO 2007},
pages = {11},
title = {{The Multi-Objective Next Release Problem}},
year = {2007}
}
@inproceedings{pearl91,
author = {Pearl, J and Verma, T S},
booktitle = {Proceedings of the Principles of Knowledge Representation and Reasoning Conference},
editor = {{J.A. Allan}, R Fikes and Sandewall, E},
pages = {441--452.},
publisher = {Morgan Kaufmann},
title = {{A Theory of Inferred Causation}},
year = {1991}
}
@inproceedings{tosun09,
author = {Tosun, A and Bener, A and Turhan, B},
booktitle = {PROMISE'09},
title = {{Practical Considerations of Deploying AI in Defect Prediction: A Case Study within the Turkish Telecommunication Industry}},
year = {2009}
}
@inproceedings{me99n,
author = {Menzies, T},
booktitle = {KAW'99: the 12th Workshop on Knowledge Acquisition, Modeling and Management, Voyager Inn, Banff, Alberta, Canada Oct 16-22, 1999},
title = {{h\{Q\}kb- The High Quality Knowledge Base Initiative (Sisyphus V: Learning Design Assessment Knowledge)}},
year = {1999}
}
@inproceedings{HOLZ2008,
address = {Berlin, Heidelberg},
author = {Holz, Wolfgang and Premraj, Rahul and Zimmermann, Thomas and Zeller, Andreas},
booktitle = {PROFES '08: Proceedings of the 9th international conference on Product-Focused Software Process Improvement},
doi = {http://dx.doi.org/10.1007/978-3-540-69566-0\_6},
isbn = {978-3-540-69564-6},
pages = {34--44},
publisher = {Springer-Verlag},
title = {{Predicting Software Metrics at Design Time}},
year = {2008}
}
@article{jorgensen07,
author = {J\o rgensen, M and Shepperd, M},
file = {:Users/timm/svns/doc/cost/07Jorgensen.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
month = jan,
pages = {33--53},
title = {{A Systematic Review of Software Development Cost Estimation Studies}},
year = {2007}
}
@inproceedings{conf/icse/NagappanB05a,
author = {Nagappan, Nachiappan and Ball, Thomas},
booktitle = {ICSE},
pages = {580--586},
title = {{Static analysis tools as early indicators of pre-release defect density}},
url = {http://doi.acm.org/10.1145/1062558},
year = {2005}
}
@article{korf85,
author = {Korf, R E},
journal = {Artificial Intelligence},
pages = {97--109},
title = {{Depth-First Iterative Deepening: an Optimal Admissible Tree Search}},
volume = {27},
year = {1985}
}
@article{simon52,
author = {Simon, H A},
journal = {Journal Philosphy},
pages = {517--528},
title = {{On the Definition of the Causal Relationship}},
volume = {49},
year = {1952}
}
@book{holz90,
author = {Holzmann, Gerard J},
publisher = {\{P\}rentice \{H\}all},
title = {{\{D\}esign and \{V\}alidation of \{C\}omputer \{P\}rotocols}},
year = {1990}
}
@misc{spear00,
title = {{No Title}}
}
@inproceedings{me99l,
author = {Menzies, T},
booktitle = {11th Annual International Conference on Software Engineering and Knowledge Engineering, Kaiserslautern, Germany, June 17 - 19, 1999},
title = {{Knowledge Maintenance Heresies: Meta-Knowledge Complicates KM}},
year = {1999}
}
@inproceedings{gel03a,
author = {Geletko, D and Menzies, T},
booktitle = {IEEE NASE SEW 2003},
title = {{Model-Based Software Testing via Treatment Learning}},
year = {2003}
}
@article{krauskopf90,
author = {Krauskopgf, R and Rash, F},
journal = {IEEE Potentials},
pages = {12--14},
title = {{Independent Verification and Validation}},
year = {1990}
}
@book{pol85,
author = {Politakis, P},
publisher = {Pitman},
title = {{Empirical Analsis for Expert Systems}},
year = {1985}
}
@article{pearl87,
author = {Pearl, J and Korf, R E},
journal = {Ann. Rev. Comput. Sci. 1987},
pages = {451--467},
title = {{Search Techniques}},
volume = {2},
year = {1987}
}
@inproceedings{BRAGA08,
address = {New York, NY, USA},
author = {Braga, Petr\^{o}nio L and Oliveira, Adriano L I and Meira, Silvio R L},
booktitle = {SAC '08: Proceedings of the 2008 ACM symposium on Applied computing},
doi = {http://doi.acm.org/10.1145/1363686.1364116},
isbn = {978-1-59593-753-7},
pages = {1788--1792},
publisher = {ACM},
title = {{A GA-based feature selection and parameters optimization for support vector regression applied to software effort estimation}},
year = {2008}
}
@inproceedings{me92zb,
author = {Menzies, T J and Compton, P},
booktitle = {ECAI '92 Workshop on Improving the Use of Knowledge-Based Systems with Explanations, Vienna},
title = {{Causal Explanations as a Tool for Refining Qualitative Models}},
year = {1992}
}
@inproceedings{moher93,
author = {Moher, T G and Mak, D C and Blumenthal, B and Leventhal, L M},
booktitle = {Empirical Studies of Programmers: Fifth Workshop},
pages = {137--161},
title = {{Comparing the Comprehensibility of Textual and Graphical Programs: The Case of Petri Nets}},
year = {1993}
}
@article{jacob95,
author = {Jacobson, I and Christerson, M},
journal = {JOOP},
pages = {15--19},
title = {{A \{G\}rowing \{C\}onsensus on \{U\}se \{C\}ases}},
year = {1995}
}
@inproceedings{me96j,
author = {Menzies, T and Ramakrishnan, S},
booktitle = {Tools Pacific, Melbourne},
title = {{Comparing and Generalising Models for Metrics Repositories}},
year = {1996}
}
@inproceedings{me97c,
author = {Menzies, T J and Cohen, R E},
booktitle = {European Symposium on the Validation and Verification of Knowledge Based Systems, Leuven, Belgium},
title = {{A Graph-Theoretic Optimisation of Temporal Abductive Validation}},
year = {1997}
}
@article{for93a,
author = {Forbus, K},
journal = {Artifical Intelligence},
pages = {115--123},
title = {{Qualitative Process Theory: Twelve Years After.}},
volume = {59},
year = {1993}
}
@article{linster92,
author = {Linster, M and Musen, M},
journal = {Knowledge Acquisition},
pages = {55--88},
title = {{Use of \{KADS\} to \{C\}reate a \{C\}onceptual \{M\}odel of the \{ONCOCIN\} task}},
volume = {4},
year = {1992}
}
@article{mair00investigation,
author = {Mair, Carolyn and Kadoda, Gada and Lefley, Martin and Phalp, Keith and Ofield1, Chris Sch and Shepperd, Martin and Webster, Steve},
journal = {The Journal of Systems and Software},
number = {1},
pages = {23--29},
title = {{An investigation of machine learning based prediction systems}},
url = {citeseer.ist.psu.edu/mair99investigation.html},
volume = {53},
year = {2000}
}
@misc{Boetticher:Menzies:Ostrand:2007,
author = {Boetticher, G and Menzies, T and Ostrand, T},
institution = {West Virginia University, Department of Computer Science},
title = {{\{PROMISE\} Repository of empirical software engineering data}},
url = {http://promisedata.org/repository},
year = {2007}
}
@inproceedings{wilson97,
author = {Wilson, W M and Rosenberg, L H and Hyatt, L E},
booktitle = {ICSE '97},
month = may,
pages = {161--171},
title = {{Automated Analysis of Requirement Specifications}},
year = {1997}
}
@misc{fen96,
author = {Fensel, D and Schonegge, A and Groenboom, R and Wielinga, B},
booktitle = {Proceedings of the 10th Knowledge Acquisition Workshop for Knowledge-Based Systems, Banff,Canada},
title = {{Specification and Verification of Knowledge-Based Systems}},
year = {1996}
}
@inproceedings{me03h,
author = {Chiang, E and Menzies, T},
booktitle = {Prosim '03},
title = {{Position Paper: Summary of simulations for Very Early Lifecycle Quality Evaluations}},
year = {2003}
}
@article{swig89,
author = {Swigger, K M and Brazile, R P},
journal = {International Journal of Man-Machine Studies},
pages = {47--60},
title = {{Experimental Comparisons of Design/Documentation Formats for Expert Systems}},
volume = {31},
year = {1989}
}
@book{buchanan84,
author = {Buchanan, B G and Shortliffe, E H},
publisher = {Addison-Wesley},
title = {{Rule-\{B\}ased \{E\}xpert \{S\}ystems: The \{MYCIN\} \{E\}xperiments of the \{S\}tanford \{H\}euristic \{P\}rogramming \{P\}roject}},
year = {1984}
}
@article{TURHAN2009,
address = {Tarrytown, NY, USA},
author = {Turhan, Burak and Kocak, Gozde and Bener, Ayse},
doi = {http://dx.doi.org/10.1016/j.eswa.2008.12.028},
issn = {0957-4174},
journal = {Expert Syst. Appl.},
number = {6},
pages = {9986--9990},
publisher = {Pergamon Press, Inc.},
title = {{Data mining source code for locating software bugs: A case study in telecommunication industry}},
volume = {36},
year = {2009}
}
@inproceedings{HAYES2005-2,
address = {New York, NY, USA},
author = {Hayes, Jane Huffman and Dekhtyar, Alex},
booktitle = {TEFSE '05: Proceedings of the 3rd international workshop on Traceability in emerging forms of software engineering},
doi = {http://doi.acm.org/10.1145/1107656.1107661},
isbn = {1-59593-243-7},
pages = {20--23},
publisher = {ACM},
title = {{Humans in the traceability loop: can't live with 'em, can't live without 'em}},
year = {2005}
}
@inproceedings{gama06,
address = {New York, NY, USA},
annote = {Available from $\backslash$url\{http://www.liacc.up.pt/\~{}jgama/IWKDDS/Papers/p6.pdf \}},
author = {Gama, Joao and Pinto, Carlos},
booktitle = {SAC '06: Proceedings of the 2006 ACM symposium on Applied computing},
file = {:Users/timm/svns/doc/pinto05.pdf:pdf},
isbn = {1-59593-108-2},
pages = {662--667},
publisher = {ACM Press},
title = {{Discretization from data streams: applications to histograms and data mining}},
year = {2006}
}
@book{schon83,
author = {Schon, D A},
publisher = {Harper Collins/ Basic Books},
title = {{The Reflective Practioner}},
year = {1983}
}
@article{wittig97,
author = {Wittig, G and Finnie, G},
journal = {Information and Software Technology},
number = {7},
pages = {469--476},
title = {{Estimating Software Development Effort with Connectionist Models}},
volume = {39},
year = {1997}
}
@inproceedings{simmons96,
author = {Simmons, D B and Ellis, N C and W, Kuo},
booktitle = {Proceedings of the Eigth International Conference on Software Engineering and Knowledge Engineering},
pages = {323--329},
title = {{Software Process Agents}},
year = {1996}
}
@inproceedings{jurjens06,
address = {New York, NY, USA},
author = {Jerjens, Jan and Fox, Jorge},
booktitle = {ICSE '06: Proceeding of the 28th international conference on Software engineering},
doi = {http://doi.acm.org.proxy.lib.muohio.edu/10.1145/1134285.1134423},
isbn = {1-59593-375-1},
pages = {819--822},
publisher = {ACM Press},
title = {{Tools for model-based security engineering}},
year = {2006}
}
@article{preece92a,
author = {Preece, A D},
journal = {The Knowledge Engineering Review},
pages = {115--141},
title = {{Principles and Practice in Verifying Rule-based Systems}},
volume = {7},
year = {1992}
}
@phdthesis{jalali07,
author = {Jalali, Omid},
school = {Lane Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{Evaluation Bias in Effort Estimation}},
year = {2007}
}
@inproceedings{god97,
author = {Godefroid, P},
booktitle = {The 1996 DIMACS workshop on Partial Order Methods in Verification, July 24-26, 1996},
pages = {289--303},
title = {{On the Costs and Benefits of Using Partial-Order Methods for the Verificiation of Concurrent Systems (invited papers)}},
year = {1997}
}
@article{Meda2010,
abstract = {When designing a business workflow, it is customary practice to create the control flow structure first and to ensure its correctness. Information about the flow of data is introduced subsequently into the workflow and its correctness is independently verified. Improper specification of data requirements of tasks and XOR splits can cause problems such as wrong branching at XOR splits and the failure of tasks to execute. Here we present a graph traversal algorithm called GTforDF for detecting data flow errors in both nested and unstructured workflows, and illustrate its operation on realistic examples. Two of these have interconnected loops and are free of control flow errors, and the third one is an unstructured loop-free workflow. Our approach extends and generalizes data flow verification methods that have been recently proposed. It also makes use of the concept of corresponding pairs lately introduced in control flow verification. It thus has the potential for development into a unified algorithmic procedure for the concurrent detection of control flow and data flow errors. The correctness of the algorithm has been proved theoretically. It has also been tested experimentally on many examples.},
author = {Meda, Hema S. and Sen, Anup Kumar and Bagchi, Amitava},
issn = {1936-1955},
journal = {Journal of Data and Information Quality (JDIQ)},
keywords = {Corresponding pair,Data flow errors,Workflow management,pareto},
mendeley-tags = {pareto},
number = {1},
title = {{On Detecting Data Flow Errors in Workflows}},
url = {http://portal.acm.org/citation.cfm?id=1805286.1805290},
volume = {2},
year = {2010}
}
@inproceedings{Mohamed1993,
annote = {unread},
author = {Mohamed, W E and Sadler, C J and Law, D},
booktitle = {Proceedings of Software Quality Management, Elsevier Science and CMP, Southampton},
pages = {417--430},
title = {{Experimentation in Software Engineering: A New Framework}},
year = {1993}
}
@article{codd:81,
author = {Codd, E F},
journal = {Communications of the ACM},
pages = {109--117},
title = {{Relational Database: A Practical Foundation for Productivity}},
volume = {25},
year = {1981}
}
@inproceedings{compton89,
author = {Compton, P and Horn, K and Quinlan, J R and Lazarus, L},
booktitle = {Applications of Expert Systems},
editor = {Quinlan, J R},
pages = {366--385},
publisher = {Addison Wesley},
title = {{Maintaining an Expert System}},
year = {1989}
}
@misc{Coiera96,
annote = {Technical Report HPL-96-65, May, 1996},
author = {Coiera, E},
institution = {Hewlett-Packard Laboratories},
title = {{Communication in Organisations}},
year = {1996}
}
@article{jorgensen04,
author = {Jorgensen, M and Molokken-Ostvold, K},
journal = {IEEE Transactions on Software Engineering},
month = dec,
number = {12},
title = {{Reasons for Software Effort Estimation Error: Impact of Respondent Error, Information Collection Approach, and Data Analysis Method}},
volume = {30},
year = {2004}
}
@book{coplein92,
author = {Coplein, J},
publisher = {Addison-Wesley},
title = {{Advanced C++ Programming Styles and Idioms}},
year = {1992}
}
@article{heinze02,
author = {Heinze, Clinton and Goss, Simon and Josefsson, Torgny and Bennett, Kerry and Waugh, Sam and Lloyd, Ian and Murray, Graeme and Oldfeild, John},
journal = {AI Magazine},
number = {2},
title = {{Interchanging agents and humans in military simulation}},
volume = {23},
year = {2002}
}
@inproceedings{burk04,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/04lean.pdf\}},
author = {Burkleaux, T and Menzies, T and Owen, D},
booktitle = {Proceedings of WITSE 2005},
title = {{LEAN = (LURCH+TAR3) = Reusable Modeling Tools}},
year = {2004}
}
@article{porter90,
author = {Porter, A A and Selby, R W},
journal = {IEEE Software},
month = mar,
pages = {46--54},
title = {{Empirically Guided Software Development Using Metric-Based Classification Trees}},
year = {1990}
}
@book{press92,
author = {Press, H and Flannery, B P and Teukolsky, S A and Vetterling, W T},
isbn = {0521437202},
publisher = {Cambridge University Press, second edition},
title = {{Numerical Recipes in C Example Book : The Art of Scientific Computing (The Art of Scientific Computing)}},
year = {1992}
}
@book{brownston92,
author = {Brownston, L and Farell, R and Kant, E and Martin, N},
publisher = {Addison-Wesley},
title = {{Programming Expert Systems in OPS5: An Introduction to Rule-Based Programming}},
year = {1985}
}
@book{forr69,
author = {Forrester, J W},
publisher = {Pegasus Communications},
title = {{Urban Dynamics}},
year = {1969}
}
@inproceedings{ginsberg90,
author = {Ginsberg, A},
booktitle = {AAAI '90},
pages = {777--782},
title = {{Theory Reduction, Theory Revision, and Retranslation}},
year = {1990}
}
@article{frakes95,
author = {Frakes, W B and Fox, C J},
journal = {Communications of the ACM},
month = jun,
number = {6},
pages = {75--87},
title = {{Sixteen Questions About Software Reuse}},
volume = {38},
year = {1995}
}
@article{shepperd01,
author = {Shepperd, M and Kadoda, Gada F},
journal = {IEEE Trans. Software Eng},
number = {11},
pages = {1014--1022},
title = {{Comparing Software Prediction Techniques Using Simulation}},
volume = {27},
year = {2001}
}
@article{boehm00,
author = {Boehm, B and Abts, C and Chulani, S},
journal = {Annals of Software Engineering},
pages = {177--205},
title = {{Software Development Cost Estimation Approaches - A Survey}},
volume = {10},
year = {2000}
}
@inproceedings{door93,
author = {Doorenbos, R D},
booktitle = {AAAI '93},
pages = {290--296},
title = {{Matching 100,000 Learnt Rules}},
year = {1993}
}
@incollection{mich93,
author = {Michalski, R S},
booktitle = {Readings in Knowledge Acquisition and Learning: Automatic Construction and Improvement of Expert System},
editor = {Buchanan, B G and Wilkin, D C},
publisher = {Morgan Kaufmann Publishers},
title = {{Toward a Unified Theory of Learning: Multistrategy Task-adaptive Learning}},
year = {1993}
}
@inproceedings{selman96,
address = {Providence RI},
author = {Selman, Bart and Kautz, Henry A and Cohen, Bram},
booktitle = {Proceedings of the Second \{DIMACS\} Challange on Cliques, Coloring, and Satisfiability},
editor = {Trick, Michael and Johnson, David Stifler},
title = {{Local Search Strategies for Satisfiability Testing}},
url = {citeseer.ist.psu.edu/selman95local.html},
year = {1993}
}
@article{aguilarevolutionary,
author = {Aguilar-Ruiz, Jesus S and Ramos, Isabel and Riquelme, Jose and Toro, Miguel},
journal = {Information and Software Technology},
number = {14},
pages = {875--882},
title = {{An evolutionary approach to estimating software development projects}},
url = {citeseer.ist.psu.edu/aguilar-ruiz01evolutionary.html},
volume = {43},
year = {2001}
}
@inproceedings{YANG08,
address = {New York, NY, USA},
author = {Yang, Ye and He, Mei and Li, Mingshu and Wang, Qing and Boehm, Barry},
booktitle = {ESEM '08: Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
doi = {http://doi.acm.org/10.1145/1414004.1414016},
isbn = {978-1-59593-971-5},
pages = {61--69},
publisher = {ACM},
title = {{Phase distribution of software development effort}},
year = {2008}
}
@inproceedings{dwyer98a,
author = {Dwyer, M B and Avrunin, G S and Corbett, J C},
booktitle = {ICSE98: Proceedings of the 21st International Conference on Software Engineering},
month = may,
title = {{Patterns in Property Specifications for Finite-state Verification}},
year = {1998}
}
@article{Barskia,
author = {Barski, Conrad},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Barski - 2010 - The Land of Lisp.pdf:pdf},
title = {{Conrad Barski, M.D.}}
}
@inproceedings{Chaslot2006a,
author = {Chaslot, Guillaume and Bakkes, Sander and Szita, Istvan and Spronck, Pieter},
booktitle = {Artificial Intelligence},
file = {:Users/timm/svns/doc/sander08.pdf:pdf},
keywords = {gaming},
mendeley-tags = {gaming},
title = {{Monte-Carlo Tree Search : A New Framework for Game AI Monte-Carlo Tree Search Application to Video Games}},
year = {2006}
}
@inproceedings{Hinneburg1999a,
author = {Hinneburg, A. and Keim, D.A.},
booktitle = {25th VLDB},
file = {:Users/timm/svns/doc/hinneburg99.pdf:pdf},
keywords = {Grid cluster},
publisher = {Citeseer},
title = {{Optimal grid-clustering: Towards breaking the curse of dimensionality in high-dimensional clustering}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.44.4721\&amp;rep=rep1\&amp;type=pdf},
year = {1999}
}
@article{tambe94,
author = {Tambe, M and Rosenbloom, P S},
journal = {Artificial Intelligence},
number = {1},
title = {{Investigating Production System Representations for Non-combinatorial Match}},
volume = {68},
year = {1994}
}
@misc{menz85,
annote = {School of Econometrics, University of New England},
author = {Menzies, G D},
title = {{An Econometric Analysis of the Dark Figure of Crime}},
year = {1985}
}
@inproceedings{craven98,
author = {Craven, M and DiPasquo, D and Freitag, D and McCallum, A and Mitchell, T and Nigam, K and Slattery, S},
booktitle = {AAAI-98},
title = {{Learning to Extract Symbolic Knowledge from the World Wide Web}},
year = {1998}
}
@inproceedings{kakas01,
author = {Kakas, Antonis C and Nuffelen, Bert Van and Denecker, Marc},
booktitle = {IJCAI},
pages = {591--596},
title = {{A-System: Problem Solving through Abduction.}},
year = {2001}
}
@article{selby88,
author = {Selby, R W and Porter, A A},
journal = {IEEE Trans. Software Eng.},
month = dec,
pages = {1,741--743,757},
title = {{Learning from Examples: Generation and Evalaution of Decision Trees for Software Resource Analysis}},
year = {1988}
}
@article{ho94,
author = {Ho, T K and Hull, J J and Srihari, S N},
file = {::},
journal = {IEEE Trans Pattern Analysis and Machine Intelligence},
number = {1},
pages = {66--75},
title = {{Decision combination in multiple classifier systems}},
volume = {16},
year = {1994}
}
@inproceedings{nov95,
author = {Jr., G S Novak},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and {N.H. Narayanan}, B Chandrasekaran},
pages = {753--774},
publisher = {The AAAI Press},
title = {{Diagrams for Solving Physical Problems}},
year = {1995}
}
@inproceedings{me08h,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08costcurves.pdf\}},
author = {{Y. Jiang}, B Cukic and Menzies, T},
booktitle = {Proceedings, ISSRE'08},
title = {{Cost Curve Evaluation of Fault Prediction Models}},
year = {2008}
}
@inproceedings{webb03,
address = {New York, NY, USA},
author = {Webb, Geoffrey I and Butler, Shane and Newlands, Douglas},
booktitle = {KDD '03: Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining},
doi = {http://doi.acm.org/10.1145/956750.956781},
isbn = {1-58113-737-0},
pages = {256--265},
publisher = {ACM Press},
title = {{On detecting differences between groups}},
year = {2003}
}
@book{simon96,
author = {Simon, H},
publisher = {MIT Press},
title = {{The Science of the Artificial (third edition)}},
year = {1996}
}
@inproceedings{levy96a,
author = {Levy, A Y and Rousset, M},
booktitle = {Proceedings of the 12th European Conference on AI (ECAI-96), Budapest, Hungary},
title = {{CARIN: A Representation Language Combining Horn Rules and Description Logics}},
year = {1006}
}
@misc{ram95a,
author = {Ramakrishnan, S},
number = {TR95-8},
title = {{An \{E\}xperimental \{A\}pproach to \{O-O\} \{S\}oftware \{P\}rocess and \{P\}roduct \{M\}easurements}},
year = {1995}
}
@inproceedings{tracey98,
author = {Tracey, N and Clarke, J and Mander, K},
booktitle = {International Symposium on Software Testing and Analysis},
month = mar,
pages = {73--81},
publisher = {ACM/SIGSOFT},
title = {{Automated program flaw finding using simulated annealing}},
year = {1998}
}
@article{lohse93,
author = {Lohse, G L},
journal = {Human-Computer Interaction},
pages = {353--388},
title = {{A Cognitive Model for Understanding Graphical Perception}},
volume = {8},
year = {1993}
}
@inproceedings{RANA2008,
address = {New York, NY, USA},
author = {Rana, Zeeshan Ali and Shamail, Shafay and Awais, Mian Muhammad},
booktitle = {WoSQ '08: Proceedings of the 6th international workshop on Software quality},
doi = {http://doi.acm.org/10.1145/1370099.1370108},
isbn = {978-1-60558-023-4},
pages = {35--40},
publisher = {ACM},
title = {{Towards a generic model for software quality prediction}},
year = {2008}
}
@article{Lub,
author = {Lu, Jingli and Yang, Ying and Webb, Geoffrey I},
file = {:Users/timm/svns/doc/webb08.pdf:pdf},
journal = {Learning},
title = {{Incremental Discretization for Na\"{\i}ve-Bayes Classifier}}
}
@inproceedings{harman02,
author = {Harman, M and Hierons, R and Proctor, M},
booktitle = {GECO 2002: Proceedings of the Genetic and Evolutionary Computation Conference},
month = jul,
pages = {1351--1358},
publisher = {Morgan Kaufmann},
title = {{A new representation and crossover operator for search-based optimization of software modularization}},
year = {2002}
}
@article{shadbolt00,
annote = {(to appear)},
author = {Shadbolt, N and O'Hara, K and Crow, L},
journal = {International Journal of Human-Computer Studies},
title = {{The Experimental Evaluation of Knowledge Acquisition Techniques and Methods: History, Problems and New Directions}},
year = {2000}
}
@misc{kadoda00,
author = {Kadoda, G and Cartwright, M and Chen, L and Shepperd, M},
title = {{Experiences Using CaseBased Reasoning to Predict Software Project Effort}},
url = {citeseer.ist.psu.edu/kadoda00experiences.html},
year = {2000}
}
@inproceedings{MOSER2008,
address = {New York, NY, USA},
author = {Moser, Raimund and Pedrycz, Witold and Succi, Giancarlo},
booktitle = {ICSE '08: Proceedings of the 30th international conference on Software engineering},
doi = {http://doi.acm.org/10.1145/1368088.1368114},
isbn = {978-1-60558-079-1},
pages = {181--190},
publisher = {ACM},
title = {{A comparative analysis of the efficiency of change metrics and static code attributes for defect prediction}},
year = {2008}
}
@inproceedings{PS91,
author = {Palsberg, J and Schwartzbach, M},
booktitle = {Proc. OOPSLA'91, ACM SIGPLAN Sixth Annual Conference on Object-Oriented Programming Systems, Languages and Applications},
pages = {146--161},
title = {{Object-Oriented Type Inference}},
year = {1991}
}
@misc{ying02,
author = {Hu, Y},
title = {{Treatment learning}},
year = {2002}
}
@article{marques92,
author = {Marques, D and Dallemagne, G and Kliner, G and McDermott, J and Tung, D},
journal = {IEEE Expert},
month = jun,
pages = {16--29},
title = {{Easy \{P\}rogramming: Empowering \{P\}eople to \{B\}uild \{T\}heir Own \{A\}pplications}},
year = {1992}
}
@inproceedings{dekhtyar07,
author = {Dekhtyar, A and Hayes, J H and Larsen, J},
booktitle = {3rd International Workshop on Predictive Modeling in Software Engineering (PROMISE'2007)},
title = {{Make the Most of Your Time: How Should the Analyst Work with Automated Traceability Tools?}},
year = {2007}
}
@article{musc98,
author = {Muscettola, N and Nayak, P Pandurang and Pell, B and Williams, B},
journal = {Artificial Intelligence},
month = aug,
number = {1-2},
pages = {5--48},
title = {{Remote Agent: To Boldly Go Where No AI System Has Gone Before}},
volume = {103},
year = {1998}
}
@inproceedings{yol96,
author = {Gil, Y and Melz, E},
booktitle = {Proceedings AAAI' 96},
title = {{Explicit Representations of Problem-Soving Strategies to Support Knowledge Acquisition}},
year = {1996}
}
@inproceedings{webb96,
author = {Webb, G I and Wells, J},
booktitle = {Proceedings PKAW '96: Pacific Knowledge Acquisition Workshop},
title = {{Experimental Evaluation of Integrating Machine Learning with Knowledge Acquisition Through Direct Interaction with Domain Experts}},
year = {1996}
}
@inproceedings{me02m,
author = {Menzies, T and Pearce, A and {C. Heinze} and Goss, S},
booktitle = {Formal Aspects of Agent-Based Systems},
title = {{What is an agent and why should I care?}},
year = {2002}
}
@incollection{hayes97,
author = {Hayes, C C},
booktitle = {Expertise in Context},
chapter = {14},
editor = {Feltovich, P J and Ford, K M and Hoffman, R R},
pages = {339--362},
publisher = {MIT PRess},
title = {{A Study in Solution Quality Human Expert and Knolwedge-Based System Reasoning}},
year = {1997}
}
@article{jiang02,
author = {Jiang, J J and Klein, G and Chen, H and Lin, L},
journal = {International Journal of Project Management},
month = oct,
number = {7},
pages = {507--515},
title = {{Reducing user-related risks during and prior to system development}},
volume = {20},
year = {2002}
}
@inproceedings{poole85,
author = {Poole, D},
booktitle = {\{IJCAI\} '85},
pages = {144--147},
title = {{On the \{C\}omparison of \{T\}heories: \{P\}referring the \{M\}ost \{S\}pecific \{E\}xplanation}},
year = {1985}
}
@book{date95,
author = {Date, C J},
publisher = {Addison-Wesley},
title = {{An Introduction to Database Systems}},
volume = {6},
year = {1995}
}
@article{dwyer97,
author = {Dwyer, M B and Avrunin, G S and Corbett, J C},
journal = {$\backslash$url\{http://www.cis.ksu.edu/santos/spec-patterns/\}},
title = {{A System Specification of Patterns}},
year = {1997}
}
@article{buch78,
author = {Buchanan, B G and Feigenbaum, E A},
journal = {Artificial Intelligence},
pages = {5--24},
title = {{DENDRAL and META-DENDRAL: their applications dimensions}},
volume = {11},
year = {1978}
}
@article{smith90,
annote = {automatic programming},
author = {Smith, D R},
journal = {IEEE Transactions on Software Engineering (SE), Sept},
number = {9},
title = {{\{KIDS\}: \{A\} Semi-Automated Program Development System}},
volume = {16},
year = {1990}
}
@article{silver92,
author = {Silverman, B G},
journal = {Communications of the ACM},
pages = {106--127},
title = {{Survey of Expert Critiquing Systems: Practical and Theoretical Frontiers}},
volume = {35},
year = {1992}
}
@inproceedings{YanWeb02Comparative,
author = {Yang, Ying and Webb, Geoffrey I},
booktitle = {Proceedings of PKAW 2002: The 2002 Pacific Rim Knowledge Acquisition Workshop},
pages = {159--173},
title = {{A Comparative Study of Discretization Methods for Naive-Bayes Classifiers}},
year = {2002}
}
@inproceedings{agrawal94,
author = {Agrawal, R and Srikant, R},
booktitle = {Proceedings of the 20th International Conference on Very Large Databases},
title = {{Fast Algorithms for Mining Association Rules}},
year = {1994}
}
@misc{pricing05,
annote = {Available from $\backslash$url\{http://fast.faa.gov/pricing/c1919-5.htm\}},
author = {System, U S Government Federal Aviation Administration Acquisition},
title = {{Software Cost Estimating Methdologies}},
year = {2005}
}
@inproceedings{luqi96a,
author = {Luqi},
booktitle = {Proceedings of SEKE '96},
pages = {189--197},
title = {{Specifications in Software Prototyping}},
year = {1996}
}
@book{beck99,
author = {Beck, K},
isbn = {0201616416},
publisher = {Addison-Wesley},
title = {{Extreme Programming Xplained}},
year = {1999}
}
@inproceedings{me94z,
annote = {$\backslash$url\{http://menzies.us/pdf/banff94.pdf\}},
author = {Menzies, T J and Compton, P},
booktitle = {Proceedings of the 8th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge-Based Systems Workshop, Banff, Canada},
title = {{Knowledge Acquisition for Performance Systems; or: When can "tests" replace "tasks"?}},
year = {1994}
}
@article{boetticher03,
author = {Boetticher, G},
journal = {IEEE Intelligent Systems},
month = jun,
title = {{When Will it Be Done? The 300 Billion Dollar Question, Machine Learner Answers}},
year = {2003}
}
@inproceedings{nar92,
editor = {Narayanan, N H},
title = {{AAAI Spring Symposium on Reasoning with Diagrammatic Representations}},
year = {1992}
}
@article{me07b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06learnPredict.pdf\}},
author = {{Menzies T, Greenwald J}, FrankA},
file = {::},
journal = {IEEE Software},
month = jan,
title = {{Datamining static code attributes to learn defect predictors}},
year = {2007}
}
@article{Menzies2006,
author = {Menzies, Tim and Chen, Zhihao and Hihn, Jairus and Lum, Karen},
doi = {10.1109/TSE.2006.114},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Menzies et al. - 2006 - Selecting Best Practices for Effort Estimation.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
keywords = {data mining,effort estimation method,heuristic rejection rule,project management,software cost estimation,standard statistical method,statistical analysisCOSEEKMO toolkit},
number = {11},
pages = {883--895},
title = {{Selecting Best Practices for Effort Estimation}},
volume = {32},
year = {2006}
}
@inproceedings{GOKHALE2008,
address = {New York, NY, USA},
author = {Gokhale, Swapna S and Mullen, Robert},
booktitle = {PROMISE '08: Proceedings of the 4th international workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1370788.1370810},
isbn = {978-1-60558-036-4},
pages = {93--100},
publisher = {ACM},
title = {{Software defect repair times: a multiplicative model}},
year = {2008}
}
@inproceedings{luqi96b,
author = {Luqi},
booktitle = {Proceedings of SEKE '96},
pages = {189--197},
title = {{Specifications in Software Prototyping}},
year = {1996}
}
@book{sed88,
author = {Sedgewick, R},
publisher = {Addison-Wesley},
title = {{Algorithms}},
year = {1988}
}
@article{koru09,
author = {Koru, A G and Zhang, Dongsong and {El Emam}, K and Liu, Hongfang},
journal = {Software Engineering, IEEE Transactions on},
number = {2},
pages = {293--304},
title = {{An Investigation into the Functional Form of the Size-Defect Relationship for Software Modules}},
volume = {35},
year = {2009}
}
@article{mylo92,
author = {Mylopoulos, J and Chung, L and Nixon, B},
journal = {IEEE Transactions of Software Engineering},
month = jun,
number = {6},
pages = {483--497},
title = {{Representing and Using Nonfunctional Requirements: A Process-Oriented Approach}},
volume = {18},
year = {1992}
}
@article{chase73,
author = {Chase, W G and Simon, H A},
journal = {Cognitive Psychology},
pages = {55--81},
title = {{Perception in Chess}},
volume = {1},
year = {1973}
}
@book{cormen90,
annote = {ISBN: 0262031418},
author = {Cormen, T E and Leiserson, C E and Rivest, R L},
publisher = {MIT Press},
title = {{Introduction to Algorithms}},
year = {1990}
}
@inproceedings{me09a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08drastic.pdf\}},
author = {Menzies, T and Williams, S and El-rawas, O and Boehm, B and Hihn, J},
booktitle = {ICSE'09},
title = {{How to Avoid Drastic Software Process Change (using Stochastic Statbility)}},
year = {2009}
}
@incollection{me10b,
author = {Menzies, Tim and Shull, Forrest},
booktitle = {Making Software: What Really Works and We We Believe it},
editor = {Oram, A and G.Wilson},
publisher = {O'Reilly Books},
title = {{The Quest for Convincing Evidence}},
year = {2010}
}
@book{buch84,
author = {Buchanan, B G and Shortliffe, E H},
publisher = {Addison-Wesley},
title = {{Rule-\{B\}ased \{E\}xpert \{S\}ystems: The \{MYCIN\} \{E\}xperiments of the \{S\}tanford \{H\}euristic \{P\}rogramming \{P\}roject}},
year = {1984}
}
@inproceedings{SARCIA2009-2,
address = {New York, NY, USA},
author = {Sarcia', Salvatore Alessandro and Basili, Victor Robert and Cantone, Giovanni},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540464},
isbn = {978-1-60558-634-2},
pages = {1--9},
publisher = {ACM},
title = {{Using uncertainty as a model selection and comparison criterion}},
year = {2009}
}
@inproceedings{gaines89a,
annote = {Available on-line at $\backslash$url\{http://ksi.cpsc.ucalgary.ca/articles/Induct/ML89/\}},
author = {Gaines, B R},
booktitle = {Proceedings of the Sixth International Workshop on Machine Learning},
pages = {156--159},
title = {{An ounce of knowledge is worth a ton of data: quantitative studies of the trade-off between expertise and data based on statistically well-founded empirical induction}},
year = {1989}
}
@misc{adams95,
annote = {Object Worlds},
author = {Adam, S},
title = {{Personal communication}},
year = {1995}
}
@inproceedings{jahnke97,
author = {Jahnke, J and Zundorf, A},
booktitle = {Proc. of ESEC:FSE '97 Workshop on Object-Oriented Reengineering},
title = {{Rewriting poor Design Patterns by good Design Patterns}},
year = {1997}
}
@book{down94,
author = {Down, A and Coleman, M and Absolon, P},
publisher = {McGraw-Hill},
title = {{Risk Management for Software Projects}},
year = {1994}
}
@inproceedings{compton93,
author = {Compton, P and Kang, B and Preston, P and Mulholland, M},
booktitle = {European Knowledge Acquisition Workshop},
title = {{Knowledge Acquisition Without Analysis}},
year = {1993}
}
@phdthesis{orrego04,
author = {Orrego, A S},
school = {Computer Science, West Virginia University},
title = {{SAWTOOTH: Learning from Huge Amounts of Data}},
year = {2004}
}
@misc{mcgibbon96,
author = {McGibbon, T},
month = sep,
title = {{A Business Case for Software Process Improvement, Data Analysis Center for Software State-of-the-Art Report, prepared for Rome Laboratory,}},
year = {1996}
}
@inproceedings{menz91,
author = {Menzies, T J},
booktitle = {Tools Pacific 4},
editor = {Meyer, B},
title = {{\{ISA\} \{O\}bject \{PARTOF\} \{K\}nowledge \{R\}epresentation (Part Two)?}},
year = {1991}
}
@misc{dabney07,
author = {Dabney, J B},
title = {{Return on Investment for \{IV\&V\}}}
}
@inproceedings{WEDEL2008,
address = {New York, NY, USA},
author = {Wedel, Michael and Jensen, Uwe and G\"{o}hner, Peter},
booktitle = {ESEM '08: Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
doi = {http://doi.acm.org/10.1145/1414004.1414052},
isbn = {978-1-59593-971-5},
pages = {282--284},
publisher = {ACM},
title = {{Mining software code repositories and bug databases using survival analysis models}},
year = {2008}
}
@article{vicente95,
author = {Vicente, K J and Christoffersen, K and Pereklita, A},
journal = {IEEE Transactions of Systems, Man, and Cybernetics},
month = apr,
number = {4529-545},
title = {{Supporting Operator Problem Solving Through Ecological Interface Design}},
volume = {25},
year = {1995}
}
@inproceedings{cooper01,
author = {{Kendra Cooper Tim Menzies}, Mabo Ito},
booktitle = {UBC ECE tech report},
title = {{Assessment of a Lightweight Formal Method for Specifying and Analyzing Requirements}},
year = {2001}
}
@article{kitchenham97,
address = {Los Alamitos, CA, USA},
author = {Kitchenham, Barbara and Linkman, Stephen},
doi = {http://dx.doi.org/10.1109/52.589239},
issn = {0740-7459},
journal = {IEEE Softw.},
number = {3},
pages = {69--74},
publisher = {IEEE Computer Society Press},
title = {{Estimates, Uncertainty, and Risk}},
volume = {14},
year = {1997}
}
@inproceedings{musilek02,
address = {Washington, DC, USA},
author = {Musilek, Petr and Pedrycz, Witold and Sun, Nan and Succi, Giancarlo},
booktitle = {METRICS '02: Proceedings of the 8th International Symposium on Software Metrics},
isbn = {0-7695-1339-5},
pages = {13},
publisher = {IEEE Computer Society},
title = {{On the Sensitivity of COCOMO II Software Cost Estimation Model}},
year = {2002}
}
@article{Diakonikolas,
author = {Diakonikolas, Ilias},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Diakonikolas - Unknown - Succinct Approximate Convex Pareto Curves ( Extended Abstract ).pdf:pdf},
keywords = {pareto},
mendeley-tags = {pareto},
pages = {74--83},
title = {{Succinct Approximate Convex Pareto Curves ( Extended Abstract )}}
}
@inproceedings{boy95,
author = {Boy, G},
booktitle = {Proceedings of the 6th IFAC Symposium on Analysis, Design and Evaluation of Man-Machine Systems},
title = {{Supportability-based design rationale}},
year = {1995}
}
@article{SINGH2009,
address = {New York, NY, USA},
author = {Singh, Yogesh and Kaur, Arvinder and Malhotra, Ruchika},
doi = {http://doi.acm.org/10.1145/1457516.1457529},
issn = {0163-5948},
journal = {SIGSOFT Softw. Eng. Notes},
number = {1},
pages = {1--6},
publisher = {ACM},
title = {{Application of support vector machine to predict fault prone classes}},
volume = {34},
year = {2009}
}
@incollection{boehm06,
annote = {Available from $\backslash$url\{sunset.usc.edu/csse/TECHRPTS/2005/usccse2005-504/usccse2005-504.pdf\}},
author = {Boehm, B},
booktitle = {Value-based Software Engineering},
editor = {Biffl, Stefan and Aurum, Aybuke and Boehm, Barry and Erdogmus, Hakan and Grunbacher, Paul},
pages = {3--14},
publisher = {Spring Verlag},
title = {{Value-Based Software Engineering: Overview and Agenda}},
year = {2006}
}
@article{me08i,
annote = {Avialable from $\backslash$url\{http://menzies.us/pdf/08promised.pdf\}},
author = {Menzies, T},
file = {::},
journal = {Empirical Software Engineering},
month = oct,
title = {{Editorial, special issue, repeatable experiments in software engineering}},
year = {2008}
}
@article{Lu,
author = {Lu, Jingli and Yang, Ying and Webb, Geoffrey I},
file = {:Users/timm/svns/doc/webb08.pdf:pdf},
journal = {Learning},
title = {{Incremental Discretization for Na\"{\i}ve-Bayes Classifier}}
}
@article{Harel87:statecharts,
author = {Harel, D},
journal = {Science of Computer Programming},
month = jun,
number = {3},
pages = {231--274},
title = {{Statecharts: A Visual Formalism for Complex Systems}},
volume = {8},
year = {1987}
}
@article{vose86,
author = {Vose, G M and Williams, G},
journal = {Byte},
pages = {84--92},
title = {{LabVIEW: Laboratory Virtual Instrument Engineering Workbench}},
volume = {11},
year = {1986}
}
@inproceedings{memaco92,
author = {Menzies, T and Mahidadia, A and Compton, P},
booktitle = {Proceedings of the 7th \{AAAI\}-Sponsored \{B\}anff Knowledge Acquisition for Knowledge-Based Systems Workshop \{B\}anff, \{C\}anada, October 11-16},
title = {{Using \{C\}ausality as a \{G\}eneric \{K\}nowledge \{R\}epresentation, or \{W\}hy and \{H\}ow \{C\}entralised \{K\}nowledge \{S\}ervers \{C\}an \{U\}se \{C\}ausality}},
year = {1992}
}
@inproceedings{Ester1996,
author = {Ester, Martin and Kriegel, H.P. and Sander, J\"{o}rg and Xu, Xiaowei},
booktitle = {Proceedings of the 2nd International Conference on Knowledge Discovery and Data mining},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Ester et al. - 1996 - A density-based algorithm for discovering clusters in large spatial databases with noise.pdf:pdf},
keywords = {arbitrary shape of clus-,clustering algorithms,databases,efficiency on large spatial,handling noise,ters},
pages = {226--231},
publisher = {Portland: AAAI Press},
title = {{A density-based algorithm for discovering clusters in large spatial databases with noise}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:A+Density-Based+Algorithm+for+Discovering+Clusters+in+Large+Spatial+Databases+with+Noise\#0},
volume = {1996},
year = {1996}
}
@book{coles74,
author = {Coles, H S},
publisher = {Sussex University Press},
title = {{Thinking About the Future: A Critique of the Limits to Growth}},
year = {1974}
}
@book{lave88,
author = {Lave, J},
publisher = {Cambridge University Press},
title = {{Cognition in Practice}},
year = {1988}
}
@misc{omg03,
editor = {Miller, J and Mukerji, J},
institution = {Object Management Group},
month = jun,
number = {omg2003-06-01},
title = {{\{MDA\} Guide Version 1.0.1}},
url = {http://www.omg.org/mda/presentations.htm},
year = {2003}
}
@article{smythe82,
author = {Smythe, G A and Duncam, M W and Bradshaw, J E and Cai, M Y and Symons, R G},
journal = {Endocrinology},
pages = {376--383},
title = {{Control of Growth Hormone Secretion: Hypothalmic Dopamine, Norepinephrine and Serotonin Levels and Metabolism in Three Hyposomatrophic Rat Models and in Normal Rats}},
volume = {110},
year = {1982}
}
@inproceedings{me00b,
author = {Menzies, Tim and Cukic, Bojan and Singh, Harhsinder and Powell, John},
booktitle = {ISSRE 2000},
title = {{Testing Nondeterminate Systems}},
year = {2000}
}
@misc{fowl02,
author = {Fowler, Martin},
title = {{The New Methodology}},
year = {2002}
}
@inproceedings{maxwelldata,
address = {Englewood Cliffs, NJ},
author = {Maxwell, K D},
publisher = {Prentice-Hall},
title = {{Applied Statistics for Software Managers}},
year = {2002}
}
@article{dekleer86c,
author = {DeKleer, J},
journal = {Artificial Intelligence},
pages = {197--224},
title = {{Problem Solving with the ATMS}},
volume = {28},
year = {1986}
}
@misc{1278.4,
author = {Society, IEEE Computer},
title = {{IEEE Recommended Practice 1278.4-1007 -2004 for Distributed Interactive Simulation- Verification, Validation, and Accreditation}},
year = {1997}
}
@article{me02k,
author = {Menzies, T and Stefano, J S Di},
journal = {IEEE Transactions on Software Engineering},
month = may,
title = {{More Success and Failure Factors in Software Reuse}},
year = {2003}
}
@inproceedings{goseva07,
author = {Goseva-Popstojanova, K and Hamill, M},
booktitle = {Computer Software and Applications Conference, 2007},
pages = {423--430},
title = {{Architecture-Based Software Reliability: Why Only a Few Parameters Matter?}},
year = {2007}
}
@book{rum91,
author = {Rumbaugh, J and Blaha, M and Premerlani, W and Eddy, F and Lorenson, W},
publisher = {Prentice-Hall},
title = {{Object-Oriented Modeling and Design}},
year = {1991}
}
@misc{me95l,
author = {Menzies, T J},
institution = {Department of Software Development, Monash University},
number = {TR95-35},
title = {{Frameworks for Assessing Visual Languages}},
year = {1995}
}
@book{kalman02,
author = {Kalman, John A},
publisher = {Rinton Press},
title = {{Automated Reasoning with OTTER}},
year = {2002}
}
@article{basili91,
author = {Basili, V R and Rombach, H D},
journal = {Software Engineering Journal},
month = sep,
pages = {303--316},
title = {{Support for Comprehensive Reuse}},
year = {1991}
}
@article{clancey87,
author = {Clancey, W},
journal = {Artificial Intelligence},
pages = {233--250},
title = {{Book Review of Winograd \& Flores, Understanding Computers and Cognition: A New Foundation for Design}},
volume = {31},
year = {1987}
}
@book{lenz98,
author = {Et. al., M Lenz},
publisher = {Springer Verlag},
title = {{Case-Based Reasoning Technology- From Foundations to Applications}},
year = {1998}
}
@inproceedings{me07f,
address = {New York, NY, USA},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07casease-v0.pdf\}},
author = {Menzies, T and Elrawas, O and Hihn, J and Feathear, M and Boehm, B and Madachy, R},
booktitle = {ASE '07: Proceedings of the twenty-second IEEE/ACM international conference on Automated software engineering},
doi = {http://doi.acm.org/10.1145/1321631.1321676},
file = {::},
isbn = {978-1-59593-882-4},
pages = {303--312},
publisher = {ACM},
title = {{The Business Case for Automated Software Engineerng}},
year = {2007}
}
@inproceedings{perry99,
author = {Perry, D E},
booktitle = {Proceedings of WISR9: The 9th annual workshop on Institutionalizing Software Reuse},
title = {{Some holes in the emperor's reused clothes}},
year = {1999}
}
@article{hott90,
author = {Horty, J F and Thomson, R H and Touretzky, D S},
journal = {Artificial Intelligence},
number = {1},
pages = {311--348},
title = {{Skeptical \{T\}heory of \{I\}nheritance in \{N\}onmonotonic \{S\}emantic \{N\}etworks}},
volume = {42},
year = {1990}
}
@phdthesis{clark97,
annote = {Available from $\backslash$url\{http://sunset.usc.edu/\~{}bkclark/Research/PMAT990406.pdf\}},
author = {Clark, B},
school = {University of Southern California},
title = {{The Effects of Process Maturity on Software Development Effort}},
year = {1997}
}
@article{pong83,
author = {Pong, M C and Ng, N},
journal = {Software Practice Experience},
number = {9},
pages = {847--855},
title = {{PIGS - A System for Programming with Interactive Graphical Support}},
volume = {13},
year = {1983}
}
@article{shull00a,
author = {Shull, F and Rus, I and Basili, V R},
journal = {IEEE Computer},
number = {7},
pages = {73--79},
title = {{How Perspective-Based Reading Can Improve Requirements Inspections}},
volume = {33},
year = {2000}
}
@article{reiss87,
author = {Reiss, S P},
journal = {IEEE Software},
month = nov,
pages = {16--27},
title = {{Working in the Garden Environment for Conceptual Programming}},
year = {1987}
}
@inproceedings{heitmeyer02,
author = {Heitmeyer, C L},
booktitle = {Encyclopedia of Software Engineering},
editor = {Marciniak, John J},
isbn = {0-471-02895-9},
month = jan,
title = {{Software Cost Reduction}},
year = {2002}
}
@book{putnam80,
author = {Putnam, Lawrence H},
publisher = {The Institute of Electrical and Electronics Engineers, Inc.},
title = {{Software Cost Estimating and Life-Cycle Control: Getting the Software Numbers, New York}},
year = {1980}
}
@inproceedings{smith00,
author = {Smtih, B and Feather, M and Muscettola, N},
booktitle = {Proceedings of the Fifth International Conference on Artificial Intelligence Planning Systems (AIPS-2000)},
title = {{Challenges and Methods in Validating the Remote Agent Planner}},
year = {2000}
}
@misc{bailey02,
author = {Bailey, John},
title = {{Using Monte Carlo and COCOMO-2 to Model a Large IT System Development}},
url = {http://sunset.usc.edu/events/2002/cocomo17/John Bailey--COCOMO and Monte Carlo 10-24.pdf},
year = {2002}
}
@article{burgess01,
author = {Burgess, C J and Lefley, Martin},
journal = {Information and Software Technology},
month = dec,
number = {14},
pages = {863--873},
title = {{Can genetic programming improve software effort estimation? A comparative evaluation}},
volume = {43},
year = {2001}
}
@inproceedings{me02e,
author = {Menzies, Tim and DiStefeno, Justin S and Chapman, Mike and Mcgill, Kenneth},
booktitle = {27th NASA SEL workshop on Software Engineering},
file = {::},
title = {{Metrics that Matter}},
year = {2002}
}
@book{motwani95,
annote = {(reprinted 1997,2000)},
author = {Motwani, R and Raghavan, P},
isbn = {0521474655},
publisher = {Cambridge University Press},
title = {{Randomized Algorithms}},
year = {1995}
}
@phdthesis{bredeweg92,
author = {Bredeweg, B},
school = {University of Amsterdam},
title = {{Expertise in Qualitative Prediction of Behaviour}},
year = {1992}
}
@inproceedings{me03b,
author = {Liu, Y and Menzies, T and Cukic, B},
title = {{Detecting Novelties by Mining Association Rules}},
year = {2003}
}
@phdthesis{clark05,
author = {Clark, R},
title = {{Faster Treatment Learning, \{C\}omputer \{S\}cience, \{P\}ortland \{S\}tate \{U\}niversity}},
year = {2005}
}
@article{Zitzler,
author = {Zitzler, Eckart and Laumanns, Marco and Bleuler, Stefan},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Zitzler, Laumanns, Bleuler - Unknown - A Tutorial on Evolutionary Multiobjective Optimization.pdf:pdf},
keywords = {pareto},
mendeley-tags = {pareto},
title = {{A Tutorial on Evolutionary Multiobjective Optimization}}
}
@book{fenton91,
author = {Fenton, N E},
publisher = {Chapman and Hall, London},
title = {{Software Metrics}},
year = {1991}
}
@phdthesis{sahlin91,
address = {Stockholm, Sweden},
author = {Sahlin, D},
month = may,
school = {The Royal Institute of Technology (KTH)},
title = {{An Automatic Partial Evaluator for Full Prolog}},
year = {1991}
}
@article{Cha2002,
author = {Cha, S},
doi = {10.1016/S0031-3203(01)00118-2},
file = {:Users/timm/svns/doc/distanceBetweenHistograms.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {distance measure,histogram,modulo,nominal,ordinal},
month = jun,
number = {6},
pages = {1355--1370},
title = {{On measuring the distance between histograms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320301001182},
volume = {35},
year = {2002}
}
@article{vandebrug86,
author = {de Brug, A Van and Bachant, J and McDermott, J},
journal = {IEEE Expert},
pages = {33--39},
title = {{The \{T\}aming of \{R1\}}},
year = {1986}
}
@misc{nikora04,
author = {Nikora, A},
title = {{Personnel communication on the accuracy of severity determinations in NASA databases}},
year = {2004}
}
@book{Shere88,
author = {Shere, K D},
publisher = {Prentice Hall},
title = {{Software Engineering and Management}},
year = {1988}
}
@article{benj94z,
author = {Benjamins, V R and Jansweijer, W N H},
journal = {IEEE Expert},
month = oct,
number = {5},
pages = {43--53},
title = {{Toward a Competence Theory of Diagnosis}},
volume = {9},
year = {1994}
}
@inproceedings{cor95,
author = {Corbridge, C and Major, N P and Shadbolt, N R},
booktitle = {Proceedings of the 9th \{AAAI\}-Sponsored \{B\}anff Knowledge Acquisition for Knowledge Based Systems},
title = {{Models \{E\}xposed: An \{E\}mpirical \{S\}tudy}},
year = {1995}
}
@article{ruhe09,
author = {Ngo-The, An and Ruhe, G},
journal = {Software Engineering, IEEE Transactions on},
number = {1},
pages = {109--123},
title = {{Optimized Resource Allocation for Software Release Planning}},
volume = {35},
year = {2009}
}
@inproceedings{me02h,
author = {Menzies, T and Owen, D and Cukic, B},
booktitle = {Formal Aspects of Agent-Based Systems},
file = {::},
title = {{You seem friendly, but can I trust you?}},
year = {2002}
}
@misc{bsc99,
author = {Page, Web},
title = {{No Title}}
}
@incollection{brac89,
author = {Brachman, R J and Gilbert, V P and Levesque, H J},
booktitle = {Readings in Artificial Intelligence and Databases},
editor = {Mylopoulos, J and Brodie, M L},
pages = {293--300},
publisher = {Morgan Kaufmann},
title = {{An \{E\}ssential \{H\}ybrid \{R\}easoning \{S\}ystem: \{K\}nowledge and \{S\}ymbol \{L\}evel \{A\}ccounts of \{K\}rypton}},
year = {1989}
}
@misc{fowl02,
author = {Fowler, Martin},
title = {{The New Methodology}},
year = {2002}
}
@inproceedings{selman92,
author = {Selman, B and Levesque, H and Mitchell, D},
booktitle = {\{AAAI\} '92},
pages = {440--446},
title = {{A New Method for Solving Hard Satisfiability Problems}},
year = {1992}
}
@article{lark87,
author = {Larkin, J H and Simon, H A},
journal = {Cognitive Science},
pages = {65--99},
title = {{Why a Diagram is (Sometimes) Worth Ten Thousand Words}},
year = {1987}
}
@article{widmer96learning,
annote = {Availabel from $\backslash$url\{http://citeseer.ist.psu.edu/widmer96learning.html\}},
author = {Widmer, Gerhard and Kubat, Miroslav},
journal = {Machine Learning},
number = {1},
pages = {69--101},
title = {{Learning in the Presence of Concept Drift and Hidden Contexts}},
volume = {23},
year = {1996}
}
@article{benj97,
author = {Benjamins, R and Aben, M},
journal = {International Journal of Human-Computer Studies},
pages = {259--288},
title = {{Structure-Preserving Knowledge-Based Systems Development Thorugh Reusable Libraries: A Case Study in Diagnosis}},
volume = {47},
year = {1997}
}
@inproceedings{richards97,
author = {Richards, D and Compton, P},
booktitle = {SEKE '97: Proceedings of 1997 Conf. on Software Eng. \& Knowledge Eng, Madrid},
title = {{Combining Formal Concept Analysis and Ripple Down Rules to Support the Reuse of Knowledge}},
year = {1997}
}
@article{geigner93,
author = {Geigner, D and Pax, A and Pearl, J},
journal = {International Journal of Intelligent Systems},
pages = {231--247},
title = {{Learning Simple Causal Structures}},
volume = {8},
year = {1993}
}
@book{MillingtonIandFunge2009,
author = {{Millington, I and Funge}, J},
booktitle = {International dental journal},
file = {:Users/timm/svns/doc/millington09.pdf:pdf},
issn = {0020-6539},
keywords = {Artificial Intelligence,Games},
month = aug,
number = {4},
pages = {269--72},
pmid = {20949757},
title = {{Artificial intelligence for games}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20949757},
volume = {60},
year = {2009}
}
@book{deb98e,
author = {Debenham, J},
publisher = {Springer-Verlag},
title = {{Knowledge Engineering: Unifying Knowledge Base and Database Design}},
year = {1998}
}
@article{pendharkar05,
address = {Piscataway, NJ, USA},
author = {Pendharkar, Parag C and Subramanian, Girish H and Rodger, James A},
doi = {http://dx.doi.org/10.1109/TSE.2005.75},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {7},
pages = {615--624},
publisher = {IEEE Press},
title = {{A Probabilistic Model for Predicting Software Development Effort}},
volume = {31},
year = {2005}
}
@misc{ctc86,
annote = {Vol. 2, No. 3},
howpublished = {Control Theory and Advanced Technology},
month = sep,
title = {{Special Issue on Expert Systems}},
year = {1986}
}
@inproceedings{quinlan92b,
author = {Quinlan, J R},
booktitle = {5th Australian Joint Conference on Artificial Intelligence},
pages = {343--348},
title = {{Learning with \{C\}ontinuous \{C\}lasses}},
year = {1992}
}
@inproceedings{ambler87,
author = {Ambler, A L},
booktitle = {Proceedings Workshop on Visual Languages, Tryck-Center, Linkoping, Sweden},
pages = {105--117},
title = {{Forms: Expanding the Visualness of Sheet Languages}},
year = {1987}
}
@book{mead72,
author = {Meadows, D H and Meadows, D L and Randers, J and Behrens, W W},
publisher = {Potomac Associates},
title = {{The Limits to Growth}},
year = {1972}
}
@book{mcintosh80,
author = {McIntosh, J E A and McIntosh, R P},
publisher = {Springer-Verlag},
title = {{Mathematical Modeling and Computers in Endocrinology}},
year = {1980}
}
@inproceedings{me00p,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/00ml.pdf\}},
author = {Menzies, T},
booktitle = {Handbook of Software Engineering and Knowledge Engineering},
isbn = {981-02-4973-X},
month = dec,
publisher = {World-Scientific},
title = {{Practical Machine Learning for Software Engineering and Knowledge Engineering}},
year = {2001}
}
@inproceedings{cio02,
author = {Ciolkowski, M and Laitenberger, O and Rombach, D H and Shull, F and Perry, D},
booktitle = {Proceedings of ICSE 2002},
pages = {641--642},
title = {{Software inspections, reviews and walkthroughs}},
year = {2002}
}
@book{wier96,
author = {Wieringa, R J},
publisher = {Wiley},
title = {{Requirements Engineering: Frameworks for Understanding}},
year = {1996}
}
@misc{me97r,
author = {Menzies, T and Waugh, S and Goss, S and Cohen, Robert F},
howpublished = {Submitted to FOIS '97},
title = {{Evaluating a Temporal Causal Ontology}},
year = {1997}
}
@phdthesis{baker07,
author = {Baker, Dan},
file = {:Users/timm/svns/doc/cost/07Baker.pdf:pdf},
school = {Lane Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{A Hybrid Approach to Expert and Model-based Effort Estimation}},
year = {2007}
}
@article{wallace68,
author = {Wallace, C S and Boulton, D M},
journal = {Computer Journal},
pages = {185--194},
title = {{An Information Measure for Classification}},
volume = {vol 11.2},
year = {1968}
}
@misc{mccabe,
title = {{McCabe QA\^{}\{$\backslash$mbox $\backslash$textregistered\}}},
url = {$\backslash$url\{http://www.mccabe.com\}},
year = {2005}
}
@article{stefik82,
author = {Stefik, M and Aikins, J and Balzer, R and Benoit, J and Birnhaum, L and Hayes-Roth, F and Sacerdoti, E},
journal = {Artificial Intelligence},
pages = {127--135},
title = {{The \{O\}rganisation of \{E\}xpert \{S\}ystems, \{A\} \{T\}utorial}},
volume = {18},
year = {1982}
}
@inproceedings{Daran96,
author = {Daran, M and Thevenod-Fosse, P},
booktitle = {Proc. ISSTA 96},
keywords = {Error propagation,mutation,testing},
pages = {158--171},
title = {{Software Error Analysis: \{A\} Real Case Study Involving Real Faults and Mutations}},
year = {1996}
}
@inproceedings{lukose99,
author = {Lukose, Dickson and Nechab, Said and Pritchard, Simon and Lee, Ashley and Hussen, Sajid and Clawley, Jon and Jackson, Philip and Hare, Chris and Bayliss, Tony and Hawcutts, Mike and Bdar, Alex},
booktitle = {Proceedings of the Banff Knowledge Acquisition Workshop},
title = {{TAPS: Knowledge Management System}},
year = {1999}
}
@inproceedings{me00s,
author = {Menzies, T and Cukic, B},
booktitle = {International Workshop on Empirical Studies of Software Maintenance (WESS 2000), October 14, San Jose CA},
title = {{Maintaining Maintainability = Recognizing Reachability}},
year = {2000}
}
@article{yu79,
author = {Yu, V L and Fagan, L M and Wraith, S M and Clancey, W J and Scott, A C and Hanigan, J F and Blum, R L and Buchanan, B G and Cohen, S N},
journal = {Journal of American Medical Association},
pages = {1279--1282},
title = {{Antimicrobial \{S\}election by a \{C\}omputer: a \{B\}linded \{E\}valuation by \{I\}nfectious \{D\}isease \{E\}xperts}},
volume = {242},
year = {1979}
}
@article{boda85,
author = {Boehm-Davis, D A and Fregly, A M},
journal = {Human Factors},
pages = {423--432},
title = {{Documentation of Concurrent Programs}},
volume = {27},
year = {1985}
}
@misc{kern98,
author = {Kerningham, B W and Wyk, C J Van},
title = {{Timing Trials, or, the Trials of Timing: Experiments with Scripting and User-Interface Languages}},
year = {1998}
}
@article{caraca99,
annote = {To appear.},
author = {Caraca-Valente, J P and Gonzalez, L and Morant, J L and Pozas, J},
journal = {International Journal of Human-Computer Studies},
title = {{Knowledge-based Systems Validation: When to Stop Running Test Cases}},
year = {2000}
}
@article{hamlet90,
author = {Hamlet, D and Taylor, R},
journal = {IEEE Transactions on Software Engineering},
month = dec,
number = {12},
pages = {1402--1411},
title = {{Partition Testing Does Not Inspire Confidence}},
volume = {16},
year = {1990}
}
@inproceedings{clarke93,
author = {Clark, E M and Filkorn, T},
booktitle = {Fifth International Conference on Computer Aided Verification},
publisher = {Springer-Verlag},
title = {{Exploiting Symmetry in Temporal Logic Model Checking}},
year = {1993}
}
@misc{me98a,
author = {Menzies, T and Waugh, S and Goss, S},
howpublished = {Submitted to ECAI '98},
title = {{Taming Chatter with Relevant Envisionments}},
year = {1998}
}
@book{feigen83,
author = {Feigenbaum, E and McCorduck, P},
publisher = {Addison-Wesley},
title = {{The \{F\}ifth \{G\}eneration}},
year = {1983}
}
@book{saaty80,
author = {Saaty, T},
isbn = {0-07-054371-2},
publisher = {McGraw-Hill},
title = {{The Analytic Hierarchy Process: Planning, Priority Setting, Resource Allocation}},
year = {1980}
}
@book{wirfs90,
author = {Wirfs-Brock, R J and Wilkerson, B and Weiner, L},
publisher = {Prentice-Hall},
title = {{Designing Object-Oriented Software}},
year = {1990}
}
@article{boehm86,
author = {Boehm, B},
journal = {Software Engineering Notes},
number = {4},
pages = {22},
title = {{A Spiral Model of Software Development and Enhancement}},
volume = {11},
year = {1986}
}
@book{winter83,
author = {Winter, Frank},
publisher = {Smithsonian Institution Press},
title = {{Prelude to the Space Age: The Rocket Societies 1924-1940}},
year = {1983}
}
@misc{bax95,
annote = {Available from $\backslash$url\{http://citeseer.ist.psu.edu/baxter95mdl.html\}},
author = {Baxter, R A and Oliver, J J},
institution = {Computer Science, Monash University, Melbourne, Australia},
month = mar,
title = {{\{MDL\} and \{MML\}: Similarities and Differences}},
year = {1995}
}
@article{Holte2006a,
author = {Holte, Robert C.},
doi = {10.1214/088342306000000033},
file = {:Users/timm/svns/doc/holte06.pdf:pdf},
issn = {0883-4237},
journal = {Statistical Science},
month = feb,
number = {1},
pages = {24--26},
title = {{Elaboration on Two Points Raised in âClassifier Technology and the Illusion of Progressâ}},
url = {http://projecteuclid.org/Dienst/getRecord?id=euclid.ss/1149600842/},
volume = {21},
year = {2006}
}
@article{dennett82,
annote = {8 June 24},
author = {Dennett, D C},
journal = {The New York Review of Books},
pages = {56--57},
title = {{Letter to the Editor}},
year = {1982}
}
@article{hart89,
author = {Hartson, H R and Hicks, D},
journal = {ACM Computing Surveys},
pages = {5--92},
title = {{Human-Computer Interface Development: Concepts and Systems for its Management.}},
volume = {21},
year = {1989}
}
@article{ferens98,
author = {Ferens, D and Christensen, D},
journal = {Journal of Parametrics},
month = nov,
number = {1},
pages = {55--74},
title = {{Calibrating Software Cost Models to \{D\}epartment of \{D\}efense \{D\}atabase: A Review of Ten Studies}},
volume = {18},
year = {1998}
}
@inproceedings{ginsberg87,
author = {Ginsberg, A},
booktitle = {Proc. 3rd Annual Expert Systems in Government Conference},
organization = {IEEE Computer Society},
pages = {102--111},
title = {{A new \{A\}pproach to \{C\}hecking \{K\}nowledge \{B\}ases for \{I\}nconsistency and \{R\}edundancy}},
year = {1987}
}
@article{jorg04uncertainty,
address = {Piscataway, NJ, USA},
author = {Jorgensen, Magne},
doi = {http://dx.doi.org/10.1109/TSE.2004.1274041},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {4},
pages = {209--217},
publisher = {IEEE Press},
title = {{Realism in Assessment of Effort Estimation Uncertainty: It Matters How You Ask}},
volume = {30},
year = {2004}
}
@article{lenat90,
author = {Lenat, D B and Gutha, R V},
journal = {AI Magazine},
pages = {32--59},
title = {{CYC: A Midterm Report}},
year = {1990}
}
@article{FreSch97,
author = {Freund, Y and Schapire, R E},
journal = {JCSS: Journal of Computer and System Sciences},
title = {{A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting}},
volume = {55},
year = {1997}
}
@article{nilsson91,
author = {Nilsson, N J},
journal = {Artificial Intelligence},
pages = {31--56},
title = {{Logic and Artificial Intelligence}},
volume = {47},
year = {1991}
}
@article{wakeland04,
annote = {Available from $\backslash$url\{http://www.sba.pdx.edu/faculty/davidr/draccess/WEB/publications/JOURNAL/SPIP-DOE.pdf\}},
author = {Waleland, W and Martin, R and Raffo, D},
journal = {Software Process: Improvement and Practice},
number = {2},
pages = {107--119},
title = {{Using Design of Experiments, Sensitivity Analysis. and Hybird Simulation to Evaluate Changes to a Software Development Process: A Case Study}},
volume = {9},
year = {2004}
}
@misc{rush88,
annote = {SRI-CSL-88-7R, SRI Project 4616},
author = {Rushby, J},
title = {{Quality Measures and Assurance for AI Software}},
year = {1988}
}
@article{DH88,
author = {Harel, D},
journal = {Communications of the ACM},
number = {5},
pages = {514--530},
title = {{On visual formalisms}},
volume = {31},
year = {1988}
}
@book{musa98,
author = {Musa, John},
isbn = {0079132715},
publisher = {McGraw-Hill},
title = {{Software Reliability Engineered Testing}},
year = {1998}
}
@article{zave97,
author = {Zave, Pamela and Jackson, Michael},
issn = {1049-331X},
journal = {ACM Trans. Softw. Eng. Methodol.},
number = {1},
pages = {1--30},
title = {{Four dark corners of requirements engineering}},
volume = {6},
year = {1997}
}
@article{gordon85,
annote = {Dempster-Shafer theory explained and generalized.},
author = {Gordon, J and Shortliffe, E H},
journal = {Artificial Intelligence},
month = jul,
number = {3},
pages = {323--357},
title = {{A Method for Managing Evidential Reasoning in a Hierarchical Hypothesis Space}},
volume = {26},
year = {1985}
}
@article{even75,
author = {Even, S and Tarjan, S E},
journal = {\{SIAM\} \{J\}. \{C\}omputing},
pages = {507--518},
title = {{Network \{F\}low and \{T\}esting \{G\}raph \{C\}onnectivity}},
volume = {4},
year = {1975}
}
@inproceedings{mus93,
author = {Musen, M A and Tu, S W},
booktitle = {Knowledge-Oriented Software Design},
editor = {Cuena, J},
publisher = {Elsevier, Amsterdam},
title = {{Probelm-Solving Models for Generation of Task-Specific Knowledge Acquisition Tools}},
year = {1993}
}
@article{voas95,
author = {Voas, J M and Miller, K W},
journal = {IEEE Software},
month = may,
pages = {17--28},
title = {{Software Testability: The New Verification}},
year = {1995}
}
@inproceedings{dejong00,
author = {DeJong, K A and Spears, W M},
booktitle = {Proc. First Workshop Parallel Problem Solving from Nature},
publisher = {Springer-Verlag},
title = {{An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms}},
year = {1990}
}
@inproceedings{goa06,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06compsac.pdf\}},
author = {Gao, J and Heimdahl, M and Owen, D and Menzies, T},
booktitle = {COMPSAC '06},
title = {{On the Distribution of Property Violations in Formal Models: An Initial Study}},
year = {2006}
}
@inproceedings{benj94y,
author = {Benjamins, R},
booktitle = {Proceedings of the European Knowledge Acquisition Workshop, 1994},
title = {{On a Role of Probem Solving Methods in Knowledge Acquisition- Experiments with Diagnostic Strategies}},
year = {1994}
}
@inproceedings{meedng92,
author = {Menzies, T J and Edwards, J and Ng, K},
booktitle = {Tools Pacific 1992},
pages = {421--428},
publisher = {Prentice Hall},
title = {{The \{M\}ysterious \{C\}ase of the \{M\}issing \{R\}e-usable \{C\}lass \{L\}ibraries}},
year = {1992}
}
@misc{kruchten03,
author = {Kruchten, Philippe},
month = feb,
title = {{What Is the Rational Unified Process?}},
year = {2003}
}
@article{smith94,
author = {Smith, T and Setliff, D},
journal = {Automated Software Engineering},
pages = {155--176},
title = {{Using simulated annealing to synthesize resource-bounded software}},
year = {1994}
}
@inproceedings{brle84,
author = {Brachman, R J and Levesque, H J},
booktitle = {\{AAAI\} '84},
pages = {34--37},
title = {{The Tractability of Subsumption in Frame-Based Description Languages}},
year = {1984}
}
@inproceedings{bradshaw91,
author = {Bradshaw, J M and Ford, K M and Adams-Webber, J},
booktitle = {6th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge-Based Systems Workshop, ,October 6-11 1991, Banff, Canada},
pages = {4.1 -- 4.25},
title = {{Knowledge Representation of Knowledge Acquisition: A Three-Schemata Approach}},
year = {1991}
}
@inproceedings{Kir92,
author = {Kira, K and Rendell, L},
booktitle = {The Ninth International Conference on Machine Learning},
pages = {pp. 249--256},
publisher = {Morgan Kaufmann},
title = {{A Practical Approach to Feature Selection}},
year = {1992}
}
@inproceedings{lee95,
author = {Lee, M and Compton, P},
booktitle = {Proceedings of the 8th Australian Joint Conference on Aritificial Intelligence (AI'95)},
pages = {83--90},
title = {{From Heuristic Knowledge to Causal Explanations}},
year = {1995}
}
@misc{treinish98,
author = {Treinish, L A},
title = {{A Function-Based Data Model for Visualization}},
year = {1998}
}
@misc{CLCS03,
annote = {$\backslash$url\{http://www.spaceref.com/news/viewnews.html?id=475\}},
author = {Spareref.com},
title = {{NASA to Shut Down Checkout \& Launch Control System}}
}
@inproceedings{agrawal92,
author = {R.Agrawal and T.Imeilinski and A.Swami},
booktitle = {Proceedings of the 1993 ACM SIGMOD Conference, Washington DC, USA},
title = {{Mining Association Rules between Sets of Items in Large Databases}},
year = {1993}
}
@article{Hagelb2010,
author = {Hagelb, Johan and Johansson, Stefan J and Ieee, Member},
file = {::},
journal = {Computational Intelligence},
pages = {139--145},
title = {{A Study on Human like Characteristics in Real Time Strategy Games}},
year = {2010}
}
@article{me89za,
author = {Menzies, T J},
journal = {AI Magazine},
title = {{An Investigation of the AI and Expert Systems Literature 1980-1984}},
year = {1989}
}
@article{bol95,
author = {Boland, R J and Tenkasi, R V},
journal = {Organization Science},
number = {4},
title = {{Perspective Making and Perspective Taking in Communities of Knowledge}},
volume = {6},
year = {1995}
}
@inproceedings{gaines92a,
author = {Gaines, B R and Compton, P},
booktitle = {Proceedings, Australian AI '92},
pages = {349--354},
publisher = {World Scientific},
title = {{Induction of Ripple Down Rules}},
year = {1992}
}
@article{Larsen1999,
address = {New York, New York, USA},
author = {Larsen, Bjornar and Aone, Chinatsu},
doi = {10.1145/312129.312186},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Larsen, Aone - 1999 - Fast and effective text mining using linear-time document clustering(2).pdf:pdf},
isbn = {1581131437},
journal = {Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '99},
keywords = {clustering,multi-document summarization,text mining},
pages = {16--22},
publisher = {ACM Press},
title = {{Fast and effective text mining using linear-time document clustering}},
url = {http://portal.acm.org/citation.cfm?doid=312129.312186},
year = {1999}
}
@misc{nilsson00,
author = {Nilsson, N J},
title = {{AI RISING, invited talk, AAAI}},
year = {2000}
}
@book{shaw96,
author = {Shaw, M and Garlan, D},
publisher = {Prentice Hall},
title = {{Software Architecture: Perspectives on an Emerging Discipline}},
year = {1996}
}
@article{Kohavi1995e,
author = {Kohavi, R.},
file = {:Users/timm/svns/doc/kohavi95a.pdf:pdf},
journal = {Machine Learning: ECML-95},
pages = {174--189},
publisher = {Springer},
title = {{The power of decision tables}},
url = {http://www.springerlink.com/index/P5N736U105315054.pdf},
year = {1995}
}
@article{darke96,
author = {Darke, P and Shanks, G},
journal = {Requirements Engineering},
number = {2},
pages = {88--105},
title = {{Stakeholder Viewpoints in Requirements Definition: A Framework for Understanding Viewpoint Development Approaches}},
volume = {1},
year = {1996}
}
@incollection{john92,
author = {Johnson, R},
booktitle = {Proceedings of OOPSLA'92},
publisher = {ACM SIGPLAN},
title = {{Documenting Frameworks using Patterns}},
year = {1992}
}
@inproceedings{whittle00,
author = {Whittle, J and Schumann, J},
booktitle = {Proceedings of the 22nd International Conference on Software Engineering (ICSE). Limerick, Ireland},
month = jun,
title = {{Generating Statechart Designs From Scenarios}},
year = {2000}
}
@inproceedings{iwasaki95a,
author = {Iwasaki, Y and Tesseler, S and Law, K H},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and Narayanan, H and Chandrasekaran, B},
pages = {711--729},
publisher = {MIT Press},
title = {{Qualitative Structural Analysis Through Mixed Diagrammatic and Symbolic Reasoning}},
year = {1995}
}
@article{funt80,
author = {Funt, B V},
journal = {Artificial Intelligence},
pages = {201--230},
title = {{Problem-Solving with Diagrammatic Representations}},
volume = {13},
year = {1980}
}
@article{martin01,
author = {Martin, R H and {D. M}, Raffo},
journal = {Journal of Systems and Software},
number = {3},
title = {{Application of a Hybrid Process Simulation Model to a Software Development Project}},
volume = {59},
year = {2001}
}
@misc{predict,
title = {{Predict\^{}\{$\backslash$mbox $\backslash$textregistered\}}},
url = {$\backslash$url\{http://www.ismwv.com/products.asp\}},
year = {2005}
}
@article{stout97,
author = {Stout, Bryan},
journal = {Game Developer Magazine},
number = {7},
title = {{Smart Moves: Intelligent Pathfinding}},
url = {http://www.gamasutra.com/features/19970801/pathfinding.htm},
year = {1997}
}
@misc{faa06,
author = {Administration, Federal Aviation},
title = {{System Engineering Manual Version 3.1, Section 4.6: Trade Studies}},
year = {2006}
}
@inproceedings{me94,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/ai94.pdf\}},
author = {Menzies, T J and Compton, P},
booktitle = {Proceedings of Australian AI'94},
editor = {Zhang, C and Debenham, J and Lukose, D},
pages = {149--156},
publisher = {World Scientific},
title = {{A \{P\}recise \{S\}emantics for \{V\}ague \{D\}iagrams}},
year = {1994}
}
@inproceedings{chulani98,
author = {{S. Chulani B. Clark}, B Boehm and Steece, B},
booktitle = {Proceceedings ISPA,98},
title = {{Calibration Approach and Results of the COCOMO II Post-Architecture Model}},
year = {1998}
}
@inproceedings{owen03c,
author = {Owen, David and Menzies, Tim and Heimdahl, Mats and Gao, Jimin},
booktitle = {IEEE NASE SEW 2003},
title = {{On the Advantages of Approximate vs. Complete Verification: Bigger Models, Faster, Less Memory, Usually Accurate}},
year = {2003}
}
@inproceedings{Kocaguneli2009,
author = {Kocaguneli, Ekrem and Kultur, Y. and Bener, A.B.},
booktitle = {ISSRE '09},
file = {:Users/timm/svns/doc/ekrem09a.pdf:pdf},
title = {{Combining Multiple Learners Induced on Multiple Datasets for Software Effort Prediction}},
url = {http://www.issre2009.org/papers/issre2009\_245.pdf},
year = {2009}
}
@article{such93,
author = {Suchman, L},
journal = {Cognitive Science},
pages = {71--75},
title = {{Response to Vera and Simon's Situated Action: A Symbolic Interpretation}},
volume = {17},
year = {1993}
}
@inproceedings{sammut92,
author = {Sammut, C and Hurst, S and Kedzier, D and Michie, D},
booktitle = {Ninth International Conference on Machine Learning},
editor = {Sleeman, D},
pages = {385--393},
publisher = {Morgan Kaufmann},
title = {{Learning to Fly}},
year = {1992}
}
@misc{david00,
annote = {$\backslash$url\{http://www.space.com/businesstechnology/business/spear\_report\_000313.html\}},
author = {David, Leonard},
month = mar,
title = {{\{NASA\} report: Too Many Failures with Faster, Better, Cheaper}},
year = {2000}
}
@article{leake91,
author = {Leake, D B},
journal = {Cognitive Science},
pages = {509--545},
title = {{Goal-Based Explanation Evaluation}},
volume = {15},
year = {1991}
}
@misc{taylor02,
author = {Taylor, B},
title = {{Development of Methodologies for IV\&V Neural Networks: Literature Survey of Current V\&V Technology}},
year = {2004}
}
@article{console91,
author = {Console, L and Torasso, P},
journal = {Computational Intelligence},
pages = {133--141},
title = {{A \{S\}pectrum of \{D\}efinitions of \{M\}odel-\{B\}ased \{D\}iagnosis}},
volume = {7},
year = {1991}
}
@article{by91,
author = {Bylander, T and Allemang, D and Tanner, M C and Josephson, J R},
journal = {Artificial Intelligence},
pages = {25--60},
title = {{The \{C\}omputational \{C\}omplexity of \{A\}bduction}},
volume = {49},
year = {1991}
}
@article{newell82,
author = {Newell, A},
journal = {Artificial Intelligence},
pages = {87--127},
title = {{The \{K\}nowledge \{L\}evel}},
volume = {18},
year = {1982}
}
@inproceedings{decu95,
author = {DeCuyper, J and Keymeulen, D and Steels, L},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and {N.H. Narayanan}, B Chandrasekaran},
pages = {731--752},
publisher = {The AAAI Press},
title = {{A Hybrid Architecture for Modeling Liquid Behavior}},
year = {1995}
}
@book{BERGE89,
author = {Berge, Claude},
publisher = {North-Holland},
title = {{Hypergraphs}},
year = {1989}
}
@book{sterling94,
author = {Sterling, L and Shapiro, E},
publisher = {MIT Press},
title = {{The Art of Prolog (second edition)}},
year = {1994}
}
@book{fenton96,
author = {Fenton, N E and Pfleeger, S L},
publisher = {International Thompson Press},
title = {{Software Metrics: A Rigorous \& Practical Approach (second edition)}},
year = {1995}
}
@article{car,
annote = {Available on-line at $\backslash$url\{http://spectrum.ieee.org/green-tech/advanced-cars/this-car-runs-on-code\}},
author = {Charette, R N},
journal = {IEEE Spectrum},
title = {{This Car Runs on Code}},
year = {2009}
}
@misc{discouse,
annote = {Available on-line at $\backslash$url\{ http://swan.mindinformatics.org/spec/1.2/discourserelationships.html\}},
author = {Ciccarese, Paolo and Clark, Tim and Kinoshita, June and Ocana, Marco and Wong, Gwen and Wu, Elizabeth},
title = {{Scientific Discourse Relationships Ontology Specification}},
year = {2007}
}
@article{dolado01,
author = {Dolado, J J},
journal = {Information and Software Technology},
pages = {61--72},
title = {{On the problem of the software cost function}},
volume = {43},
year = {2001}
}
@phdthesis{Hall98,
author = {Hall., M A},
school = {Department of Computer Science, University of Waikato, Hamilton, New Zealand},
title = {{Correlation-based feature selection for machine learning}},
year = {1998}
}
@book{poole98,
author = {Poole, D and Mackworth, A and Goebel, R},
title = {{Computational Intelligence: A Logical Approach}},
year = {1998}
}
@book{lyu96,
author = {Lyu, M R},
publisher = {McGraw-Hill},
title = {{The Handbook of Software Reliability Engineering}},
year = {1996}
}
@inproceedings{easter00,
author = {Easterbrook, S and Chechik, M},
booktitle = {ICSE 2001},
title = {{Framework for Multi-Valued Reasoning over Inconsistent Viewpoints}},
year = {2001}
}
@misc{me97s,
author = {Menzies, T J},
title = {{Evaluation Issues for Problem Visual Programming Languages}},
year = {1998}
}
@article{Ag2003a,
author = {Ag, Chrysler and Tic, Cicyt and Evanco, William M and Spencer, N and Keppel, H and Brader, D and Brader, M},
file = {:Users/timm/svns/doc/Evanco.pdf:pdf},
journal = {Statistics},
number = {7},
title = {{Comments on â The Confounding Effect of Class Size on the Validity of Object-Oriented Metrics â Comments on â The Confounding Effect of Class Size on the Validity of Object-Oriented Metrics â}},
volume = {29},
year = {2003}
}
@article{shn83,
author = {Shneiderman, B},
journal = {Computer},
month = aug,
pages = {57--69},
title = {{Direct Manipulation: A Step Beyond Programming Languages}},
year = {1983}
}
@article{Strouthidis2010a,
abstract = {To evaluate the reproducibility of the Heidelberg retina tomograph (HRT) Glaucoma Probability Score (GPS) and assess its potential for monitoring progression.},
author = {Strouthidis, Nicholas G and Demirel, Shaban and Asaoka, Ryo and Cossio-Zuniga, Claudio and Garway-Heath, David F},
doi = {10.1016/j.ophtha.2009.09.036},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Strouthidis et al. - 2010 - The Heidelberg retina tomograph Glaucoma Probability Score reproducibility and measurement of progression.pdf:pdf},
issn = {1549-4713},
journal = {Ophthalmology},
keywords = {Adult,Aged,Aged, 80 and over,Diagnostic Techniques, Ophthalmological,Disease Progression,Female,Glaucoma, Open-Angle,Glaucoma, Open-Angle: diagnosis,Glaucoma, Open-Angle: physiopathology,Humans,Intraocular Pressure,Intraocular Pressure: physiology,Male,Middle Aged,Observer Variation,Ocular Hypertension,Ocular Hypertension: diagnosis,Ocular Hypertension: physiopathology,Probability,Reproducibility of Results,Sensitivity and Specificity,Tomography,Tomography: methods,Visual Fields,Visual Fields: physiology,Young Adult},
month = apr,
number = {4},
pages = {724--9},
pmid = {20045564},
title = {{The Heidelberg retina tomograph Glaucoma Probability Score: reproducibility and measurement of progression.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20045564},
volume = {117},
year = {2010}
}
@inproceedings{me03q,
author = {Menzies, Tim and Di\~{}Stefano, Justin S},
booktitle = {2004 IEEE Conference on High Assurance Software Engineering},
title = {{How Good is Your Blind Spot Sampling Policy?}},
year = {2003}
}
@article{harr99,
author = {Harrison, W and Raffo, D and Settle, J and Eickelmann, N},
journal = {Software Quality Journal},
number = {3},
title = {{Adapting Financial Measures: Making a Business Case for Software Process Improvement}},
volume = {8},
year = {1999}
}
@inproceedings{turhan08,
annote = {hW},
author = {Turhan, B and Bener, A and Menzies, T},
booktitle = {Proceedings, DEFECTS 2008},
title = {{Nearest Neighbor Sampling for Cross Company Defect Predictors}},
year = {2008}
}
@inproceedings{meha94,
author = {Menzies, T J and Haynes, P},
booktitle = {Tools Pacific '94},
pages = {83--92},
publisher = {Prentice-Hall},
title = {{The \{M\}ethodologies of \{M\}ethodologies; or, \{E\}valuating \{C\}urrent \{M\}ethodologies: \{W\}hy and \{H\}ow}},
year = {1994}
}
@article{keung2008b,
address = {Piscataway, NJ, USA},
author = {Keung, Jacky Wai and Kitchenham, Barbara A and Jeffery, David Ross},
doi = {http://dx.doi.org/10.1109/TSE.2008.34},
file = {::},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {4},
pages = {471--484},
publisher = {IEEE Press},
title = {{Analogy-X: Providing Statistical Inference to Analogy-Based Software Cost Estimation}},
volume = {34},
year = {2008}
}
@article{me99p,
author = {Menzies, T},
journal = {ACM SIGART Intelligence magazine},
title = {{Cost Benefits of Ontologies}},
year = {1999}
}
@article{me07e,
annote = {$\backslash$url\{http://menzies.us/pdf/07precision.pdf\}},
author = {Menzies, Tim and Dekhtyar, Alex and Distefano, Justin and Greenwald, Jeremy},
file = {::},
journal = {IEEE Transactions on Software Engineering},
month = sep,
title = {{Problems with Precision}},
year = {2007}
}
@inproceedings{cohen99,
author = {Cohen, P and Chaudhri, V and Pease, A and Schrag, R},
booktitle = {AAAI'99},
title = {{Does Prior Knowledge Facilitate the Development of Knowledge-based Systems?}},
year = {1999}
}
@inproceedings{falk90,
author = {Falkenhainer, B},
booktitle = {Working Notes of the 1990 Spring Symposium on Automated Abduction},
editor = {O'Rourke, P},
pages = {135--139},
title = {{Abduction as \{S\}imilarity-\{D\}riven \{E\}xplanation}},
year = {1990}
}
@article{woolridge95,
author = {Wooldridge, M J and Jennings, N R},
journal = {The Knowledge Engineering Review},
number = {2},
pages = {115--152},
title = {{Intelligent agents: Theory and practice}},
volume = {10},
year = {1995}
}
@book{milne26,
annote = {Why is this here? -Kel},
author = {Milne, A A},
publisher = {Methuen Children's Book},
title = {{Winnie-the-Pooh}},
year = {1926}
}
@inproceedings{fecosm89a,
author = {Feldman, B and Compton, P and Smythe, G},
booktitle = {4th \{AAAI\}-Sponsored Knowledge Acquisition for Knowledge-based Systems Workshop \{B\}anff, \{C\}anada},
title = {{Hypothesis \{T\}esting: an \{A\}ppropriate \{T\}ask for \{K\}nowledge-\{B\}ased \{S\}ystems}},
year = {1989}
}
@book{medawar79,
author = {Medawar, P B},
publisher = {Pan Books},
title = {{Advice to a Young Scientist}},
year = {1979}
}
@inproceedings{cor95,
author = {Corbridge, C and Major, N P and Shadbolt, N R},
booktitle = {Proceedings of the 9th \{AAAI\}-Sponsored \{B\}anff Knowledge Acquisition for Knowledge Based Systems},
title = {{Models \{E\}xposed: An \{E\}mpirical \{S\}tudy}},
year = {1995}
}
@misc{NORTH93,
author = {North, S C},
howpublished = {preprint},
title = {{Drawing ranked digraphs with recursive clusters}},
year = {1993}
}
@inproceedings{yost89,
author = {Yost, G R and Newell, A},
booktitle = {\{IJCAI\} '89},
pages = {621--627},
title = {{A \{P\}roblem \{S\}pace \{A\}pproach to \{E\}xpert \{S\}ystem \{S\}pecification}},
year = {1989}
}
@article{hirakawa94,
author = {Hirakawa, M and Ichikawa, T},
journal = {Software- Concepts and Tools},
pages = {61--67},
title = {{Visual Language Studies - A Perspective}},
year = {1994}
}
@inproceedings{me95m,
author = {Menzies, T J and Goss, S},
booktitle = {AI in Defence Workshop, Australian AI'95, also Technical Report TR95-31, Department of Software Development, Monash University},
title = {{Applications of Abduction \#3: ``Black-Box'' to ``Gray-Box'' Model}},
year = {1995}
}
@incollection{ammarel86,
author = {Michalski, R S and Carbonell, J G and Mitchell, T M},
booktitle = {Machine Learning: An Artificial Intelligence Approach},
pages = {499--569},
publisher = {Morgan Kaufmann},
title = {{Program Synthesis as a Theory Formation Task: Problem Representations and Solution Methods,}},
volume = {2},
year = {1986}
}
@inproceedings{kitch04,
address = {Washington, DC, USA},
author = {Kitchenham, Barbara A and Dyba, Tore and Jorgensen, Magne},
booktitle = {ICSE '04: Proceedings of the 26th International Conference on Software Engineering},
isbn = {0-7695-2163-0},
pages = {273--281},
publisher = {IEEE Computer Society},
title = {{Evidence-Based Software Engineering}},
year = {2004}
}
@misc{schw02,
author = {Schwaber, Ken},
title = {{No Title}},
year = {2002}
}
@article{lukins10,
address = {Newton, MA, USA},
author = {Lukins, Stacy K and Kraft, Nicholas A and Etzkorn, Letha H},
issn = {0950-5849},
journal = {Inf. Softw. Technol.},
number = {9},
pages = {972--990},
publisher = {Butterworth-Heinemann},
title = {{Bug localization using latent Dirichlet allocation}},
volume = {52},
year = {2010}
}
@inproceedings{jiang08a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08transform.pdf\}},
author = {Jiang, Y and Cukic, B and Menzies, T},
booktitle = {Defects 2008},
title = {{Does Transformation Help?}},
year = {2008}
}
@inproceedings{clancey91a,
author = {Clancey, W},
booktitle = {NATO Workshop on Emergance, Situatedness, Subsumption, and Symbol},
title = {{A Boy Scout, Toto, and a Bird: How Situated Cognition is Different from Situated Robotics}},
year = {1991}
}
@article{martin00,
author = {Martin, R H and Raffo, D M},
journal = {International Journal of Software Process Improvement and Practice},
title = {{A Model of the Software Development Process Using Both Continuous and Discrete Models}},
year = {2000}
}
@book{sed88,
author = {Sedgewick, R},
publisher = {Addison-Wesley},
title = {{Algorithms}},
year = {1988}
}
@inproceedings{nagappan05,
author = {Nagappan, Nachiappan and Ball, Thomas},
booktitle = {ICSE 2005, St. Louis},
title = {{Static Analysis Tools as Early Indicators of Pre-Release Defect Density}},
year = {2005}
}
@article{Lipowezky1998,
author = {Lipowezky, U},
journal = {Pattern Recognition Letters},
keywords = {global optimization,optimal prototype subset,single hypercube,test sample set},
number = {10},
pages = {907ï¿½918},
publisher = {Elsevier},
title = {{Selection of the optimal prototype subset for 1-NN classification}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865598000750},
volume = {19},
year = {1998}
}
@article{searle95,
author = {Searle, J},
journal = {The New York Review of Books},
month = dec,
pages = {83--84},
title = {{'The Mystery of Consciousness': An Exchange}},
year = {1995}
}
@inproceedings{robertson96,
author = {Robertson, D},
booktitle = {ECAI '96, Budapest},
pages = {390--394},
title = {{Distributed Specification}},
year = {1996}
}
@book{harmon86,
author = {Harmon, D and King, D},
publisher = {John Wiley \& Sons},
title = {{Expert Systems: Artificial Intelligence in Business}},
year = {1983}
}
@inproceedings{KITCHENHAM2009,
address = {New York, NY, USA},
author = {Kitchenham, Barbara and Mendes, Emilia},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540444},
file = {::},
isbn = {978-1-60558-634-2},
pages = {1--5},
publisher = {ACM},
title = {{Why comparative effort prediction studies may be invalid}},
year = {2009}
}
@article{davis93,
author = {Davis, R and Shrobe, H and Szolovits, P},
journal = {\{AI\} Magazine},
pages = {17--33},
title = {{What is a \{K\}nowledge \{R\}epresentation?}},
year = {1993}
}
@article{Abrahamsson2007b,
author = {Abrahamsson, Pekka and Moser, Raimund and Pedrycz, Witold and Sillitti, Alberto and Succi, Giancarlo},
doi = {10.1109/ESEM.2007.16},
file = {::},
isbn = {978-0-7695-2886-1},
journal = {First International Symposium on Empirical Software Engineering and Measurement (ESEM 2007)},
month = sep,
pages = {344--353},
publisher = {Ieee},
title = {{Effort Prediction in Iterative Software Development Processes -- Incremental Versus Global Prediction Models}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4343762},
year = {2007}
}
@article{dorigo97,
author = {Dorigo, M and Gambardella, L M},
journal = {IEEE Transactions on Evolutionary Computation},
month = apr,
number = {1},
pages = {53--66},
title = {{Ant Colony System: \{A\} Cooperative Learning Approach to the Traveling Salesman Problem}},
type = {Paper},
volume = {1},
year = {1997}
}
@article{pearl86,
author = {Pearl, J},
journal = {Artificial Intelligence},
pages = {241--288},
title = {{Fusion, propagation, and structuring in belief networks}},
volume = {29},
year = {1986}
}
@misc{wiel97,
annote = {Draft},
author = {Wielinga, B J and Akkermans, J M and Schreiber, A.Th.},
title = {{A Comptence Theory Approach to Problem Solving Method Construction}},
year = {1997}
}
@inproceedings{me93k,
author = {Menzies, T J},
booktitle = {DX-93: The International Workshop on Principles on Model-Based Diagnosis},
title = {{The Complexity of Model Review}},
year = {1993}
}
@article{davis93,
author = {Davis, R and Shrobe, H and Szolovits, P},
journal = {\{AI\} Magazine},
pages = {17--33},
title = {{What is a \{K\}nowledge \{R\}epresentation?}},
year = {1993}
}
@inproceedings{craven98,
author = {Craven, M and DiPasquo, D and Freitag, D and McCallum, A and Mitchell, T and Nigam, K and Slattery, S},
booktitle = {AAAI-98},
title = {{Learning to Extract Symbolic Knowledge from the World Wide Web}},
year = {1998}
}
@article{phillips84,
author = {Phillips, L D},
journal = {Acta Psychologica},
pages = {29--48},
title = {{A Theory of Requisite Decision Models}},
volume = {56},
year = {1984}
}
@article{Kitchenham2009b,
author = {Kitchenham, B and Pearlbrereton, O and Budgen, D and Turner, M and Bailey, J and Linkman, S},
doi = {10.1016/j.infsof.2008.09.009},
file = {:Users/timm/svns/doc/Kitchenham\_2009.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {evidence-based software engineering,systematic literature review},
month = jan,
number = {1},
pages = {7--15},
title = {{Systematic literature reviews in software engineering â A systematic literature review}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950584908001390},
volume = {51},
year = {2009}
}
@article{Grosan2010,
author = {Grosan, Crina and Abraham, Ajith},
doi = {10.1016/j.ins.2009.12.018},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Grosan, Abraham - 2010 - Approximating Pareto frontier using a hybrid line search approach.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {pareto},
mendeley-tags = {pareto},
month = jul,
number = {14},
pages = {2674--2695},
title = {{Approximating Pareto frontier using a hybrid line search approach}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0020025509005489},
volume = {180},
year = {2010}
}
@article{dietterich97,
author = {Dietterich, T G},
journal = {AI Magazine},
number = {4},
pages = {97--136},
title = {{Machine Learning Research: Four Current Directions}},
volume = {18},
year = {1997}
}
@inproceedings{clarkelong89,
author = {Clark, E and Long, D E},
booktitle = {Fourth Annual Symposium on Logic in Computer Science},
title = {{Compositional Model Checking}},
year = {1989}
}
@article{uschold98c,
author = {Uschold, M and King, M and Moralee, S and Zorgios, Y},
journal = {The Knowledge Engineering Review},
month = feb,
number = {1},
title = {{The enterprise ontology}},
volume = {13},
year = {1998}
}
@inproceedings{clancey96a,
author = {Clancey, W and Sachs, P and Sierhuis, M and van Hoof, R},
booktitle = {Proceedings PKAW '96: Pacific Knowledge Acquisition Workshop},
editor = {Compton, P and Mizoguchi, R and Motoda, H and Menzies, T},
publisher = {Department of Artificial Intelligence},
title = {{Brahms: Simulating Practice for Work Systems Design}},
year = {1996}
}
@phdthesis{me95,
author = {Menzies, T J},
school = {University of New South Wales},
title = {{Principles for Generalised Testing of Knowledge Bases}},
year = {1995}
}
@article{haye79,
author = {Hayes, P J},
journal = {Frame Conceptions and Text Understanding},
pages = {46--61},
publisher = {Walter de Gruyter and Co.},
title = {{The Logic of Frames}},
year = {1979}
}
@misc{me96o,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/96ie.pdf\}},
author = {Menzies, T and Tucker, S},
title = {{Subject Handbook SFT3500/SYS3030: Industrial Experience Project}},
year = {1996}
}
@article{Diakonikolas,
author = {Diakonikolas, Ilias},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Diakonikolas - Unknown - Succinct Approximate Convex Pareto Curves ( Extended Abstract ).pdf:pdf},
keywords = {pareto},
mendeley-tags = {pareto},
pages = {74--83},
title = {{Succinct Approximate Convex Pareto Curves ( Extended Abstract )}}
}
@inproceedings{elkan01,
annote = {Available from $\backslash$url\{http://www-cse.ucsd.edu/users/elkan/rescale.pdf\}},
author = {Elkan, Charles},
booktitle = {Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence (IJCAIâ01)},
title = {{The Foundations of Cost-Sensitive Learning}},
year = {2001}
}
@inproceedings{WINKLER2009,
address = {Washington, DC, USA},
author = {Winkler, Stefan},
booktitle = {TEFSE '09: Proceedings of the 2009 ICSE Workshop on Traceability in Emerging Forms of Software Engineering},
doi = {http://dx.doi.org/10.1109/TEFSE.2009.5069583},
isbn = {978-1-4244-3741-2},
pages = {49--56},
publisher = {IEEE Computer Society},
title = {{Trace retrieval for evolving artifacts}},
year = {2009}
}
@inproceedings{cruz93,
author = {Cruz-Neira, C and Sandin, D and DeFanti, T},
booktitle = {Proceedings of SIGGRAPH '93, ACM SIGGRAPH},
month = aug,
pages = {135--142},
title = {{Surround-Screen Projection-Based Virtual Reality: The Design and Implementation of the CAVE}},
year = {1993}
}
@inproceedings{hameph95,
author = {Haynes, P and Menzies, T and Phipps, G},
booktitle = {OOPSLA Workshop on OO Process and Metrics for Effort Estimation},
title = {{Using The Size of Classes and Methods as the Basis for Early Effort Prediction; Empirical Observations, Initial Application; A Practitioners Experience Report}},
year = {1995}
}
@inproceedings{shull02,
address = {Washington, DC, USA},
author = {Shull, Forrest and Basili, Victor and Carver, Jeffrey and Maldonado, Jos\'{e} C and Travassos, Guilherme Horta and Mendon\c{c}a, Manoel and Fabbri, Sandra},
booktitle = {ISESE '02: Proceedings of the 2002 International Symposium on Empirical Software Engineering},
isbn = {0-7695-1796-X},
pages = {7},
publisher = {IEEE Computer Society},
title = {{Replicating Software Engineering Experiments: Addressing the Tacit Knowledge Problem}},
year = {2002}
}
@incollection{bucsmi89,
author = {Buchanan, B G and Smith, R G},
booktitle = {The Handbook of Artificial Intelligence, Volume 4},
editor = {{A. Barr}, P R Cohen and Feigenbaum, E A},
pages = {149--192},
publisher = {Addison-Wesley},
title = {{Fundamentals of \{E\}xpert \{S\}ystems}},
volume = {4},
year = {1989}
}
@article{willems91,
author = {Willems, J L and Abreu-Lima, C and Arnaud, P and van Bemmel, J H and Brohet, C and Degani, R and Denis, B and Gehring, J and Graham, I and van Herpen, G},
journal = {The New England Journal of Medicine, December 19},
number = {25},
pages = {1767--1773},
title = {{The diagnostic performance of computer programs for the interpretation of electrocardiograms}},
volume = {325},
year = {1991}
}
@misc{nasa92,
title = {{\{NASA\} Headquarters Safety and Mission Quality Office (Code Q) letter of 13 January 1992; Clarification of NASA's Independent Verification and Validation (IV\&V) Perspective}},
year = {1992}
}
@article{ZheWeb00Lazy,
author = {Zheng, Zijian and Webb, Geoffrey I},
doi = {http://dx.doi.org/10.1023/A:1007613203719},
issn = {0885-6125},
journal = {Mach. Learn.},
number = {1},
pages = {53--84},
publisher = {Kluwer Academic Publishers},
title = {{Lazy Learning of Bayesian Rules}},
volume = {41},
year = {2000}
}
@inproceedings{bin07,
author = {Bin, L and Zhi-Shu, L and Yan-Hong, C and Bao-Lin, L},
booktitle = {Workshop of Computational Intelligence and Security Workshops, 2007, CISW 2007},
pages = {183--186},
title = {{Automatic Test Data Generation Tool Based on Genetic Simulated Annealing Algorithm}},
year = {2007}
}
@inproceedings{gaines89,
author = {Gaines, B R and Shaw, M L G},
booktitle = {IJCAI '89},
pages = {633--638},
title = {{Comparing the Conceptual Systems of Experts}},
year = {1989}
}
@article{fenton94,
author = {Fenton, N and Pfleeger, S L and Glass, R L},
journal = {IEEE Software},
month = jul,
pages = {86--95},
title = {{Science and \{S\}ubstance: A \{C\}hallenge to \{S\}oftware \{E\}ngineers}},
year = {1994}
}
@inproceedings{BOETTICHER2005,
address = {New York, NY, USA},
author = {Boetticher, Gary D},
booktitle = {PROMISE '05: Proceedings of the 2005 workshop on Predictor models in software engineering},
doi = {http://doi.acm.org/10.1145/1083165.1083173},
isbn = {-159593-125-2},
pages = {1--6},
publisher = {ACM},
title = {{Nearest neighbor sampling for better defect prediction}},
year = {2005}
}
@incollection{forbus92,
author = {Forbus, K},
booktitle = {Recent Advances in Qualitative Physics},
editor = {Faltings, B and Struss, P},
pages = {245--261},
publisher = {The MIT Press},
title = {{Pushing the Edge of the (QP) Envelope}},
year = {1992}
}
@article{me05c,
author = {Chen, Zhihao and Menzies, Tim and Port, Dan and Boehm, Barry},
journal = {IEEE Software},
month = nov,
title = {{Finding the Right Data for Software Cost Modeling}},
year = {2005}
}
@misc{boehm09,
author = {Boehm, B},
title = {{Future Challenges for Software Data Collection and Analysis}},
year = {2009}
}
@inproceedings{ang96,
author = {Angele, J and Fensel, D and Studer, R},
booktitle = {Domain Knowledge for Interactive System Design},
editor = {Et.al., A Sutcliffe},
publisher = {Chapman \& Hall},
title = {{Domain and Task Modelling in MIKE}},
year = {1996}
}
@inproceedings{me00m,
author = {Menzies, T J and Debenham, J},
booktitle = {Encyclopedia of Computer Science and Technology},
editor = {Kent, A and Williams, J G},
number = {27},
pages = {35--54},
publisher = {Marcell Dekker Inc.},
title = {{Expert Systems Maintenance}},
volume = {47},
year = {2000}
}
@article{Nebro2008,
author = {Nebro, Antonio J. and Luna, Francisco and Alba, Enrique and Dorronsoro, Bernab\'{E} and Durillo, Juan J. and Beham, Andreas},
doi = {10.1109/TEVC.2007.913109},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Nebro et al. - 2008 - AbYSS Adapting Scatter Search to Multiobjective Optimization.pdf:pdf},
issn = {1089-778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {diversity,external archive,hybridization,multiobjective optimization,pareto,performance comparison,scatter search},
mendeley-tags = {pareto},
month = aug,
number = {4},
pages = {439--457},
title = {{AbYSS: Adapting Scatter Search to Multiobjective Optimization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4455350},
volume = {12},
year = {2008}
}
@article{suwa82,
author = {Suwa, M and Scott, A C and Shortliffe, E H},
journal = {AI Magazine},
number = {4},
pages = {16--21},
title = {{Completeness and Consistency in Rule-Based Expert Systems}},
volume = {3},
year = {1982}
}
@article{wiel92,
author = {Wielinga, B J and Schreiber, A T and Breuker, J A},
journal = {Knowledge Acquisition},
pages = {1--162},
title = {{\{KADS\}: a \{M\}odeling \{A\}pproach to \{K\}nowledge \{E\}ngineering.}},
volume = {4},
year = {1992}
}
@book{bi05,
author = {editors. {S. Biffl A. Aurum}, B Boehm H Erogmus P Grï¿½nbacher},
publisher = {Springer},
title = {{Value-Based Software Engineering}},
year = {2005}
}
@inproceedings{glas95a,
author = {Glasgow, J and Papadias, D},
booktitle = {Diagrammatic Reasoning},
editor = {Glasgow, J and Narayanan, N H and Chandrasekaran, B},
pages = {435--480},
publisher = {The AAAI Press},
title = {{Computational Imagery}},
year = {1995}
}
@book{miller02,
author = {Miller, A},
isbn = {1-58488-171-2},
publisher = {Chapman \& Hall},
title = {{Subset Selection in Regression (second edition)}},
year = {2002}
}
@inproceedings{me09j,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09pom2.pdf\}},
author = {Lemon, B and Riesbeck, A and Menzies, T and Price, J and D'Alessandro, J and Carlsson, R and Prifiti, T and Peters, F and Lu, H and Port, D},
booktitle = {IEEE ASE'09},
title = {{Applications of Simulation and AI Search: Assessing the Relative Merits of Agile vs Traditional Software Development}},
year = {2009}
}
@inproceedings{abrahamsson07,
author = {Abrahamsson, P and Moser, R and Pedrycz, W and Sillitti, A and Succi, G},
booktitle = {First International Symposium on Empirical Software Engineering and Measurement (ESEM 2007)},
pages = {344--353},
title = {{Effort Prediction in Iterative Software Development Processes -- Incremental Versus Global Prediction Models}},
year = {2007}
}
@inproceedings{mega94,
author = {Menzies, T J and Gambetta, W},
booktitle = {ECAI '94 Workshop on Validation of Knowledge-Based Systems},
title = {{Exhaustive \{A\}bduction: A \{P\}ractical \{M\}odel \{V\}alidation \{T\}ool}},
year = {1994}
}
@article{adlassnig89,
author = {Adlassnig, K P and Scheithauer, W},
journal = {Computers and Biomedical Research},
number = {4},
pages = {297--313},
title = {{Performance evaluation of medical expert systems using ROC curves}},
volume = {22},
year = {1989}
}
@misc{boehm09a,
annote = {Keynote address, PROMISE'09},
author = {Boehm, B},
title = {{No Title}},
year = {2009}
}
@book{shull07,
editor = {{F. Shull J. Singer} and Sjoberg, D},
publisher = {Spring},
title = {{Guide to Advanced Empirical Software Engineering}},
year = {2007}
}
@misc{me96c,
author = {Menzies, T and Haynes, P},
title = {{Empirical Observations of Class-level Encapsulation and Inheritance}},
year = {1996}
}
@misc{Blake+Merz:1998,
author = {Blake, C L and Merz, C J},
institution = {University of California, Irvine, Dept. of Information and Computer Sciences},
title = {{\{UCI\} Repository of machine learning databases}},
year = {1998}
}
@inproceedings{owen03a,
author = {Owen, D and Menzies, T},
booktitle = {SEKE '03},
title = {{Lurch: a Lightweight Alternative to Model Checking}},
year = {2003}
}
@misc{robb98,
author = {Robbins, Jason E},
month = nov,
title = {{Design Critiquing Systems}},
year = {1998}
}
@misc{McCaugherty98,
author = {McCaugherty, D},
howpublished = {presentation by Averstar Inc.},
month = feb,
title = {{Criticality Analysis and Risk Assessment (CARA)}},
year = {1998}
}
@misc{BET93,
author = {Di\~{}Battista, G and Eades, P and Tamassia, R and Tollis, I},
institution = {Department of Computer Science, Brown University},
title = {{Algorithms for Drawing Graphs: An Annotated Bibliography}},
year = {1993}
}
@article{clark03,
annote = {Available from $\backslash$url\{http://www.brunel.ac.uk/\~{}csstrmh/papers/sbse.ps\}},
author = {Clark, J and Dolado, J J and Harman, M and Hierons, R M and Jones, B and Lumkin, M and Mitchell, B and Mancoridis, S and Rees, K and Roper, M and Shepperd, M},
journal = {IEE Proceedings on Software},
number = {3},
pages = {161--175},
title = {{Reformulating Software Engineering as a Search Problem}},
volume = {150},
year = {2003}
}
@article{brooks91,
author = {Brooks, R A},
journal = {Artificial Intelligence},
pages = {139--159},
title = {{Intelligence Without Representation}},
volume = {47},
year = {1991}
}
@phdthesis{elrawas08,
annote = {Available from $\backslash$url\{http://unbox.org/wisp/var/ous/thesis/thesis.pdf\}},
author = {El-Rawas, O},
school = {Lane Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{Software Process Control Without Calibration}},
year = {2008}
}
@article{Watson,
author = {Watson, Hugh J and Wixom, Barbara H},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Watson, Wixom - Unknown - Intelligence.pdf:pdf},
journal = {Idea},
title = {{Intelligence}}
}
@book{hamid91,
author = {Abdel-Hamid, T and Madnick, S},
isbn = {0-13-822040-9},
publisher = {Prentice-Hall Software Series},
title = {{Software Project Dynamics: An Integrated Approach}},
year = {1991}
}
@inproceedings{deb95a,
author = {Debenham, J},
booktitle = {Proceedings Sixth International Conference on Database and Expert Systems Applications DEXA'95, London, September},
title = {{Understanding Expert Systems Maintenance}},
year = {1995}
}
@inproceedings{hun97,
author = {Hunter, A and Nuseibeh, B},
booktitle = {International Symposium on Requirements Engineering},
pages = {78--86},
title = {{Analysing Inconsistent Specifications}},
year = {1997}
}
@article{cohen95w,
author = {Cohen, W W},
journal = {Automated Software Engineering},
pages = {107--129},
publisher = {Kluwer Academic Publishers},
title = {{Inductive Specification recovery: Understanding software by learning from example behaviors}},
volume = {2},
year = {1995}
}
@inproceedings{basili92,
annote = {LNCS 706, Springer-Verlag},
author = {Basili, V R},
booktitle = {Experimental Software Engineering Issues: Critical Assessment and Future Directions, International Workshop, Germany},
editor = {Rombach, H D and Basili, V R and Selby, R W},
pages = {3--12},
title = {{The Experimental Paradigm in Software Engineering}},
year = {1992}
}
@article{provost01,
author = {Provost, F and Fawcett, T},
journal = {Machine Learning},
month = mar,
number = {3},
title = {{Robust Classification for Imprecise Environments}},
volume = {42},
year = {2001}
}
@article{GOKHALE2010,
address = {Hingham, MA, USA},
author = {Gokhale, Swapna S and Mullen, Robert E},
doi = {http://dx.doi.org/10.1007/s10664-009-9115-y},
issn = {1382-3256},
journal = {Empirical Softw. Engg.},
number = {3},
pages = {296--319},
publisher = {Kluwer Academic Publishers},
title = {{A multiplicative model of software defect repair times}},
volume = {15},
year = {2010}
}
@article{fenton00b,
author = {Fenton, N and Ohlsson, N},
journal = {IEEE Transactions on Software Engineering},
month = aug,
pages = {797--814},
title = {{Quantitative Analysis of Faults and Failures in a Complex Software System}},
year = {2000}
}
@inproceedings{me91a,
author = {Compton, P and Edwards, G and Kang, B and Lazarus, L and Malor, R and Menzies, T and Preston, P and Srinivasan, A and Sammut, C},
booktitle = {6th Banff AAAI Knowledge Acquisition for Knowledge Based Systems},
title = {{Ripple down rules: possibilities and limitations}},
year = {1991}
}
@book{schank83,
address = {New York, NY, USA},
author = {Schank, Roger C},
isbn = {0521248582},
publisher = {Cambridge University Press},
title = {{Dynamic Memory: A Theory of Reminding and Learning in Computers and People}},
year = {1983}
}
@article{Thomas1994,
author = {Thomas, M and McGarry, F},
journal = {IEEE Software},
month = jul,
number = {4},
pages = {2},
title = {{Top-down vs. Bottom-up Process Improvement}},
volume = {11},
year = {1994}
}
@article{lutz01,
author = {Lutz, R},
journal = {Journal of Systems Architecture},
pages = {613--634},
title = {{Evolving good hierarchical decomposition of complex systems}},
volume = {47},
year = {2001}
}
@book{aho88,
author = {Aho, A V and Kernigham, B W and Wienberger, P J},
publisher = {Addison-Wesley},
title = {{The AWK Programming Language}},
year = {1988}
}
@article{coiera92,
author = {Coiera, E},
journal = {The Knowledge Engineering Review},
pages = {1--23},
title = {{The \{Q\}ualitative \{R\}epresentation of \{P\}hysical \{S\}ystems}},
volume = {7},
year = {1992}
}
@article{wu94,
author = {Wu, X},
journal = {Informatica: An International Journal of Computing and Informatics},
number = {2},
pages = {197--218},
title = {{Lecture notes in machine learning}},
volume = {18},
year = {1994}
}
@inproceedings{hoos00,
author = {Hoos, H H and Boutilier, C},
booktitle = {Proc. of AAAI-2000},
pages = {22--29},
publisher = {MIT Press},
title = {{Solving Combinatorial Auctions using Stochastic Local Search}},
year = {2000}
}
@article{saud89,
author = {Sanderson, P M and Verhapge, A G and Fuld, R B},
journal = {Ergonomics},
number = {11},
pages = {1343--1372},
title = {{State-space and Verbal Protocol Methods for Studying the Human Operator in Process Control}},
volume = {32},
year = {1989}
}
@inproceedings{lait02,
author = {Laitenberger, O},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{A Survey of Software inspection Techniques}},
year = {2002}
}
@inproceedings{comp98,
author = {Compton, P and Ramadan, Z and Preston, P and Le-Gia, T and V.Chellen and Mulholland, M and Hibbert, D B and Haddad, P R and Kang, B},
booktitle = {Banff Workshop on Knowledge Acquisition},
title = {{A Trade-off Between Domain Knowledge and Problem-Solving Method Power,}},
year = {1998}
}
@inproceedings{conf/ictai/TangK04,
author = {Tang, Wei and Khoshgoftaar, Taghi M},
booktitle = {ICTAI},
pages = {373--378},
title = {{Noise Identification with the k-Means Algorithm}},
url = {http://doi.ieeecomputersociety.org/10.1109/ICTAI.2004.93},
year = {2004}
}
@article{Hand2007b,
abstract = {Data mining is the discovery of interesting, unexpected or valuable structures in large datasets. As such, it has two rather different aspects. One of these concerns large-scale, 'global' structures, and the aim is to model the shapes, or features of the shapes, of distributions. The other concerns small-scale, 'local' structures, and the aim is to detect these anomalies and decide if they are real or chance occurrences. In the context of signal detection in the pharmaceutical sector, most interest lies in the second of the above two aspects; however, signal detection occurs relative to an assumed background model, therefore, some discussion of the first aspect is also necessary. This paper gives a lightning overview of data mining and its relation to statistics, with particular emphasis on tools for the detection of adverse drug reactions.},
author = {Hand, David J},
file = {:Users/timm/svns/doc/hand01.pdf:pdf},
issn = {0114-5916},
journal = {Drug safety : an international journal of medical toxicology and drug experience},
keywords = {Adverse Drug Reaction Reporting Systems,Adverse Drug Reaction Reporting Systems: organizat,Databases, Factual,Drug Industry,Humans,Information Systems,Information Systems: organization \& administration,Product Surveillance, Postmarketing},
month = jan,
number = {7},
pages = {621--2},
pmid = {17604416},
title = {{Principles of data mining.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17604416},
volume = {30},
year = {2007}
}
@misc{costello05,
author = {Costello, Kenneth},
title = {{Software Integrity Level Assessment Process (\{SILAP\}) , \{NASA\} \{IV\&V\} Facility}},
year = {2005}
}
@inproceedings{krieger80,
author = {Krieger, D T},
booktitle = {Neuroendocrinology},
editor = {Krieger, D T and Hughes, J C},
pages = {3--122},
publisher = {Sinauer Associates, Inc.},
title = {{The Hypothalmus and Neuroendocrinology}},
year = {1980}
}
@book{witten99,
author = {Witten, I H and Frank, E},
isbn = {1-55860-552-5},
publisher = {Morgan Kaufmann},
title = {{Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations}},
year = {1999}
}
@article{sendall03,
author = {Sendall, S and Kozacaynski, W},
journal = {IEEE Software},
number = {5},
pages = {42--45},
title = {{Model Transformation: The Heart and Soul of Model-Driven Software Development}},
volume = {20},
year = {2003}
}
@article{dennett95,
author = {Dennett, D C},
journal = {The New York Review of Books},
month = dec,
pages = {83},
title = {{'The Mystery of Consciousness': An Exchange}},
year = {1995}
}
@article{rich92,
author = {Rich, C and Feldman, Y A},
journal = {IEEE Transactions on Software Engineering},
month = jun,
number = {6},
pages = {451--469},
title = {{Seven Layers of Knowledge Represeentation and Reasoning in Support of Software Development}},
volume = {18},
year = {1992}
}
@book{davi91,
author = {Davison, A},
publisher = {The PARLOG Group, Dept. of Computing, Imperial College, London},
title = {{Design Issues for Logic-Programming-based Object-Oriented Languages}},
year = {1991}
}
@article{Malone1994,
author = {Malone, Thomas W and Crowston, Kevin},
file = {:Users/timm/svns/doc/malone94.pdf:pdf},
journal = {Computing},
number = {1},
title = {{The Interdisciplinary Study of Coordination}},
volume = {2},
year = {1994}
}
@inproceedings{shepperd07,
author = {Shepperd, M},
booktitle = {International Conference on Software Engineering 2007: Future of Software Engineering},
title = {{Software Project Economics: A Roadmap}},
year = {2007}
}
@misc{me01c,
author = {Menzies, T and Kiper, J D},
title = {{How to Argue Less}},
year = {2001}
}
@inproceedings{gotel97,
author = {Gotel, O and Finkelstein, A},
booktitle = {International Symposium on Requirements Engineering (RE'97)},
pages = {169--178},
title = {{Extended Requirements Traceability: Results of an Industrial Case Study}},
year = {1997}
}
@inproceedings{bandekar89,
author = {Bandekar, V R},
booktitle = {Artifical Intelligence in Engineering},
number = {2},
title = {{Causal Models for Diagnostic Reasoning}},
volume = {4},
year = {1989}
}
@inproceedings{feather08c,
author = {Feather, M S and Hicks, K A and Mackey, R M and Uckun, S},
booktitle = {IEEE International Conference on Requirements Engineering, Industrial Practice and Experience track Barcelona, Spain},
title = {{Guiding Technology Deployment Decisions using a Quantitative Requirements Analysis Technique}},
year = {2008}
}
@article{bobrow85,
author = {Bobrow, D G},
journal = {IEEE Transactions on Software Engineering},
month = nov,
number = {11},
pages = {1401--1408},
title = {{If Prolog is the Answer, What is the Question? or What it Takes to Support AI Programming Paradigms}},
volume = {11},
year = {1985}
}
@article{miller56,
annote = {Available from $\backslash$url\{http://www.well.com/\~{}smalin/miller.html\}},
author = {Miller, G A},
journal = {The Psychological Review},
pages = {81--97},
title = {{The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information}},
volume = {63},
year = {1956}
}
@article{Hughes1990a,
author = {Hughes, John},
file = {:Users/timm/svns/doc/hughes90.pdf:pdf},
number = {April 1989},
pages = {98--107},
title = {{Why Functional Programming Matters}},
volume = {32},
year = {1990}
}
@misc{moberg92,
author = {Moberg, D},
title = {{Personal comminication}},
year = {1992}
}
@inproceedings{bayana03,
author = {Bayana, S and Owen, D and Menzies, T and Mukhopadhyay, S},
title = {{God Does Play Dice: Diagnosis and Validation for Autonomous Systems}},
year = {2004}
}
@phdthesis{ma07,
author = {Ma, Y},
month = jan,
school = {West Virginia University, Lane Department of Computer Science and Electrical Engineering},
title = {{An Empirical Investigation of Tree Ensembles in Biometrics and Bioinformatics}},
year = {2007}
}
@inproceedings{FayIra93Multi,
author = {Fayyad, U M and Irani, I H},
booktitle = {Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence},
pages = {1022--1027},
title = {{Multi-interval Discretization of Continuous-valued Attributes for Classification Learning}},
year = {1993}
}
@book{hall92,
author = {P.A.V.Hall},
publisher = {Chapman \& Hall},
title = {{Software reuse and reverse engineering in practice}},
year = {1992}
}
@book{spinbook,
author = {Holzmann, G},
publisher = {Addison-Wesley},
title = {{\{T\}he \{SPIN\} \{M\}odel \{C\}hecker: \{P\}rimer and \{R\}eference \{M\}anual}},
year = {2003}
}
@inproceedings{mcallestor80,
author = {McAllester, D},
booktitle = {MIT AI Laboratory},
title = {{Memo 551, an outlook on truth maintenance}},
year = {1980}
}
@inproceedings{Guo2010,
annote = {Social metrics stuff.},
author = {Guo, PJ and Zimmermann, T and Nagappan, N},
booktitle = {Proceedings of the 32nd International Conference on Software Engineering},
file = {:Users/timm/svns/doc/guo10.pdf:pdf},
pages = {495--504},
title = {{Characterizing and predicting which bugs get fixed: An empirical study of microsoft windows}},
url = {http://portal.acm.org/citation.cfm?id=1806871},
year = {2010}
}
@inproceedings{yolanda97,
author = {Gil, Y and Tallis, M},
booktitle = {Proceedings of the Fourteenth National Conference on Artificial Intelligence (AAAI-97)},
title = {{A Script-Based Approach to Modifying Knowledge Bases}},
year = {1997}
}
@inproceedings{me96n,
author = {Menzies, T},
booktitle = {Proceedings of the ECAI '96 workshop on Validation, Verification, and Refinement of KBS},
title = {{Generalised Test = Generalised Inference}},
year = {1996}
}
@inproceedings{molo03,
author = {Molokken, K and Jorgensen, M},
booktitle = {ISESE'03},
title = {{A Review of Surveys on Software Effort Estimation}},
year = {2003}
}
@book{jones96,
author = {Jones, C},
publisher = {McGraw Hill},
title = {{Applied Software Measurement (second edition)}},
year = {1991}
}
@inproceedings{compton89,
author = {Compton, P and Horn, K and Quinlan, J R and Lazarus, L},
booktitle = {Applications of Expert Systems},
editor = {Quinlan, J R},
pages = {366--385},
publisher = {Addison Wesley},
title = {{Maintaining an Expert System}},
year = {1989}
}
@article{ichikawa90,
author = {Ichikawa, T and Chang, S K},
journal = {IEEE Transactions on Software Engineering},
number = {10},
pages = {1105--1197},
title = {{Special Issue on Visual Programming}},
volume = {16},
year = {1990}
}
@article{turing50,
author = {Turing, Alan M},
journal = {Mind},
month = oct,
pages = {433--460},
title = {{Computing machinery and intelligence}},
year = {1950}
}
@inproceedings{me97n,
author = {Menzies, T J},
booktitle = {Banff Knowledge Acquisition workshop, 1998},
title = {{Evaluation Issues for Problem Solving Methods}},
year = {1998}
}
@inproceedings{cox86,
author = {Cox, P T and Pietrzykowski, T},
booktitle = {8th International Conference on Automated Deduction},
pages = {608--621},
publisher = {Springer-Verlag},
title = {{Causes for Events: Their Computation and Applications}},
year = {1986}
}
@inproceedings{quinlan96,
address = {Berlin},
author = {Quinlan, J R},
booktitle = {Proceedings of the 7th International Workshop on Algorithmic Learning Theory},
editor = {Arikawa, Setsuo and Sharma, Arun K},
isbn = {3-540-61863-5},
pages = {143--155},
publisher = {Springer},
series = {LNAI},
title = {{Boosting first-order learning}},
volume = {1160},
year = {1996}
}
@inproceedings{greese99,
author = {v. Wangenheim, C Gresse and Althoff, K.-D. and Barcia, R},
booktitle = {Proceedings of SEKE '99},
title = {{Intelligent Retrieval of Software Engineering Experienceware}},
year = {1999}
}
@article{batarekh91,
author = {Batarekh, A and Preece, A D and Bennett, A and Grogono, P},
journal = {Expert Systems with Applications},
pages = {285--303},
title = {{Specifying an Expert System}},
volume = {2},
year = {1991}
}
@inproceedings{mul93,
author = {Mulholland, M and Preston, P and Hibbert, B and Compton, P},
booktitle = {Proceedings of the Sixth International Conference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems, Edinburgh},
title = {{An expert system for ion chromatography developed using machine learning and knowledge in context}},
year = {1996}
}
@misc{Coiera99,
annote = {Technical Report, 1999, to appear},
author = {Coiera, E},
institution = {Hewlett-Packard Laboratories},
title = {{Communication under scarcity of resources}},
year = {1999}
}
@article{DietrichWettscherreckDavidW.Aha1997,
author = {{Dietrich Wettscherreck, David W. Aha}, Takao Mohri},
file = {:Users/timm/svns/doc/a\_review\_and\_empirical\_evaluation\_of\_fea\_117226.pdf:pdf},
issn = {0269-2821},
journal = {Artificial Intelligence Review},
number = {1},
pages = {273--314},
publisher = {Springer},
title = {{A review and empirical evaluation of feature weighting methods for a class of lazy learning algorithms}},
url = {http://www.springerlink.com/index/R1323574686528KT.pdf},
volume = {11},
year = {1997}
}
@misc{atanacio01,
author = {Atanacio, B},
booktitle = {SEI, Carnegie Mellon University},
title = {{Modeling the Space Shuttle Liquid Hydrogen Subsystem}},
year = {2001}
}
@inproceedings{darden90,
author = {Darden, L},
booktitle = {Computational Models of Scientific Discovery and Theory Formation},
editor = {Sharager, J and Langley, P},
publisher = {Morgan Kaufmann Publishers Inc.},
title = {{Diagnosing and Fixing Faults in Theories}},
year = {1990}
}
@article{srinivasan95,
author = {Srinivasan, K and Fisher, D},
journal = {IEEE Trans. Soft. Eng.},
month = feb,
pages = {126--137},
title = {{Machine Learning Approaches to Estimating Software Development Effort}},
year = {1995}
}
@inproceedings{me95za,
author = {Menzies, T J},
booktitle = {Proceedings of the Melbourne Workshop on Intelligent Decision Support Department of Information Systems Monash University, Caulfield Campus, Melbourne Monday, March 20, 1995},
title = {{Applications of Abduction \#1: Intelligent Decision Support Systems.}},
year = {1995}
}
@book{ok90,
author = {O'Keefe, R A},
publisher = {MIT Press},
title = {{The Craft of Prolog}},
year = {1990}
}
@inproceedings{QWFENG95a,
author = {Feng, Q W and Cohen, R F and Eades, P},
booktitle = {Proc. of the Third European Symposium on Algorithms},
publisher = {Springer-Verlag},
series = {Lecture Notes in Computer Science},
title = {{Planarity for Clustered Graphs}},
year = {1995}
}
@inproceedings{born89,
author = {Borning, A and Maher, M and Martindale, A and Wilson, W},
booktitle = {Proceedings of Sixth International Logic Programming Conference Lisbon, Portugal},
pages = {149--164},
title = {{Constraint Hierachies and Logic Programming}},
year = {1989}
}
@inproceedings{corn02,
author = {Cornford, S and Dunphy, J and Feather, M S},
booktitle = {IEEE Aerospace Conference, Big Sky Montana},
month = mar,
pages = {9--16},
title = {{Optimizing the Design of end-to-end Spacecraft Systems using risk as a currency}},
year = {2002}
}
@article{myers77,
author = {Myers, G J},
journal = {Communications of the ACM},
pages = {760--768},
title = {{A Controlled Experiment in Program Testing and Code Walkthroughs/Inspections}},
volume = {21},
year = {1977}
}
@inproceedings{lum02,
author = {Lum, K and Powell, J and Hihn, J},
booktitle = {ISPA Conference Proceedings, Software Modeling Track},
month = may,
title = {{Validation of Spacecraft Software Cost Estimation Models for Flight and Ground Systems}},
year = {2002}
}
@article{gar95,
author = {Garzotto, F and Mainetti, L and Paolini, P},
journal = {Communications of the ACM},
month = aug,
number = {8},
pages = {74--86},
title = {{Hypermedia Design Analysis and Evaluation Issues}},
volume = {38},
year = {1995}
}
@inproceedings{have01,
author = {Havelund, K and Rosu, G},
booktitle = {The 6th International Symposium on AI, Robotics and Automation in Space},
month = may,
title = {{Java PathExplorer - A Runtime Verification Tool}},
year = {2001}
}
@inproceedings{me99h,
author = {Menzies, T and Cukic, B and Coiera, E},
booktitle = {AAAI'99 workshop on Conflicts and Identifying Opportunities.},
title = {{Smaller, Faster Dialogues via Conversational Probing}},
year = {1999}
}
@article{me00d,
author = {Menzies, T and Cukic, B},
journal = {International Journal on Artificial Intelligence Tools (IJAIT)},
month = jun,
title = {{Adequacy of Limited Testing for Knowledge Based Systems}},
year = {2000}
}
@article{me98d,
author = {Menzies, T J and Clancey, B},
journal = {International Journal of Human-Computer Studies},
title = {{Editorial, Special Issue on Situated Cognition}},
volume = {49},
year = {1998}
}
@article{Kim2001,
author = {Kim, Yang Sok and Kang, Sung Won and Kang, Byeong Ho and Compton, Paul},
file = {:Users/timm/svns/doc/kang09.pdf:pdf},
journal = {Knowledge Creation Diffusion Utilization},
keywords = {mcrdr,scheduling,web monitoring},
pages = {169--180},
title = {{Using Knowledge Base for Event-Driven Scheduling of Web Monitoring Systems}},
year = {2001}
}
@article{Robson2002,
author = {Robson, C},
journal = {Blackwell Publisher Ltd},
title = {{Real world research: a resource for social scientists and practitioner-researchers}},
year = {2002}
}
@article{Babu2001,
author = {Babu, T.R. and Murty, M.N.},
file = {:Users/timm/svns/doc/gaProtoSelect.pdf:pdf},
journal = {Pattern Recognition},
number = {2},
pages = {523--525},
publisher = {Elsevier Ltd},
title = {{Comparison of genetic algorithm based prototype selection schemes}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Comparison+of+genetic+algorithm+based+prototype+selection+schemes\#0},
volume = {34},
year = {2001}
}
@misc{Boetticher2007,
author = {Boetticher, G and Menzies, T and Ostrand, T},
title = {{PROMISE}}
}
@inproceedings{FayIra93Multi,
author = {Fayyad, U M and Irani, I H},
booktitle = {Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence},
pages = {1022--1027},
title = {{Multi-interval Discretization of Continuous-valued Attributes for Classification Learning}},
year = {1993}
}
@article{Boehm2003,
author = {Boehm, Barry},
journal = {Software Engineering Notes},
number = {2},
pages = {1--12},
title = {{Value-Based Software Engineering}},
volume = {28},
year = {2003}
}
@article{Finnie1996,
address = {Washington, DC, USA},
author = {Finnie, Gavin R and Wittig, Gerhard E},
isbn = {0-8186-7379-6},
journal = {SEEP '96: Proceedings of the 1996 International Conference on Software Engineering: Education and Practice (SE:EP '96)},
pages = {346},
publisher = {IEEE Computer Society},
title = {{AI Tools for Software Development Effort Estimation}},
year = {1996}
}
@article{Li2009a,
author = {Li, Y and Xie, M and T., Goh},
journal = {Empirical Software Engineering},
pages = {603--643},
title = {{A study of the non-linear adjustment for analogy based software cost estimation}},
year = {2009}
}
@inproceedings{Shepperd2007,
author = {Shepperd, Martin},
booktitle = {FOSE '07: 2007 Future of Software Engineering},
pages = {304--315},
title = {{Software project economics: a roadmap}},
year = {2007}
}
@article{Beeferman2000,
author = {Beeferman, D and Berger, A},
journal = {In Knowledge Discovery and Data Mining},
pages = {407--416},
title = {{Agglomerative clustering of a search engine query log}},
year = {2000}
}
@inproceedings{Juristo2009,
author = {Juristo, Natalia and Vegas, Sira},
booktitle = {International Symposium on Empirical Software Engineering and Measurement},
pages = {356--366},
title = {{Using Differences among Replications of Software Engineering Experiments to Gain Knowledge}},
year = {2009}
}
@inproceedings{Juristo2009,
author = {Juristo, Natalia and Vegas, Sira},
booktitle = {International Symposium on Empirical Software Engineering and Measurement},
pages = {356--366},
title = {{Using Differences among Replications of Software Engineering Experiments to Gain Knowledge}},
year = {2009}
}
@inproceedings{gama06,
address = {New York, NY, USA},
author = {Gama, Joao and Pinto, Carlos},
booktitle = {SAC '06: Proceedings of the 2006 ACM symposium on Applied computing},
file = {:Users/timm/svns/doc/pinto05.pdf:pdf},
pages = {662--667},
publisher = {ACM Press},
title = {{Discretization from data streams: applications to histograms and data mining}},
year = {2006}
}
@article{Myrtveit,
author = {Myrtveit, I and Stensrud, E and Shepperd, M},
journal = {IEEE Transactions on Software Engineering},
month = may,
pages = {31no5pp380----391},
title = {{Reliability and validity in comparative studies of software prediction models}},
volume = {vol},
year = {2005}
}
@article{Basili1996,
address = {Piscataway, NJ, USA},
author = {Basili, Victor R and Briand, Lionel C and Melo, Walc$\backslash$'elio L},
doi = {http://dx.doi.org/10.1109/32.544352},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
pages = {751--761},
title = {{A Validation of Object-Oriented Design Metrics as Quality Indicators}},
volume = {22},
year = {1996}
}
@inproceedings{Kultur2008,
address = {New York, NY, USA},
author = {Kultur, Yigit and Turhan, Burak and Bener, Ayse Basar},
booktitle = {SIGSOFT '08/FSE-16: Proceedings of the 16th ACM SIGSOFT International Symposium on Foundations of software engineering},
pages = {330--338},
title = {{ENNA: software effort estimation using ensemble of neural networks with associative memory}},
year = {2008}
}
@article{Atkinson1994,
author = {Atkinson, K and Shepperd, M J},
journal = {in Proc. European Software Cost Modelling Meeting . Ivrea, Italy},
title = {{The use of function points to find cost analogies}},
year = {1994}
}
@book{Boehm1981,
address = {Upper Saddle River, NJ, USA},
author = {Boehm, Barry W},
isbn = {0138221227},
publisher = {Prentice Hall PTR},
title = {{Software Engineering Economics}},
year = {1981}
}
@misc{jpl2008,
title = {{Next NASA Mars Mission Rescheduled For 2011}},
year = {2008}
}
@article{Review2000,
author = {Review, The Knowledge Engineering},
journal = {Review Literature And Arts Of The Americas},
pages = {257--284},
title = {{Building large-scale Bayesian networks}},
volume = {15},
year = {2000}
}
@article{Eisen,
author = {Eisen, M B and Spellman, P T and Brown, P O and Botstein, D},
journal = {Proc. of the National Academy of Science},
pages = {14863--14868},
title = {{Cluster Analysis and Display of Genome-Wide Expression Patterns}},
volume = {95},
year = {1998}
}
@article{Jorgensen2003,
address = {New York, NY, USA},
author = {Jorgensen, Magne},
doi = {http://doi.acm.org/10.1145/966221.966238},
journal = {SIGSOFT Softw. Eng. Notes},
pages = {5},
title = {{How much does a vacation cost?: or what is a software cost estimate?}},
volume = {28},
year = {2003}
}
@inproceedings{Li2007,
author = {Li, Jingzhou and Ruhe, Guenther},
booktitle = {PROMISE '07: Proceedings of the Third International Workshop on Predictor Models in Software Engineering},
pages = {6},
title = {{Decision Support Analysis for Software Effort Estimation by Analogy}},
year = {2007}
}
@inproceedings{Frank03,
author = {Frank, Eibe and Hall, Mark and Pfahringer, Bernhard},
booktitle = {Proceedings of the Conference on Uncertainty in Artificial Intelligence},
pages = {249--256},
publisher = {Morgan Kaufmann},
title = {{Locally Weighted Naive Bayes}},
year = {2003}
}
@inproceedings{Jiang2008a,
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim},
booktitle = {ISSRE '08: Proceedings of the 2008 19th International Symposium on Software Reliability Engineering},
pages = {197--206},
title = {{Cost Curve Evaluation of Fault Prediction Models}},
year = {2008}
}
@book{Alpaydin2004,
author = {Alpaydin, Ethem},
publisher = {MIT Press},
title = {{Introduction to Machine Learning}},
year = {2004}
}
@article{Stewart2002,
author = {Stewart, B},
doi = {10.1002/smr.250},
journal = {Journal of Software Maintenance and Evolution: Research and Practice},
keywords = {bayesian networks,machine learning,model trees,neural networks,software effort estimation},
month = may,
number = {3},
pages = {161--179},
title = {{Predicting project delivery rates using the Naive-Bayes classifier}},
volume = {14},
year = {2002}
}
@book{rumel86,
author = {Rumelhart, David E and {McClelland James}, L and {the PDP Research Group}},
publisher = {MIT Press},
title = {{Parallel distributed processing: explorations in the microstructure vol. 2}},
year = {1986}
}
@article{Premraj2007,
author = {Premraj, Rahul and Zimmermann, Thomas},
journal = {ESEM},
title = {{Building Software Cost Estimation Models using Homogenous Data}},
year = {2007}
}
@article{chulani99,
author = {Chulani, Sunita and Boehm, Barry and Steece, Bert},
file = {::},
journal = {IEEE Trans. Softw. Eng.},
number = {4},
pages = {573--583},
title = {{Bayesian Analysis of Empirical Software Engineering Cost Models}},
volume = {25},
year = {1999}
}
@article{myrtveit05,
author = {Myrtveit, Ingunn and Stensrud, Erik and Shepperd, Martin},
journal = {IEEE Transactions on Software Engineerining},
month = may,
number = {5},
pages = {380--391},
title = {{Reliability and Validity in Comparative Studies of Software Prediction Models}},
volume = {31},
year = {2005}
}
@article{angelis00,
address = {Hingham, MA, USA},
author = {Angelis, L and Stamelos, I},
issn = {1382-3256},
journal = {Empirical Softw. Engg.},
number = {1},
pages = {35--68},
publisher = {Kluwer Academic Publishers},
title = {{A Simulation Tool for Efficient Analogy Based Cost Estimation}},
volume = {5},
year = {2000}
}
@inproceedings{Korte2008,
author = {Korte, Marcel and Port, Dan},
booktitle = {PROMISE '08: Proceedings of the 4th international workshop on Predictor models in software engineering},
file = {::},
pages = {63--70},
title = {{Confidence in software cost estimation results based on MMRE and PRED}},
year = {2008}
}
@article{Fenton1994,
author = {Fenton, Norman},
journal = {IEEE Transactions on Software Engineering},
number = {3},
title = {{Software Measurement: A Necessary Scientific Basis}},
volume = {20},
year = {1994}
}
@inproceedings{Yiftachel2006,
address = {New York, NY, USA},
author = {Yiftachel, Peleg and Peled, Dan and Hadar, Irit and Goldwasser, Dan},
booktitle = {EDSER '06: Proceedings of the 2006 international workshop on Economics driven software engineering research},
doi = {http://doi.acm.org/10.1145/1139113.1139124},
isbn = {1-59593-396-4},
pages = {43--48},
title = {{Resource allocation among development phases: an economic approach}},
year = {2006}
}
@article{Menzies2005a,
address = {New York, NY, USA},
author = {Menzies, Tim and Port, Dan and Chen, Zhihao and Hihn, Jairus and Stukes, Sherry},
doi = {http://doi.acm.org/10.1145/1062455.1062559},
isbn = {1-59593-963-2},
journal = {ICSE '05: Proceedings of the 27th international conference on Software engineering},
pages = {587--595},
publisher = {ACM},
title = {{Validation methods for calibrating software effort models}},
year = {2005}
}
@inproceedings{quinlan96,
address = {Berlin},
author = {Quinlan, J R},
booktitle = {Proceedings of the 7th International Workshop on Algorithmic Learning Theory},
editor = {Arikawa, Setsuo and Sharma, Arun K},
isbn = {3-540-61863-5},
pages = {143--155},
publisher = {Springer},
series = {LNAI},
title = {{Boosting first-order learning}},
volume = {1160},
year = {1996}
}
@book{Boehm2000a,
address = {Upper Saddle River, NJ, USA},
author = {Boehm, Barry W and Abts, Chris and Brown, A Winsor and Chulani, Sunita and Clark, Bradford K and Horowitz, Ellis and Madachy, Ray and Reifer, Donald J and Steece, Bert},
isbn = {0130266922},
publisher = {Prentice Hall PTR},
title = {{Software Cost Estimation with Cocomo II}},
year = {2000}
}
@article{Kirsopp2002a,
address = {San Francisco, CA, USA},
author = {Kirsopp, Colin and Shepperd, Martin J and Hart, John},
isbn = {1-55860-878-8},
journal = {GECCO '02: Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1367--1374},
publisher = {Morgan Kaufmann Publishers Inc.},
title = {{Search Heuristics, Case-based Reasoning And Software Project Effort Prediction}},
year = {2002}
}
@inproceedings{lum02,
author = {Lum, K and Powell, J and Hihn, J},
booktitle = {ISPA Conference Proceedings, Software Modeling Track},
month = may,
title = {{Validation of Spacecraft Software Cost Estimation Models for Flight and Ground Systems}},
year = {2002}
}
@article{Kadoda2001,
author = {Shepperd, M and Kadoda, G},
journal = {IEEE Transactions on Software Engineering},
pages = {1014--1022},
title = {{Comparing Software Prediction Models Using Simulation}},
year = {2001}
}
@article{chang74,
author = {Chang, C L},
journal = {IEEE Trans. on Computers},
pages = {1179--1185},
title = {{Finding Prototypes for Nearest Neighbor Classifiers}},
year = {1974}
}
@article{Lipowezky1998,
author = {Lipowezky, U.},
journal = {Pattern Recognition Letters},
keywords = {global optimization,optimal prototype subset,single hypercube,test sample set},
number = {10},
pages = {907--918},
publisher = {Elsevier},
title = {{Selection of the optimal prototype subset for 1-NN classification}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865598000750},
volume = {19},
year = {1998}
}
@article{keung2008b,
address = {Piscataway, NJ, USA},
author = {Keung, Jacky Wai and Kitchenham, Barbara A and Jeffery, David Ross},
doi = {http://dx.doi.org/10.1109/TSE.2008.34},
file = {::},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {4},
pages = {471--484},
publisher = {IEEE Press},
title = {{Analogy-X: Providing Statistical Inference to Analogy-Based Software Cost Estimation}},
volume = {34},
year = {2008}
}
@article{Huang2002,
author = {Huang, YS and Chiang, CC and Shieh, JW and Grimson, E.},
journal = {Pattern Recognition},
keywords = {classi\"{y}cation oriented error function,competitive learning,neural,prototype construction,prototype optimization},
number = {6},
pages = {1237--1245},
publisher = {Elsevier},
title = {{Prototype optimization for nearest-neighbor classification}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320301001248},
volume = {35},
year = {2002}
}
@inproceedings{quinlan92b,
author = {Quinlan, J R},
booktitle = {5th Australian Joint Conference on Artificial Intelligence},
pages = {343--348},
title = {{Learning with Continuous Classes}},
year = {1992}
}
@article{Kirsopp2003,
author = {Kirsopp, C. and Shepperd, M. and House, R.L.},
journal = {Research and development in intelligent systems XIX: proceedings of ES2002, the twenty-second SGAI International Conference on Knowledge Based Systems and Applied Artificial Intelligence},
pages = {61},
publisher = {Springer-Verlag New York Inc},
title = {{Case and feature subset selection in case-based software project effort prediction}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Case+and+Feature+Subset+Selection+in+Case-+Based+Software+Project+Effort+Prediction\#0},
year = {2003}
}
@article{park08,
author = {Park, Heejun and Baek, Seung},
journal = {Expert Syst. Appl.},
number = {3},
pages = {929--937},
title = {{An empirical validation of a neural network model for software effort estimation}},
volume = {35},
year = {2008}
}
@article{Stensrud,
address = {Hingham, MA, USA},
author = {Stensrud, Erik and Foss, Tron and Kitchenham, Barbara and Myrtveit, Ingunn},
doi = {http://dx.doi.org/10.1023/A:1023010612345},
issn = {1382-3256},
journal = {Empirical Softw. Engg.},
number = {2},
pages = {139--161},
publisher = {Kluwer Academic Publishers},
title = {{A Further Empirical Investigation of the Relationship Between MRE and Project Size}},
volume = {8},
year = {2003}
}
@article{kemerer87,
author = {Kemerer, C F},
file = {::},
journal = {Communications of the ACM},
month = may,
number = {5},
pages = {416--429},
title = {{An Empirical Validation of Software Cost Estimation Models}},
volume = {30},
year = {1987}
}
@inproceedings{lum06,
author = {Lum, K and Hihn, J and Menzies, T},
booktitle = {ISPA Conference Proceedings},
title = {{Sudies in Software Cost Model Behavior: Do we Really Understand Cost Model Performance?}},
year = {2006}
}
@phdthesis{baker07,
author = {Baker, Dan},
file = {:Users/timm/svns/doc/cost/07Baker.pdf:pdf},
school = {Lane Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{A Hybrid Approach to Expert and Model-based Effort Estimation}},
year = {2007}
}
@article{Menzies2006a,
address = {Los Alamitos, CA, USA},
author = {Menzies, Tim and Hihn, Jairus},
doi = {http://dx.doi.org/10.1109/MS.2006.99},
issn = {0740-7459},
journal = {IEEE Softw.},
number = {4},
pages = {64--66},
publisher = {IEEE Computer Society Press},
title = {{Evidence-Based Cost Estimation for Better-Quality Software}},
volume = {23},
year = {2006}
}
@inproceedings{Yang2008,
address = {New York, NY, USA},
annote = {for related work: 6,10,11,12,18},
author = {Yang, Ye and He, Mei and Li, Mingshu and Wang, Qing and Boehm, Barry},
booktitle = {ESEM '08: Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
doi = {http://doi.acm.org/10.1145/1414004.1414016},
isbn = {978-1-59593-971-5},
pages = {61--69},
title = {{Phase distribution of software development effort}},
year = {2008}
}
@article{Lum2008,
author = {Lum, Karen and Menzies, Tim and Baker, Dan},
journal = {ISPA / SCEA},
number = {May},
pages = {12--14},
title = {{2CEE, A TWENTY FIRST CENTURY EFFORT ESTIMATION METHODOLOGY}},
year = {2008}
}
@article{Kadoda2000,
author = {Kadoda, G and Cartwright, M and Shepperd, M},
journal = {UK CBR Workshop, Cambridge, UK},
pages = {1--10},
title = {{On configuring a case-based reasoning software project prediction system}},
year = {2000}
}
@inproceedings{Menzies2005,
address = {New York, NY, USA},
author = {Menzies, Tim and Port, Dan and Chen, Zhihao and Hihn, Jairus and Stukes, Sherry},
booktitle = {ICSE '05: Proceedings of the 27th international conference on Software Engineering},
doi = {http://doi.acm.org/10.1145/1062455.1062559},
isbn = {1-59593-963-2},
pages = {587--595},
publisher = {ACM},
title = {{Validation methods for calibrating software effort models}},
year = {2005}
}
@inproceedings{Jiang2008,
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim and Bartlow, Nick},
booktitle = {Proceedings, PROMISE 2008},
pages = {11--18},
title = {{Comparing Design and Code Metrics for Software Quality Prediction}},
year = {2008}
}
@article{Kasten2007,
author = {Kasten, Eric P and Mckinley, Philip K},
journal = {IEEE Transactions on Knowledge and Data Engineering},
number = {4},
pages = {485--499},
title = {{MESO: Supporting Online Decision Making in Autonomic Computing Systems}},
volume = {19},
year = {2007}
}
@article{Li2008,
author = {Li, Jingzhou and Ruhe, Guenther},
doi = {10.1007/s10664-007-9054-4},
journal = {Learning},
pages = {63--96},
title = {{Analysis of attribute weighting heuristics for analogy-based software effort estimation method AQUA +}},
year = {2008}
}
@article{Mendes2003,
author = {Mendes, Emilia and Watson, Ian D and Triggs, Chris and Mosley, Nile and Counsell, Steve},
journal = {Empirical Software Engineering},
number = {2},
pages = {163--196},
title = {{A Comparative Study of Cost Estimation Models for Web Hypermedia Applications}},
volume = {8},
year = {2003}
}
@inproceedings{Milic2004,
author = {Milic, Drazen and Wohlin, Claes},
booktitle = {Euromicro},
title = {{Distribution Patterns of Effort Estimations}},
year = {2004}
}
@misc{CLCS03,
author = {Spareref.com},
title = {{NASA to Shut Down Checkout \& Launch Control System}}
}
@article{Boehm2000,
author = {Boehm, Barry and Abts, Chris and Chulani, Sunita},
journal = {Annals of Software Engineering},
pages = {177--205},
title = {{Software development cost estimation approaches â A survey}},
volume = {10},
year = {2000}
}
@inproceedings{1321676,
address = {New York, NY, USA},
author = {Menzies, Tim and Elrawas, Oussama and Hihn, Jairus and Feather, Martin and Madachy, Ray and Boehm, Barry},
booktitle = {ASE '07: Proceedings of the twenty-second IEEE/ACM international conference on Automated software engineering},
doi = {http://doi.acm.org/10.1145/1321631.1321676},
file = {::},
isbn = {978-1-59593-882-4},
pages = {303--312},
title = {{The business case for automated software engineering}},
year = {2007}
}
@article{Demsar2006,
author = {Demsar, J},
journal = {Journal of Machine Learning Research},
title = {{Statistical comparisons of classifiers over multiple data sets}},
volume = {7},
year = {2006}
}
@inproceedings{Shepperd1996,
address = {Washington, DC, USA},
author = {Shepperd, Martin and Schofield, Chris and Kitchenham, Barbara},
booktitle = {ICSE '96: Proceedings of the 18th international conference on Software engineering},
file = {::},
isbn = {0-8186-7246-3},
pages = {170--178},
publisher = {IEEE Computer Society},
title = {{Effort estimation using analogy}},
year = {1996}
}
@inproceedings{me06f,
annote = {Available from $\backslash$url\{http://menzies.us/06deviations.pdf\}},
author = {Menies, T and Lum, K and Hihn, J},
booktitle = {PROMISE, 2006},
title = {{The Deviance Problem in Effort Estimation}},
year = {2006}
}
@article{Menzies2008,
author = {Menzies, Tim and Elrawas, Oussama and Boehm, Barry and Madachy, Raymond and Hihn, Jairus and Baker, Daniel and Lum, Karen},
file = {::},
journal = {ICSP},
pages = {210--221},
title = {{Accurate Estimates without Calibration?}},
year = {2008}
}
@article{Foss,
author = {Foss, T and Stensrud, E and Kitchenham, B and Myrtveit, I},
journal = {IEEE Transactions on Software Engineering},
title = {{A simulation study of the model evaluation criterion MMRE}},
year = {2003}
}
@inproceedings{Briand1999,
address = {New York, NY, USA},
author = {Briand, Lionel C and {El Emam}, Khaled and Surmann, Dagmar and Wieczorek, Isabella and Maxwell, Katrina D},
booktitle = {ICSE '99: Proceedings of the 21st international conference on Software engineering},
doi = {http://doi.acm.org/10.1145/302405.302647},
file = {::},
isbn = {1-58113-074-0},
pages = {313--322},
publisher = {ACM},
title = {{An assessment and comparison of common software cost estimation modeling techniques}},
year = {1999}
}
@article{kleijnen97,
author = {Kliijnen, J P C},
journal = {Journal Statistical Computation and Simulation},
number = {1--4},
pages = {111--142},
title = {{Sensitivity Analysis and Related Analyses: a Survey of Statistical Techniques}},
volume = {57},
year = {1997}
}
@article{Member1997,
author = {Member, Senior},
journal = {IEEE Transactions on Software Engineering},
number = {3},
pages = {1996--1997},
title = {{Comments on Towards a Framework for Software Measurement Validationï¿½}},
volume = {23},
year = {1997}
}
@inproceedings{keung2008a,
address = {New York, NY, USA},
author = {Keung, Jacky},
booktitle = {ESEM '08: Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
doi = {http://doi.acm.org/10.1145/1414004.1414057},
isbn = {978-1-59593-971-5},
pages = {294--296},
publisher = {ACM},
title = {{Empirical evaluation of analogy-x for software cost estimation}},
year = {2008}
}
@article{Lokan2001,
address = {Los Alamitos, CA, USA},
author = {Lokan, Chris and Wright, Terry and Hill, Peter R and Stringer, Michael},
doi = {http://dx.doi.org/10.1109/52.951491},
issn = {0740-7459},
journal = {IEEE Softw.},
number = {5},
pages = {26--32},
publisher = {IEEE Computer Society Press},
title = {{Organizational Benchmarking Using the ISBSG Data Repository}},
volume = {18},
year = {2001}
}
@article{ferens98,
author = {Ferens, D and Christensen, D},
journal = {Journal of Parametrics},
month = nov,
number = {1},
pages = {55--74},
title = {{Calibrating Software Cost Models to Department of Defense Database: A Review of Ten Studies}},
volume = {18},
year = {1998}
}
@article{Albrecht1983,
author = {Albrecht, A and Gaffney, J},
file = {:Users/timm/svns/doc/83albrecht.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
number = {6},
pages = {639--648},
title = {{Software function, source lines of code and development effort prediction: A software science validation}},
volume = {9},
year = {1983}
}
@article{Menzies2006,
author = {Menzies, Tim and Chen, Zhihao and Hihn, Jairus and Lum, Karen},
doi = {10.1109/TSE.2006.114},
file = {::},
journal = {IEEE Transactions on Software Engineering},
keywords = {data mining,effort estimation method,heuristic rejection rule,project management,software cost estimation,standard statistical method,statistical analysisCOSEEKMO toolkit},
number = {11},
pages = {883--895},
title = {{Selecting Best Practices for Effort Estimation}},
volume = {32},
year = {2006}
}
@article{Briand1992,
author = {Briand, Lionel C},
journal = {IEEE Transactions on Software Engineering},
number = {11},
pages = {931--942},
title = {{A Pattern Recognition Approach for Software Engineering Data Analysis}},
volume = {18},
year = {1992}
}
@article{Kitchenham2001,
author = {Kitchenham, B A and Pickard, L M and Macdonell, S G and Shepperd, M J},
file = {::},
journal = {IEEE Proceedings-Software},
number = {3},
pages = {101049/ip----sen20010506},
title = {{What accuracy statistics really measure}},
volume = {148},
year = {2001}
}
@article{shepperd01,
author = {Shepperd, M and Kadoda, Gada F},
journal = {IEEE Trans. Software Eng},
number = {11},
pages = {1014--1022},
title = {{Comparing Software Prediction Techniques Using Simulation}},
volume = {27},
year = {2001}
}
@inproceedings{vent93,
author = {Venkatachalam, A R},
booktitle = {Proceedings of international joint conference on neural networks},
pages = {987--990},
title = {{Software cost estimation using artificial neural networks}},
year = {1993}
}
@article{Jorgensen2009,
author = {Jorgensen, M and Gruschke, T M},
journal = {IEEE Transactions on Software Engineering},
number = {3},
pages = {368--383},
title = {{The Impact of Lessons-Learned Sessions on Effort Estimation and Uncertainty Assessments}},
volume = {35},
year = {2009}
}
@article{Li2007,
author = {Li, Jingzhou and Ruhe, Guenther and Al-emran, Ahmed and Richter, Michael M},
doi = {10.1007/s10664-006-7552-4},
journal = {Empirical Software Engineering},
pages = {65--106},
title = {{A exible method for software effort estimation by analogy}},
year = {2007}
}
@phdthesis{Desharnais1989,
author = {Desharnais, J},
school = {Univ. of Montreal},
title = {{Analyse Statistique de la Productivitie des Projets Informatique a Partie de la Technique des Point des Fonction}},
year = {1989}
}
@inproceedings{keung2008c,
address = {Washington, DC, USA},
author = {Keung, Jacky and Kitchenham, Barbara},
booktitle = {ASWEC '08: Proceedings of the 19th Australian Conference on Software Engineering},
isbn = {978-0-7695-3100-7},
pages = {229--238},
publisher = {IEEE Computer Society},
title = {{Experiments with Analogy-X for Software Cost Estimation}},
year = {2008}
}
@incollection{nus96,
author = {Nuseibeh, B},
booktitle = {Proc. of 8th IEEE International Workshop on Software Specification \& Design (IWSSD-8)},
pages = {164--169},
title = {{To Be and Not to Be: On Managing Inconsistency in Software Development}},
year = {1996}
}
@inproceedings{briand00,
author = {Briand, L C and Langley, T and Wieczorek, I},
booktitle = {Proceedings of the 22nd International Conference on Software Engineering, Limerick, Ireland},
pages = {377--386},
title = {{A replicated assessment and comparison of common software cost modeling techniques}},
year = {2000}
}
@book{303873,
address = {Boston, MA, USA},
author = {Kruchten, Philippe},
isbn = {0-201-60459-0},
title = {{The Rational Unified Process: an introduction}},
year = {1999}
}
@misc{shepperd07,
author = {Shepperd, Martin},
title = {{Personnel communication on the value of different evaluation criteria}},
year = {2007}
}
@article{Auer2006,
author = {Auer, Martin and Trendowicz, Adam and Graser, Bernhard and Haunschmid, Ernst and Biffl, Stefan},
journal = {IEEE Transactions on Software Engineering},
number = {2},
pages = {83--92},
title = {{Optimal Project Feature Weights in Analogy-Based Cost Estimation: Improvement and Limitations}},
volume = {32},
year = {2006}
}
@article{Shepperd1997,
address = {Piscataway, NJ, USA},
author = {Shepperd, Martin and Schofield, Chris},
doi = {http://dx.doi.org/10.1109/32.637387},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {11},
pages = {736--743},
publisher = {IEEE Press},
title = {{Estimating Software Project Effort Using Analogies}},
volume = {23},
year = {1997}
}
@article{Li2006,
author = {Li, J and Ruhe, G},
journal = {Proceedings of the 2006 ACM/IEEE international symposium on Empirical software engineering},
pages = {74},
publisher = {ACM},
title = {{A comparative study of attribute weighting heuristics for effort estimation by analogy}},
url = {http://portal.acm.org/citation.cfm?id=1159733.1159746},
year = {2006}
}
@article{Mendes2007,
address = {Piscataway, NJ, USA},
annote = {Member-Kitchenham, Barbara A.},
author = {Kitchenham, Barbara and Mendes, Emilia and Travassos, Guilherme H},
doi = {http://dx.doi.org/10.1109/TSE.2007.1001},
file = {::},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {5},
pages = {316--329},
publisher = {IEEE Press},
title = {{Cross versus Within-Company Cost Estimation Studies: A Systematic Review}},
volume = {33},
year = {2007}
}
@inproceedings{Steinbach00,
author = {Steinbach, Michael and Karypis, George and Kumar, Vipin},
booktitle = {KDD Workshop on Text Mining},
title = {{A comparison of document clustering techniques}},
year = {2000}
}
@article{hall03,
author = {Hall, M A and Holmes, G},
file = {:Users/timm/svns/doc/03hall.pdf:pdf},
journal = {IEEE Transactions On Knowledge And Data Engineering},
number = {6},
pages = {1437--1447},
title = {{Benchmarking Attribute Selection Techniques for Discrete Class Data Mining}},
volume = {15},
year = {2003}
}
@inproceedings{319657,
address = {Los Alamitos, CA, USA},
author = {Miyazaki, Yukio and Mori, Kuniaki},
booktitle = {ICSE '85: Proceedings of the 8th international conference on Software engineering},
isbn = {0-8186-0620-7},
pages = {292--299},
title = {{COCOMO evaluation and tailoring}},
year = {1985}
}
@book{byrson69,
address = {New York},
author = {{Arthur Earl Bryson}, Yu-Chi Ho},
publisher = {Hemisphere Pub. Corp.},
title = {{Applied optimal control: Optimization, estimation, and control}},
year = {1969}
}
@book{Kolodner1993,
address = {San Francisco, CA, USA},
author = {Kolodner, Janet},
isbn = {1-55860-237-2},
publisher = {Morgan Kaufmann Publishers Inc.},
title = {{Case-based reasoning}},
year = {1993}
}
@inproceedings{Kitchenham2009,
address = {New York, NY, USA},
author = {Kitchenham, Barbara and Mendes, Emilia},
booktitle = {PROMISE '09: Proceedings of the 5th International Conference on Predictor Models in Software Engineering},
doi = {http://doi.acm.org/10.1145/1540438.1540444},
file = {::},
isbn = {978-1-60558-634-2},
pages = {1--5},
publisher = {ACM},
title = {{Why comparative effort prediction studies may be invalid}},
year = {2009}
}
@article{Li2006a,
author = {Li, Jingzhou and Ruhe, Guenther},
journal = {Comparative and General Pharmacology},
pages = {66--74},
title = {{A Comparative Study of Attribute Weighting Heuristics for Effort Estimation by Analogy}},
year = {2006}
}
@inproceedings{Heijstek2007,
author = {Heijstek, Werner and Chaudron, Michel R V},
booktitle = {2nd Workshop on Model Size Metrics},
title = {{Effort Distribution in Model-Based Development}},
year = {2007}
}
@article{Walter,
author = {Walter, B. and Bala, K. and Kulkarni, M. and Pingali, K.},
journal = {IEEE Symposium on Interactive Ray Tracing (RT)},
keywords = {agglomerative clustering,bottom-up tree construction,bounding volume hierarchy,dendogram,lightcuts rendering},
pages = {2--7},
title = {{Fast agglomerative clustering for rendering}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Fast+Agglomerative+Clustering+for+Rendering\#0},
year = {2008}
}
@article{JÃ¸rgensen2004,
author = {J\o rgensen, M},
doi = {10.1016/S0164-1212(02)00156-5},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {e ort estimation,expert judgment,project planning,software development},
month = feb,
number = {1-2},
pages = {37--60},
title = {{A review of studies on expert estimation of software development effort}},
volume = {70},
year = {2004}
}
@article{Walkerden1999,
address = {Hingham, MA, USA},
author = {Walkerden, Fiona and Jeffery, Ross},
doi = {http://dx.doi.org/10.1023/A:1009872202035},
issn = {1382-3256},
journal = {Empirical Softw. Engg.},
number = {2},
pages = {135--158},
publisher = {Kluwer Academic Publishers},
title = {{An Empirical Study of Analogy-based Software Effort Estimation}},
volume = {4},
year = {1999}
}
@article{Li2009,
author = {LI, Y and XIE, M and GOH, T},
doi = {10.1016/j.jss.2008.06.001},
file = {::},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {analogy based estimation,software cost estimation},
month = feb,
number = {2},
pages = {241--252},
title = {{A study of project selection and feature weighting for analogy based software cost estimation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0164121208001325},
volume = {82},
year = {2009}
}
@article{Guha1998,
author = {Guha, S and Rastogi, R and Cure, K Shim.},
journal = {In In Proceedings of ACM SIGMOD International Conference on Management of Data},
pages = {73--84},
title = {{An efficient clustering algorithm for large databases}},
volume = {pages},
year = {1998}
}
@article{Bakir2009,
author = {Bakir, Ayse and Turhan, Burak and Bener, Ayse},
doi = {10.1007/s11219-009-9081-z},
journal = {Software Quality Journal},
title = {{A new perspective on data homogeneity in software cost estimation: A study in the embedded systems domain}},
url = {http://dx.doi.org/10.1007/s11219-009-9081-z},
year = {2009}
}
@article{Kirsopp2002,
author = {Kirsopp, C. and Shepperd, M.},
doi = {10.1049/ip-sen},
journal = {IEE Proc.},
number = {5},
title = {{Making inferences with small numbers of training sets}},
volume = {149},
year = {2002}
}
@article{Fenton1991,
address = {London, UK, UK},
author = {Fenton, Norman E},
isbn = {0442313551},
publisher = {Chapman \& Hall, Ltd.},
title = {{Software Metrics: A Rigorous Approach}},
year = {1991}
}
@article{Jorgensen2007,
address = {Piscataway, NJ, USA},
author = {Jorgensen, Magne and Shepperd, Martin},
doi = {http://dx.doi.org/10.1109/TSE.2007.3},
issn = {0098-5589},
journal = {IEEE Trans. Softw. Eng.},
number = {1},
pages = {33--53},
publisher = {IEEE Press},
title = {{A Systematic Review of Software Development Cost Estimation Studies}},
volume = {33},
year = {2007}
}
@inproceedings{YanWeb02Comparative,
author = {Yang, Ying and Webb, Geoffrey I},
booktitle = {Proceedings of PKAW 2002: The 2002 Pacific Rim Knowledge Acquisition Workshop},
pages = {159--173},
title = {{A Comparative Study of Discretization Methods forNaive-Bayes Classifiers}},
year = {2002}
}
@article{Wang2009,
author = {Wang, Y and Song, Q and MacDonell, S and Shepperd, M and Shen, J},
journal = {IEEE Transactions on Systems},
pages = {647--658},
title = {{Integrate the GM(1,1) and Verhulst Models to Predict Software Stage-Effort}},
volume = {39},
year = {2009}
}
@inproceedings{me03k,
abstract = { Traditional methods of generating quality code indicators (e.g. linear regression, decision tree induction) can be demonstrated to be inappropriate for IV\&amp;V purposes. IV\&amp;V is a unique aspect of the software lifecycle, and different methods are necessary to produce quick and accurate results. If quality code indicators could be produced on a per-project basis, then IV\&amp;V could proceed in a more straight-forward fashion, saving time and money. We present one case study on just such a project, showing that by using the proper metrics and machine learning algorithms, quality indicators can be found as early as 3 months into the IV\&amp;V process.},
author = {Menzies, T. and Stefano, J.S. Di and Chapman, M.},
booktitle = {Proceedings. 5th International Workshop on Enterprise Networking and Computing in Healthcare Industry (IEEE Cat. No.03EX717)},
doi = {10.1109/METRIC.2003.1232458},
isbn = {0-7695-1987-3},
issn = {1530-1435},
title = {{Learning early lifecycle IV \&amp;amp; V quality indicators}},
year = {2003}
}
@inproceedings{me11e,
abstract = {The practices of industrial and academic data mining are very different. These differences have significant implications for (a) how we manage industrial data mining projects; (b) the direction of academic studies in data mining; and (c) training programs for engineers who seek to use data miners in an industrial setting.},
address = {New York, NY, USA},
author = {Menzies, Tim and Bird, Christian and Zimmermann, Thomas and Schulte, Wolfram and Kocaganeli, Ekrem},
booktitle = {Proceedings of the International Workshop on Machine Learning Technologies in Software Engineering SE - MALETS '11},
doi = {10.1145/2070821.2070824},
isbn = {978-1-4503-1022-2},
keywords = {inductive engineering,industry},
pages = {19--26},
publisher = {ACM},
series = {MALETS '11},
title = {{The inductive software engineering manifesto: principles for industrial data mining}},
url = {citeulike-article-id:10194816$\backslash$nhttp://dx.doi.org/10.1145/2070821.2070824$\backslash$nhttp://portal.acm.org/citation.cfm?id=2070824},
year = {2011}
}
@inproceedings{me92m,
author = {Mahidadia, a J and Compton, P and Menzies, T J and Sammut, C and Smythe, G a},
booktitle = {AI '92, Horbart, Australia},
publisher = {World-Scientific},
title = {{Inventing Causal Qualitative Models: A Tool for Experimental Research}},
year = {1992}
}
@article{Lin2013a,
abstract = {The Internet has provided IS researchers with the opportunity to conduct studies with extremely large sam- ples, frequently well over 10,000 observations. There are many advantages to large samples, but researchers using statistical inference must be aware of the p-value problem associated with them. In very large samples, p-values go quickly to zero, and solely relying on p-values can lead the researcher to claim support for results of no practical significance. In a survey of large sample IS research, we found that a significant number of papers rely on a low p-value and the sign of a regression coefficient alone to support their hypotheses. This research commentary recommends a series of actions the researcher can take to mitigate the p-value problem in large samples and illustrates them with an example of over 300,000 camera sales on eBay. We believe that addressing the p-value problem will increase the credibility of large sample IS research as well as provide more insights for readers.},
author = {Lin, Mingfeng and Lucas, Henry C},
doi = {http://dx.doi.org/10.1287/isre.2013.0480},
file = {:Users/timm/svns/doc/13problemsWithPValues.pdf:pdf},
issn = {1047-7047},
journal = {Information Systems Research},
keywords = {2 weeks for 1,2012,alok gupta,and was with the,authors,effect size,empirical modeling,history,in advance,inference,on august 15,p -value,practical significance,published online in articles,revision,senior editor,statistical significance,this paper was received},
pages = {1--12},
title = {{Too Big to Fail : Large Samples and the p -Value Problem}},
volume = {7047},
year = {2013}
}
@book{gleick87,
author = {Gleick, J},
pages = {352},
publisher = {Cardinal},
title = {{Chaos}},
year = {1987}
}
@misc{fowl02,
abstract = {In the past few years there's been a blossoming of a new style of software methodology - referred to as agile methods. Alternatively characterized as an antidote to bureaucracy or a license to hack they've stirred up interest all over the software landscape. In this essay I explore the reasons for agile methods, focusing not so much on their weight but on their adaptive nature and their people-first orientation.},
author = {Fowler, Martin},
title = {{The New Methodology}},
url = {http://www.martinfowler.com/articles/newMethodology.html},
year = {2005}
}
@article{liu10,
abstract = {A novel search-based approach to software quality modeling with multiple software project repositories is presented. Training a software quality model with only one software measurement and defect data set may not effectively encapsulate quality trends of the development organization. The inclusion of additional software projects during the training process can provide a cross-project perspective on software quality modeling and prediction. The genetic-programming-based approach includes three strategies for modeling with multiple software projects: Baseline Classifier, Validation Classifier, and Validation-and-Voting Classifier. The latter is shown to provide better generalization and more robust software quality models. This is based on a case study of software metrics and defect data from seven real-world systems. A second case study considers 17 different (nonevolutionary) machine learners for modeling with multiple software data sets. Both case studies use a similar majority-voting approach for predicting fault-proneness class of program modules. It is shown that the total cost of misclassification of the search-based software quality models is consistently lower than those of the non-search-based models. This study provides clear guidance to practitioners interested in exploiting their organization's software measurement data repositories for improved software quality modeling.},
author = {Liu, Yi and Khoshgoftaar, Taghi M. and Seliya, Naeem},
doi = {10.1109/TSE.2010.51},
file = {:Users/timm/svns/doc/transfer/10liu.pdf:pdf},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Genetic programming,defects,machine learning,optimization,software measurement,software quality},
number = {6},
pages = {852--864},
title = {{Evolutionary optimization of software quality modeling with multiple repositories}},
volume = {36},
year = {2010}
}
@inproceedings{me03m,
author = {Menzies, Tim and Ammar, Kareem},
booktitle = {Tech report, Computer Science, Portland State University},
keywords = {artificial intelligence,defect detectors,empirical studies and metrics,fault models,feature subset selection,learning,metrics,nents analysis,principal compo-,product metrics,software testing and verification},
pages = {1--28},
title = {{How Simple is Software Defect Detection ?}},
year = {2003}
}
@inproceedings{koc13b,
author = {Kocaguneli, Ekrem and Cukic, Bojan and Menzies, Tim and Lu, Huihua},
booktitle = {PROMSE'13},
month = oct,
title = {{Building a Second Opinion: Learning Cross-Company Data}},
year = {2013}
}
@inproceedings{me02h,
author = {Menzies, Tim and Owen, David and Cukic, Bojan},
booktitle = {October},
issn = {03029743},
pages = {1--12},
title = {{You seem friendly , but can I trust you ?}},
year = {2002}
}
@inproceedings{me03b,
author = {Liu, Y and Menzies, T and Cukic, B},
title = {{Detecting Novelties by Mining Association Rules}},
year = {2003}
}
@article{Nicholls2008a,
abstract = {Two essential aspects of virtual screening are considered: experimental design and performance metrics. In the design of any retrospective virtual screen, choices have to be made as to the purpose of the exercise. Is the goal to compare methods? Is the interest in a particular type of target or all targets? Are we simulating a âreal-worldâ setting, or teasing out distinguishing features of a method? What are the confidence limits for the results? What should be reported in a publication? In particular, what criteria should be used to decide between different performance metrics? Comparing the field of molecular modeling to other endeavors, such as medical statistics, criminology, or computer hardware evaluation indicates some clear directions. Taken together these suggest the modeling field has a long way to go to provide effective assessment of its approaches, either to itself or to a broader audience, but that there are no technical reasons why progress cannot be made.},
author = {Nicholls, Anthony},
doi = {10.1007/s10822-008-9170-2},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Nicholls2007.pdf:pdf},
isbn = {1082200891},
issn = {0920654X},
journal = {Journal of Computer-Aided Molecular Design},
keywords = {AUC,Metrics,ROC curves,Statistics,Virtual screening},
number = {3-4},
pages = {239--255},
pmid = {18253702},
title = {{What do we know and when do we know it?}},
volume = {22},
year = {2008}
}
@phdthesis{me95,
author = {Menzies, T J},
school = {University of New South Wales},
title = {{Principles for Generalised Testing of Knowledge Bases}},
year = {1995}
}
@article{jorgensen09,
abstract = {Inaccurate estimates of software development effort is a frequently reported cause of IT-project failures. We report results from a study that investigated the effect of introducing lessons-learned sessions on estimation accuracy and the assessment of uncertainty. Twenty software professionals were randomly allocated to a Learning group or a Control group and instructed to estimate and complete the same five development tasks. Those in the Learning group but not those in the Control group were instructed to spend at least 30 minutes on identifying, analyzing, and summarizing their effort estimation and uncertainty assessment experience after completing each task. We found that the estimation accuracy and the realism of the uncertainty assessment were not better in the Learning group than in the Control group. A follow-up study with 83 software professionals was completed to better understand this lack of improvement from lessons-learned sessions. The follow-up study found that receiving feedback about other software professionals' estimation performance led to more realistic uncertainty assessments than receiving the same feedback of one's own estimates. Lessons-learned sessions, not only in estimation contexts, have to be carefully designed to avoid wasting resources on learning processes that stimulate rather than reduce learning biases.},
author = {J\o rgensen, Magne and Gruschke, Tanja M.},
doi = {10.1109/TSE.2009.2},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Cost estimation,Process implementation and change,Review and evaluation,Software psychology},
number = {3},
pages = {368--383},
title = {{The impact of lessons-learned sessions on effort estimation and uncertainty assessments}},
volume = {35},
year = {2009}
}
@inproceedings{pohl11,
abstract = {The formalization of variability models (e.g. feature models) is a prerequisite for the automated analysis of these models. The efficient execution of the analysis operations depends on the selection of well-suited solver implementations. Regarding feature models, on the one hand, the formalization with Boolean expressions enables the use of SAT or BDD solvers. On the other hand, feature models can be transformed into a Constraint-Satisfaction Problem (CSP) in order to use CSP solvers for validation. This paper presents a performance comparison regarding nine contemporary high-performance solvers, three for each base problem structure (BDD, CSP, and SAT). Four operations on 90 feature models are run on each solver. The results will in turn clear the way for new improvements regarding the automatic verification of software product lines, since the efficient execution of analysis operations is essential to such automatic verification approaches. Â© 2011 IEEE.},
author = {Pohl, Richard and Lauenroth, Kim and Pohl, Klaus},
booktitle = {2011 26th IEEE/ACM International Conference on Automated Software Engineering, ASE 2011, Proceedings},
doi = {10.1109/ASE.2011.6100068},
file = {:Users/timm/svns/doc/11featureMaps.pdf:pdf},
isbn = {9781457716393},
issn = {1938-4300},
keywords = {automated reasoning techniques,feature model,performance measurement,software product line},
pages = {313--322},
title = {{A performance comparison of contemporary algorithmic approaches for automated analysis operations on feature models}},
year = {2011}
}
@misc{me98g,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/99ab.pdf\}},
author = {Menzies, T and Waugh, S},
title = {{Abduction: Experiments and Implications}},
year = {1999}
}
@article{yann00,
abstract = {In this study we present a review of the emerging field of meta-knowledge components as practised over the past decade among a variety of practitioners. We use the artificially-defined term `meta-knowledge' to encompass all those different but overlapping notions used by the Artificial Intelligence and Software Engineering communities to represent reusable modelling frameworks: ontologies, problem-solving methods, experience factories and experience bases, patterns, to name a few. We then elaborate on how meta-knowledge is deployed in the context of system's design to improve its reliability by consistency checking, enhance its reuse potential, and manage its knowledge sharing. We speculate on its usefulness and explore technologies for supporting deployment of meta-knowledge. We argue that, despite the different approaches being followed in systems design by divergent communities, meta-knowledge is present in all cases, in a tacit or explicit form, and its utilisation depends on pragmatic aspects which we try to identify and critically review on criteria of effectiveness.},
author = {Kalfoglou, Yannis and Menzies, Tim and Althoff, Klaus-Dieter and Motta, Enrico},
doi = {10.1017/S0269888900004033},
issn = {0269-8889},
journal = {The Knowledge Engineering Review},
month = dec,
number = {4},
title = {{Meta-Knowledge in systems design: panacea ...or undelivered promise?}},
url = {http://eprints.soton.ac.uk/260533/},
volume = {15},
year = {2000}
}
@article{me10d,
abstract = {There exists a large and growing number of proposed estimation methods but little conclusive evidence ranking one method over another. Prior effort estimation studies suffered from  conclusion instability , where the rankings offered to different methods were not stable across (a)Â different evaluation criteria; (b)Â different data sources; or (c)Â different random selections of that data. This paper reports a study of 158 effort estimation methods on data sets based on COCOMO features. Four  best  methods were detected that were consistently better than the  rest  of the other 154 methods. These rankings of  best  and  rest  methods were stable across (a)Â three different evaluation criteria applied to (b)Â multiple data sets from two different sources that were (c)Â divided into hundreds of randomly selected subsets using four different random seeds. Hence, while there exists no single universal  best  effort estimation method, there appears to exist a small number (four) of most useful methods. This result both complicates and simplifies effort estimation research. The complication is that any future effort estimation analysis should be preceded by a  selection study  that finds the best local estimator. However, the simplification is that such a study need not be labor intensive, at least for COCOMO style data sets.},
author = {Menzies, Tim and Jalali, Omid and Hihn, Jairus and Baker, Dan and Lum, Karen},
doi = {10.1007/s10515-010-0070-z},
issn = {09288910},
journal = {Automated Software Engineering},
keywords = {COCOMO,Data mining,Effort estimation,Evaluation},
month = dec,
number = {4},
pages = {409--437},
title = {{Stable rankings for different effort models}},
volume = {17},
year = {2010}
}
@article{Morik2012a,
abstract = {Large media collections rapidly evolve in the World Wide Web. In addition to the targeted retrieval as is performed by search engines, browsing and explorative navigation is an important issue. Since the collections grow fast and authors most often do not annotate their web pages according to a given ontology, automatic structuring is in demand as a prerequisite for any pleasant human-computer interface. In this paper, we investigate the problem of finding alternative high-quality structures for navigation in a large collection of high-dimensional data. We express desired properties of frequent termset clustering \{(FTS)\} in terms of objective functions. In general, these functions are conflicting. This leads to the formulation of \{FTS\} clustering as a multi-objective optimization problem. The optimization is solved by a genetic algorithm. The result is a set of Pareto-optimal solutions. Users may choose their favorite type of a structure for their navigation through a collection or explore the different views given by the different optimal solutions. We explore the capability of the new approach to produce structures that are well suited for browsing on a social bookmarking data set.},
author = {Morik, Katharina and Kaspari, Andreas and Wurst, Michael and Skirzynski, Marcin},
doi = {10.1007/s10115-011-0431-3},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/morik08.pdf:pdf},
isbn = {1011501104},
issn = {02191377},
journal = {Knowledge and Information Systems},
keywords = {Collaborative clustering,Distributed data mining,Ensemble clustering,Multi-media collections},
number = {3},
pages = {715--738},
title = {{Multi-objective frequent termset clustering}},
volume = {30},
year = {2012}
}
@article{kampenes07,
abstract = {An effect size quantifies the effects of an experimental treatment. Conclusions drawn from hypothesis testing results might be erroneous if effect sizes are not judged in addition to statistical significance. This paper reports a systematic review of 92 controlled experiments published in 12 major software engineering journals and conference proceedings in the decade 1993â2002. The review investigates the practice of effect size reporting, summarizes standardized effect sizes detected in the experiments, discusses the results and gives advice for improvements. Standardized and/or unstandardized effect sizes were reported in 29\% of the experiments. Interpretations of the effect sizes in terms of practical importance were not discussed beyond references to standard conventions. The standardized effect sizes computed from the reviewed experiments were equal to observations in psychology studies and slightly larger than standard conventions in behavioral science.},
author = {Kampenes, Vigdis By and Dyb\aa, Tore and Hannay, Jo E. and Sj\o berg, Dag I.K.},
doi = {10.1016/j.infsof.2007.02.015},
file = {:Users/timm/svns/doc/erin/references/ClusterQuality/EffectSizeKampenes07.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
number = {11-12},
pages = {1073--1086},
title = {{A systematic review of effect size in software engineering experiments}},
volume = {49},
year = {2007}
}
@techreport{kang90a,
abstract = {Successful software reuse requires the systematic discovery and ex- ploitation of commonality across related software systems. By examining related software systems and the underlying theory of the class of systems they repre- sent, domain analysis can provide a generic description of the requirements of that class of systems and a set of approaches for their implementation. This re- port will establish methods for performing a domain analysis and describe the products of the domain analysis process. To illustrate the application of domain analysis to a representative class of software systems, this report will provide a domain analysis of window management system software.},
author = {Cohen, Sholom G and Hess, James a and Novak, William E and Peterson, a Spencer},
booktitle = {Distribution},
doi = {10.1080/10629360701306050},
institution = {Carnegie-Mellon University, Software Engineering Institute},
isbn = {1111111111},
issn = {1062936X},
number = {November},
pmid = {17514565},
title = {{Feasibility Study Feature-Oriented Domain Analysis (FODA)}},
year = {1990}
}
@article{albrecht83,
abstract = { One of the most important problems faced by software developers and users is the prediction of the size of a programming system and its development effort. As an alternative to "size," one might deal with a measure of the "function" that the software is to perform. Albrecht [1] has developed a methodology to estimate the amount of the "function" the software is to perform, in terms of the data it is to use (absorb) and to generate (produce). The "function" is quantified as "function points," essentially, a weighted sum of the numbers of "inputs," "outputs,"master files," and "inquiries" provided to, or generated by, the software. This paper demonstrates the equivalence between Albrecht's external input/output data flow representative of a program (the "function points" metric) and Halstead's [2] "software science" or "software linguistics" model of a program as well as the "soft content" variation of Halstead's model suggested by Gaffney [7].},
author = {a.J. Albrecht and Gaffney, J.E., Jr.},
doi = {10.1109/TSE.1983.235271},
file = {:Users/timm/svns/doc/83albrecht.pdf:pdf},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Cost estimating,function points,software linguistics},
month = nov,
number = {6},
pages = {639--648},
title = {{Software Function, Source Lines of Code, and Development Effort Prediction: A Software Science Validation}},
volume = {SE-9},
year = {1983}
}
@inproceedings{kohavi96,
author = {Jiang, L. and Wang, D. and Cai, Z. and Jiang, S. and Yan, X.},
booktitle = {International Journal of Computers and Applications},
doi = {10.2316/Journal.202.2009.1.202-2453},
issn = {1925-7074},
number = {1},
pages = {202--207},
title = {{Scaling Up the Accuracy of K -Nearest-Neighbour Classifiers: a Naive-Bayes Hybrid}},
volume = {31},
year = {2009}
}
@inproceedings{me00m,
author = {Menzies, T J and Debenham, J},
booktitle = {Encyclopedia of Computer Science and Technology},
editor = {Kent, A and Williams, J G},
number = {27},
pages = {35--54},
publisher = {Marcell Dekker Inc.},
title = {{Expert Systems Maintenance}},
volume = {47},
year = {2000}
}
@inproceedings{me92k,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/ai92.pdf\}},
author = {Menzies, T J},
booktitle = {Proceedings of AI '92, Australia},
title = {{Maintaining Procedural Knowledge: Ripple-Down-Functions}},
year = {1992}
}
@inproceedings{me03p,
abstract = { One of the goals of verification and validation (V\&amp;V) activities for online adaptive control systems is providing assurance that they are able to detect novel system behaviors and provide adequate (safe) control actions. Novel (or abnormal) system behaviors cannot be enumerated or fully and explicitly described in requirements documentation. Therefore, they have to be observed and recognized during the operation. Novelty detection methods, therefore, provide an adequate approach for the V\&amp;V purposes. We propose a novelty detection method based on support sector data description (SVDD) as a candidate approach for validating adaptive control systems. As a one-class classifier, the support vector data description is able to form a decision boundary around the learned data domain with very little or no knowledge of data points outside the boundary (outliers). We apply the SVDD techniques for novelty detection as part of the validation on an intelligent flight control system (IFCS). Experimental results show that the SVDD can be adopted as an effective tool for finding indications of the safe region for the learned domain, whereby we are able to separate faulty behavior from normal events.},
author = {Liu, Yan Liu Yan and Gururajan, S. and Cukic, B. and Menzies, T. and Napolitano, M.},
booktitle = {Proceedings. 15th IEEE International Conference on Tools with Artificial Intelligence},
doi = {10.1109/TAI.2003.1250215},
isbn = {0-7695-2038-3},
issn = {1082-3409},
title = {{Validating an online adaptive system using SVDD}},
year = {2003}
}
@inproceedings{me04e,
author = {Menzies, T and Pecheur, C},
booktitle = {Advances in Computing},
editor = {Zelkowtiz, M},
publisher = {Elsevier},
title = {{Verification and \{V\}alidation and \{A\}rtificial \{I\}ntelligence}},
volume = {65},
year = {2005}
}
@article{emse12,
abstract = {The goal of science is conclusion stability, i.e. to discover some effect X that holds in multiple situations. Sadly, there are all too few examples of stable conclusions in software engineering (SE). In fact, the typical result is conclusion instability where what is true for project one, does not hold for project two. We can find numerous studies of the following form: there is as much evidence for as against the argument that some aspect X adds value to a software project. Below are four examples of this type of problem which we believe to be endemic within SE.},
author = {Menzies, Tim and Shepperd, Martin},
doi = {10.1007/s10664-011-9193-5},
issn = {13823256},
journal = {Empirical Software Engineering},
number = {1-2},
pages = {1--17},
title = {{Special issue on repeatable results in software engineering prediction}},
volume = {17},
year = {2012}
}
@book{Johnson2009a,
author = {Johnson, J G},
booktitle = {Perspectives on cognition and action in sport},
file = {:Users/timm/svns/doc/11mehlhorn.pdf:pdf},
isbn = {9789036753227},
pages = {171--180},
title = {{Cognitive models of athlete decision making      }},
year = {2009}
}
@misc{gay07,
author = {Gay, G and Menzies, T},
institution = {Lane Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{Under- vs Over- Sampling for C4.5 and Naive Bayes Defect Predictors}},
year = {2007}
}
@inproceedings{Ohlemacher2011b,
abstract = {There has been a great deal of research into the use of Information Retrieval (IR)-based techniques to support concept location in source code. Much of this research has been focused on determining how to use various IR techniques to support concept location. Very little attention has been given to the effect of different configurations of corpus building and indexing on query results. In this paper, we propose a tool designed to support large-scale studies of IR techniques in varying configurations of parameters with the intention of automatically calibrating these parameters. We also discuss preliminary efforts to create the benchmark data such studies require.},
address = {Kingston, ON, Canada},
annote = {Laura. Fixed on 09/25/2012},
author = {Ohlemacher, Scott and Marcus, Andrian},
booktitle = {19th IEEE International Conference on Program Comprehension (ICPC'11)},
keywords = {information\_retrieval concept\_feature\_concern\_loca},
pages = {1017263},
title = {{Towards a Benchmark and Automatic Calibration for IR-Based Concept Location How is Information Retrieval used for Concept OUR PROPOSED APPROACH : THE IR-TUNING TOOL SET}}
}
@article{jones98az,
abstract = {In many engineering optimization problems, the number of function evaluations is severely limited by time or cost. These problems pose a special challenge to the field of global optimization, since existing methods often require more function evaluations than can be comfortably afforded. One way to address this challenge is to fit response surfaces to data collected by evaluating the objective and constraint functions at a few points. These surfaces can then be used for visualization, tradeoff analysis, and optimization. In this paper, we introduce the reader to a response surface methodology that is especially good at modeling the nonlinear, multimodal functions that often occur in engineering. We then show how these approximating functions can be used to construct an efficient global optimization algorithm with a credible stopping rule. The key to using response surfaces for global optimization lies in balancing the need to exploit the approximating surface (by sampling where it is minimized) with the need to improve the approximation (by sampling where prediction error may be high). Striking this balance requires solving certain auxiliary problems which have previously been considered intractable, but we show how these computational obstacles can be overcome.},
address = {Hingham, MA, USA},
author = {Jones, Dr and Schonlau, Matthias and Welch, Wj},
doi = {10.1023/a:1008306431147},
isbn = {0925-5001},
issn = {09255001},
journal = {Journal of Global optimization},
keywords = {bayesian global optimization,kriging,process,random function,response surface,stochastic,visualization},
month = dec,
number = {4},
pages = {455--492},
pmid = {21858987},
publisher = {Kluwer Academic Publishers},
title = {{Efficient global optimization of expensive black-box functions}},
url = {http://www.springerlink.com/index/M5878111M101017P.pdf$\backslash$nhttp://link.springer.com/article/10.1023/A:1008306431147},
volume = {13},
year = {1998}
}
@article{koc11b,
abstract = {Background: There are too many design options for software effort estimators. How can we best explore them all? Aim: We seek aspects on general principles of effort estimation that can guide the design of effort estimators. Method: We identified the essential assumption of analogy-based effort estimation, i.e., the immediate neighbors of a project offer stable conclusions about that project. We test that assumption by generating a binary tree of clusters of effort data and comparing the variance of supertrees versus smaller subtrees. Results: For 10 data sets (from Coc81, Nasa93, Desharnais, Albrecht, ISBSG, and data from Turkish companies), we found: 1) The estimation variance of cluster subtrees is usually larger than that of cluster supertrees; 2) if analogy is restricted to the cluster trees with lower variance, then effort estimates have a significantly lower error (measured using MRE, AR, and Pred(25) with a Wilcoxon test, 95 percent confidence, compared to nearest neighbor methods that use neighborhoods of a fixed size). Conclusion: Estimation by analogy can be significantly improved by a dynamic selection of nearest neighbors, using only the project data from regions with small variance.},
author = {Kocaguneli, Ekrem and Menzies, Tim and Bener, Ayse Basar and Keung, Jacky W.},
doi = {10.1109/TSE.2011.27},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Software cost estimation,analogy,k-NN},
number = {2},
pages = {425--438},
title = {{Exploiting the essential assumptions of analogy-based effort estimation}},
volume = {38},
year = {2012}
}
@article{Verma2012a,
abstract = {Recent theory work has found that a special type of spatial partition tree - called a random projection tree - is adaptive to the intrinsic dimension of the data from which it is built. Here we examine this same question, with a combination of theory and experiments, for a broader class of trees that includes k-d trees, dyadic trees, and PCA trees. Our motivation is to get a feel for (i) the kind of intrinsic low dimensional structure that can be empirically verified, (ii) the extent to which a spatial partition can exploit such structure, and (iii) the implications for standard statistical tasks such as regression, vector quantization, and nearest neighbor search.},
archivePrefix = {arXiv},
arxivId = {1205.2609},
author = {Verma, Nakul and Kpotufe, Samory and Dasgupta, Sanjoy},
eprint = {1205.2609},
file = {:Users/timm/svns/doc/09rptrees.pdf:pdf},
isbn = {978-0-9749039-5-8},
title = {{Which Spatial Partition Trees are Adaptive to Intrinsic Dimension?}},
url = {http://arxiv.org/abs/1205.2609},
year = {2012}
}
@article{Demsar2007a,
abstract = {Visualization can largely improve biomedical data analysis. It plays a crucial role in explorative data analysis and may support various data mining tasks. The paper presents FreeViz, an optimization method that finds linear projection and associated scatterplot that best separates instances of different class. In a single graph, the resulting FreeViz visualization can provide a global view of the classification problem being studied, reveal interesting relations between classes and features, uncover feature interactions, and provide information about intra-class similarities. The paper gives mathematical foundations of FreeViz, and presents its utility on various biomedical data sets. Â© 2007 Elsevier Inc. All rights reserved.},
author = {Dem\v{s}ar, Janez and Leban, Gregor and Zupan, Bla\v{z}},
doi = {10.1016/j.jbi.2007.03.010},
file = {:Users/timm/svns/doc/2007-Demsar.pdf:pdf},
isbn = {1532-0480 (Electronic)$\backslash$n1532-0464 (Linking)},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Explorative data analysis,Intelligent visualisation,Multivariate visualization,Projection search for supervised data},
number = {6},
pages = {661--671},
pmid = {17531544},
title = {{FreeViz-An intelligent multivariate visualization approach to explorative analysis of biomedical data}},
volume = {40},
year = {2007}
}
@misc{Bavota2012b,
abstract = {During software evolution changes are inevitable. These changes may lead$\backslash$nto design erosion and the introduction of inadequate design solutions,$\backslash$nsuch as design antipatterns. Several empirical studies provide evidence$\backslash$nthat the presence of antipatterns is generally associated with lower$\backslash$nproductivity, greater rework, and more significant design efforts for$\backslash$ndevelopers. In order to improve the quality and remove antipatterns,$\backslash$nrefactoring operations are needed. In this demo, we present the Extract$\backslash$nclass features of ARIES (Automated Refactoring In EclipSe), an Eclipse$\backslash$nplug-in that supports the software engineer in removing the ``Blob\{''\}$\backslash$nantipattern.},
annote = {Laura. Fixed on 10/17/2012},
author = {Bavota, Gabriele and {De Lucia}, Andrea and Marcus, Andrian and Oliveto, Rocco and Palomba, Fabio},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2012.6227233},
isbn = {9781467310673},
issn = {02705257},
keywords = {Design,Quality,Refactoring},
month = jun,
pages = {1419--1422},
title = {{Supporting extract class refactoring in eclipse: The ARIES project}},
year = {2012}
}
@inproceedings{come96,
author = {Connell, M and Menzies, T J},
booktitle = {Tools Pacific, 1996, Melbourne},
title = {{Quality Metrics: Test Coverage Analysis for Smalltalk}},
year = {1996}
}
@inproceedings{mebfd92,
author = {Menzies, T J and Black, J and Fleming, J and Dean, M},
booktitle = {The first Conference on Practical Applications of Prolog},
title = {{An Expert System for Raising Pigs}},
year = {1992}
}
@misc{me96o,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/96ie.pdf\}},
author = {Menzies, T and Tucker, S},
title = {{Subject Handbook SFT3500/SYS3030: Industrial Experience Project}},
year = {1996}
}
@article{me12d,
author = {Menzies, Tim and Butcher, Andrew and Cok, David},
doi = {http://dx.doi.org/10.1109/TSE.2012.83},
journal = {Software Engineering, IEEE Transactions on},
number = {6},
pages = {822 -- 834},
title = {{Local versus Global Lessons for Defect Prediction and Effort Estimation}},
volume = {39},
year = {2013}
}
@inproceedings{me07g,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07fix.pdf\}},
author = {Menzies, T and Elrawas, O and Baker, D and Hihn, J and Lum, K},
booktitle = {International Workshop on Living with Uncertainty (an ASE'07 co-located event)},
title = {{On the Value of Stochastic Abduction (if you fix everything, you lose fixes for everything else)}},
year = {2007}
}
@misc{wyatt12,
author = {Wyatt, Patrick},
month = dec,
title = {{Whose bug is this anyway?!? $\backslash$url\{http://www.codeofhonor.com/blog/whose-bug-is-this-anyway\}}},
year = {2012}
}
@inproceedings{me07f,
abstract = {Adoption of advanced automated SE (ASE) tools would be favored if a business case could be made that these tools are more valuable than alternate methods. In theory, software prediction models can be used to make that case. In practice, this is complicated by the "local tuning" problem. Normally, predictors for software effort and defects and threat use local data to tune their predictions. Such local tuning data is often unavailable. This paper shows that assessing the relative merits of different SE methods need not require precise local tunings. STAR1 is a simulated annealer plus a Bayesian post-processor that explores the space of possible local tunings within software prediction models. STAR1 ranks project decisions by their effects on effort and defects and threats. In experiments with two NASA systems, STAR1 found that ASE tools were necessary to minimize effort/ defect/ threats.},
address = {New York, NY, USA},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07casease-v0.pdf\}},
author = {Menzies, Tim and Feather, Martin S and Madachy, Ray and Boehm, Barry W.},
booktitle = {Proc. ASE},
doi = {http://doi.acm.org/10.1145/1321631.1321676},
isbn = {978-1-59593-882-4},
pages = {303--312},
publisher = {ACM},
title = {{The Business Case for Automated Software Engineering}},
url = {http://portal.acm.org/citation.cfm?id=1321631.1321676},
year = {2007}
}
@misc{menz85,
annote = {School of Econometrics, University of New England},
author = {Menzies, G D},
title = {{An Econometric Analysis of the Dark Figure of Crime}},
year = {1985}
}
@inproceedings{gray11,
abstract = {Background: The NASA Metrics Data Program data sets have been heavily used in software defect prediction experiments. Aim: To demonstrate and explain why these data sets require significant pre-processing in order to be suitable for defect prediction. Method: A meticulously documented data cleansing process involving all 13 of the original NASA data sets. Results: Post our novel data cleansing process; each of the data sets had between 6 to 90 percent less of their original number of recorded values. Conclusions: One: Researchers need to analyse the data that forms the basis of their findings in the context of how it will be used. Two: Defect prediction data sets could benefit from lower level code metrics in addition to those more commonly used, as these will help to distinguish modules, reducing the likelihood of repeated data points. Three: The bulk of defect prediction experiments based on the NASA Metrics Data Program data sets may have led to erroneous findings. This is mainly due to repeated data points potentially causing substantial amounts of training and testing data to be identical.},
author = {Gray, D. and Bowes, D. and Davey, N. and Christianson, B.},
booktitle = {15th Annual Conference on Evaluation \& Assessment in Software Engineering (EASE 2011)},
doi = {10.1049/ic.2011.0012},
isbn = {978-1-84919-509-6},
month = apr,
pages = {96--103},
title = {{The misuse of the NASA Metrics Data Program data sets for automated software defect prediction}},
url = {http://digital-library.theiet.org/content/conferences/10.1049/ic.2011.0012},
year = {2011}
}
@article{Dejaeger2013a,
author = {Dejaeger, Karel and Verbraken, Thomas and Baesens, Bart},
file = {:Users/timm/svns/doc/xplain/13Dejaeger.pdf:pdf},
number = {2},
pages = {237--257},
title = {{Prediction Models Using Bayesian Network Classifiers}},
volume = {39},
year = {2013}
}
@article{Jiang2011a,
abstract = {In recent years, some spectral feature selec- tion methods are proposed to choose those features with high power of preserving sam- ple similarity. However, when there exist lots of irrelevant or noisy features in data, the similarity matrix constructed from all the un-weighted features may be not reli- able, which then misleads existing spectral feature selection methods to select âwrongâ features. To solve this problem, we pro- pose that feature importance should be eval- uated according to their impacts on similar- ity matrix, which means features with high impacts on similarity matrix should be cho- sen as important ones. Since graph Lapla- cian(Luxburg, 2007) is defined on the simi- larity matrix, then the impact of each feature on similarity matrix can be reflected on the change of graph Laplacian, especially on its eigen-system. Based on this point of view, we propose an Eigenvalue Sensitive Crite- ria (EVSC) for feature selection, which aims at seeking those features with high impact on graph Laplacianâs eigenvalues. Empirical analysis demonstrates our proposed method outperforms some traditional spectral feature selection methods. 1.},
author = {Jiang, Yi and Ren, Jiangtao},
file = {:Users/timm/svns/doc/11fssSpectral.pdf:pdf},
isbn = {978-1-4503-0619-5},
journal = {Icml},
pages = {89--96},
title = {{Eigenvalue Sensitive Feature Selection}},
year = {2011}
}
@article{valerdi11b,
abstract = {Engineering cannot wait until all phenomena are explained. Engineers may work effectively, often for centuries, with heuristics. This paper provides thirty one heuristics that have been inspired by the development and application of a systems engineering cost estimation model. The objective of this paper is to present such heuristics in a simple manner so that they can benefit systems engineering researchers and practitioners that develop, calibrate, and use cost models.},
author = {Valerdi, Ricardo},
doi = {10.1109/JSYST.2010.2065131},
isbn = {1932-8184 VO  - 5},
issn = {19328184},
journal = {IEEE Systems Journal},
number = {1},
pages = {91--98},
title = {{Heuristics for Systems Engineering Cost Estimation}},
volume = {5},
year = {2010}
}
@article{VanUitert2008b,
abstract = {Genomic datasets often consist of large, binary, sparse data matrices. In such a dataset, one is often interested in finding contiguous blocks that (mostly) contain ones. This is a biclustering problem, and while many algorithms have been proposed to deal with gene expression data, only two algorithms have been proposed that specifically deal with binary matrices. None of the gene expression biclustering algorithms can handle the large number of zeros in sparse binary matrices. The two proposed binary algorithms failed to produce meaningful results. In this article, we present a new algorithm that is able to extract biclusters from sparse, binary datasets. A powerful feature is that biclusters with different numbers of rows and columns can be detected, varying from many rows to few columns and few rows to many columns. It allows the user to guide the search towards biclusters of specific dimensions. When applying our algorithm to an input matrix derived from TRANSFAC, we find transcription factors with distinctly dissimilar binding motifs, but a clear set of common targets that are significantly enriched for GO categories.},
author = {van Uitert, Miranda and Meuleman, Wouter and Wessels, Lodewyk},
doi = {10.1089/cmb.2008.0066},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/vanUitert08.pdf:pdf},
issn = {1066-5277},
journal = {Journal of computational biology : a journal of computational molecular cell biology},
keywords = {biclustering,binary data,transcription factor binding},
number = {10},
pages = {1329--1345},
pmid = {19040367},
title = {{Biclustering sparse binary genomic data.}},
volume = {15},
year = {2008}
}
@inproceedings{me04c,
author = {Menzies, Tim and Stefano, Justin S Di and Cunanan, Chris and Chapman, Robert Mike and Virginia, West},
booktitle = {IET Software},
doi = {10.1049/ic:20040480},
isbn = {0 86341 432 X},
title = {{Mining Repositories to Assist in Project Planning and Resource Allocation}},
year = {2004}
}
@inproceedings{men87a,
author = {Menzies, T J and Markey, B R},
booktitle = {Proceedings of the Third Australian Conference on Expert Systems, May 13-15},
title = {{A Micro-Computer, Rule-Based Prolog Expert-System for Process Control in a Petrochemical Plant}},
year = {1987}
}
@inproceedings{Ramakrishnan1995,
author = {Ramakrishnan, S and Menzies, T},
booktitle = {Proceedings SEEP'96, New Zealand},
title = {{An Ongoing Experiment in O-O Software Process and Product Measurements}},
year = {1996}
}
@inproceedings{me09f,
abstract = {"Faster, Better, Cheaper" (FBC) was a development philosophy adopted by the NASA administration in the mid to late 1990s. that lead to some some dramatic successes such as Mars Pathfinder as well as a number highly publicized mission failures, such as the Mars Climate Orbiter \& Polar Lander. $\backslash$nThe general consensus on FBC was "Faster, Better, Cheaper? Pick any two". According to that view, is impossibly to optimize on all three criteria without compromising the third. This paper checks that view using an AI search tool called STAR. We show that FBC is indeed feasible and produces similar or better results when compared to other methods However, for FBC to work, there must be a balanced concern and concentration on the quality aspects of a project. If not, "FBC" becomes "CF" (cheaper and faster) with the inevitable lose in project quality.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09bfc.pdf\}},
author = {Menzies, Tim and El-Rawas, Oussama and Hihn, Jairus and Boehm, Barry},
booktitle = {Proceedings of the 5th International Conference on Predictor Models in Software Engineering - PROMISE '09},
doi = {10.1145/1540438.1540442},
isbn = {9781605586342},
keywords = {cheaper,cocomo,faster better,predictor models,simulated annealing,software engineering,software processes},
pages = {1},
title = {{Can we build software faster and better and cheaper?}},
url = {http://portal.acm.org/citation.cfm?doid=1540438.1540442},
year = {2009}
}
@inproceedings{me09n,
abstract = {The mantra of the PROMISE series is "repeatable, improvable, maybe refutable" software engineering experiments. This community has successfully created a library of reusable software engineering data sets. The next challenge in the PROMISE community will be to not only share data, but to share experiments. Our experience with existing data mining environments is that these tools are not suitable for publishing or sharing repeatable experiments. OURMINE is an environment for the development of data mining experiments. OURMINE offers a succinct notation for describing experiments. Adding new tools to OURMINE, in a variety of languages, is a rapid and simple process. This makes it a useful research tool. Complicated graphical interfaces have been eschewed for simple command-line prompts. This simplifies the learning curve for data mining novices. The simplicity also encourages large scale modification and experimentation with the code. In this paper, we show the OURMINE code required to reproduce a recent experiment checking how defect predictors learned from one site apply to another. This is an important result for the PROMISE community since it shows that our shared repository is not just a useful academic resource. Rather, it is a valuable resource industry: companies that lack the local data required to build those predictors can use PROMISE data to build defect predictors.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09ourmine.pdf\}},
author = {Gay, Gregory and Menzies, Tim and Cukic, Bojan and Turhan, Burak},
booktitle = {Proceedings of the 5th International Conference on Predictor Models in Software Engineering - PROMISE '09},
doi = {10.1145/1540438.1540460},
isbn = {9781605586342},
keywords = {algorithms,development of data mining,envi-,experimentation,measurement,of powerful open-source development,platforms also came the,with the recent rise},
pages = {1},
title = {{How to build repeatable experiments}},
url = {http://portal.acm.org/citation.cfm?doid=1540438.1540460},
year = {2009}
}
@inproceedings{me04h,
abstract = { COCONUT calibrates effort estimation models using an exhaustive search over the space of calibration parameters in a Cocomo I model. This technique is much simpler than other effort estimation method yet yields PRED levels comparable to those other methods. Also, it does so with less project data and fewer attributes (no scale factors). However, a comparison between COCONUT and other methods is complicated by differences in the experimental methods used for effort estimation. A review of those experimental methods concludes that software effort estimation models should be calibrated to local data using incremental holdout (not jack knife) studies, combined with randomization and hypothesis testing, repeated a statistically significant number of times.},
author = {Menzies, T. and Port, D. and Chen, Zhihao Chen Zhihao and Hihn, J.},
booktitle = {Proceedings. 27th International Conference on Software Engineering, 2005. ICSE 2005.},
doi = {10.1109/ICSE.2005.1553605},
isbn = {1-59593-963-2},
title = {{Validation methods for calibrating software effort models}},
year = {2005}
}
@article{jorg11,
abstract = {Context: The effort estimates of software development work are on average too low. A possible reason for this tendency is that software developers, perhaps unconsciously, assume ideal conditions when they estimate the most likely use of effort. In this article, we propose and evaluate a two-step estimation process that may induce more awareness of the difference between idealistic and realistic conditions and as a consequence more realistic effort estimates. The proposed process differs from traditional judgmentbased estimation processes in that it starts with an effort estimation that assumes ideal conditions before the most likely use of effort is estimated. Objective: The objective of the paper is to examine the potential of the proposed method to induce more realism in the judgment-based estimates of work effort. Method: Three experiments with software professionals as participants were completed. In all three experiments there was one group of participants which followed the proposed and another group which followed the traditional estimation process. In one of the experiments there was an additional group which started with a probabilistically defined estimate of minimum effort before estimating the most likely effort. Results: We found, in all three experiments, that estimation of most likely effort seems to assume rather idealistic assumptions and that the use of the proposed process seems to yield more realistic effort estimates. In contrast, starting with an estimate of the minimum effort, rather than an estimate based on ideal conditions, did not have the same positive effect on the subsequent estimate of the most likely effort. Conclusion: The empirical results from our studies together with similar results from other domains suggest that the proposed estimation process is promising for the improvement of the realism of software development effort estimates. ?? 2011 Elsevier B.V. All rights reserved.},
author = {Jorgensen, Magne},
doi = {10.1016/j.infsof.2011.07.001},
isbn = {0950-5849},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Effort estimation,Expert estimation,Human judgment},
number = {12},
pages = {1382--1390},
title = {{Contrasting ideal and realistic conditions as a means to improve judgment-based software development effort estimation}},
volume = {53},
year = {2010}
}
@article{Algorithm2000a,
author = {Algorithm, The Metropolis and Method, Monte Carlo},
file = {:Users/timm/svns/doc/dataFarm/00metropolis.pdf:pdf},
pages = {65--69},
title = {{He etropolis lgorithm}},
year = {2000}
}
@article{Chu2010a,
abstract = {Instead of finding clusters in the full feature space, subspace clustering is an emergent task which aims at detecting clusters embedded in subspaces. Most of previous works in the literature are density-based approaches, where a cluster is regarded as a high-density region in a subspace. However, the identification of dense regions in previous works lacks of considering a critical problem, called "the density divergence problemrdquo in this paper, which refers to the phenomenon that the region densities vary in different subspace cardinalities. Without considering this problem, previous works utilize a density threshold to discover the dense regions in all subspaces, which incurs the serious loss of clustering accuracy (either recall or precision of the resulting clusters) in different subspace cardinalities. To tackle the density divergence problem, in this paper, we devise a novel subspace clustering model to discover the clusters based on the relative region densities in the subspaces, where the clusters are regarded as regions whose densities are relatively high as compared to the region densities in a subspace. Based on this idea, different density thresholds are adaptively determined to discover the clusters in different subspace cardinalities. Due to the infeasibility of applying previous techniques in this novel clustering model, we also devise an innovative algorithm, referred to as DENCOS (density conscious subspace clustering), to adopt a divide-and-conquer scheme to efficiently discover clusters satisfying different density thresholds in different subspace cardinalities. As validated by our extensive experiments on various data sets, DENCOS can discover the clusters in all subspaces with high quality, and the efficiency of DENCOS outperformes previous works.},
author = {Chu, Yi Hong and Huang, Jen Wei and Chuang, Kun Ta and Yang, De Nian and Chen, Ming Syan},
doi = {10.1109/TKDE.2008.224},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/chu10.pdf:pdf},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {And association rules,Classification,Clustering,Data clustering,Data mining,Subspace clustering.},
number = {1},
pages = {16--30},
title = {{Density conscious subspace clustering for high-dimensional data}},
volume = {22},
year = {2010}
}
@inproceedings{me11b,
abstract = {Background: Building effort estimators requires the training data. How can we find that data? It is tempting to cross the boundaries of development type, location, language, application and hardware to use existing datasets of other organizations. However, prior results caution that using such cross data may not be useful. Aim: We test two conjectures: (1) instance selection can automatically prune irrelevant instances and (2) retrieval from the remaining examples is useful for effort estimation, regardless of their source. Method: We selected 8 cross-within divisions (21 pairs of within-cross subsets) out of 19 datasets and evaluated these divisions under different analogy-based estimation (ABE) methods. Results: Between the within \&\#x0026; cross experiments, there were few statistically significant differences in (i) the performance of effort estimators, or (ii) the amount of instances retrieved for estimation. Conclusion: For the purposes of effort estimation, there is little practical difference between cross and within data. After applying instance selection, the remaining examples (be they from within or from cross source divisions) can be used for effort estimation.},
author = {Kocaguneli, Ekrem and Menzies, Tim},
booktitle = {2011 International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2011.34},
isbn = {978-0-7695-4604-9},
issn = {1938-6451},
keywords = {cross resource,k-NN,software cost estimation,within resource},
pages = {255--264},
title = {{How to Find Relevant Data for Effort Estimation?}},
year = {2011}
}
@article{jorgensen07,
abstract = {This paper aims to provide a basis for the improvement of software estimation research through a systematic review of previous work. The review identifies 304 software cost estimation papers in 76 journals and classifies the papers according to research topic, estimation approach, research approach, study context and data set. A web-based library of these cost estimation papers is provided to ease the identification of relevant estimation research results. The review results combined with other knowledge provide support for recommendations for future software cost estimation research, including: 1) Increase the breadth of the search for relevant studies, 2) Search manually for relevant papers within a carefully selected set of journals when completeness is essential, 3) Conduct more studies on estimation methods commonly used by the software industry, and, 4) Increase the awareness of how properties of the data sets impact the results when evaluating estimation methods.},
author = {J\o rgensen,  M and Shepperd,  M J},
doi = {10.1109/TSE.2007.3},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {empirical software engineering,software cost estimation,software effort estimation,systematic review},
month = jan,
pages = {33--53},
title = {{A Systematic Review of Software Development Cost Estimation Studies}},
url = {http://dx.doi.org/10.1109/TSE.2007.3},
year = {2007}
}
@inproceedings{me99l,
author = {Menzies, T},
booktitle = {11th Annual International Conference on Software Engineering and Knowledge Engineering, Kaiserslautern, Germany, June 17 - 19, 1999},
title = {{Knowledge Maintenance Heresies: Meta-Knowledge Complicates KM}},
year = {1999}
}
@article{me07e,
annote = {$\backslash$url\{http://menzies.us/pdf/07precision.pdf\}},
author = {Menzies, Tim and Menzies, Tim and Dekhtyar, Alex and Dekhtyar, Alex and Distefano, Justin and Distefano, Justin and Greenwald, Jeremy},
journal = {Engineering},
month = sep,
number = {1},
pages = {11--14},
title = {{Problems with Precision}},
volume = {6},
year = {2007}
}
@inproceedings{me03p,
abstract = { One of the goals of verification and validation (V\&amp;V) activities for online adaptive control systems is providing assurance that they are able to detect novel system behaviors and provide adequate (safe) control actions. Novel (or abnormal) system behaviors cannot be enumerated or fully and explicitly described in requirements documentation. Therefore, they have to be observed and recognized during the operation. Novelty detection methods, therefore, provide an adequate approach for the V\&amp;V purposes. We propose a novelty detection method based on support sector data description (SVDD) as a candidate approach for validating adaptive control systems. As a one-class classifier, the support vector data description is able to form a decision boundary around the learned data domain with very little or no knowledge of data points outside the boundary (outliers). We apply the SVDD techniques for novelty detection as part of the validation on an intelligent flight control system (IFCS). Experimental results show that the SVDD can be adopted as an effective tool for finding indications of the safe region for the learned domain, whereby we are able to separate faulty behavior from normal events.},
author = {Liu, Yan Liu Yan and Gururajan, S. and Cukic, B. and Menzies, T. and Napolitano, M.},
booktitle = {Proceedings. 15th IEEE International Conference on Tools with Artificial Intelligence},
doi = {10.1109/TAI.2003.1250215},
isbn = {0-7695-2038-3},
issn = {1082-3409},
title = {{Validating an online adaptive system using SVDD}},
year = {2003}
}
@book{silver12,
author = {Silver, N},
isbn = {978-1-59420-411-1},
pages = {534},
publisher = {Penguin},
title = {{The signal and the noice: why most predictions fail but some don't}},
year = {2012}
}
@article{Ignjatovic2009a,
author = {Ignjatovic, Aleksandar and Lee, Chung Tong and Kutay, Cat and Guo, Hui and Compton, Paul},
file = {:Users/timm/svns/doc/Ignjatovic\_2009.pdf:pdf},
journal = {International \ldots},
pages = {1--7},
title = {{Computing marks from multiple assessors using adaptive averaging}},
url = {http://cgi.cse.unsw.edu.au/~ignjat/Computing Marks.pdf},
year = {2009}
}
@inproceedings{sayyad13b,
abstract = {Software product lines are hard to configure. Techniques that work for medium sized product lines fail for much larger product lines such as the Linux kernel with 6000+ features. This paper presents simple heuristics that help the Indicator-Based Evolutionary Algorithm (IBEA) in finding sound and optimum configurations of very large variability models in the presence of competing objectives. We employ a combination of static and evolutionary learning of model structure, in addition to utilizing a pre-computed solution used as a âseedâ in the midst of a randomly-generated initial population. The seed solution works like a single straw that is enough to break the camel's back -given that it is a feature-rich seed. We show promising results where we can find 30 sound solutions for configuring upward of 6000 features within 30 minutes.},
author = {Sayyad, Abdel Salam and Ingram, Joseph and Menzies, Tim and Ammar, Hany},
booktitle = {2013 28th IEEE/ACM International Conference on Automated Software Engineering, ASE 2013 - Proceedings},
doi = {10.1109/ASE.2013.6693104},
isbn = {9781479902156},
keywords = {SMT solvers,Variability models,automated configuration,evolutionary algorithms,multiobjective optimization},
pages = {465--474},
title = {{Scalable product line configuration: A straw to break the camel's back}},
year = {2013}
}
@inproceedings{bird11,
abstract = {We describe the activities of the Empirical Software Engi-neering (ESE) group at Microsoft Research. We highlight our research themes and activities using examples from our research on socio technical congruence, bug reporting and triaging, and data-driven software engineering to illustrate our relationship to the CSCW community. We highlight our unique ability to leverage industrial data and developers and the ability to make near term impact on Microsoft via the results of our studies. We also present the collaborations our group has with academic researchers.},
author = {Bird, Christian and Murphy, Brendan and Nagappan, Nachiappan and Zimmermann, Thomas},
booktitle = {Proceedings of the ACM 2011 conference on Computer supported cooperative work},
doi = {10.1145/1958824.1958846},
isbn = {978-1-4503-0556-3},
pages = {143--150},
series = {CSCW '11},
title = {{Empirical software engineering at Microsoft Research}},
url = {http://doi.acm.org/10.1145/1958824.1958846},
year = {2011}
}
@inproceedings{keung2008a,
address = {New York, NY, USA},
author = {Keung, Jacky},
booktitle = {ESEM '08: Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement},
doi = {http://doi.acm.org/10.1145/1414004.1414057},
isbn = {978-1-59593-971-5},
pages = {294--296},
publisher = {ACM},
title = {{Empirical evaluation of analogy-x for software cost estimation}},
year = {2008}
}
@misc{brown09,
annote = {$\backslash$url\{http://www.nasa.gov/mission\_pages/mars/news/msl-20081204.html\}},
author = {Brown, Dwayne},
title = {{Next NASA Mars Mission Rescheduled For 2011}},
year = {2008}
}
@article{me09e,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09nodata.pdf\}},
author = {Menzies, T and Williams, S and Elrawas, O and Baker, D and Boehm, B and Hihn, J and Lum, K and Madachy, R},
journal = {Software Process Improvement and Practice},
month = jul,
number = {4},
pages = {213--225},
title = {{Accurate estimates without local data?}},
url = {http://www3.interscience.wiley.com/journal/122364893/abstract},
volume = {14},
year = {2009}
}
@article{me08e,
author = {Menzies, Tim and Milton, Z and Bener, a and Cukic, Bojan and Gay, G and Jiang, Y and Turhan, B},
journal = {Submitted to IEEE TSE},
title = {{Overcoming Ceiling Effects in Defect Prediction}},
year = {2008}
}
@article{andrews10,
author = {Andrews, James H and Menzies, Tim and Li, Felix C H},
journal = {IEEE Transactions on Software Engineering},
month = mar,
number = {1},
pages = {1--33},
title = {{Controlling Randomized Unit Testing With Genetic Algorithms}},
volume = {1},
year = {2001}
}
@inproceedings{me99a,
abstract = {Multiple viewpoints are often used in requirements engineering to
facilitate traceability to stakeholders, to structure the requirements
process, and to provide richer modelling by incorporating multiple
conflicting descriptions. In the latter case, the need to reason with
inconsistent models introduces considerable extra complexity. We
describe an empirical study of the utility of multiple world reasoning
(using abduction) for domain modelling. In the study we used a range of
different models (ranging from correct to very incorrect), different
fanouts, different amounts of data available from the domain, and
different modelling primitives for representing time. In the experiments
there was no significant change in the expressive power of models that
incorporate multiple conflicting viewpoints. Whilst this does not negate
the advantages of viewpoints during requirements elicitation it does
suggest some limits to the utility of viewpoints during requirements
modelling},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/99re.pdf\}},
author = {Menzies, T. and Easterbrook, S. and Nuseibeh, B. and Waugh, S.},
booktitle = {Proceedings IEEE International Symposium on Requirements Engineering (Cat. No.PR00188)},
doi = {10.1109/ISRE.1999.777990},
isbn = {0-7695-0188-5},
issn = {1090-705X},
title = {{An empirical investigation of multiple viewpoint reasoning in
requirements engineering}},
year = {1999}
}
@article{brady10a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/10w0.pdf\}},
author = {Brady, Adam},
doi = {10.4236/jsea.2010.311118},
issn = {1945-3116},
journal = {Journal of Software Engineering and Applications},
number = {11},
pages = {1005--1014},
title = {{Case-Based Reasoning for Reducing Software Development Effort}},
volume = {03},
year = {2010}
}
@phdthesis{acree80,
author = {Acree, a T},
school = {School of Information and Computer Science, Georgia Institute of Technology},
title = {{On Mutations}},
year = {1980}
}
@article{Qin2009a,
author = {Qin, a K and Huang, V L and Suganthan, P N},
file = {:Users/timm/svns/doc/09de.pdf:pdf},
number = {2},
pages = {398--417},
title = {{Adaptation for Global Numerical Optimization}},
volume = {13},
year = {2009}
}
@article{Minku2013a,
abstract = {Ensembles of learning machines are promising for$\backslash$nsoftware effort estimation (SEE), but need to be$\backslash$ntailored for this task to have their potential$\backslash$nexploited. A key issue when creating ensembles is to$\backslash$nproduce diverse and accurate base models. Depending on$\backslash$nhow differently different performance measures behave$\backslash$nfor SEE, they could be used as a natural way of$\backslash$ncreating SEE ensembles. We propose to view SEE model$\backslash$ncreation as a multiobjective learning problem. A$\backslash$nmultiobjective evolutionary algorithm (MOEA) is used to$\backslash$nbetter understand the tradeoff among different$\backslash$nperformance measures by creating SEE models through the$\backslash$nsimultaneous optimisation of these measures. We show$\backslash$nthat the performance measures behave very differently,$\backslash$npresenting sometimes even opposite trends. They are$\backslash$nthen used as a source of diversity for creating SEE$\backslash$nensembles. A good tradeoff among different measures can$\backslash$nbe obtained by using an ensemble of MOEA solutions.$\backslash$nThis ensemble performs similarly or better than a model$\backslash$nthat does not consider these measures explicitly.$\backslash$nBesides, MOEA is also flexible, allowing emphasis of a$\backslash$nparticular measure if desired. In conclusion, MOEA can$\backslash$nbe used to better understand the relationship among$\backslash$nperformance measures and has shown to be very effective$\backslash$nin creating SEE models.},
author = {Minku, Leandro L and Yao, Xin},
doi = {http://dx.doi.org/10.1145/2522920.2522928},
file = {:Users/timm/svns/doc/cost/13minku.pdf:pdf},
issn = {1049-331X (print), 1557-7392 (electronic)},
journal = {ACM Transactions on Software Engineering and Methodology},
number = {4},
pages = {1--32},
title = {{Software effort estimation as a multiobjective learning problem}},
url = {http://dl.acm.org/citation.cfm?doid=2522920.2522928$\backslash$npapers2://publication/doi/10.1145/2522920.2522928},
volume = {22},
year = {2013}
}
@inproceedings{me06f,
author = {Menies, T and Lum, K and Hihn, J},
booktitle = {Promise 2006},
pages = {1--5},
title = {{The Deviance Problem in Effort Estimation}},
year = {2006}
}
@inproceedings{me03h,
author = {Chiang, E and Menzies, T},
booktitle = {Prosim '03},
title = {{Position Paper: Summary of simulations for Very Early Lifecycle Quality Evaluations}},
year = {2003}
}
@misc{me98g,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/99ab.pdf\}},
author = {Menzies, T and Waugh, S},
title = {{Abduction: Experiments and Implications}},
year = {1999}
}
@article{Grassberger1983a,
abstract = {We study the correlation exponent v introduced recently as a characteristic measure of strange attractors which allows one to distinguish between deterministic chaos and random noise. The exponent v is closely related to the fractal dimension and the information dimension, but its computation is considerably easier. Its usefulness in characterizing experimental data which stem from very high dimensional systems is stressed. Algorithms for extracting v from the time series of a single variable are proposed. The relations between the various measures of strange attractors and between them and the Lyapunov exponents are discussed. It is shown that the conjecture of Kaplan and Yorke for the dimension gives an upper bound for v. Various examples of finite and infinite dimensional systems are treated, both numerically and analytically.},
author = {Grassberger, Peter and Procaccia, Itamar},
doi = {10.1016/0167-2789(83)90298-1},
file = {:Users/timm/svns/doc/83intrinsicDimension.pdf:pdf},
isbn = {978-981-02-2310-6},
issn = {01672789},
journal = {Physica D: Nonlinear Phenomena},
number = {1-2},
pages = {189--208},
title = {{Measuring the strangeness of strange attractors}},
volume = {9},
year = {1983}
}
@inproceedings{Faloutsos1995,
abstract = {A very promising idea for fast searching in traditional and multimedia databases is to map objects into points in k-d space, using k feature-extraction functions, provided by a domain expert [25]. Thus, we can subsequently use highly fine-tuned spatial access methods (SAMs), to answer several types of queries, including the 'Query By Example' type (which translates to a range query); the 'all pairs' query (which translates to a spatial join [8]); the nearest-neighbor or best-match query, etc.However, designing feature extraction functions can be hard. It is relatively easier for a domain expert to assess the similarity/distance of two objects. Given only the distance information though, it is not obvious how to map objects into points.This is exactly the topic of this paper. We describe a fast algorithm to map objects into points in some k-dimensional space (k is user-defined), such that the dis-similarities are preserved. There are two benefits from this mapping: (a) efficient retrieval, in conjunction with a SAM, as discussed before and (b) visualization and data-mining: the objects can now be plotted as points in 2-d or 3-d space, revealing potential clusters, correlations among attributes and other regularities that data-mining is looking for.We introduce an older method from pattern recognition, namely, Multi-Dimensional Scaling (MDS) [51]; although unsuitable for indexing, we use it as yardstick for our method. Then, we propose a much faster algorithm to solve the problem in hand, while in addition it allows for indexing. Experiments on real and synthetic data indeed show that the proposed algorithm is significantly faster than MDS, (being linear, as opposed to quadratic, on the database size N), while it manages to preserve distances and the overall structure of the data-set.},
author = {Faloutsos, Christos and Lin, King-Ip},
booktitle = {ACM SIGMOD Record},
doi = {10.1145/568271.223812},
isbn = {0-89791-731-6},
issn = {0163-5808},
number = {2},
pages = {163},
series = {SIGMOD '95},
title = {{FastMap: A fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets}},
url = {http://portal.acm.org/citation.cfm?id=568271.223812},
volume = {24},
year = {1995}
}
@book{Arbenz2011a,
author = {Arbenz, Markus},
file = {:Users/timm/svns/doc/12MachineLearningIAction.pdf:pdf},
isbn = {9781933988771},
number = {November 2010},
title = {{In Action}},
year = {2011}
}
@article{DeSouza2006a,
author = {{De Souza}, Jerffeson Teixeira and Matwin, Stan and Japkowicz, Nathalie},
doi = {10.1007/s00453-006-1220-3},
file = {:Users/timm/svns/doc/06jeffFSSparallel.pdf:pdf},
issn = {01784617},
journal = {Algorithmica (New York)},
keywords = {Feature selection,Hybrid system,Master-slave design pattern,Parallelism},
number = {3},
pages = {433--456},
title = {{Parallelizing feature selection}},
volume = {45},
year = {2006}
}
@inproceedings{me00s,
author = {Menzies, T and Cukic, B},
booktitle = {International Workshop on Empirical Studies of Software Maintenance (WESS 2000), October 14, San Jose CA},
title = {{Maintaining Maintainability = Recognizing Reachability}},
year = {2000}
}
@inproceedings{me03l,
author = {Menzies, Tim},
booktitle = {Soft Computing in Software Engineering},
editor = {Madravio, M},
publisher = {Springer-Verlag},
title = {{Chapter 99 Maybes Mean ( Mostly ) the Same Thing}},
year = {2003}
}
@inproceedings{me00a,
author = {Menzies, T and Sinsel, E and Kurtz, T},
booktitle = {Workshop on Intelligent Software Engineering, an ICSE workshop, and NASA/WVU Software Research Lab, Fairmont, WV, Tech report \# NASA-IVV-99-027},
keywords = { Monte-Carlo simulations, decision support systems, effort estimation, risk assessment,COCOMO-II,Keywords: Machine learning},
title = {{Learning to Reduce Risks with COCOMO-II}},
year = {2000}
}
@inproceedings{me96l,
author = {Ramakrishnan, S and Menzies, T and Hasslinger, M and Bok, P and Mccarthy, H and Devakadadcham, B and Moulder, D},
booktitle = {Proceedings of Tools-Pacific, Melbourne},
publisher = {Prentice-Hall},
title = {{On Building an Effective Measurement System for OO Software Process}},
year = {1996}
}
@inproceedings{me97d,
author = {Postema, M and Menzies, T J and Wu, X},
booktitle = {The Joint Pacific Asia Conference on Expert Systems/Singapore International Conference on Intelligent Systems. (PACES/SPICIS '97)},
title = {{A Decision Support Tool for Tuning Parameters in a Machine Leraning Algorithm}},
year = {1997}
}
@inproceedings{JALALI2007,
address = {Washington, DC, USA},
author = {Jalali, Omid and Jalali, Omid and Menzies, Tim and Menzies, Tim and Baker, Dan and Baker, Dan},
booktitle = {Jet Propulsion},
doi = {http://dx.doi.org/10.1109/PROMISE.2007.3},
isbn = {0-7695-2954-2},
pages = {1--9},
publisher = {IEEE Computer Society},
title = {{Column Pruning Beats Strati cation in Effort Estimation}},
year = {2007}
}
@article{Dai2008a,
abstract = {BACKGROUND: Many proposed statistical measures can efficiently compare protein sequence to further infer protein structure, function and evolutionary information. They share the same idea of using k-word frequencies of protein sequences. Given a protein sequence, the information on its related protein sequences hasn't been used for protein sequence comparison until now. This paper proposed a scheme to construct protein 'sequence space' which was associated with protein sequences related to the given protein, and the performances of statistical measures were compared when they explored the information on protein 'sequence space' or not. This paper also presented two statistical measures for protein: gre.k (generalized relative entropy) and gsm.k (gapped similarity measure). RESULTS: We tested statistical measures based on protein 'sequence space' or not with three data sets. This not only offers the systematic and quantitative experimental assessment of these statistical measures, but also naturally complements the available comparison of statistical measures based on protein sequence. Moreover, we compared our statistical measures with alignment-based measures and the existing statistical measures. The experiments were grouped into two sets. The first one, performed via ROC (Receiver Operating Curve) analysis, aims at assessing the intrinsic ability of the statistical measures to discriminate and classify protein sequences. The second set of the experiments aims at assessing how well our measure does in phylogenetic analysis. Based on the experiments, several conclusions can be drawn and, from them, novel valuable guidelines for the use of protein 'sequence space' and statistical measures were obtained. CONCLUSION: Alignment-based measures have a clear advantage when the data is high redundant. The more efficient statistical measure is the novel gsm.k introduced by this article, the cos.k followed. When the data becomes less redundant, gre.k proposed by us achieves a better performance, but all the other measures perform poorly on classification tasks. Almost all the statistical measures achieve improvement by exploring the information on 'sequence space' as word's length increases, especially for less redundant data. The reasonable results of phylogenetic analysis confirm that Gdis.k based on 'sequence space' is a reliable measure for phylogenetic analysis. In summary, our quantitative analysis verifies that exploring the information on 'sequence space' is a promising way to improve the abilities of statistical measures for protein comparison.},
author = {Dai, Qi and Wang, Tianming},
doi = {10.1186/1471-2105-9-394},
file = {:Users/timm/svns/doc/erin/references/AlgsForDNA/ComparisonK-wordStatMeasuresDai2008.pdf:pdf},
issn = {1471-2105},
journal = {BMC bioinformatics},
pages = {394},
pmid = {18811946},
title = {{Comparison study on k-word statistical measures for protein: from sequence to 'sequence space'.}},
volume = {9},
year = {2008}
}
@article{Basha2010a,
abstract = {Reliable effort estimation remains an ongoing challenge to software engineers. Accurate effort estimation is the state of art of software engineering, effort estimation of software is the preliminary phase between the client and the business enterprise. The relationship between the client and the business enterprise begins with the estimation of the software. The credibility of the client to the business enterprise increases with the accurate estimation. Effort estimation often requires generalizing from a small number of historical projects. Generalization from such limited experience is an inherently under constrained problem. Accurate estimation is a complex process because it can be visualized as software effort prediction, as the term indicates prediction never becomes an actual. This work follows the basics of the empirical software effort estimation models. The goal of this paper is to study the empirical software effort estimation. The primary conclusion is that no single technique is best for all situations, and that a careful comparison of the results of several approaches is most likely to produce realistic estimates.},
archivePrefix = {arXiv},
arxivId = {1004.1239},
author = {Basha, Saleem and Ponnurangam, Dhavachelvan},
eprint = {1004.1239},
file = {:Users/timm/svns/doc/cost/10Saleem.pdf:pdf},
keywords = {-software estimation,wilcoxon signed-rank test},
number = {3},
title = {{Analysis of Empirical Software Effort Estimation Models}},
url = {http://arxiv.org/abs/1004.1239},
volume = {7},
year = {2010}
}
@article{step05,
abstract = {A gateway event is a change to a system that leads to the possibility of huge increases in kinds and levels of complexity. It opens up a whole new kind of phase space to the systemâs dynamics. Gateway events during evolution of life on earth include the appearance of eukaryotes (organisms with a cell nucleus), an oxygen atmosphere, multi-cellular organisms, and grass. Gateway events during the development of mathematics include each invention of a new class of numbers (negative, irrational, imaginary, \ldots), and dropping Euclidâs parallel postulate. A gateway event produces a profound and fundamental change to the system: once through the gateway, life is never the same again. We are currently poised on the threshold of a significant gateway event in computation: that of breaking free from many of our current âclassical computationalâ assumptions. Our Grand Challenge for computer science is to journey through the gateway event obtained by breaking our current classical computational assumptions, and thereby develop a mature science of Non-Classical Computation},
author = {Stepney, S. and Braunstein, S.L. and Clark, J.a. and Tyrrell, a. and Adamatzky, a. and Addis, T. and Johnson, C. and Timmis, J. and Welch, P. and Milner, R. and Partridge, D. and Smith, R.E.},
doi = {10.1080/17445760500033291},
issn = {1744-5760},
journal = {International Journal of Parallel, Emergent and Distributed Systems},
number = {1},
pages = {5--19},
publisher = {Taylor \& Francis},
title = {{Journeys in non-classical computation I: A grand challenge for computing research}},
url = {http://dx.doi.org/10.1080/17445760500033291},
volume = {20},
year = {2005}
}
@inproceedings{me93k,
author = {Menzies, T J},
booktitle = {DX-93: The International Workshop on Principles on Model-Based Diagnosis},
title = {{The Complexity of Model Review}},
year = {1993}
}
@inproceedings{me05b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05sawtooth.pdf\}},
author = {Menzies, Tim},
number = {August},
pages = {1--6},
title = {{Incremental Discretization and Bayes Classifiers Handles Concept Drift and Scales Very Well}},
volume = {X},
year = {2005}
}
@inproceedings{sammut92,
abstract = {This year marks the fifth anniversary of West Michigan Air Care, the first merged, hospital-based air medical program in the United States. This milestone is being observed with a certain satisfaction that comes from achieving what others said "couldn't be done."},
author = {{Timothy Stack}, R and Sardone, F J},
booktitle = {Michigan health \& hospitals},
doi = {10.1145/1015330.1015384},
editor = {Sleeman, D},
isbn = {1581138285},
number = {5},
pages = {17},
pmid = {10185207},
publisher = {Morgan Kaufmann},
title = {{Learning to fly.}},
volume = {34},
year = {1992}
}
@inproceedings{sayyad13d,
author = {Sayyad, A and Ammar, H},
booktitle = {International Workshop on Realizing Synergies between Artificial Intelligence and Software Engineering (RAISEâ13)},
title = {{Pareto-Optimal Search-Based Software Engineering: A Literature Survey}},
year = {2013}
}
@article{Stoltenburg2007a,
abstract = {SELEX stands for systematic evolution of ligands by exponential enrichment. This method, described primarily in 1990 [Ellington, A.D., Szostak, J.W., 1990. In vitro selection of RNA molecules that bind specific ligands. Nature 346, 818-822; Tuerk, C., Gold, L., 1990. Systematic evolution of ligands by exponential enrichment: RNA ligands to bacteriophage T4 DNA polymerase. Science 249, 505-510] aims at the development of aptamers, which are oligonucleotides (RNA or ssDNA) binding to their target with high selectivity and sensitivity because of their three-dimensional shape. Aptamers are all new ligands with a high affinity for considerably differing molecules ranging from large targets as proteins over peptides, complex molecules to drugs and organic small molecules or even metal ions. Aptamers are widely used, including medical and pharmaceutical basic research, drug development, diagnosis, and therapy. Analytical and separation tools bearing aptamers as molecular recognition and binding elements are another big field of application. Moreover, aptamers are used for the investigation of binding phenomena in proteomics. The SELEX method was modified over the years in different ways to become more efficient and less time consuming, to reach higher affinities of the aptamers selected and for automation of the process. This review is focused on the development of aptamers by use of SELEX and gives an overview about technologies, advantages, limitations, and applications of aptamers. ?? 2007 Elsevier B.V. All rights reserved.},
author = {Stoltenburg, Regina and Reinemann, Christine and Strehlitz, Beate},
doi = {10.1016/j.bioeng.2007.06.001},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Stoltenberg07.pdf:pdf},
isbn = {1389-0344},
issn = {13890344},
journal = {Biomolecular Engineering},
keywords = {Aptamer,Random oligonucleotide library,SELEX,Target},
number = {4},
pages = {381--403},
pmid = {17627883},
title = {{SELEX-A (r)evolutionary method to generate high-affinity nucleic acid ligands}},
volume = {24},
year = {2007}
}
@inproceedings{cor95,
author = {Corbridge, C and Major, N P and Shadbolt, N R},
booktitle = {Proceedings of the 9th \{AAAI\}-Sponsored \{B\}anff Knowledge Acquisition for Knowledge Based Systems},
title = {{Models \{E\}xposed: An \{E\}mpirical \{S\}tudy}},
year = {1995}
}
@inproceedings{me06f,
annote = {Available from $\backslash$url\{http://menzies.us/06deviations.pdf\}},
author = {Menies, T and Lum, K and Hihn, J},
booktitle = {Promise 2006},
pages = {1--5},
title = {{The Deviance Problem in Effort Estimation}},
year = {2006}
}
@inproceedings{port08,
abstract = {Agile and traditional plan-based approaches to software system development both agree that prioritizing requirements is an essential activity. They differ in basic strategy - when to prioritize, to what degree, and how to guide implementation. As with many software engineering methods, verifying the benefit of following a particular approach is a challenge. Industry and student/classroom based experimental studies are generally impractical to use for large numbers of controlled experiments and benefits are difficult to measure directly. We use simulation to validate the fundamental, yet typically intangible benefits of requirements prioritization strategies. Our simulation is directly based on detailed empirical studies of agile and plan-based requirements management studies. Our simulation shows, as many have claimed, that an agile strategy excels when requirements are highly volatile, whereas a plan-based strategy excels when requirements are stable, and that there exist mixed strategies that are better than either for typical development efforts.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08simrequire.pdf\}},
author = {Port, Dan and Olkov, Alexy and Menzies, Tim},
booktitle = {ASE 2008 - 23rd IEEE/ACM International Conference on Automated Software Engineering, Proceedings},
doi = {10.1109/ASE.2008.37},
isbn = {9781424421886},
issn = {1527-1366},
keywords = {Agile,Plan-based,Requirements,Simulation},
pages = {268--277},
title = {{Using simulation to investigate requirements prioritization strategies}},
year = {2008}
}
@inproceedings{me07g,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07fix.pdf\}},
author = {Menzies, T and Elrawas, O and Baker, D and Hihn, J and Lum, K},
booktitle = {International Workshop on Living with Uncertainty (an ASE'07 co-located event)},
title = {{On the Value of Stochastic Abduction (if you fix everything, you lose fixes for everything else)}},
year = {2007}
}
@article{gay10,
abstract = {Testing large-scale systems is expensive in terms of both time and money. Running simulations early in the process is a proven method of finding the design faults likely to lead to critical system failures, but determining the exact cause of those errors is still time-consuming and requires access to a limited number of domain experts. It is desirable to find an automated method that explores the large number of combinations and is able to isolate likely fault points.   Treatment learning is a subset of minimal contrast-set learning that, rather than classifying data into distinct categories, focuses on finding the unique factors that lead to a particular classification. That is, they find the smallest change to the data that causes the largest change in the class distribution. These treatments, when imposed, are able to identify the factors most likely to cause a mission-critical failure. The goal of this research is to comparatively assess treatment learning against state-of-the-art numerical optimization techniques. To achieve this, this paper benchmarks the TAR3 and TAR4.1 treatment learners against optimization techniques across three complex systems, including two projects from the Robust Software Engineering (RSE) group within the National Aeronautics and Space Administration (NASA) Ames Research Center. The results clearly show that treatment learning is both faster and more accurate than traditional optimization methods.},
author = {Gay, Gregory and Menzies, Tim and Davies, Misty and Gundy-Burlet, Karen},
doi = {10.1007/s10515-010-0072-x},
issn = {09288910},
journal = {Automated Software Engineering},
keywords = {Contrast-set learning,Monte carlo filtering,Optimization,Search-based software engineering,Simulation},
month = dec,
number = {4},
pages = {439--468},
title = {{Automatically finding the control variables for complex system behavior}},
volume = {17},
year = {2010}
}
@inproceedings{owen02a,
abstract = { This paper studies how details of a particular model can effect the efficacy of a search for detects. We find that if the test method is fixed, we can identity classes of software that are more or less testable. Using a combination of model mutators and machine learning, we find that we can isolate topological features that significantly change the effectiveness of a defect detection tool. More specifically, we show that for one defect detection tool (a stochastic search engine) applied to a certain representation (finite state machines), we can increase the average odds of finding a defect from 69\% to 91\%. The method used to change those odds is quite general and should apply to other defect detection tools being applied to other representations.},
author = {Owen, D. and Menzies, T. and Cukic, B.},
booktitle = {Proceedings 17th IEEE International Conference on Automated Software Engineering,},
doi = {10.1109/ASE.2002.1115019},
isbn = {0-7695-1736-6},
issn = {1527-1366},
title = {{What makes finite-state models more (or less) testable?}},
year = {2002}
}
@article{Song2010b,
abstract = {BACKGROUND\&\#x02014;Predicting defect-prone software components is an economically important activity and so has received a good deal of attention. However, making sense of the many, and sometimes seemingly inconsistent, results is difficult. OBJECTIVE\&\#x02014;We propose and evaluate a general framework for software defect prediction that supports 1) unbiased and 2) comprehensive comparison between competing prediction systems. METHOD\&\#x02014;The framework is comprised of 1) scheme evaluation and 2) defect prediction components. The scheme evaluation analyzes the prediction performance of competing learning schemes for given historical data sets. The defect predictor builds models according to the evaluated learning scheme and predicts software defects with new data according to the constructed model. In order to demonstrate the performance of the proposed framework, we use both simulation and publicly available software defect data sets. RESULTS\&\#x02014;The results show that we should choose different learning schemes for different data sets (i.e., no scheme dominates), that small details in conducting how evaluations are conducted can completely reverse findings, and last, that our proposed framework is more effective and less prone to bias than previous approaches. CONCLUSIONS\&\#x02014;Failure to properly or fully evaluate a learning scheme can be misleading; however, these problems may be overcome by our proposed framework.},
author = {Song, Qinbao and Jia, Zihan and Shepperd, Martin and Ying, Shi and Liu, Jin},
doi = {10.1109/TSE.2010.90},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework(2).pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Machine learning,Scheme evaluation,Software defect prediction,Software defect-proneness prediction},
number = {3},
pages = {356--370},
title = {{A general software defect-proneness prediction framework}},
volume = {37},
year = {2011}
}
@article{Schutze2011a,
abstract = {BACKGROUND: SELEX is an iterative process in which highly diverse synthetic nucleic acid libraries are selected over many rounds to finally identify aptamers with desired properties. However, little is understood as how binders are enriched during the selection course. Next-generation sequencing offers the opportunity to open the black box and observe a large part of the population dynamics during the selection process.$\backslash$n$\backslash$nMETHODOLOGY: We have performed a semi-automated SELEX procedure on the model target streptavidin starting with a synthetic DNA oligonucleotide library and compared results obtained by the conventional analysis via cloning and Sanger sequencing with next-generation sequencing. In order to follow the population dynamics during the selection, pools from all selection rounds were barcoded and sequenced in parallel.$\backslash$n$\backslash$nCONCLUSIONS: High affinity aptamers can be readily identified simply by copy number enrichment in the first selection rounds. Based on our results, we suggest a new selection scheme that avoids a high number of iterative selection rounds while reducing time, PCR bias, and artifacts.},
author = {Sch\"{u}tze, Tatjana and Wilhelm, Barbara and Greiner, Nicole and Braun, Hannsj\"{o}rg and Peter, Franziska and M\"{o}rl, Mario and Erdmann, Volker a. and Lehrach, Hans and Konthur, Zolt\'{a}n and Menger, Marcus and Arndt, Peter F. and Gl\"{o}kler, J\"{o}rn},
doi = {10.1371/journal.pone.0029604},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Schutze11.pdf:pdf},
isbn = {1932-6203 (Electronic)$\backslash$n1932-6203 (Linking)},
issn = {19326203},
journal = {PLoS ONE},
number = {12},
pages = {1--11},
pmid = {22242135},
title = {{Probing the SELEX process with next-generation sequencing}},
volume = {6},
year = {2011}
}
@article{me89zb,
author = {Menzies, T J},
journal = {AI Expert},
title = {{Domain-Specific Knowledge Representations}},
year = {1989}
}
@incollection{hameco95,
abstract = {The field of software visualization (SV) investigates approaches and techniques for static and dynamic graphical representations of algorithms, programs (code), and processed data. SV is concerned primarily with the analysis of programs and their development. The goal is to improve our understanding of inherently invisible and intangible software, particularly when dealing with large information spaces that characterize domains like software maintenance, reverse engineering, and collaborative development. The main challenge is to find effective mappings from different software aspects to graphical representations using visual metaphors. This paper provides an overview of the SV research, describes current research directions, and includes an extensive list of recommended readings.},
author = {Gra\v{c}anin, Denis and Matkovi\'{c}, Kre\v{s}imir and Eltoweissy, Mohamed},
booktitle = {Innov. Syst. Softw. Eng.},
chapter = {Visualisat},
doi = {10.1007/s11334-005-0019-8},
issn = {1614-5046},
keywords = {Software Visualization},
number = {2},
pages = {221--230},
publisher = {World-Scientific},
title = {{Software Visualization}},
url = {http://www.springerlink.com/content/q4r0t56w726620u4/},
volume = {1},
year = {2005}
}
@article{turhan13,
abstract = {Context: Defect prediction research mostly focus on optimizing the performance of models that are constructed for isolated projects (i.e. within project (WP)) through retrospective analyses. On the other hand, recent studies try to utilize data across projects (i.e. cross project (CP)) for building defect prediction models for new projects. There are no cases where the combination of within and cross (i.e. mixed) project data are used together. Objective: Our goal is to investigate the merits of using mixed project data for binary defect prediction. Specifically, we want to check whether it is feasible, in terms of defect detection performance, to use data from other projects for the cases (i) when there is an existing within project history and (ii) when there are limited within project data. Method: We use data from 73 versions of 41 projects that are publicly available. We simulate the two above-mentioned cases, and compare the performances of naive Bayes classifiers by using within project data vs. mixed project data. Results: For the first case, we find that the performance of mixed project predictors significantly improves over full within project predictors (p-value < 0.001), however the effect size is small (Hedgesâ² g = 0.25). For the second case, we found that mixed project predictors are comparable to full within project predictors, using only 10\% of available within project data (p-value = 0.002, g = 0.17). Conclusion: We conclude that the extra effort associated with collecting data from other projects is not feasible in terms of practical performance improvement when there is already an established within project defect predictor using full project history. However, when there is limited project history, e.g. early phases of development, mixed project predictions are justifiable as they perform as good as full within project models. Â© 2012 Elsevier B.V. All rights reserved.},
author = {Turhan, Burak and {Tosun Misirli}, AyÅe and Bener, AyÅe},
doi = {10.1016/j.infsof.2012.10.003},
file = {:Users/timm/svns/doc/13turhanMixed.pdf:pdf},
isbn = {0950-5849},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Cross project,Defect prediction,Fault prediction,Mixed project,Product metrics,Within project},
number = {6},
pages = {1101--1118},
title = {{Empirical evaluation of the effects of mixed project data on learning defect predictors}},
volume = {55},
year = {2013}
}
@inproceedings{peters12,
abstract = {Ideally, we can learn lessons from software projects across$\backslash$nmultiple organizations. However, a major impediment to such knowledge$\backslash$nsharing are the privacy concerns of software development organizations.$\backslash$nThis paper aims to provide defect data-set owners with an effective$\backslash$nmeans of privatizing their data prior to release. We explore MORPH which$\backslash$nunderstands how to maintain class boundaries in a data-set. MORPH is a$\backslash$ndata mutator that moves the data a random distance, taking care not to$\backslash$ncross class boundaries. The value of training on this MORPHed data is$\backslash$ntested via a 10-way within learning study and a cross learning study$\backslash$nusing Random Forests, Naive Bayes, and Logistic Regression for ten$\backslash$nobject-oriented defect datasets from the PROMISE data repository.$\backslash$nMeasured in terms of exposure of sensitive attributes, the MORPHed data$\backslash$nwas four times more private than the unMORPHed data. Also, in terms of$\backslash$nthe f-measures, there was little difference between the MORPHed and$\backslash$nunMORPHed data (original data and data privatized by data-swapping) for$\backslash$nboth the cross and within study. We conclude that at least for the kinds$\backslash$nof OO defect data studied in this project, data can be privatized$\backslash$nwithout concerns for inference efficacy.},
annote = {$\backslash$url\{http://menzies.us/pdf/12privacy.pdf\}},
author = {Peters, Fayola and Menzies, Tim},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2012.6227194},
isbn = {9781467310673},
issn = {02705257},
keywords = {data mining,defect prediction,privacy},
pages = {189--199},
title = {{Privacy and utility for defect prediction: Experiments with MORPH}},
year = {2012}
}
@article{Seo2013a,
abstract = {Context Along with expert judgment, analogy-based estimation, and algorithmic methods (such as Function point analysis and COCOMO), Least Squares Regression (LSR) has been one of the most commonly studied software effort estimation methods. However, an effort estimation model using LSR, a single LSR model, is highly affected by the data distribution. Specifically, if the data set is scattered and the data do not sit closely on the single LSR model line (do not closely map to a linear structure) then the model usually shows poor performance. In order to overcome this drawback of the LSR model, a data partitioning-based approach can be considered as one of the solutions to alleviate the effect of data distribution. Even though clustering-based approaches have been introduced, they still have potential problems to provide accurate and stable effort estimates. Objective In this paper, we propose a new data partitioning-based approach to achieve more accurate and stable effort estimates via LSR. This approach also provides an effort prediction interval that is useful to describe the uncertainty of the estimates. Method Empirical experiments are performed to evaluate the performance of the proposed approach by comparing with the basic LSR approach and clustering-based approaches, based on industrial data sets (two subsets of the ISBSG (Release 9) data set and one industrial data set collected from a banking institution). Results The experimental results show that the proposed approach not only improves the accuracy of effort estimation more significantly than that of other approaches, but it also achieves robust and stable results according to the degree of data partitioning. Conclusion Compared with the other considered approaches, the proposed approach shows a superior performance by alleviating the effect of data distribution that is a major practical issue in software effort estimation. ?? 2013 Elsevier B.V. All rights reserved.},
author = {Seo, Yeong Seok and Bae, Doo Hwan and Jeffery, Ross},
doi = {10.1016/j.infsof.2013.03.007},
file = {:Users/timm/svns/doc/13effortPartition.pdf:pdf},
isbn = {0950-5849},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Adaptive recursive data partitioning,Data distribution,Least squares regression,Software cost estimation,Software effort estimation,Software project management},
number = {10},
pages = {1710--1725},
publisher = {Elsevier B.V.},
title = {{AREION: Software effort estimation based on multiple regressions with adaptive recursive data partitioning}},
url = {http://dx.doi.org/10.1016/j.infsof.2013.03.007},
volume = {55},
year = {2013}
}
@article{Quinlan1986a,
abstract = {Recent literature has demonstrated the applicability of genetic programming to induction of decision trees for modelling toxicity endpoints. Compared with other decision tree induction techniques that are based upon recursive partitioning employing greedy searches to choose the best splitting attribute and value at each node that will necessarily miss regions of the search space, the genetic programming based approach can overcome the problem. However, the method still requires the discretization of the often continuous-valued toxicity endpoints prior to the tree induction. A novel extension of this method, YAdapt, is introduced in this work which models the original continuous endpoint by adaptively finding suitable ranges to describe the endpoints during the tree induction process, removing the need for discretization prior to tree induction and allowing the ordinal nature of the endpoint to be taken into account in the models built.},
author = {Quinlan, J. R.},
doi = {10.1007/BF00116251},
file = {:Users/timm/svns/doc/86LearningTreesquinlan.pdf:pdf},
isbn = {9783540283485},
issn = {08856125},
journal = {Machine Learning},
keywords = {classification,decision trees,expert systems,induction,information theory,knowledge acquisition},
number = {1},
pages = {81--106},
pmid = {17050186},
title = {{Induction of decision trees}},
volume = {1},
year = {1986}
}
@article{Attarzadeh2011a,
abstract = {An approach for the retrieval of price information from internet sites is applied to real-world application problems in this paper. The Web Information Retrieval System (WIRS) utilizes Hidden Markov Model (HMM) for its powerful capability to process temporal information. HMM is an extremely flexible tool and has been successfully applied to a wide variety of stochastic modeling tasks. In order to compare the prices and features of products from various web sites, the WIRS extracts prices and descriptions of various products within web pages. The WIRS is evaluated with real-world problems and compared with a conventional method and the result is reported in this paper. Â© Springer-Verlag Berlin Heidelberg 2011.},
author = {Kim, Tae Hyun and Park, Dong Chul and Huh, Woong and Kim, Hyen Ug and Yoon, Chung Hwa and Park, Chong Dae and Woo, Dong Min and Jeong, Taikyeong and Cho, Il Hwan and Lee, Yunsik},
doi = {10.1007/978-3-642-18134-4},
file = {:Users/timm/svns/doc/cost/11Iman.pdf:pdf},
isbn = {978-3-642-18133-7},
issn = {18650929},
journal = {Communications in Computer and Information Science},
keywords = {artificial neural networks,cocomo model,cost estimation models,soft computing techniques,software,software engineering,software project management},
number = {PART 2},
pages = {509--514},
title = {{Intelligent Computing and Information Science}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84880748568\&partnerID=tZOtx3y1},
volume = {135},
year = {2011}
}
@article{zimmermann10a,
abstract = {In software development, bug reports provide crucial information to developers. However, these reports widely differ in their quality. We conducted a survey among developers and users of APACHE, ECLIPSE, and MOZILLA to find out what makes a good bug report. The analysis of the 466 responses revealed an information mismatch between what developers need and what users supply. Most developers consider steps to reproduce, stack traces, and test cases as helpful, which are, at the same time, most difficult to provide for users. Such insight is helpful for designing new bug tracking tools that guide users at collecting and providing more helpful information. Our CUEZILLA prototype is such a tool and measures the quality of new bug reports; it also recommends which elements should be added to improve the quality. We trained CUEZILLA on a sample of 289 bug reports, rated by developers as part of the survey. The participants of our survey also provided 175 comments on hurdles in reporting and resolving bugs. Based on these comments, we discuss several recommendations for better bug tracking systems, which should focus on engaging bug reporters, better tool support, and improved handling of bug duplicates.},
author = {Zimmermann, Thomas and Premraj, Rahul and Bettenburg, Nicolas and Just, Sascha and Schr\"{o}ter, Adrian and Weiss, Cathrin},
doi = {10.1109/TSE.2010.63},
isbn = {9781595939951},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Testing and debugging,and enhancement,distribution,human factors,maintenance,management,measurement},
month = sep,
number = {5},
pages = {618--643},
title = {{What makes a good bug report?}},
volume = {36},
year = {2010}
}
@article{shannon53,
author = {Shannon, Claude E},
journal = {Trans. of the IRE Professional Group on Information Theory (TIT)},
pages = {169--174},
title = {{Discussion on Dr. Shannon's papers}},
volume = {1},
year = {1953}
}
@article{El-halym2009a,
author = {El-halym, Howida a Abd and Mahmoud, Imbaby I and Abdeltawab, a},
file = {:Users/timm/svns/doc/pso/09psoParticleFiltering.pdf:pdf},
journal = {Electronics and Communications},
keywords = {object tracking,particle filter,particle swarm optimization},
pages = {1--12},
title = {{Particle Filter versus Particle Swarm Optimization for Object}},
year = {2009}
}
@misc{me00c,
author = {Menzies, Tim and Cukic, Bojan and Coiera, Enrico},
month = apr,
number = {April},
pages = {7--10},
title = {{Agents Talking Faster Â¤Â£}},
year = {2000}
}
@inproceedings{hameph95,
author = {Haynes, P and Menzies, T and Phipps, G},
booktitle = {OOPSLA Workshop on OO Process and Metrics for Effort Estimation},
title = {{Using The Size of Classes and Methods as the Basis for Early Effort Prediction; Empirical Observations, Initial Application; A Practitioners Experience Report}},
year = {1995}
}
@inproceedings{zhang10,
author = {Zhang, Hongyu and Nelson, Adam and Menzies, Tim},
title = {{Proceedings of PROMISE'10}},
year = {2010}
}
@article{me09d,
annote = {Avialable from $\backslash$url\{http://menzies.us/pdf/09ir4pc.pdf\}},
author = {Etzkorn, L and Menzies, T},
journal = {Empirical Software Engineering},
number = {1},
pages = {1--4},
title = {{Editorial, Special issue on information retrieval for program comprehension}},
volume = {14},
year = {2009}
}
@article{me08b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ddp.pdf\}},
author = {Feather, M and Cornford, S and Hicks, K and Kiper, J and Menzies, T},
journal = {IEEE Software},
month = may,
title = {{Application of a broad-spectrum quantitative requirements model to early-lifecycle decision making}},
year = {2008}
}
@misc{Boetticher:Menzies:Ostrand:2007,
author = {Menzies, T and Caglayan, B and Kocaguneli, E and Krall, J and Peters, F and Turhan, B},
booktitle = {Available: promisedata. googlecode. com},
institution = {West Virginia University, Department of Computer Science},
title = {{The promise repository of empirical software engineering data}},
url = {http://promisedata.org/repository},
year = {2012}
}
@misc{lee04,
author = {Lee, S C and Santo, a G},
booktitle = {Design},
pages = {1--8},
title = {{Tradeoffs in Functional Allocation Between Spacecraft Autonomy and Ground Operations : the Near ( Near Earth Asteroid Rendezvous ) Experience}},
year = {1999}
}
@inproceedings{bayana03,
author = {Bayana, S and Owen, D and Menzies, T and Mukhopadhyay, S},
title = {{God Does Play Dice: Diagnosis and Validation for Autonomous Systems}},
year = {2004}
}
@article{Molecular2010a,
author = {Molecular, Heterogeneous and Databases, Biology},
doi = {10.1089/cmb.1995.2.537.Published},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/vanUitertSearchResults.pdf:pdf},
issn = {10665277},
journal = {Journal of Computational Biology},
pages = {1--27},
title = {{Journal of Computational Biology Journal of Computational Biology}},
year = {2010}
}
@article{Zitzler1998a,
abstract = {Since 1985 various evolutionary approaches to multiobjective$\backslash$noptimization have been developed, capable of searching for multiple$\backslash$nsolutions concurrently in a single run. But the few comparative studies$\backslash$nof different methods available to date are mostly qualitative and$\backslash$nrestricted to two approaches. In this paper an extensive, quantitative$\backslash$ncomparison is presented, applying four multiobjective evolutionary$\backslash$nalgorithms to an extended 0/1 knapsack problem.},
author = {Zitzler, E and Thiele, L},
doi = {10.1007/BFb0056872},
file = {:Users/timm/svns/doc/98speaa.pdf:pdf},
isbn = {3-540-65078-4},
issn = {0302-9743},
journal = {Parallel Problem Solving From Nature - Ppsn V},
number = {September},
pages = {292--301},
title = {{Multiobjective optimization using evolutionary algorithms - A comparative case study}},
volume = {1498},
year = {1998}
}
@inproceedings{me96n,
author = {Menzies, T},
booktitle = {Proceedings of the ECAI '96 workshop on Validation, Verification, and Refinement of KBS},
title = {{Generalised Test = Generalised Inference}},
year = {1996}
}
@inproceedings{me07,
author = {Tar, The and Learner, Treatment},
booktitle = {Review Literature And Arts Of The Americas},
keywords = {contrast set learning,tar3,treatment learning},
title = {{Just Enough Learning ( of Association Rules ):}},
year = {2007}
}
@inproceedings{Mac06,
author = {Machanavajjhala, Ashwin and Gehrke, Johannes and Kifer, Daniel and Venkitasubramaniam, Muthuramakrishnan},
booktitle = {ICDE},
pages = {24},
title = {{l-Diversity: Privacy Beyond k-Anonymity}},
year = {2006}
}
@article{Fang2008a,
abstract = {A method is presented to partition a given set of data entries embedded in Euclidean space by recursively bisecting clusters into smaller ones. The initial set is subdivided into two subsets whose centroids are farthest from each other, and the process is repeated recursively on each subset. An approximate algorithm is proposed to solve the original integer programming problem which is NP-hard. Experimental evidence shows that the clustering method often outperforms a standard spectral clustering method, albeit at a slightly higher computational cost. The paper also discusses improvements of the standard K-means algorithm. Specifically, the clustering quality resulting from the K-means technique can be significantly enhanced by using the proposed algorithm for its initialization.},
author = {Fang, Haw Ren and Saad, Yousef},
doi = {10.1109/ICMLA.2008.141},
file = {:Users/timm/svns/doc/08farthestCentroidsDivisiveClustering.pdf:pdf},
isbn = {9780769534954},
journal = {Proceedings - 7th International Conference on Machine Learning and Applications, ICMLA 2008},
keywords = {graph partitioning,k-means algorithm,lanczos method,spectral bisection,unsupervised clustering},
pages = {232--238},
title = {{Farthest centroids divisive clustering}},
year = {2008}
}
@article{pearson1901,
abstract = {AbstractDownload full textRelated$\backslash$n $\backslash$n $\backslash$n$\backslash$n $\backslash$n$\backslash$n$\backslash$n $\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n var addthis\_config = \{$\backslash$n ui\_cobrand: "Taylor \&amp; Francis Online",$\backslash$n services\_compact: "citeulike,netvibes,twitter,technorati,delicious,linkedin,facebook,stumbleupon,digg,google,more",$\backslash$n pubid: "ra-4dff56cd6bb1830b"$\backslash$n \};$\backslash$n$\backslash$n $\backslash$n$\backslash$n $\backslash$n$\backslash$n $\backslash$n $\backslash$n Add to shortlist$\backslash$n $\backslash$n $\backslash$n$\backslash$n $\backslash$n$\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n Link$\backslash$n $\backslash$n$\backslash$n $\backslash$n $\backslash$n $\backslash$n Permalink$\backslash$n $\backslash$n$\backslash$n $\backslash$n $\backslash$n $\backslash$n$\backslash$n $\backslash$n$\backslash$n$\backslash$n$\backslash$n $\backslash$n $\backslash$n $\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n $\backslash$n $\backslash$n http://dx.doi.org/10.1080/14786440109462720$\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n$\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n Download Citation$\backslash$n $\backslash$n $\backslash$n$\backslash$n $\backslash$n $\backslash$n $\backslash$n Recommend to:$\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n$\backslash$n $\backslash$n$\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n$\backslash$n A friend},
author = {Pearson, Karl},
doi = {10.1080/14786440109462720},
isbn = {1941-5982},
issn = {1941-5982},
journal = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
pages = {559--572},
title = {{LIII. On lines and planes of closest fit to systems of points in space}},
url = {http://dx.doi.org/10.1080/14786440109462720},
volume = {2},
year = {1901}
}
@book{endres03,
abstract = {This book is intended as a handbook for students and practitioners alike. The book is structured around the type of tasks that practitioners are confronted with, beginning with requirements definition and concluding with maintenance and withdrawal. It identifies and discusses existing laws that have a significant impact on the software engineering field. These laws are largely independent of the technologies involved, which allow students to learn the principles underlying software engineering. This also guides students toward the best practice when implementing software engineering techniques.},
author = {Moitra, D.},
booktitle = {IEEE Software},
doi = {10.1109/MS.2004.1270773},
isbn = {0321154207},
issn = {0740-7459},
number = {2},
pmid = {4005},
publisher = {Addison Wesley},
title = {{A handbook of software and systems engineering: empirical observations, laws and theories [Book Review]}},
volume = {21},
year = {2004}
}
@article{Lee2009c,
abstract = {Community Question Answering (cQA) services, such as Yahoo! Answers and MSN QnA, facilitate knowledge sharing through question answering by an online community of users. These services include incentive mechanisms to entice participation and self-regulate the quality of the content contributed by the users. In order to encourage quality contributions, community members are asked to nominate the \&amp;\#x02018;best\&amp;\#x02019; among the answers provided to a question. The service then awards extra points to the author who provided the winning answer and to the voters who cast their vote for that answer. The best answers are typically selected by plurality voting, a scheme that is simple, yet vulnerable to random voting and collusion. We propose a weighted voting method that incorporates information about the voters\&amp;\#x02019; behavior. It assigns a score to each voter that captures the level of agreement with other voters. It uses the voter scores to aggregate the votes and determine the best answer. The mathematical formulation leads to the application of the Brouwer Fixed Point Theorem which guarantees the existence of a voter scoring function that satisfies the starting axiom. We demonstrate the robustness of our approach through simulations and analysis of real cQA service data.},
author = {Lee, Chong Tong and Rodrigues, Eduarda Mendes and Kazai, Gabriella and Mili\'{c}-Frayling, Nata\v{s}a and Ignjatovi\'{c}, Aleksandar},
doi = {10.1109/WI-IAT.2009.23},
file = {:Users/timm/svns/doc/Milic-Frayling\_2009.pdf:pdf},
isbn = {9780769538013},
journal = {Proceedings - 2009 IEEE/WIC/ACM International Conference on Web Intelligence, WI 2009},
keywords = {Community question answering,FPS method,Fixed point theorem,Vote spam,Voter score,Weighted voting},
pages = {116--123},
title = {{Model for voter scoring and best answer selection in community Q\&A services}},
volume = {1},
year = {2009}
}
@article{vasil13,
author = {Papakroni, Vasil and Menzies, Tim and Peters, Fayola and Partington, Susan and Marcus, Andrian and State, Wayne},
isbn = {2011680013004},
journal = {Submitted to the International Conference on Automated Software Engineering (ASE'13)},
keywords = {-data mining,clas-,clustering,defect prediction,feature selection,instance based,planning,sification},
title = {{Peeking at Data Considered Harmful ?}},
year = {2012}
}
@inproceedings{krall14aaai,
author = {Krall, Joseph and Menzies, Tim and Davies, Misty},
booktitle = {2014 AAAI Spring Symposium Series},
title = {{Learning the Task Management Space of an Aircraft Approach Model}},
year = {2014}
}
@misc{me99d,
annote = {In preperation},
author = {Menzies, T and Cukic, B},
howpublished = {NASA/WVU IVV tech report.},
month = mar,
title = {{An Average-Case Model of Reachability}},
year = {1999}
}
@misc{me95i,
author = {Menzies, T J and Taylor, a},
institution = {Department of Software Development, Monash University},
number = {TR95-36},
title = {{Abduction and Memoing}},
year = {1995}
}
@misc{me09c,
author = {Gundy-Burlet, K and Schumann, J and Menzies, T and Barrett, T},
booktitle = {AIAA Aerospace, 2009},
title = {{Parametric Analysis of a Hover Test Vehicle Using Advanced Test Generation and Data Analysis}},
year = {2009}
}
@inproceedings{me97e,
author = {M.Posterma and Wu, X and Menzies, T J},
booktitle = {First Pacific Asia Conference on Knowledge Discovery and Data Mining (PAKDD97)},
title = {{A Tuning Aid for Discretization in Rule Induction}},
year = {1997}
}
@inproceedings{meedng92,
author = {Menzies, T J and Edwards, J and Ng, K},
booktitle = {Tools Pacific 1992},
pages = {421--428},
publisher = {Prentice Hall},
title = {{The \{M\}ysterious \{C\}ase of the \{M\}issing \{R\}e-usable \{C\}lass \{L\}ibraries}},
year = {1992}
}
@article{Thomas2013a,
abstract = {Bug localization is the task of determining which source code$\backslash$nentities are relevant to a bug report. Manual bug localization is labor$\backslash$nintensive since developers must consider thousands of source code$\backslash$nentities. Current research builds bug localization classifiers, based on$\backslash$ninformation retrieval models, to locate entities that are textually$\backslash$nsimilar to the bug report. Current research, however, does not consider$\backslash$nthe effect of classifier configuration, i.e., all the parameter values$\backslash$nthat specify the behavior of a classifier. As such, the effect of each$\backslash$nparameter or which parameter values lead to the best performance is$\backslash$nunknown. In this paper, we empirically investigate the effectiveness of$\backslash$na large space of classifier configurations, 3,172 in total. Further, we$\backslash$nintroduce a framework for combining the results of multiple classifier$\backslash$nconfigurations since classifier combination has shown promise in other$\backslash$ndomains. Through a detailed case study on over 8,000 bug reports from$\backslash$nthree large-scale projects, we make two main contributions. First, we$\backslash$nshow that the parameters of a classifier have a significant impact on$\backslash$nits performance. Second, we show that combining multiple$\backslash$nclassifiers--whether those classifiers are hand-picked or randomly$\backslash$nchosen relative to intelligently defined subspaces of$\backslash$nclassifiers--improves the performance of even the best individual$\backslash$nclassifiers.},
author = {Thomas, Stephen W. and Nagappan, Meiyappan and Blostein, Dorothea and Hassan, Ahmed E.},
doi = {10.1109/TSE.2013.27},
file = {:Users/timm/svns/doc/Thomas\_2013\_TSE.pdf:pdf},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {LDA,LSI,Software maintenance,VSM,bug localization,classifier combination,information retrieval},
number = {10},
pages = {1427--1443},
title = {{The impact of classifier configuration and classifier combination on bug localization}},
volume = {39},
year = {2013}
}
@inproceedings{me09n,
abstract = {The mantra of the PROMISE series is "repeatable, improvable, maybe refutable" software engineering experiments. This community has successfully created a library of reusable software engineering data sets. The next challenge in the PROMISE community will be to not only share data, but to share experiments. Our experience with existing data mining environments is that these tools are not suitable for publishing or sharing repeatable experiments. OURMINE is an environment for the development of data mining experiments. OURMINE offers a succinct notation for describing experiments. Adding new tools to OURMINE, in a variety of languages, is a rapid and simple process. This makes it a useful research tool. Complicated graphical interfaces have been eschewed for simple command-line prompts. This simplifies the learning curve for data mining novices. The simplicity also encourages large scale modification and experimentation with the code. In this paper, we show the OURMINE code required to reproduce a recent experiment checking how defect predictors learned from one site apply to another. This is an important result for the PROMISE community since it shows that our shared repository is not just a useful academic resource. Rather, it is a valuable resource industry: companies that lack the local data required to build those predictors can use PROMISE data to build defect predictors.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09ourmine.pdf\}},
author = {Gay, Gregory and Menzies, Tim and Cukic, Bojan and Turhan, Burak},
booktitle = {Proceedings of the 5th International Conference on Predictor Models in Software Engineering - PROMISE '09},
doi = {10.1145/1540438.1540460},
isbn = {9781605586342},
keywords = {algorithms,development of data mining,envi-,experimentation,measurement,of powerful open-source development,platforms also came the,with the recent rise},
pages = {1},
title = {{How to build repeatable experiments}},
url = {http://portal.acm.org/citation.cfm?doid=1540438.1540460},
year = {2009}
}
@article{me12a,
abstract = {The goal of science is conclusion stability, i.e. to discover some effect X that holds in multiple situations. Sadly, there are all too few examples of stable conclusions in software engineering (SE). In fact, the typical result is conclusion instability where what is true for project one, does not hold for project two. We can find numerous studies of the following form: there is as much evidence for as against the argument that some aspect X adds value to a software project. Below are four examples of this type of problem which we believe to be endemic within SE.},
author = {Menzies, Tim and Shepperd, Martin},
doi = {10.1007/s10664-011-9193-5},
issn = {13823256},
journal = {Empirical Software Engineering},
number = {1-2},
pages = {1--17},
title = {{Special issue on repeatable results in software engineering prediction}},
volume = {17},
year = {2012}
}
@article{wernick03,
author = {Wernick, Paul and Scacchi, Walt},
doi = {10.1002/spip.195},
issn = {1099-1670},
journal = {Software Process: Improvement and Practice},
number = {2},
pages = {51--53},
publisher = {John Wiley \& Sons, Ltd.},
title = {{Special Issue on ProSim 2003, The 4th International Workshop on Software Process Simulation and Modeling, Portland, OR, May 2003}},
url = {http://doi.wiley.com/10.1002/spip.195$\backslash$npapers2://publication/doi/10.1002/spip.195},
volume = {9},
year = {2004}
}
@inproceedings{me09f,
abstract = {"Faster, Better, Cheaper" (FBC) was a development philosophy adopted by the NASA administration in the mid to late 1990s. that lead to some some dramatic successes such as Mars Pathfinder as well as a number highly publicized mission failures, such as the Mars Climate Orbiter \& Polar Lander. $\backslash$nThe general consensus on FBC was "Faster, Better, Cheaper? Pick any two". According to that view, is impossibly to optimize on all three criteria without compromising the third. This paper checks that view using an AI search tool called STAR. We show that FBC is indeed feasible and produces similar or better results when compared to other methods However, for FBC to work, there must be a balanced concern and concentration on the quality aspects of a project. If not, "FBC" becomes "CF" (cheaper and faster) with the inevitable lose in project quality.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09bfc.pdf\}},
author = {Menzies, Tim and El-Rawas, Oussama and Hihn, Jairus and Boehm, Barry},
booktitle = {Proceedings of the 5th International Conference on Predictor Models in Software Engineering - PROMISE '09},
doi = {10.1145/1540438.1540442},
isbn = {9781605586342},
keywords = {cheaper,cocomo,faster better,predictor models,simulated annealing,software engineering,software processes},
pages = {1},
title = {{Can we build software faster and better and cheaper?}},
url = {http://portal.acm.org/citation.cfm?doid=1540438.1540442},
year = {2009}
}
@article{Ordonez2001a,
abstract = {Clustering is a data mining problem that has received significant
attention by the database community. Data set size, dimensionality and
sparsity have been identified as aspects that make clustering more
difficult. The article introduces a fast algorithm to cluster large
binary data sets where data points have high dimensionality and most of
their coordinates are zero. This is the case with basket data
transactions containing items, that can be represented as sparse binary
vectors with very high dimensionality. An experimental section shows
performance, advantages and limitations of the proposed approach},
author = {Ordonez, C. and Omiecinski, E. and Ezquerra, N.},
doi = {10.1109/ICDM.2001.989586},
file = {:Users/timm/svns/doc/erin/references/BinarySparseClustering/Ordonez01.pdf:pdf},
isbn = {0-7695-1119-8},
issn = {15504786},
journal = {Proceedings 2001 IEEE International Conference on Data Mining},
pages = {1--4},
title = {{A fast algorithm to cluster high dimensional basket data}},
volume = {1},
year = {2001}
}
@article{Schuffenhauer2006a,
abstract = {Following the theoretical model by Hann et al. moderately complex structures are preferable lead compounds since they lead to specific binding events involving the complete ligand molecule. To make this concept usable in practice for library design, we studied several complexity measures on the biological activity of ligand molecules. We applied the historical IC50/EC50 summary data of 160 assays run at Novartis covering a diverse range of targets, among them kinases, proteases, GPCRs, and protein-protein interactions, and compared this to the background of "inactive" compounds which have been screened for 2 years but have never shown any activity in any primary screen. As complexity measures we used the number of structural features present in various molecular fingerprints and descriptors. We found generally that with increasing activity of the ligands, their average complexity also increased, and we could therefore establish a minimum number of structural features in each descriptor needed for biological activity. Especially well suited in this context were the Similog keys and circular substructure fingerprints. These are those descriptors, which also perform especially well in the identification of bioactive compounds by similarity search, suggesting that structural features encoded in these descriptors have a high relevance for bioactivity. Since the number of features correlates with the number of atoms present in the molecule, also the number of atoms serves as a reasonable complexity measure and larger molecules have, in general, higher activities. Due to the relationship between feature counts and densities on one hand and biological activity on the other, the size bias present in almost all similarity coefficients becomes especially important. Diversity selections using these coefficients can influence the overall complexity of the resulting set of molecules, which has an impact on the biological activity that they exhibit. Using sphere-exclusion based diversity selection methods, such as OptiSim together with the Tanimoto dissimilarity, the average feature count distribution of the resulting selections is shifted toward lower complexity than that of the original set, particularly when applying tight diversity constraints. This size bias reduces the fraction of molecules in the subsets having the complexity required for a high, submicromolar activity. None of the diversity selection methods studied, namely OptiSim, divisive K-means clustering, and self-organizing maps, yielded subsets covering the activity space of the IC50 summary data set better than subsets selected randomly.},
author = {Schuffenhauer, Ansgar and Brown, Nathan and Selzer, Paul and Ertl, Peter and Jacoby, Edgar},
doi = {10.1021/ci0503558},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Schuffenhauer-JCIM-46-525-2006.pdf:pdf},
issn = {15499596},
journal = {Journal of Chemical Information and Modeling},
number = {2},
pages = {525--535},
pmid = {16562980},
title = {{Relationships between molecular complexity, biological activity, and structural diversity}},
volume = {46},
year = {2006}
}
@techreport{gent97,
author = {Gent, I P and Grant, S A and MacIntyre, E and Prosser, P and P.Shar and Smith, B M and Walsh, T},
booktitle = {The Lancet},
doi = {10.1016/S0140-6736(02)31122-X},
institution = {University of Leeds, School of Computer Studies},
issn = {01406736},
number = {2426},
pages = {323--324},
title = {{"How Not To Do It."}},
volume = {95},
year = {1870}
}
@article{beausoleil06,
abstract = {This paper introduces a multiple criteria scatter search to deal with bounded constrained non-linear continuous vector optimization problems of high dimension, applying a MultiStart Tabu Search (TS) as a diversification generation method, each TS works with its own starting point, recency memory, and aspiration threshold. Frequency memory is used to diversify the search and it is shared between the TS. A Pareto relation is applied in order to designate a subset of the best generated solutions to be reference solutions. A choice function called Kramer Choice function is used to divide the reference solutions in two subsets. The Euclidean distance is used as a measure of dissimilarity in order to find diverse solutions to be combined. Linear combinations of the reference solutions are used as a solution combination method. "Balls" in the decision space and the objective space are used to avoid duplications. Different tabu sets with different tabu tenures are employed in the scatter phase to enhance the diversity of the search. The performance of our approach is compared with Pareto-optimal frontiers and three other state-of-the-art MOEAs for a suite test problems taken from the literature. ?? 2004 Elsevier B.V. All rights reserved.},
author = {Beausoleil, Ricardo P.},
doi = {10.1016/j.ejor.2004.08.008},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Metaheuristics,Multiple objectives,Nonlinear optimization,Scatter search,Tabu search},
number = {2},
pages = {426--449},
title = {{"MOSS" multiobjective scatter search applied to non-linear multiple criteria optimization}},
volume = {169},
year = {2006}
}
@misc{me97i,
author = {Menzies, T},
howpublished = {Asian-Pacific Workshop on Intelligent Software Engineering},
title = {{Applications of Abduction: A Unified Framework for Software and Knowledge Engineering}},
year = {1998}
}
@inproceedings{me03g,
author = {{T. Menzies J. Smith}, D Raffo},
title = {{When is Pair Programming Better?}},
year = {2003}
}
@inproceedings{fea02a,
abstract = {Planning for the optimal attainment of requirements is an important early lifecycle activity. However, such planning is difficult when dealing with competing requirements, limited resources, and the incompleteness of information available at requirements time. A novel approach to requirements optimization is described. A requirements interaction model is executed to randomly sample the space of options. This produces a large amount of data, which is then condensed by a summarization tool. The result is a small list of critical decisions (i.e., those most influential in leading towards the desired optimum). This focuses human experts' attention on a relatively few decisions and makes them aware of major alternatives. This approach is iterative. Each iteration allows experts to select from among the major alternatives. In successive iterations the execution and summarization modules are run again, but each time further constrained by the decisions made in previous iteration. In the case study shown here, out of 99 yes/no decisions (approximately 10<sup>30</sup> possibilities), five iterations were sufficient to find and make the 30 key ones.},
author = {Feather, M.S. and Menzies, T.},
booktitle = {Proceedings IEEE Joint International Conference on Requirements Engineering},
doi = {10.1109/ICRE.2002.1048537},
isbn = {0-7695-1465-0},
issn = {1090-705X},
title = {{Converging on the optimal attainment of requirements}},
year = {2002}
}
@inproceedings{rich97za,
author = {Richards, D and Menzies, T J},
booktitle = {Third Australian Knowledge Acquisition Workshop, Perth},
editor = {Menzies, T J and Richards, D and Compton, P},
title = {{Extending Knowledge Engineering to Requirements Engineering from Multiple Perspectives}},
year = {1997}
}
@article{nelson11,
author = {{Adam Nelson Tim Menzies}, Gregory Gay},
journal = {Software- Practice and Experience (to appear)},
month = mar,
number = {3},
pages = {283--305},
title = {{Sharing Experiments Using Open Source Software}},
volume = {41},
year = {2011}
}
@inproceedings{me92zb,
author = {Menzies, T J and Compton, P},
booktitle = {ECAI '92 Workshop on Improving the Use of Knowledge-Based Systems with Explanations, Vienna},
title = {{Causal Explanations as a Tool for Refining Qualitative Models}},
year = {1992}
}
@article{Li2006,
abstract = {Five heuristics for attribute weighting in analogy-based effort estimation are evaluated in this paper. The baseline heuristic involves using all attributes with equal weights. We propose four additional heuristics that use rough set analysis for attribute weighting. These five heuristics are evaluated over five data sets related to software projects. Three of the data sets are publicly available, hence allowing comparison with other methods. The results indicate that three of the rough set analysis based heuristics perform better than the equal weights heuristic. This evaluation is based on an integrated measure of accuracy.},
author = {Li, Jingzhou},
doi = {10.1145/1159733.1159746},
isbn = {1595932186},
journal = {Comparative and General Pharmacology},
keywords = {attribute,attributes,estimation by analogy,missing values,non-quantitative,rough set analysis,selection and weighting,software effort estimation},
pages = {66--74},
publisher = {ACM},
title = {{A Comparative Study of Attribute Weighting Heuristics for Effort Estimation by Analogy}},
url = {http://portal.acm.org/citation.cfm?id=1159733.1159746},
year = {2006}
}
@article{dejaeger12,
abstract = {A predictive model is required to be accurate and comprehensible in order to inspire confidence in a business setting. Both aspects have been assessed in a software effort estimation setting by previous studies. However, no univocal conclusion as to which technique is the most suited has been reached. This study addresses this issue by reporting on the results of a large scale benchmarking study. Different types of techniques are under consideration, including techniques inducing tree/rule based models like M5 and CART, linear models such as various types of linear regression, nonlinear models (MARS, multilayered perceptron neural networks, radial basis function networks, and least squares support vector machines), and estimation techniques that do not explicitly induce a model (e.g., a case-based reasoning approach). Furthermore, the aspect of feature subset selection by using a generic backward input selection wrapper is investigated. The results are subjected to rigorous statistical testing and indicate that ordinary least squares regression in combination with a logarithmic transformation performs best. Another key finding is that by selecting a subset of highly predictive attributes such as project size, development, and environment related attributes, typically a significant increase in estimation accuracy can be obtained.},
author = {Dejaeger, Karel and Verbeke, Wouter and Martens, David and Baesens, Bart},
file = {:Users/timm/svns/doc/11dejaeger.pdf:pdf},
journal = {IEEE Transactions on Software Engineering},
keywords = {HF Commerce,QA76 Computer software},
pages = {375--397},
title = {{Data mining techniques for software effort estimation: a comparative study}},
url = {http://eprints.soton.ac.uk/336472/},
volume = {38},
year = {2012}
}
@article{Song2010a,
abstract = {BACKGROUND\&\#x02014;Predicting defect-prone software components is an economically important activity and so has received a good deal of attention. However, making sense of the many, and sometimes seemingly inconsistent, results is difficult. OBJECTIVE\&\#x02014;We propose and evaluate a general framework for software defect prediction that supports 1) unbiased and 2) comprehensive comparison between competing prediction systems. METHOD\&\#x02014;The framework is comprised of 1) scheme evaluation and 2) defect prediction components. The scheme evaluation analyzes the prediction performance of competing learning schemes for given historical data sets. The defect predictor builds models according to the evaluated learning scheme and predicts software defects with new data according to the constructed model. In order to demonstrate the performance of the proposed framework, we use both simulation and publicly available software defect data sets. RESULTS\&\#x02014;The results show that we should choose different learning schemes for different data sets (i.e., no scheme dominates), that small details in conducting how evaluations are conducted can completely reverse findings, and last, that our proposed framework is more effective and less prone to bias than previous approaches. CONCLUSIONS\&\#x02014;Failure to properly or fully evaluate a learning scheme can be misleading; however, these problems may be overcome by our proposed framework.},
author = {Song, Qinbao and Jia, Zihan and Shepperd, Martin and Ying, Shi and Liu, Jin},
doi = {10.1109/TSE.2010.90},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Machine learning,Scheme evaluation,Software defect prediction,Software defect-proneness prediction},
number = {3},
pages = {356--370},
publisher = {Published by the IEEE Computer Society},
title = {{A general software defect-proneness prediction framework}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/TSE.2010.90},
volume = {37},
year = {2011}
}
@article{Gaber2005a,
abstract = {The recent advances in hardware and software have enabled the capture of different measurements of data in a wide range of fields. These measurements are generated continuously and in a very high fluctuating data rates. Examples include sensor networks, web logs, and computer network traffic. The storage, querying and mining of such data sets are highly computationally challenging tasks. Mining data streams is concerned with extracting knowledge structures represented in models and patterns in non stopping streams of information. The research in data stream mining has gained a high attraction due to the importance of its applications and the increasing generation of streaming information. Applications of data stream analysis can vary from critical scientific and astronomical applications to important business and financial ones. Algorithms, systems and frameworks that address streaming challenges have been developed over the past three years. In this review paper, we present the state-of-the-art in this growing vital field.},
author = {Gaber, Mohamed Medhat and Zaslavsky, Arkady and Krishnaswamy, Shonali},
doi = {10.1145/1083784.1083789},
file = {:Users/timm/svns/doc/05stream.pdf:pdf},
isbn = {0163-5808},
issn = {01635808},
journal = {ACM SIGMOD Record},
number = {2},
pages = {18},
pmid = {15749702},
title = {{Mining data streams}},
url = {http://portal.acm.org/citation.cfm?id=1083789},
volume = {34},
year = {2005}
}
@article{Plasse2007a,
abstract = {A method to analyse links between binary attributes in a large sparse data set is proposed. Initially the variables are clustered to obtain homogeneous clusters of attributes. Association rules are then mined in each cluster. A graphical comparison of some rule relevancy indexes is presented. It is used to extract best rules depending on the application concerned. The proposed methodology is illustrated by an industrial application from the automotive industry with more than 80 000 vehicles each described by more than 3000 rare attributes. Â© 2007 Elsevier B.V. All rights reserved.},
author = {Plasse, Marie and Niang, Ndeye and Saporta, Gilbert and Villeminot, Alexandre and Leblond, Laurent},
doi = {10.1016/j.csda.2007.02.020},
file = {:Users/timm/svns/doc/erin/references/BinarySparseClustering/Plasse07.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {Association rules mining,Binary attributes,Large sparse matrix,Rule relevancy index,Variable clustering},
number = {1},
pages = {596--613},
title = {{Combined use of association rules mining and clustering methods to find relevant links between binary rare attributes in a large data set}},
volume = {52},
year = {2007}
}
@inproceedings{chen05,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05/fsscocomo.pdf\}},
author = {Chen, Zhihao and Menzies, Tim and Port, Dan and Boehm, Barry},
booktitle = {ACM SIGSOFT Software Engineering Notes},
doi = {10.1145/1082983.1083171},
isbn = {-159593-125-2},
issn = {01635948},
number = {4},
pages = {1},
title = {{Feature subset selection can improve software cost estimation accuracy}},
volume = {30},
year = {2005}
}
@inproceedings{Marcus2010b,
abstract = {Software systems are designed and engineered to process data. However, software is data too. The size and variety of today's software artifacts and the multitude of stakeholder activities result in so much data that individuals can no longer reason about all of it. We argue in this position paper that data mining, statistical analysis, machine learning, information retrieval, data integration, etc., are necessary solutions to deal with software data. New research is needed to adapt existing algorithms and tools for software engineering data and processes, and new ones will have to be created.
In order for this type of research to succeed, it should be supported with new approaches to empirical work, where data and results are shared globally among researchers and practitioners. Software engineering researchers can get inspired by other fields, such as, bioinformatics, where results of mining and analyzing biological data are often stored in databases shared across the world.},
address = {Santa Fe, NM},
annote = {Laura. Fixed on 10/01/2012},
author = {Marcus, Andrian and Menzies, Timothy},
booktitle = {Proceedings of the FSE/SDP workshop on Future of software engineering research - FoSER '10},
doi = {10.1145/1882362.1882410},
isbn = {9781450304276},
keywords = {data\_mining machine\_learning information\_retrieval},
pages = {229},
title = {{Software is data too}},
url = {http://portal.acm.org/citation.cfm?doid=1882362.1882410},
year = {2010}
}
@inproceedings{valerdi11,
abstract = {This paper discusses the notion of collective intelligence through the application of the Wideband Delphi method as a way to obtain convergence among a group of experts. The specific application is the definition and calibration of cost estimation models that use data collected from experts as part of their calibration. Convergence is important in this case because companies need to commit to cost estimates early in the planning cycle since so many other decisions are dependent on it. Our results demonstrate that, in most cases, convergence among experts can be achieved after three roundsof the Wideband Delphi. Â© 2011 by Ricardo Valerdi.},
annote = {Available from http://goo.gl/Zo9HT},
author = {Valerdi, Ricardo},
booktitle = {21st Annual International Symposium of the International Council on Systems Engineering, INCOSE 2011},
isbn = {9781618391155},
pages = {1238--1251},
title = {{Convergence of expert opinion via the wideband delphi method: An application in cost estimation models}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84877905930\&partnerID=tZOtx3y1},
volume = {2},
year = {2011}
}
@article{Sampson2003a,
abstract = {DNA and RNA microarrays have become an important analytical technique in the understanding and characterisation of genomes and transcriptomes. A recent development in this field of combinatorial chemistry has concentrated on using artificial DNA/RNA sequences-aptamers-as the screening ligand. In reviewing this technology, the article covers the topic, following a general introduction, under the headings: Generating an aptamer library, aptamer library complexity, aspects of nucleotide chemistry, constant region primer design, and the SELEX protocol for exposing an aptamer library to the desired target. ?? 2003 Elsevier Science Ltd. All rights reserved.},
author = {Sampson, Tim},
doi = {10.1016/S0172-2190(03)00035-8},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Sampson03.pdf:pdf},
isbn = {0172-2190},
issn = {01722190},
journal = {World Patent Information},
keywords = {Aptamers,Combinatorial chemistry,Exponential enrichment,Microarrays,Molecular evolution,Oligonucleotide ligands,SELEX protocol,Screening library,Spiegelmers},
number = {2},
pages = {123--129},
title = {{Aptamers and SELEX: The technology}},
volume = {25},
year = {2003}
}
@inproceedings{koc11c,
abstract = {Background: Building effort estimators requires the training data. How can we find that data? It is tempting to cross the boundaries of development type, location, language, application and hardware to use existing datasets of other organizations. However, prior results caution that using such cross data may not be useful. Aim: We test two conjectures: (1) instance selection can automatically prune irrelevant instances and (2) retrieval from the remaining examples is useful for effort estimation, regardless of their source. Method: We selected 8 cross-within divisions (21 pairs of within-cross subsets) out of 19 datasets and evaluated these divisions under different analogy-based estimation (ABE) methods. Results: Between the within \&\#x0026; cross experiments, there were few statistically significant differences in (i) the performance of effort estimators, or (ii) the amount of instances retrieved for estimation. Conclusion: For the purposes of effort estimation, there is little practical difference between cross and within data. After applying instance selection, the remaining examples (be they from within or from cross source divisions) can be used for effort estimation.},
author = {Kocaguneli, Ekrem and Menzies, Tim},
booktitle = {2011 International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2011.34},
isbn = {978-0-7695-4604-9},
issn = {1938-6451},
keywords = {cross resource,k-NN,software cost estimation,within resource},
pages = {255--264},
title = {{How to Find Relevant Data for Effort Estimation?}},
year = {2011}
}
@inproceedings{rahman12,
author = {Rahman, Foyzur and Posnett, Daryl and Devanbu, Premkumar T},
booktitle = {Foundations of Software Engineering (FSE-20)},
pages = {61},
title = {{Recalling the "imprecision" of cross-project defect prediction}},
year = {2012}
}
@misc{budgen06,
annote = {Keynote address, CSEET'06},
author = {Budgen, D},
title = {{No Title}},
year = {2006}
}
@misc{aranda11,
annote = {Available from $\backslash$url\{http://goo.gl/Tfjpc\}},
author = {Aranda, Jorge},
title = {{How do practitioners perceive software engineering research?}}
}
@inproceedings{MENZIES2005,
address = {New York, NY, USA},
author = {Menzies, Tim and Port, Dan and Chen, Zhihao and Hihn, Jairus},
booktitle = {ACM SIGSOFT Software Engineering Notes},
doi = {10.1145/1082983.1083170},
isbn = {-159593-125-2},
issn = {01635948},
number = {4},
pages = {1},
publisher = {ACM},
title = {{Simple software cost analysis}},
volume = {30},
year = {2005}
}
@inproceedings{me08d,
abstract = {Context: There are many methods that input static code features and output a predictor for faulty code modules. These data mining methods have hit a "performance ceiling"; i.e., some inherent upper bound on the amount of information offered by, say, static code features when identifying modules which contain faults. Objective: We seek an explanation for this ceiling effect. Perhaps static code features have "limited information content"; i.e. their information can be quickly and completely discovered by even simple learners. Method: An initial literature review documents the ceiling effect in other work. Next, using three sub-sampling techniques (under-, over-, and micro-sampling), we look for the lower useful bound on the number of training instances. Results: Using micro-sampling, we find that as few as 50 instances yield as much information as larger training sets. Conclusions: We have found much evidence for the limited information hypothesis. Further progress in learning defect predictors may not come from better algorithms. Rather, we need to be improving the information content of the training data, perhaps with case-based reasoning methods. Copyright 2008 ACM.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ceiling.pdf\}},
author = {Menzies, Tim and Turhan, Burak and Bener, Ayse and Gay, Gregory and Cukic, Bojan and Jiang, Yue},
booktitle = {Proceedings of the 4th international workshop on Predictor models in software engineering - PROMISE '08},
doi = {10.1145/1370788.1370801},
isbn = {9781605580364},
issn = {02705257},
keywords = {Defect prediction,Naive bayes,Over-sampling,Under-sampling},
pages = {47},
title = {{Implications of ceiling effects in defect predictors}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-57049155106\&partnerID=tZOtx3y1},
year = {2008}
}
@inproceedings{me05e,
author = {Menzies, T and Richardson, J},
booktitle = {COCOMO forum, 2005},
title = {{XOMO: Understanding Development Options for Autonomy}},
year = {2005}
}
@misc{me99d,
annote = {In preperation},
author = {Menzies, T and Cukic, B},
howpublished = {NASA/WVU IVV tech report.},
month = mar,
title = {{An Average-Case Model of Reachability}},
year = {1999}
}
@inproceedings{me01g,
author = {Menzies, Tim and Hu, Ying},
booktitle = {First International Workshop on Model-based Requirements Engineering},
title = {{Constraining Discussions in Requirements Engineering via Models}},
year = {2001}
}
@article{me97a,
abstract = {It is difficult to assess hypothetical models in poorly measured domains such as neuroendocrinology. Without a large library of observations to constrain inference, the execution of such incomplete models implies making assumptions. Mutually exclusive assumptions must be kept in separate worlds. We define a general abductive multiple-worlds engine that assesses such models by (i) generating the worlds and (ii) tests if these worlds contain known behaviour. World generation is constrained via the use of relevant envisionment. We describe QCM, a modeling language for compartmental models that can be processed by this inference engine. This tool has been used to find faults in theories published in international refereed journals; i.e. QCM can detect faults which are invisible to other methods. The generality and computational limits of this approach are discussed. In short, this approach is applicable to any representation that can be compiled into an and-or graph, provided the graphs are not too big or too intricate (fanout < 7).},
author = {Menzies, Tim and Compton, Paul},
doi = {10.1016/S0933-3657(97)00391-6},
issn = {09333657},
journal = {Artificial Intelligence in Medicine},
keywords = {Abduction,Hypothesis testing,Neuroendocrinology,Qualitative reasoning},
number = {2},
pages = {145--175},
pmid = {9201384},
title = {{Applications of abduction: Hypothesis testing of neuroendocrinological qualitative compartmental models}},
volume = {10},
year = {1997}
}
@article{dej13z,
abstract = {Software testing is a crucial activity during software development and fault prediction models assist practitioners herein by providing an upfront identification of faulty software code by drawing upon the machine learning literature. While especially the Naive Bayes classifier is often applied in this regard, citing predictive performance and comprehensibility as its major strengths, a number of alternative Bayesian algorithms that boost the possibility of constructing simpler networks with fewer nodes and arcs remain unexplored. This study contributes to the literature by considering 15 different Bayesian Network (BN) classifiers and comparing them to other popular machine learning techniques. Furthermore, the applicability of the Markov blanket principle for feature selection, which is a natural extension to BN theory, is investigated. The results, both in terms of the AUC and the recently introduced H-measure, are rigorously tested using the statistical framework of DemsÌar. It is concluded that simple and comprehensible networks with less nodes can be constructed using BN classifiers other than the Naive Bayes classifier. Furthermore, it is found that the aspects of comprehensibility and predictive performance need to be balanced out, and also the development context is an item which should be taken into account during model selection.},
author = {Dejaeger, Karel and Verbraken, Thomas and Baesens, Bart},
doi = {10.1109/TSE.2012.20},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Bayesian networks,Software fault prediction,classification,comprehensibility},
month = feb,
number = {2},
pages = {237--257},
title = {{Toward comprehensible software fault prediction models using bayesian network classifiers}},
volume = {39},
year = {2013}
}
@inproceedings{meha94,
author = {Menzies, T J and Haynes, P},
booktitle = {Tools Pacific '94},
pages = {83--92},
publisher = {Prentice-Hall},
title = {{The \{M\}ethodologies of \{M\}ethodologies; or, \{E\}valuating \{C\}urrent \{M\}ethodologies: \{W\}hy and \{H\}ow}},
year = {1994}
}
@article{Dy2004c,
author = {Dy, Jennifer G. and Brodley, Carla E.},
file = {:Users/timm/svns/doc/04dy.pdf:pdf},
issn = {1536-1241},
journal = {Journal of Macine Learning Research},
keywords = {clustering,expectation-maximization,feature selection,unsupervised learning},
pages = {845--889},
title = {{Feature Selection for Unsupervised Learning}},
volume = {5},
year = {2004}
}
@inproceedings{goa06,
abstract = {Model-checking techniques are successfully used in the verification of both hardware and software systems of industrial relevance. Unfortunately, the capability of current techniques is still limited and the effort required for verification can be prohibitive (if verification is possible at all). As a complement, fast, but incomplete, search tools may provide practical benefits not attainable with full verification tools, for example, reduced need for manual abstraction and fast detection of property violations during model development. In this report we investigate the performance of a simple random search technique. We conducted an experiment on a production-sized formal model of the mode-logic of a flight guidance system. Our results indicate that random search quickly finds the vast majority of property violations in our case-example. In addition, the times to detect various property violations follow an acutely right-skewed distribution and are highly biased toward the easy side. We hypothesize that the observations reported here are related to the phase transition phenomenon seen in Boolean satisfiability and other NP-complete problems. If so, these observations could be revealing some of the fundamental aspects of software (model) faults and have implications on how software engineering activities, such as analysis, testing, and reliability modeling, should be performed},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06compsac.pdf\}},
author = {Gao, Jimin and Heimdahl, Mats and Owen, David and Menzies, Tim},
booktitle = {Proceedings - International Computer Software and Applications Conference},
doi = {10.1109/COMPSAC.2006.64},
isbn = {0769526551},
issn = {07303157},
pages = {150--157},
title = {{On the distribution of property violations in formal models: An initial study}},
volume = {1},
year = {2006}
}
@inproceedings{burk04,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/04lean.pdf\}},
author = {Burkleaux, T and Menzies, T and Owen, D},
booktitle = {Proceedings of WITSE 2005},
title = {{LEAN = (LURCH+TAR3) = Reusable Modeling Tools}},
year = {2004}
}
@article{Ding2004a,
author = {Ding, C and He, X},
file = {:Users/timm/svns/doc/04dingClusteringPca.pdf:pdf},
journal = {International Conference on Machine Learning},
title = {{K-means Clustering via Principal Component Analysis}},
year = {2004}
}
@article{Askira-Gelman1998a,
abstract = {Knowledge discovery in databases (KDD) and machine learning
researchers recognize that comprehensibility is an important condition
for the use, and therefore usefulness, of knowledge discovery methods.
An investigation of the comprehensibility of the discovered patterns may
benefit IS research as well. This paper identifies some of the issues
that such inquiry may face. Related findings and conclusions of four
case studies focusing on applications of decision tree induction
methods, are described. A discussion based on these studies suggests,
among the rest, that the problem of comprehensibility is complicated by
a complex context due to a diversity of problem domain attributes, user
and task characteristics, algorithmic methods, and concurrency of user
goals. Solutions to problems of discovered patterns that are not easy to
interpret and validate may involve integration of available information
technologies, and utilization of multiple information types and sources.
An investigation of comprehensibility issues may benefit from the
adoption of multiple definitions in relation to this concept},
author = {Askira-Gelman, I.},
doi = {10.1109/HICSS.1998.648319},
file = {:Users/timm/svns/doc/xplain/98Gelman.pdf:pdf},
isbn = {0-8186-8255-8},
issn = {10603425},
journal = {Proceedings of the Thirty-First Hawaii International Conference on System Sciences},
number = {c},
title = {{Knowledge discovery: comprehensibility of the results}},
volume = {5},
year = {1998}
}
@article{Wu1991a,
author = {Wu, Shaun-inn},
doi = {10.1145/122438.122440},
file = {:Users/timm/svns/doc/ooprolog/p28-wu.pdf:pdf},
issn = {10556400},
journal = {ACM SIGPLAN OOPS Messenger},
number = {1},
pages = {28--37},
title = {{Integrating logic and object-oriented programming}},
volume = {2},
year = {1991}
}
@article{Noda1999a,
author = {Noda, Edgar and Noda, Edgar},
file = {:Users/timm/svns/doc/xplain/98noda.pdf:pdf},
isbn = {0780355369},
pages = {1322--1329},
title = {{Discovering Pnteresting Prediction Rules with a Genetic Algorithm}},
year = {1999}
}
@inproceedings{me09a,
abstract = {Before performing drastic changes to a project, it is worthwhile to thoroughly explore the available options within the current structure of a project. An alternative to drastic change are internal changes that adjust current options within a software project. In this paper, we show that the effects of numerous internal changes can out-weigh the effects of drastic changes. That is, the benefits of drastic change can often be achieved without disrupting a project. The key to our technique is SEESAW, a novel stochastic stability tool that (a) considers a very large set of minor changes using stochastic sampling; and (b) carefully selects the right combination of effective minor changes. Our results show, using SEESAW, project managers have more project improvement options than they currently realize. This result should be welcome news to managers struggling to maintain control and continuity over their project in the face of multiple demands for drastic change.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08drastic.pdf\}},
author = {Menzies, T. and Williams, S. and El-Rawas, O. and Boehm, B. and Hihn, J.},
booktitle = {2009 IEEE 31st International Conference on Software Engineering},
doi = {10.1109/ICSE.2009.5070552},
isbn = {978-1-4244-3453-4},
issn = {0270-5257},
title = {{How to avoid drastic software process change (using stochastic stability)}},
year = {2009}
}
@inproceedings{me97b,
author = {Menzies, T J and Mahidadia, a},
booktitle = {Workshop on Problem-Solving Methods for Knowledge-based Systems, IJCAI '97, August 23.},
title = {{Ripple-Down Rationality: A Framework for Maintaining PSMs}},
year = {1997}
}
@inproceedings{me03o,
author = {Menzies, Tim and Gunnalan, Rajesh and Appukutty, Kalaivani},
booktitle = {Business},
number = {1},
pages = {1--19},
title = {{Learning Tiny Theories}},
year = {2003}
}
@inproceedings{jiang08a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08transform.pdf\}},
author = {Jiang, Y and Cukic, B and Menzies, T},
booktitle = {Defects 2008},
title = {{Does Transformation Help?}},
year = {2008}
}
@book{schank77a,
abstract = {Published in 1977, Scripts, Plans, Goals and Understanding is a valuable contribution to the field of Cognitive Psychology.},
address = {Hillsdale, NJ.},
author = {Welin, Carl Wilhelm},
booktitle = {Journal of Pragmatics},
doi = {10.1016/0378-2166(79)90031-6},
isbn = {978-0898591385},
issn = {03782166},
number = {2},
pages = {211--217},
pmid = {3929},
publisher = {Lawrence Erlbaum Associates},
title = {{Scripts, plans, goals and understanding, an inquiry into human knowledge structures}},
volume = {3},
year = {1979}
}
@misc{me97s,
author = {Menzies, T J},
title = {{Evaluation Issues for Problem Visual Programming Languages}},
year = {1998}
}
@article{Gopinath2007a,
abstract = {SELEX (systematic evolution of ligands by exponential enrichment) is a process that involves the progressive purification from a combinatorial library of nucleic acid ligands with a high affinity for a particular target by repeated rounds of partitioning and amplification. With the development of aptamer technology over the last decade, various modified SELEX processes have arisen that allow various aptamers to be developed against a wide variety of molecules, irrespective of the target size. In the present review, the separation methods used in such SELEX processes are reviewed.},
author = {Gopinath, S. C B},
doi = {10.1007/s00216-006-0826-2},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Gopinath07.pdf:pdf},
isbn = {1618-2642},
issn = {16182642},
journal = {Analytical and Bioanalytical Chemistry},
keywords = {Aptamer,DNA,RNA,SELEX,Separation},
number = {1},
pages = {171--182},
pmid = {17072603},
title = {{Methods developed for SELEX}},
volume = {387},
year = {2007}
}
@article{me13c,
author = {Zimmermann, Thomas and Menzies, Tim},
journal = {IEEE Software},
number = {4},
pages = {31--37},
title = {{Software Analytics: So What?}},
volume = {30},
year = {2013}
}
@article{kocaguneli2014transfer,
author = {Kocaguneli, Ekrem and Menzies, Tim and Mendes, Emilia},
journal = {Empirical Software Engineering},
pages = {1--31},
publisher = {Springer US},
title = {{Transfer learning in effort estimation}},
year = {2014}
}
@article{me13d,
abstract = {Background: Given information on just a few prior projects, how do we learn the best and fewest changes for current projects? Aim: To conduct a case study comparing two ways to recommend project changes. 1) Data farmers use Monte Carlo sampling to survey and summarize the space of possible outcomes. 2) Case-based reasoners (CBR) explore the neighborhood around test instances. Method: We applied a state-of-the data farmer (SEESAW) and a CBR tool ()'V2) to software project data. Results: CBR with )'V2 was more effective than SEESAW's data farming for learning best and recommended project changes, effectively reducing runtime, effort, and defects. Further, CBR with )'V2 was comparably easier to build, maintain, and apply in novel domains, especially on noisy data sets. Conclusion: Use CBR tools like )'V2 when data are scarce or noisy or when project data cannot be expressed in the required form of a data farmer. Future Work: This study applied our own CBR tool to several small data sets. Future work could apply other CBR tools and data farmers to other data (perhaps to explore other goals such as, say, minimizing maintenance effort).},
author = {Menzies, T and Brady, a and Keung, J and Hihn, J and Williams, S and El-Rawas, O and Green, P and Boehm, B},
doi = {10.1109/TSE.2013.43},
isbn = {0098-5589 VO  - 39},
issn = {0098-5589},
journal = {Software Engineering, IEEE Transactions on},
keywords = {CBR,COCOMO,Data models,Mathematical model,Monte Carlo methods,Monte Carlo sampling,Project management,SEESAW,Search methods,Search-based software engineering,Software engineering,case-based reasoning,data farming,data handling,learning (artificial intelligence),project management,project management decision learning,sampling methods,software management,software project data},
number = {12},
pages = {1698--1713},
title = {{Learning Project Management Decisions: A Case Study with Case-Based Reasoning versus Data Farming}},
volume = {39},
year = {2013}
}
@inproceedings{RamMe1996,
author = {Ramakrishnan, S and Menzies, T and Hasslinger, M and Bok, P and Mccarthy, H and Devakadadcham, B and Moulder, D},
booktitle = {Proceedings of Tools-Pacific, Melbourne},
title = {{On Building an Effective Measurement System for OO Software Process}},
year = {1996}
}
@inproceedings{me02c,
author = {Menzies, Tim and Chiang, Eliza and Feather, Martin and Hu, Ying and Kiper, James D},
booktitle = {Jet Propulsion},
editor = {Khoshgoftaar, Taghi M},
isbn = {1-4020-7427-1},
publisher = {Kluwer},
title = {{Condensing Uncertainty via Incremental Treatment Learning}},
year = {2002}
}
@inproceedings{me08c,
abstract = {Most process models calibrate their internal settings using historical data. Collecting this data is expensive, tedious, and often an incomplete process. Is it possible to make accurate software process estimates without historical data? Suppose much of uncertainty in a model comes from a small subset of the model variables. If so, then after (a) ranking variables by their ability to constrain the output; and (b) applying a small number of the top-ranked variables; then it should be possible to (c) make stable predictions in the constrained space. To test that hypothesis, we combined a simulated annealer (to generate random solutions) with a variable ranker. The results where quite dramatic: in one of the studies in this paper, we found process options that reduced the median and variance of the effort estimates by a factor of 20. In ten case studies, we show that the estimates generated in this manner are usually similar to those produced by standard local calibration. Our conclusion is that while it is always preferable to tune models to local data, it is possible to learn process control options without that data. Â© 2008 Springer-Verlag Berlin Heidelberg.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08icsp.pdf\}},
author = {Menzies, Tim and Elrawas, Oussama and Boehm, Barry and Madachy, Raymond and Hihn, Jairus and Baker, Daniel and Lum, Karen},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-540-79588-9\_19},
isbn = {3540795871},
issn = {03029743},
pages = {210--221},
title = {{Accurate estimates without calibration?}},
volume = {5007 LNCS},
year = {2008}
}
@article{me05c,
abstract = { Good software cost models can significantly help software project managers. With good models, project stakeholders can make informed decisions about how to manage resources, how to control and plan the project, or how to deliver the project on time, on schedule, and on budget. Real-world data sets, such as those coming from software engineering projects, often contain noisy, irrelevant, or redundant variables. We propose that cost modelers should perform data-pruning experiments after data collection and before model building. Such pruning experiments are simple and fast.},
author = {Chen, Z. and Menzies, T. and Port, D. and Boehm, D.},
doi = {10.1109/MS.2005.151},
issn = {0740-7459},
journal = {IEEE Software},
keywords = {COCOMO,cost modeling,feature subset selection,software engineering,time estimation,wrapper},
month = nov,
number = {6},
pmid = {21609814},
title = {{Finding the right data for software cost modeling}},
volume = {22},
year = {2005}
}
@article{Dejaeger2012a,
abstract = {A predictive model is required to be accurate and comprehensible in order to inspire confidence in a business setting. Both aspects have been assessed in a software effort estimation setting by previous studies. However, no univocal conclusion as to which technique is the most suited has been reached. This study addresses this issue by reporting on the results of a large scale benchmarking study. Different types of techniques are under consideration, including techniques inducing tree/rule based models like M5 and CART, linear models such as various types of linear regression, nonlinear models (MARS, multilayered perceptron neural networks, radial basis function networks, and least squares support vector machines), and estimation techniques that do not explicitly induce a model (e.g., a case-based reasoning approach). Furthermore, the aspect of feature subset selection by using a generic backward input selection wrapper is investigated. The results are subjected to rigorous statistical testing and indicate that ordinary least squares regression in combination with a logarithmic transformation performs best. Another key finding is that by selecting a subset of highly predictive attributes such as project size, development, and environment related attributes, typically a significant increase in estimation accuracy can be obtained.},
author = {Dejaeger, Karel and Verbeke, Wouter and Martens, David and Baesens, Bart},
file = {:Users/timm/svns/doc/cost/12Dejaeger.pdf:pdf},
keywords = {HF Commerce,QA76 Computer software},
number = {2},
pages = {375--397},
title = {{Data mining techniques for software effort estimation: a comparative study}},
url = {http://eprints.soton.ac.uk/336472/},
volume = {38},
year = {2012}
}
@article{Baralis2004a,
author = {Baralis, Elena and Baralis, Elena and Politecnico, Silvia Chiusano and Politecnico, Silvia Chiusano and The, Introduction and The, Introduction and Machines, Vector and Machines, Vector},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/baralis04.pdf:pdf},
journal = {Database},
number = {4},
pages = {635--674},
title = {{Classi cation Rule Sets}},
volume = {29},
year = {2004}
}
@inproceedings{me00q,
abstract = {Early testing of requirements can decrease the cost of removing errors in software projects. However unless done carefully, that testing process can significantly add to the cost of requirements analysis. We show that requirements expressed as topoi diagrams can be built and tested cheaply <sup>s</sup>ing our SP2 algorithm, the formal temporal properties of a large class of topoi can be proven very quickly, in time nearly linear in the number of nodes and edges in the diagram. There are two limitations to our approach. Firstly, topoi diagrams cannot express certain complex concepts such as iteration and sub-routine calls. Hence, our approach is more useful for requirements engineering than for traditional model checking domains. Secondly, our approach is better for exploring the temporal occurrence of properties than the temporal ordering of properties. Within these restrictions, we can express a useful range of concepts currently seen in requirements engineering, and a wide range of interesting temporal properties.},
author = {Menzies, T and Powell, J and Houle, M E},
booktitle = {Software Engineering, 2001. ICSE 2001. Proceedings of the 23rd International Conference on},
doi = {10.1109/ICSE.2001.919112},
isbn = {0270-5257   VO  -},
issn = {02705257},
keywords = {SP2 algorithm,fast formal requirements analysis,formal specification,formal temporal properties,program verification,requirements engineering,software projects,testing process,topoi diagrams},
pages = {391--400},
title = {{Fast formal analysis of requirements via "topoi diagrams"}},
year = {2001}
}
@incollection{me95g,
author = {Menzies, T J},
booktitle = {Proceedings of the Melbourne Workshop on Intelligent Decision Support},
publisher = {Department of Information Systems, Monash University, Melbourne},
title = {{Applications of Abduction: Intelligent Decision Support Systems}},
year = {1996}
}
@article{Druker2010a,
author = {Reference, a Desktop Quick},
file = {:Users/timm/svns/doc/cost/10Druker.pdf:pdf},
isbn = {0596002831},
number = {January},
pages = {0--27},
title = {{in a Nutshell}},
year = {2002}
}
@inproceedings{me00y,
author = {Menzies, Tim and Cukic, Bojan},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
pages = {1--22},
title = {{How Many Tests are Enough ?}},
volume = {2},
year = {2000}
}
@article{Farnstrom00scalabilityfor,
author = {Farnstrom, Fredrik and Lewis, James and Elkan, Charles},
doi = {10.1145/360402.360419},
issn = {19310145},
journal = {ACM SIGKDD Explorations Newsletter},
number = {1},
pages = {51--57},
title = {{Scalability for clustering algorithms revisited}},
volume = {2},
year = {2000}
}
@article{zlochin04,
abstract = {In this paper we introduce model-based search as a unifying framework accommodating some recently proposed metaheuristics for combinatorial optimization such as ant colony optimization, stochastic gradient ascent, cross-entropy and estimation of distribution methods. We discuss similarities as well as distinctive features of each method and we propose some extensions.},
author = {Zlochin, Mark and Birattari, Mauro and Meuleau, Nicolas and Dorigo, Marco},
doi = {10.1023/B:ANOR.0000039526.52305.af},
isbn = {0254-5330},
issn = {02545330},
journal = {Annals of Operations Research},
keywords = {adaptive optimization,ant colony optimization,cross-entropy method,estimation of distribution algorithms,metaheuristics,stochastic gradient ascent},
number = {1-4},
pages = {373--395},
title = {{Model-based search for combinatorial optimization: A critical survey}},
volume = {131},
year = {2004}
}
@book{Aboulnaga2002a,
author = {Aboulnaga, Ashraf},
file = {:Users/timm/svns/doc/07mendes.pdf:pdf},
isbn = {9781599041353},
title = {{Cost Estimation Techniques for}},
year = {2002}
}
@article{Knowles1999a,
abstract = {Most popular evolutionary algorithms for multiobjective
optimisation maintain a population of solutions from which individuals
are selected for reproduction. In this paper, we introduce a simpler
evolution scheme for multiobjective problems, called the Pareto archived
evolution strategy (PAES). We argue that PAES may represent the simplest
possible non-trivial algorithm capable of generating diverse solutions
in the Pareto optimal set. The algorithm is identified as being a (1+1)
evolution strategy, using local search from a population of one but
using a reference archive of previously found solutions in order to
identify the approximate dominance ranking of the current and candidate
solution vectors. PAES is intended as a good baseline approach, against
which more involved methods may be compared, and may also serve well in
some real-world applications when local search seems superior to or
competitive with population-based methods. The performance of the new
algorithm is compared with that of a MOEA based on the niched Pareto GA
on a real world application from the telecommunications field. In
addition, we include results from experiments carried out on a suite of
four test functions, to demonstrate the algorithm's general capability
},
author = {Knowles, Joshua and Corne, David},
doi = {10.1109/CEC.1999.781913},
file = {:Users/timm/svns/doc/99paes.pdf:pdf},
isbn = {0-7803-5536-9},
issn = {1879-1026},
journal = {Proceedings of the 1999 Congress on Evolutionary Computation, CEC 1999},
pages = {98--105},
pmid = {19520416},
title = {{The Pareto archived evolution strategy: A new baseline algorithm for Pareto multiobjective optimisation}},
volume = {1},
year = {1999}
}
@inproceedings{me02m,
abstract = {A range of agent implementation technologies are reviewed according to five user-based criteria and via a comparison with object-oriented programming. The comparison with OO shows that some parts of object technology are a candidate implementation technique for some parts of agent systems. However, many other non-object-based implementation techniques may be just as useful. Also, for agents with mentalistic attitudes, the high-level specification of agent behavior requires numerous concepts outside the object paradigm; e.g. plans, communication, intentions, roles, and teams.},
author = {Menzies, T and Pearce, a and {C Heinze} and Goss, S},
booktitle = {Formal Aspects of AgentBased Systems},
issn = {03029743},
pages = {1--14},
title = {{What is an agent and why should I care?}},
url = {http://www.springerlink.com/index/55EH2FB4AVC3HCE1.pdf},
year = {2002}
}
@inproceedings{me03o,
author = {Menzies, Tim and Gunnalan, Rajesh and Appukutty, Kalaivani},
booktitle = {Business},
number = {1},
pages = {1--19},
title = {{Learning Tiny Theories}},
year = {2003}
}
@inproceedings{me99k,
abstract = {Knowledge-based engineering and computational intelligence are
expected to become core technologies in the design and manufacturing for
the next generation of space exploration missions. Yet, if one is
concerned with the reliability of knowledge based systems, studies
indicate significant disagreement regarding the amount of testing needed
for system assessment. The sizes of standard black-box test suites are
impracticably large since the black-box approach neglects the internal
structure of knowledge-based systems. On the contrary, practical results
repeatedly indicate that only a few tests are needed to sample the range
of behaviors of a knowledge-based program. In this paper, we model
testing as a search process over the internal state space of the
knowledge-based system. When comparing different test suites, the test
suite that examines larger portion of the state space is considered more
complete. Our goal is to investigate the trade-off between the
completeness criterion and the size of test suites. The results of
testing experiment on tens of thousands of mutants of real-world
knowledge based systems indicate that a very limited gain in
completeness can be achieved through prolonged testing. The use of
simple (or random) search strategies for testing appears to be as
powerful as testing by more thorough search algorithms},
author = {Menzies, T. and Cukic, B.},
booktitle = {Proceedings 11th International Conference on Tools with Artificial Intelligence},
doi = {10.1109/TAI.1999.809838},
isbn = {0-7695-0456-6},
issn = {1082-3409},
title = {{On the sufficiency of limited testing for knowledge based systems}},
year = {1999}
}
@inproceedings{hame93,
author = {Haynes, P and Menzies, T J},
booktitle = {Tools Pacific 1993},
organization = {Prentice Hall},
pages = {75--82},
title = {{C++ is \{B\}etter than \{S\}malltalk?}},
year = {1993}
}
@inproceedings{me02o,
author = {Menzies, Tim and Mason, Lindsay},
booktitle = {Proceedings of the 2002 ACM SIGPLAN workshop on Rule-based programming - RULE '02},
doi = {10.1145/570186.570194},
isbn = {1581136064},
keywords = {history,prolog,rule-based programming},
pages = {79--92},
title = {{Some prolog macros for rule-based programming}},
url = {http://portal.acm.org/citation.cfm?doid=570186.570194},
year = {2002}
}
@inproceedings{lum06,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06ispa.pdf\}},
author = {Lum, Karen and Menzies, Tim and Hihn, Jairus},
booktitle = {ISPA Conference Proceedings},
title = {{Studies in Software Cost Model Behavior: Do We Really Understand Cost Model Performance?}},
url = {http://trs-new.jpl.nasa.gov/dspace/handle/2014/41450},
year = {2006}
}
@article{boley98,
abstract = {We propose a new algorithm capable of partitioning a set of documents or other samples based on an embedding in a high dimensional Euclidean space (i.e., in which every document is a vector of real numbers). The method is unusual in that it is divisive, as opposed to agglomerative, and operates by repeatedly splitting clusters into smaller clusters. The documents are assembled into a matrix which is very sparse. It is this sparsity that permits the algorithm to be very efficient. The performance of the method is illustrated with a set of text documents obtained from the World Wide Web. Some possible extensions are proposed for further investigation.},
author = {Boley, Daniel},
doi = {10.1023/A:1009740529316},
file = {:Users/timm/svns/doc/98principalDirectionDivisvePartitioning.pdf:pdf},
issn = {1384-5810},
journal = {Data Mining and Knowledge Discovery},
month = dec,
number = {4},
pages = {325--344},
title = {{Principal Direction Divisive Partitioning}},
url = {http://dx.doi.org/10.1023/A:1009740529316$\backslash$nhttp://www.springerlink.com/content/w15313n737603612/},
volume = {2},
year = {1998}
}
@inproceedings{zhang10,
author = {Zhang, Hongyu and Nelson, Adam and Menzies, Tim},
title = {{Proceedings of PROMISE'10}},
year = {2010}
}
@article{Garcia-Nieto2012a,
author = {Garcia-Nieto, Jos\'{e} and Alba, Enrique},
doi = {10.1145/2330163.2330168},
file = {:Users/timm/svns/doc/pso/12pso6.pdf:pdf},
isbn = {9781450311779},
journal = {\ldots of the Fourteenth International Conference on \ldots},
keywords = {distance correlation,fitness-,fitness-fitness cloud,fully informed pso,particle swarm optimization},
pages = {25},
title = {{Why six informants is optimal in PSO}},
url = {http://dl.acm.org/citation.cfm?doid=2330163.2330168$\backslash$nhttp://dl.acm.org/citation.cfm?id=2330168},
year = {2012}
}
@inproceedings{men87a,
author = {Menzies, T J and Markey, B R},
booktitle = {Proceedings of the Third Australian Conference on Expert Systems, May 13-15},
title = {{A Micro-Computer, Rule-Based Prolog Expert-System for Process Control in a Petrochemical Plant}},
year = {1987}
}
@inproceedings{me05d,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05learncost.pdf\}},
author = {Menzies, Tim and Port, D and Chen, Z and Hihn, J and Stukes, S},
booktitle = {Ieee Ase},
title = {{Specialization and extrapolation of induced domain models: Case studies in software effort estimation}},
volume = {2005},
year = {2005}
}
@article{Attarzadeh2009a,
abstract = {Software development effort estimation is the process of predicting the most realistic use of effort required for developing software based on some parameters. It has always characterised one of the biggest challenges in Computer Science for the last decades. Because time and cost estimate at the early stages of the software development are the most difficult to obtain, and they are often the least accurate. Traditional algorithmic techniques such as regression models, Software Life Cycle Management (SLIM), COCOMO model, function points, etc, require an estimation process in a long term. But, nowadays that is not acceptable for software developers and companies. Newer soft computing techniques to effort estimation based on non-algorithmic techniques such as Fuzzy Logic (FL) may offer an alternative for solving the problem. This work aims to propose a fuzzy logic realistic model to achieve more accuracy in software effort estimation. In this innovative model, by applying fuzzy logic and using training procedure to the system, the accuracy of the results is desirable in comparison with the famous traditional algorithmic technique, COCOMO II model. This novelty model will lead researchers to focus on non-algorithmic models to overcome the estimation problems. Our validation experiment was carried out on artificial dataset as well as the COCOMO standard dataset.},
author = {Attarzadeh, I. and Ow, Siew Hock Ow Siew Hock},
doi = {10.1109/ICCEE.2009.97},
file = {:Users/timm/svns/doc/cost/09Iman.pdf:pdf},
isbn = {978-1-4244-5365-8},
journal = {2009 Second International Conference on Computer and Electrical Engineering},
keywords = {COCOMO model,Software engineering,soft computing techniques,software cost estimation models},
pages = {114--118},
title = {{Proposing a New High Performance Model for Software Cost Estimation}},
volume = {2},
year = {2009}
}
@article{Liu2004f,
abstract = {This paper concerns approximate nearest neighbor searching algorithms, which have become increasingly important, especially in high dimen- sional perception areas such as computer vision, with dozens of publica- tions in recent years. Much of this enthusiasm is due to a successful new approximate nearest neighbor approach called Locality Sensitive Hash- ing (LSH). In this paper we ask the question: can earlier spatial data structure approaches to exact nearest neighbor, such as metric trees, be altered to provide approximate answers to proximity queries and if so, how? We introduce a new kind of metric tree that allows overlap: certain datapoints may appear in both the children of a parent. We also intro- duce new approximate k-NN search algorithms on this structure. We show why these structures should be able to exploit the same random- projection-based approximations that LSH enjoys, but with a simpler al- gorithm and perhaps with greater efficiency. We then provide a detailed empirical evaluation on five large, high dimensional datasets which show up to 31-fold accelerations over LSH. This result holds true throughout the spectrum of approximation levels.},
author = {Liu, Ting and Moore, Andrew W and Gray, Alexander and Yang, Ke},
file = {:Users/timm/svns/doc/05rptrees.pdf:pdf},
isbn = {0262195348},
issn = {10495258},
journal = {Advances in Neural Information Processing Systemsnformation},
pages = {8},
title = {{An investigation of practical approximate nearest neighbor algorithms}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.8527\&rep=rep1\&type=pdf},
year = {2004}
}
@article{mittas12,
abstract = {Background: Regression Error Characteristic (REC) curves provide a visualization tool, able to characterize graphically the prediction power of alternative predictive models. Due to the benefits of using such a visualization description of the whole distribution of error, REC analysis was recently introduced in software cost estimation to aid the decision of choosing the most appropriate cost estimation model during the management of a forthcoming project. Aims: Although significant information can be retrieved from a readable graph, REC curves are not able to assess whether the divergences between the alternative error functions can constitute evidence for a statistically significant difference. Method: In this paper, we propose a graphical procedure that utilizes (a) the process of repetitive permutations and (b) and the maximum vertical deviation between two comparative Regression Error Characteristic curves in order to conduct a hypothesis test for assessing the statistical significance of error functions. Results: In our case studies, the data used come from software projects and the models compared are cost prediction models. The results clearly showed that the proposed statistical test is necessary in order to assess the significance of the superiority of a prediction model, since it provides an objective criterion for the distances between the REC curves. Moreover, the procedure can be easily applied to any dataset where the objective is the prediction of a response variable of interest and the comparison of alternative prediction techniques in order to select the best strategy. Conclusions: The proposed hypothesis test, accompanying an informative graphical tool, is more easily interpretable than the conventional parametric and non-parametric statistical procedures. Moreover, it is free from normality assumptions of the error distributions when the samples are small-sized and highly skewed. Finally, the proposed graphical test can be applied to the comparisons of any alternative prediction methods and models and also to any other validation procedure. Â© 2011 Springer Science+Business Media, LLC.},
author = {Mittas, N and Angelis, L},
doi = {DOI 10.1007/s10664-011-9177-5},
issn = {1382-3256},
journal = {Empirical Software Engineering},
number = {1-2},
pages = {34--61},
title = {{A permutation test based on regression error characteristic curves for software cost estimation models}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84857374517\&partnerID=40\&md5=a628c5057b25a5e3b9b18e54f6c4a149},
volume = {17},
year = {2012}
}
@inproceedings{mkaouer14,
address = {New York, NY, USA},
author = {Mkaouer, Mohamed Wiem and Kessentini, Marouane and Bechikh, Slim and Deb, Kalyanmoy and {\'{O} Cinn\'{e}ide}, Mel},
booktitle = {Proceedings of the 2014 conference on Genetic and evolutionary computation - GECCO '14},
doi = {10.1145/2576768.2598366},
isbn = {9781450326629},
keywords = {code-smells,refactroing,search-based software engineering},
pages = {1263--1270},
publisher = {ACM},
series = {GECCO '14},
title = {{High dimensional search-based software engineering}},
url = {http://dl.acm.org/citation.cfm?id=2576768.2598366},
year = {2014}
}
@inproceedings{me02l,
abstract = { There are many machine learning algorithms currently available. In the 21st century, the problem no longer lies in writing the learner but in choosing which learners to run on a given data set. We argue that the final choice of learners should not be exclusive; in fact, there are distinct advantages in running data sets through multiple learners. To illustrate our point, we perform a case study on a reuse data set using three different styles of learners: association rule, decision tree induction, and treatment. Software reuse is a topic of avid debate in the professional and academic arena; it has proven that it can be both a blessing and a curse. Although there is much debate over where and when reuse should be instituted into a project, our learners found some procedures which should significantly improve the odds of a reuse program succeeding.},
author = {Stefano, J.S. Di and Menzies, T.},
booktitle = {14th IEEE International Conference on Tools with Artificial Intelligence, 2002. (ICTAI 2002). Proceedings.},
doi = {10.1109/TAI.2002.1180811},
isbn = {0-7695-1849-4},
issn = {1082-3409},
title = {{Machine learning for software engineering: case studies in software reuse}},
year = {2002}
}
@inproceedings{me01a,
author = {Menzies, Tim},
booktitle = {AAAI Stanford Spring Symposium on Model-based Validation of AI Systems},
pages = {0--5},
title = {{Average Case Coverage for Validation of AI Systems}},
year = {1995}
}
@inproceedings{me02g,
author = {Menzies, Tim and Lutz, Robyn},
booktitle = {Seke03},
keywords = {anomaly,artificial intelligence,association,debugging,dent,learning,metrics,nasa mis-,reports on deep space,rule learning,software engineering,surprise,testing and,treatment learning},
pages = {0--5},
title = {{Better analysis of defect data at NASA}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.197.5917\&amp;rep=rep1\&amp;type=pdf},
year = {2003}
}
@article{tosun10a,
abstract = {CONTEXT$\backslash$nBuilding defect prediction models in large organizations has many challenges due to limited resources and tight schedules in the software development lifecycle. It is not easy to collect data, utilize any type of algorithm and build a permanent model at once. We have conducted a study in a large telecommunications company in Turkey to employ a software measurement program and to predict pre-release defects. Based on our prior publication, we have shared our experience in terms of the project steps (i.e. challenges and opportunities). We have further introduced new techniques that improve our earlier results. $\backslash$n$\backslash$nOBJECTIVE$\backslash$nIn our previous work, we have built similar predictors using data representative for US software development. Our task here was to check if those predictors were specific solely to US organizations or to a broader class of software. $\backslash$n$\backslash$nMETHOD$\backslash$nWe have presented our approach and results in the form of an experience report. Specifically, we have made use of different techniques for improving the information content of the software data and the performance of a Na\"{\i}ve Bayes classifier in the prediction model that is locally tuned for the company. We have increased the information content of the software data by using module dependency data and improved the performance by adjusting the hyper-parameter (decision threshold) of the Na\"{\i}ve Bayes classifier. We have reported and discussed our results in terms of defect detection rates and false alarms. We also carried out a costâbenefit analysis to show that our approach can be efficiently put into practice. $\backslash$n$\backslash$nRESULTS$\backslash$nOur general result is that general defect predictors, which exist across a wide range of software (in both US and Turkish organizations), are present. Our specific results indicate that concerning the organization subject to this study, the use of version history information along with code metrics decreased false alarms by 22\%, the use of dependencies between modules further reduced false alarms by 8\%, and the decision threshold optimization for the Na\"{\i}ve Bayes classifier using code metrics and version history information further improved false alarms by 30\% in comparison to a prediction using only code metrics and a default decision threshold. $\backslash$n$\backslash$nCONCLUSION$\backslash$nImplementing statistical techniques and machine learning on a real life scenario is a difficult yet possible task. Using simple statistical and algorithmic techniques produces an average detection rate of 88\%. Although using dependency data improves our results, it is difficult to collect and analyze such data in general. Therefore, we would recommend optimizing the hyper-parameter of the proposed technique, Na\"{\i}ve Bayes, to calibrate the defect prediction model rather than employing more complex classifiers. We also recommend that researchers who explore statistical and algorithmic methods for defect prediction should spend less time on their algorithms and more time on studying the pragmatic considerations of large organizations.},
author = {Boetticher, Gary D. and Ruhe, Guenther and Tosun, AyÅe and Bener, AyÅe and Turhan, Burak and Menzies, Tim},
doi = {10.1016/j.infsof.2010.06.006},
isbn = {978-1-60558-634-2},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Experience report,Na\"{\i}ve Bayes,Software defect prediction,Static code attributes},
number = {11},
pages = {1242--1257},
title = {{Practical considerations in deploying statistical methods for defect prediction: A case study within the Turkish telecommunications industry}},
url = {http://www.sciencedirect.com/science/article/pii/S0950584910001163},
volume = {52},
year = {2010}
}
@inproceedings{me99b,
author = {Menzies, T J and Cukic, B},
booktitle = {Submitted to ISSRE-99},
title = {{When You Don't Need to Re-Test the System}},
year = {1999}
}
@article{Niu2008a,
author = {Niu, Kun and Zhang, Shubo and Chen, Junliang},
doi = {10.1007/s11460-008-0010-x},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/niu08.pdf:pdf},
issn = {16733460},
journal = {Frontiers of Electrical and Electronic Engineering in China},
keywords = {Attribute clustering,High dimensional data,Subspace clustering},
number = {1},
pages = {44--48},
title = {{Subspace clustering through attribute clustering}},
volume = {3},
year = {2008}
}
@inproceedings{fea02a,
abstract = {Planning for the optimal attainment of requirements is an important early lifecycle activity. However, such planning is difficult when dealing with competing requirements, limited resources, and the incompleteness of information available at requirements time. A novel approach to requirements optimization is described. A requirements interaction model is executed to randomly sample the space of options. This produces a large amount of data, which is then condensed by a summarization tool. The result is a small list of critical decisions (i.e., those most influential in leading towards the desired optimum). This focuses human experts' attention on a relatively few decisions and makes them aware of major alternatives. This approach is iterative. Each iteration allows experts to select from among the major alternatives. In successive iterations the execution and summarization modules are run again, but each time further constrained by the decisions made in previous iteration. In the case study shown here, out of 99 yes/no decisions (approximately 10<sup>30</sup> possibilities), five iterations were sufficient to find and make the 30 key ones.},
author = {Feather, M.S. and Menzies, T.},
booktitle = {Proceedings IEEE Joint International Conference on Requirements Engineering},
doi = {10.1109/ICRE.2002.1048537},
isbn = {0-7695-1465-0},
issn = {1090-705X},
title = {{Converging on the optimal attainment of requirements}},
year = {2002}
}
@inproceedings{andrews06,
abstract = {There are several problem areas that must be addressed when applying randomization to unit testing. As yet no general, fully automated solution that works for all units has been proposed. We therefore have developed RUTE-J, a Java package intended to help programmers do randomized unit testing in Java. In this paper, we describe RUTE-J and illustrate how it supports the development of per-unit solutions for the problems of randomized unit testing. We report on an experiment in which we applied RUTE-J to the standard Java TreeMap class, measuring the efficiency and effectiveness of the technique. We also illustrate the use of randomized testing in experimentation, by adapting RUTE-J so that it generates randomized minimal covering test suites, and measuring the effectiveness of the test suites generated. Copyright 2006 ACM.},
author = {Andrews, James H. and Haldar, Susmita and Lei, Yong and Li, Felix Chun Hang},
booktitle = {Proceedings of the 1st international workshop on Random testing - RT '06},
doi = {10.1145/1145735.1145741},
isbn = {159593457X},
keywords = {randomized testing,unit testing},
number = {1},
pages = {36},
title = {{Tool support for randomized unit testing}},
url = {http://portal.acm.org/citation.cfm?doid=1145735.1145741},
year = {2006}
}
@inproceedings{me99b,
author = {Menzies, T J and Cukic, B},
booktitle = {Submitted to ISSRE-99},
title = {{When You Don't Need to Re-Test the System}},
year = {1999}
}
@inproceedings{JIANG20082,
abstract = {Data preprocessing (transformation) plays an important role in data$\backslash$nmining and machine learning. In this study, we investigate the effect$\backslash$nof four different preprocessing methods to fault-proneness prediction$\backslash$nusing nine datasets from NASA Metrics Data Programs (MDP) and ten$\backslash$nclassification algorithms. Our experiments indicate that log transformation$\backslash$nrarely improves classification performance, but discretization affects$\backslash$nthe performance of many different algorithms. The impact of different$\backslash$ntransformations differs. Random forest algorithm, for example, performs$\backslash$nbetter with original and log transformed data set. Boosting and Naive$\backslash$nBayes perform significantly better with discretized data. We conclude$\backslash$nthat no general benefit can be expected from data transformations.$\backslash$nInstead, selected transformation techniques are recommended to boost$\backslash$nthe performance of specific classification algorithms.},
address = {New York, NY, USA},
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim},
booktitle = {Proceedings of the 2008 workshop on Defects in large software systems - DEFECTS '08},
doi = {10.1145/1390817.1390822},
isbn = {9781605580517},
pages = {16},
publisher = {ACM},
title = {{Can data transformation help in the detection of fault-prone modules?}},
url = {http://portal.acm.org/citation.cfm?doid=1390817.1390822},
year = {2008}
}
@misc{nsf06,
author = {Foundation, National Science},
number = {NSB-93-1},
title = {{Science and Engineering Indicators - 1993}},
year = {1993}
}
@article{macdonell10,
abstract = {BACKGROUND â the systematic review is becoming a more commonly employed research instrument in 
empirical software engineering. Before undue reliance is placed on the outcomes of such reviews it would seem useful to consider the robustness of the approach in this particular research context. 
OBJECTIVE â the aim of this study is to assess the reliability of systematic reviews as a research instrument. In particular we wish to investigate the consistency of process and the stability of outcomes. 
METHOD â we compare the results of two independent reviews under taken with a common research question. 
RESULTS â the two reviews ï¬nd similar answers to the research question, although the means of arriving at those answers vary. 
CONCLUSIONS â in addressing a well-bounded research question, groups of researchers with similar domain experience can arrive at the same review outcomes, even though they may do so in different ways. 
This provides evidence that, in this context at least, the systematic review is a robust research method.},
author = {MacDonell,  S G and Shepperd,  M J and Kitchenham,  B a and Mendes,  E},
journal = {IEEE Trans. Software Eng.},
keywords = {Cost Estimation,Empirical Software Engineering,Meta-Analysis,Systematic Review},
number = {5},
pages = {676--687},
title = {{How reliable are systematic reviews in empirical software engineering?}},
url = {http://hdl.handle.net/2438/3625},
volume = {36},
year = {2009}
}
@article{Lim2011a,
abstract = {Many experiments require a fast and cost-effective method to monitor nucleic acid sequence diversity. Here we describe a method called diversity visualization by endonuclease (DiVE) that allows rapid visualization of sequence diversity of polymerase chain reaction (PCR) products based on DNA hybridization kinetics coupled with the activity of a single-strand specific nuclease. The assay involves only a limited number of steps and can be performed in less than 4 h, including the initial PCR. After PCR, the homoduplex double-stranded DNA (dsDNA) is denatured and reannealed under stringent conditions. During the reannealing process, incubation with S1 nuclease removes single-stranded loops of formed heteroduplexes and the resulting digest is visualized on agarose gel. The sequence diversity is inversely proportional to the band intensities of S1 nuclease surviving dsDNA molecules of expected size. As an example, we employed DiVE to monitor the diversity of panning rounds from a single-framework, semisynthetic single-chain antibody fragment (scFv) phage display library. The results are in good agreement with the observed decrease in diversity in phage display panning rounds toward the selection of monoclonal scFv. We conclude that the DiVE assay allows rapid and cost-effective monitoring of diversities of various nucleotide libraries and proves to be particularly suitable for scaffold-based randomized libraries. Â© 2010 Elsevier Inc. All rights reserved.},
author = {Lim, Theam Soon and Sch\"{u}tze, Tatjana and Lehrach, Hans and Gl\"{o}kler, J\"{o}rn and Konthur, Zolt\'{a}n},
doi = {10.1016/j.ab.2010.12.024},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/LimSchutze11.pdf:pdf},
isbn = {1096-0309 (Electronic)$\backslash$n0003-2697 (Linking)},
issn = {00032697},
journal = {Analytical Biochemistry},
keywords = {Diversity Assay,Mutagenesis,Nucleotide library,Phage display,S1 nuclease},
number = {1},
pages = {16--21},
pmid = {21185254},
publisher = {Elsevier Inc.},
title = {{Diversity visualization by endonuclease: A rapid assay to monitor diverse nucleotide libraries}},
url = {http://dx.doi.org/10.1016/j.ab.2010.12.024},
volume = {411},
year = {2011}
}
@article{Costs2009a,
author = {Costs, Capital Program},
file = {:Users/timm/svns/doc/cost/GAOcostguide.pdf:pdf},
journal = {Office},
number = {March},
pages = {440},
title = {{GAO COst EstimAtinG}},
url = {http://www.gao.gov/products/GAO-09-3SP},
year = {2009}
}
@misc{basili09,
author = {Basili, Victor},
title = {{Personnel communication}},
year = {2009}
}
@article{me11f,
abstract = {Recent research has shown the value of social metrics for defect prediction. Yet many repositories lack the information required for a social analysis. So, what other means exist to infer how developers interact around their code? One option is static code metrics that have already demonstrated their usefulness in analyzing change in evolving software systems. But do they also help in defect prediction? To address this question we selected a set of static code metrics to determine what classes are most "active" (i.e., the classes where the developers spend much time interacting with each other's design and implementation decisions) in 33 open-source Java systems that lack details about individual developers. In particular, we assessed the merit of these activity-centric measures in the context of "inspection optimization" a technique that allows for reading the fewest lines of code in order to find the most defects. For the task of inspection optimization these activity measures perform as well as (usually, within 4\%) a theoretical upper bound on the performance of any set of measures. As a result, we argue that activity-centric static code metrics are an excellent predictor for defects. Â© 2012 World Scientific Publishing Company.},
author = {Lumpe, Markus and Vasa, Rajesh and Menzies, Tim and Rush, Rebecca and Turhan, Burak},
doi = {10.1142/S0218194012500179},
issn = {0218-1940},
journal = {International Journal of Software Engineering and Knowledge Engineering},
number = {05},
pages = {621--644},
title = {{Learning Better Inspection Optimization Policies}},
volume = {22},
year = {2012}
}
@book{Zourob2010a,
abstract = {Genetically engineered whole cells as biosensing systems in biosensors have been employed, in the past two decades, for the detection of a variety of analytes. In addition to being rapid, specific/selective, and sensitive, these whole-cell-based sensing systems provide information pertaining to the analyte bioavailability. This information is particularly important to study the effect of harmful/toxic chemicals on living systems. The whole cells used for designing and developing cell-based sensing systems can be either prokaryotic or eukaryotic in nature. These intact prokaryotic or eukaryotic cells can be genetically engineered to recognize the analytes of interest and respond with the production of a measurable signal in a dose-dependent manner. Generally, prokaryotic bacterial whole-cell sensing systems are developed by introducing a plasmid construct with a reporter gene fused to a promoter, which is induced by a target analyte through a regulatory protein. Similarly, a receptor, which is activated by a target analyte, is coupled with a reporter gene for the development of genetically modified eukaryotic cell-based biosensing systems. The most commonly used reporter proteins in whole-cell biosensing include luminescent proteins, such as bacterial and firefly luciferases; green fluorescent protein along with its variants; and $\beta$-galactosidase. The analytes that can be detected using genetically manipulated whole-cell sensing systems range from general toxicants and cell stress factors to specific analytes, such as metals, metalloids, organic pollutants, sugars, drugs, and bacterial signaling molecules. In order to develop self-contained sensing devices based on recombinant whole-cell sensing systems, preservation, miniaturization, and portability are important issues that need to be addressed.},
author = {Zourob, Mohammed},
booktitle = {Recognition Receptors in Biosensors},
doi = {10.1007/978-1-4419-0919-0},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Baldrich10.pdf:pdf},
isbn = {9781441909183},
keywords = {aptamer \'{a} aptasensor \'{a},development,reagentless detection \'{a} sensor},
pages = {1--863},
title = {{Recognition receptors in biosensors}},
year = {2010}
}
@article{me10a,
abstract = {Building quality software is expensive and software quality assurance (QA) budgets are limited. Data miners can learn defect predictors from static code features which can be used to control QA resources; e.g. to focus on the parts of the code predicted to be more defective. Recent results show that better data mining technology is not leading to better defect predictors. We hypothesize that we have reached the limits of the standard learning goal of maximizing area under the curve (AUC) of the probability of false alarms and probability of detection AUC(pd, pf) ; i.e. the area under the curve of a probability of false alarm versus probability of detection. Accordingly, we explore changing the standard goal. Learners that maximize AUC(effort, pd) find the smallest set of modules that contain the most errors. WHICH is a meta-learner framework that can be quickly customized to different goals. When customized to AUC(effort, pd), WHICH out-performs all the data mining methods studied here. More importantly, measured in terms of this new goal, certain widely used learners perform much worse than simple manual methods. Hence, we advise against the indiscriminate use of learners. Learners must be chosen and customized to the goal at hand. With the right architecture (e.g. WHICH), tuning a learner to specific local business goals can be a simple task.},
author = {Menzies, Tim and Milton, Zach and Turhan, Burak and Cukic, Bojan and Jiang, Yue and Bener, AyÅe},
doi = {10.1007/s10515-010-0069-5},
issn = {09288910},
journal = {Automated Software Engineering},
keywords = {Defect prediction,Static code features,Which},
number = {4},
pages = {375--407},
title = {{Defect prediction from static code features: Current results, limitations, new approaches}},
volume = {17},
year = {2010}
}
@inproceedings{me97d,
author = {Postema, M and Menzies, T J and Wu, X},
booktitle = {The Joint Pacific Asia Conference on Expert Systems/Singapore International Conference on Intelligent Systems. (PACES/SPICIS '97)},
title = {{A Decision Support Tool for Tuning Parameters in a Machine Leraning Algorithm}},
year = {1997}
}
@inproceedings{me05a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05safewhen.pdf\}},
author = {Menzies, Tim and Chen, Zhihao and Port, Dan and Hihn, Jairus},
booktitle = {Proceedings, PROMISE workshop, ICSE},
title = {{Simple software cost estimation: Safe or unsafe}},
volume = {2005},
year = {2005}
}
@article{huber09,
abstract = {Abstract We show through an analysis of a massive data set from YouTube that the productivity exhibited in crowdsourcing exhibits a strong positive dependence on attention, measured by the number of downloads. Conversely, a lack of attention leads to a ... },
archivePrefix = {arXiv},
arxivId = {arXiv:0809.3030v1},
author = {Huberman, Bernardo a and Subrahmanyam, Avanidhar and Romero, Daniel M and Wu, Fang},
doi = {10.1177/0165551509346786},
eprint = {arXiv:0809.3030v1},
isbn = {0165-5515},
issn = {0165-5515},
journal = {Journal of Information Science},
month = dec,
number = {6},
pages = {758--765},
title = {{Crowdsourcing, attention and productivity}},
url = {http://jis.sagepub.com/cgi/doi/10.1177/0165551509346786},
volume = {35},
year = {2009}
}
@inproceedings{me02m,
abstract = {A range of agent implementation technologies are reviewed according to five user-based criteria and via a comparison with object-oriented programming. The comparison with OO shows that some parts of object technology are a candidate implementation technique for some parts of agent systems. However, many other non-object-based implementation techniques may be just as useful. Also, for agents with mentalistic attitudes, the high-level specification of agent behavior requires numerous concepts outside the object paradigm; e.g. plans, communication, intentions, roles, and teams.},
author = {Menzies, T and Pearce, a and {C Heinze} and Goss, S},
booktitle = {Formal Aspects of AgentBased Systems},
issn = {03029743},
pages = {1--14},
title = {{What is an agent and why should I care?}},
url = {http://www.springerlink.com/index/55EH2FB4AVC3HCE1.pdf},
year = {2002}
}
@inproceedings{CHEN2005,
address = {New York, NY, USA},
author = {Chen, Zhihao and Menzies, Tim and Port, Dan and Boehm, Barry},
booktitle = {ACM SIGSOFT Software Engineering Notes},
doi = {10.1145/1082983.1083171},
isbn = {-159593-125-2},
issn = {01635948},
number = {4},
pages = {1},
publisher = {ACM},
title = {{Feature subset selection can improve software cost estimation accuracy}},
volume = {30},
year = {2005}
}
@article{VanDerMerwe2003b,
abstract = { This paper proposes two new approaches to using PSO to cluster data. It is shown how PSO can be used to find the centroids of a user specified number of clusters. The algorithm is then extended to use K-means clustering to seed the initial swarm. This second algorithm basically uses PSO to refine the clusters formed by K-means. The new PSO algorithms are evaluated on six data sets, and compared to the performance of K-means clustering. Results show that both PSO clustering techniques have much potential.},
author = {Merwe, D.W. Van Der and a.P. Engelbrecht},
doi = {10.1109/CEC.2003.1299577},
file = {:Users/timm/svns/doc/pso/03clusterPSO.pdf:pdf},
isbn = {0-7803-7804-0},
journal = {The 2003 Congress on Evolutionary Computation, 2003. CEC '03.},
pages = {215--220},
title = {{Data clustering using particle swarm optimization}},
volume = {1},
year = {2003}
}
@article{pearson1901.,
abstract = {AbstractDownload full textRelated$\backslash$n $\backslash$n $\backslash$n$\backslash$n $\backslash$n$\backslash$n$\backslash$n $\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n var addthis\_config = \{$\backslash$n ui\_cobrand: "Taylor \&amp; Francis Online",$\backslash$n services\_compact: "citeulike,netvibes,twitter,technorati,delicious,linkedin,facebook,stumbleupon,digg,google,more",$\backslash$n pubid: "ra-4dff56cd6bb1830b"$\backslash$n \};$\backslash$n$\backslash$n $\backslash$n$\backslash$n $\backslash$n$\backslash$n $\backslash$n $\backslash$n Add to shortlist$\backslash$n $\backslash$n $\backslash$n$\backslash$n $\backslash$n$\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n Link$\backslash$n $\backslash$n$\backslash$n $\backslash$n $\backslash$n $\backslash$n Permalink$\backslash$n $\backslash$n$\backslash$n $\backslash$n $\backslash$n $\backslash$n$\backslash$n $\backslash$n$\backslash$n$\backslash$n$\backslash$n $\backslash$n $\backslash$n $\backslash$n$\backslash$n$\backslash$n$\backslash$n$\backslash$n $\backslash$n $\backslash$n http://dx.doi.org/10.1080/14786440109462720$\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n$\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n Download Citation$\backslash$n $\backslash$n $\backslash$n$\backslash$n $\backslash$n $\backslash$n $\backslash$n Recommend to:$\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n$\backslash$n $\backslash$n$\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n $\backslash$n$\backslash$n A friend},
author = {Pearson, Karl},
doi = {10.1080/14786440109462720},
isbn = {1941-5982},
issn = {1941-5982},
journal = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
number = {11},
pages = {559--572},
title = {{LIII. On lines and planes of closest fit to systems of points in space}},
url = {http://dx.doi.org/10.1080/14786440109462720},
volume = {2},
year = {1901}
}
@inproceedings{me92zb,
author = {Menzies, T J and Compton, P},
booktitle = {ECAI '92 Workshop on Improving the Use of Knowledge-Based Systems with Explanations, Vienna},
title = {{Causal Explanations as a Tool for Refining Qualitative Models}},
year = {1992}
}
@inproceedings{kamvar03,
abstract = {We present a simple, easily implemented spectral learning algorithm which applies equally whether we have no supervisory information, pairwise link constraints, or labeled examples. In the unsupervised case, it performs consistently with other spectral clustering algorithms. In the supervised case, our approach achieves high accuracy on the categorization of thousands of documents given only a few dozen labeled training documents for the 20 Newsgroups data set. Furthermore, its classification accuracy increases with the addition of unlabeled documents, demonstrating effective use of unlabeled data. By using normalized affinity matrices which are both symmetric and stochastic, we also obtain both a probabilistic interpretation of our method and certain guarantees of performance.},
author = {Kamvar, Sepandar D. and Klein, Dan and Manning, Christopher D.},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
doi = {10.1.1.13.6919},
file = {:Users/timm/svns/doc/03spectral.pdf:pdf},
isbn = {9789533070100},
issn = {10450823},
pages = {561--566},
title = {{Spectral learning}},
year = {2003}
}
@book{duda2012,
abstract = {The first edition, published in 1973, has become a classic reference in the field. Now with the second edition, readers will find information on key new topics such as neural networks and statistical pattern recognition, the theory of machine learning, and the theory of invariances. Also included are worked examples, comparisons between different methods, extensive graphics, expanded exercises and computer project topics.  An Instructor's Manual presenting detailed solutions to all the problems in the book is available from the Wiley editorial department. },
author = {{Duda  O.}, Richard and {Hart  E.}, Peter and {Stork  G.}, David},
doi = {10.1007/BF01237942},
isbn = {978-0-471-05669-0},
issn = {0176-4268},
pages = {680},
pmid = {2630878},
publisher = {John Wiley \& Sons},
title = {{Pattern Classification}},
year = {2000}
}
@misc{me95l,
author = {Menzies, Tim},
booktitle = {TR95-40, Software Development, Monash University},
institution = {Department of Software Development, Monash University},
number = {TR95-35},
title = {{Frameworks for assessing visual languages}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.1555\&rep=rep1\&type=pdf},
year = {1995}
}
@inproceedings{arcuri11,
author = {Arcuri, Andrea and Briand, Lionel},
booktitle = {33rd International Conference onSoftware Engineering (ICSE)},
doi = {10.1145/1985793.1985795},
isbn = {978-1-4503-0445-0},
issn = {0270-5257},
keywords = {bonferroni adjustment,confidence interval,effect size,non-parametric,parametric test,statistical difference,systematic review,test},
pages = {1--10},
title = {{A Practical Guide for Using Statistical Tests to Assess Randomized Algorithms in Software Engineering}},
year = {2011}
}
@article{me13a,
abstract = {Background: Do we always need complex methods for software effort estimation (SEE)? Aim: To characterize the essential content of SEE data, i.e., the least number of features and instances required to capture the information within SEE data. If the essential content is very small, then 1) the contained information must be very brief and 2) the value added of complex learning schemes must be minimal. Method: Our QUICK method computes the euclidean distance between rows (instances) and columns (features) of SEE data, then prunes synonyms (similar features) and outliers (distant instances), then assesses the reduced data by comparing predictions from 1) a simple learner using the reduced data and 2) a state-of-the-art learner (CART) using all data. Performance is measured using hold-out experiments and expressed in terms of mean and median MRE, MAR, PRED(25), MBRE, MIBRE, or MMER. Results: For 18 datasets, QUICK pruned 69 to 96 percent of the training data (median = 89 percent). K = 1 nearest neighbor predictions (in the reduced data) performed as well as CART's predictions (using all data). Conclusion: The essential content of some SEE datasets is very small. Complex estimation methods may be overelaborate for such datasets and can be simplified. We offer QUICK as an example of such a simpler SEE method.},
author = {Kocaguneli, Ekrem and Menzies, Tim and Keung, Jacky and Cok, David and Madachy, Ray},
doi = {10.1109/TSE.2012.88},
file = {:Users/timm/svns/doc/cost/13quick.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Software cost estimation,active learning,analogy,k-NN},
number = {8},
pages = {1040--1053},
title = {{Active Learning and effort estimation: Finding the essential content of software effort estimation data}},
volume = {39},
year = {2013}
}
@inproceedings{me00p,
abstract = {Machine learning is practical for software engineering problems, even in data- starved domains. When data is scarce, knowledge can be farmed from seeds; i.e. minimal and partial descriptions of a domain. These seeds can be grown into large datasets via Monte Carlo simulations. The datasets can then be harvested using machine learning techniques. Examples of this knowledge farming approach, and the associated technique of data-mining, is given from numerous software engineering domains.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/00ml.pdf\}},
author = {Menzies, Tim},
booktitle = {Handbook of Software Engineering and Knowledge Engineering690 (2001).},
isbn = {981-02-4973-X},
month = dec,
number = {690},
pages = {690},
publisher = {World-Scientific},
title = {{Practical Machine Learning for Software Engineering and Knowledge Engineering}},
url = {http://menzies.us/pdf/00ml.pdf},
volume = {1},
year = {2001}
}
@inproceedings{me04g,
author = {Menzies, Tim and DiStefano, J and Orrego, Andres S and Chapman, Robert},
booktitle = {Proceedings of the Workshop on Predictive Software Models},
title = {{Assessing predictors of software defects}},
year = {2004}
}
@inproceedings{me94,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/ai94.pdf\}},
author = {Menzies, T J and Compton, P},
booktitle = {Proceedings of Australian AI'94},
editor = {Zhang, C and Debenham, J and Lukose, D},
pages = {149--156},
publisher = {World Scientific},
title = {{A \{P\}recise \{S\}emantics for \{V\}ague \{D\}iagrams}},
year = {1994}
}
@article{me09b,
abstract = {We propose a practical defect prediction approach for companies that do not track defect related data. Specifically, we investigate the applicability of cross-company (CC) data for building localized defect predictors using static code features. Firstly, we analyze the conditions, where CC data can be used as is. These conditions turn out to be quite few. Then we apply principles of analogy-based learning (i.e. nearest neighbor (NN) filtering) to CC data, in order to fine tune these models for localization. We compare the performance of these models with that of defect predictors learned from within-company (WC) data. As expected, we observe that defect predictors learned from WC data outperform the ones learned from CC data. However, our analyses also yield defect predictors learned from NN-filtered CC data, with performance close to, but still not better than, WC data. Therefore, we perform a final analysis for determining the minimum number of local defect reports in order to learn WC defect predictors. We demonstrate in this paper that the minimum number of data samples required to build effective defect predictors can be quite small and can be collected quickly within a few months. Hence, for companies with no local defect data, we recommend a two-phase approach that allows them to employ the defect prediction process instantaneously. In phase one, companies should use NN-filtered CC data to initiate the defect prediction process and simultaneously start collecting WC (local) data. Once enough WC data is collected (i.e. after a few months), organizations should switch to phase two and use predictors learned from WC data.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ccwc.pdf\}},
author = {Turhan, Burak and Menzies, Tim and Bener, AyÅe B. and {Di Stefano}, Justin},
doi = {10.1007/s10664-008-9103-7},
isbn = {1382-3256},
issn = {13823256},
journal = {Empirical Software Engineering},
keywords = {Cross-company,Defect prediction,Learning,Metrics (product metrics),Nearest-neighbor filtering,Within-company},
number = {5},
pages = {540--578},
title = {{On the relative value of cross-company and within-company data for defect prediction}},
volume = {14},
year = {2009}
}
@misc{prevue,
author = {$\backslash$urlhttp://www.pacorp.com, Performance Awareness Corporation},
title = {{preVue-C/S}},
year = {1998}
}
@inproceedings{me03c,
abstract = {To meet the needs of busy people who$\backslash$nonly want to know enough to achieve$\backslash$nthe most benefits, the TAR2 treatment$\backslash$nlearner generates easy-to-read and$\backslash$nimmediately useful data mining rules.},
author = {Menzies, Tim and Menzies, Tim and Hu, Ying and Hu, Ying},
booktitle = {IEEE Computer Society},
month = nov,
title = {{Data Mining for$\backslash$nVery Busy People}},
year = {2003}
}
@article{Seo2010a,
abstract = {SELEX (Systematic Evolution of Ligands by Exponential Enrichment) is a procedure by which a mixture of nucleic acids can be fractionated with the goal of identifying those with specific biochemical activities. One combines the mixture with a specific target molecule and then separates the target-NA complex from the resulting reactions. The target-NA complex is separated from the unbound NA by mechanical means (such as by filtration), the NA is eluted from the complex, amplified by PCR (polymerase chain reaction), and the process repeated. After several rounds, one should be left with the nucleic acids that best bind to the target. The problem was first formulated mathematically in Irvine et al. (J. Mol. Biol. 222:739-761, 1991). In Levine and Nilsen-Hamilton (Comput. Biol. Chem. 31:11-25, 2007), a mathematical analysis of the process was given. In Vant-Hull et al. (J. Mol. Biol. 278:579-597, 1998), multiple target SELEX was considered. It was assumed that each target has a single nucleic acid binding site that permits occupation by no more than one nucleic acid. Here, we revisit Vant-Hull et al. (J. Mol. Biol. 278:579-597, 1998) using the same assumptions. The iteration scheme is shown to be convergent and a simplified algorithm is given. Our interest here is in the behavior of the multiple target SELEX process as a discrete "time" dynamical system. Our goal is to characterize the limiting states and their dependence on the initial distribution of nucleic acid and target fraction components. (In multiple target SELEX, we vary the target component fractions, but not their concentrations, as fixed and the initial pool of nucleic acids as a variable starting condition). Given N nucleic acids and a target consisting of M subtarget component species, there is an M Ã N matrix of affinities, the (i,j) entry corresponding to the affinity of the jth nucleic acid for the ith subtarget. We give a structure condition on this matrix that is equivalent to the following statement: For any initial pool of nucleic acids such that all N species are represented, the dynamical system defined by the multiple target SELEX process will converge to a unique subset of nucleic acids, each of whose concentrations depend only upon the total nucleic acid concentration, the initial fractional target distribution (both of which are assumed to be the same from round to round), and the overall limiting association constant. (The overall association constant is the equilibrium constant for the system of MN reactions when viewed as a composite single reaction). This condition is equivalent to the statement that every member of a certain family of chemical potentials at infinite target dilution can have at most one critical point. (The condition replaces the statement for single target SELEX that the dynamical system generated via the process always converges to a pool that contains only the nucleic acid that binds best to the target). This suggests that the effectiveness of multiple target SELEX as a separation procedure may not be as useful as single target SELEX unless the thermodynamic properties of these chemical potentials are well understood.},
author = {Seo, Yeon Jung and Chen, Shiliang and Nilsen-Hamilton, Marit and Levine, Howard a.},
doi = {10.1007/s11538-009-9491-x},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/mathSelex.pdf:pdf},
isbn = {1522-9602 (Electronic)$\backslash$r0092-8240 (Linking)},
issn = {00928240},
journal = {Bulletin of Mathematical Biology},
keywords = {Asymptotic stability,Chemical potential,Discrete dynamical system,Fractionation,SELEX},
number = {7},
pages = {1623--1665},
pmid = {20077028},
title = {{A Mathematical Analysis of Multiple-Target Selex}},
volume = {72},
year = {2010}
}
@book{Breiman1984,
abstract = {The methodology used to construct tree structured rules is the focus of this monograph. Unlike many other statistical procedures, which moved from pencil and paper to calculators, this text's use of trees was unthinkable before computers. Both the practical and theoretical sides have been developed in the authors' study of tree methods. Classification and Regression Trees reflects these two sides, covering the use of trees as a data analysis method, and in a more mathematical framework, proving some of their fundamental properties.},
author = {Lucchini, a},
booktitle = {Revista medica de Chile},
isbn = {0412048418},
number = {1},
pages = {71},
pmid = {462029},
title = {{A method to estimate the requirement of physicians (author's transl)}},
volume = {107},
year = {1979}
}
@inproceedings{me88,
annote = {Adelaide, Australia},
author = {Menzies, T J and Dean, M and Black, J and Fleming, J},
booktitle = {Ai '88},
title = {{Combining Heuristics with Simulation Models: An Expert System for the Optimal Management of Pig}},
year = {1988}
}
@article{shtern12,
annote = {$\backslash$url\{http://dx.doi.org/10.1155/2012/792024\}},
author = {Shtern, Mark and Tzerpos, Vassilios},
doi = {10.1155/2012/792024},
issn = {1687-8655},
journal = {Advances in Software Engineering},
month = jan,
pages = {1--18},
title = {{Clustering Methodologies for Software Engineering}},
volume = {2012},
year = {2012}
}
@inproceedings{me05e,
author = {Menzies, T and Richardson, J},
booktitle = {COCOMO forum, 2005},
title = {{XOMO: Understanding Development Options for Autonomy}},
year = {2005}
}
@article{me11a,
abstract = {Background: Despite decades of research, there is no consensus on which software effort estimation methods produce the most accurate models. Aim: Prior work has reported that, givenM estimation methods, no single method consistently outperforms all others. Perhaps rather than recommending one estimation method as best, it is wiser to generate estimates from ensembles of multiple estimation methods. Method: Nine learners were combined with 10 preprocessing options to generate 9î10 Â¼ 90 solo methods. These were applied to 20 datasets and evaluated using seven error measures. This identified the best n (in our case n Â¼ 13) solo methods that showed stable performance across multiple datasets and error measures. The top 2, 4, 8, and 13 solo methods were then combined to generate 12 multimethods, which were then compared to the solo methods. Results: 1) The top 10 (out of 12) multimethods significantly outperformed all 90 solo methods. 2) The error rates of the multimethods were significantly less than the solo methods. 3) The ranking of the best multimethod was remarkably stable. Conclusion: While there is no best single effort estimation method, there exist best combinations of such effort estimation methods.},
author = {Kocaguneli, Ekrem and Menzies, Tim and Keung, Jacky W.},
doi = {10.1109/TSE.2011.111},
file = {:Users/timm/svns/doc/cost/11comba.pdf:pdf},
isbn = {978-1-4577-2203-5},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Software cost estimation,analogy,ensemble,k-NN,machine learning,neural nets,regression trees,support vector machines},
number = {6},
pages = {1403--1416},
title = {{On the value of ensemble effort estimation}},
volume = {38},
year = {2012}
}
@article{dijkstra68,
abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article. ACM has opted to expose the complete List rather than only correct and linked references.},
annote = {letter to the Editor},
author = {Dijkstra, Edsger W.},
doi = {10.1145/362929.362947},
isbn = {doi:10.1145/362929.362947},
issn = {00010782},
journal = {Communications of the ACM},
number = {3},
pages = {147--148},
title = {{Letters to the editor: go to statement considered harmful}},
volume = {11},
year = {1968}
}
@inproceedings{orrego09,
abstract = {Using process simulation and AI search methods, we compare software reuse against other possible changes to a project. such as reducing functionality or improving the skills of the programmer population. In one case, two generations of reuse were as good or better than any other project change (but a third and fourth generation of reuse was not useful). In another case, applying reuse to a project was demonstrable worse than several other possible changes to a project. Our conclusion is that the general claims regarding the benefits of software reuse do not hold for specific projects. We argue that the merits of software reuse need to be evaluated in a project by project basis. AI search over process models is useful for such an assessment, particularly when there is not sufficient data for precisely tuning a simulation model.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09reuse.pdf\}},
author = {{Andres Orrego, Tim Menzies}, Oussama El-Rawas},
booktitle = {Icsp2009},
pages = {186--197},
title = {{On the Relative Merits of Software Reuse}},
year = {2009}
}
@inproceedings{me96j,
author = {Menzies, T and Ramakrishnan, S},
booktitle = {Tools Pacific, Melbourne},
title = {{Comparing and Generalising Models for Metrics Repositories}},
year = {1996}
}
@misc{me99e,
annote = {in preperation},
author = {Menzies, T and Cukic, B},
howpublished = {NASA/WVU IVV tech report},
month = mar,
title = {{An Average-Case Model of Reachability}},
year = {1999}
}
@inproceedings{mega94,
author = {Menzies, T J and Gambetta, W},
booktitle = {ECAI '94 Workshop on Validation of Knowledge-Based Systems},
title = {{Exhaustive \{A\}bduction: A \{P\}ractical \{M\}odel \{V\}alidation \{T\}ool}},
year = {1994}
}
@article{Boutsidis2008a,
abstract = {Principal Components Analysis (PCA) is the predominant linear dimensionality reduction technique, and has been widely applied on datasets in all scientific domains. We consider, both theoretically and empirically, the topic of unsuper- vised feature selection for PCA, by leveraging algorithms for the so-called Column Subset Selection Problem (CSSP). In words, the CSSP seeks the âbestâ subset of exactly k columns from an mÃn data matrix A, and has been extensively stud- ied in the Numerical Linear Algebra community. We present$\backslash$na novel two-stage algorithm for the CSSP. From a theoretical perspective, for small to moderate values of k, this algorithm significantly improves upon the best previously-existing re- sults [24, 12] for the CSSP. From an empirical perspective, we evaluate this algorithm as an unsupervised feature selec- tion strategy in three application domains of modern sta- tistical data analysis: finance, document-term data, and ge- netics. We pay particular attention to how this algorithm may be used to select representative or landmark features from an object-feature matrix in an unsupervised manner. In all three application domains, we are able to identify k landmark features, i.e., columns of the data matrix, that capture nearly the same amount of information as does the subspace that is spanned by the top k âeigenfeatures.â},
author = {Boutsidis, C and Mahoney, M W and Drineas, P},
doi = {10.1145/1401890.1401903},
file = {:Users/timm/svns/doc/08pca4fss.pdf:pdf},
isbn = {978-1-60558-193-4},
journal = {Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining},
keywords = {pca,random sampling,subset selection},
pages = {61--69},
title = {{Unsupervised feature selection for principal components analysis}},
url = {papers2://publication/uuid/69910498-DD8F-4D2E-8BF8-A9F207870262},
year = {2008}
}
@inproceedings{carew05,
abstract = { It is a commonly held view by software engineers that informal requirements specifications are easier to comprehend than formal requirements specifications. Moreover, the training time required to gain a sufficient level of understanding informal notations is unknown. This paper presents an empirical study carried out to compare the comprehensibility of two specifications, a formal specification and an informal (or semi-formal) specification, in an attempt to quantify the amount of training needed to understand formal methods. The two specifications used implemented the same logic, namely a portion of the Irish Electoral System. The "informal" specification was taken directly from the legal definition of the count rules for Irish elections, and the formal specification was an implementation of the same in CafeOBJ. Both Quantitative and Qualitative data was collected. Although participants had received twenty-five hours training in formal methods, the results show that the informal specification was more comprehendible than the formal specification.},
author = {Carew, Deirdre and Exton, Chris and Buckley, Jim},
booktitle = {2005 International Symposium on Empirical Software Engineering, ISESE 2005},
doi = {10.1109/ISESE.2005.1541834},
file = {:Users/timm/svns/doc/xplain/05carew.pdf:pdf},
isbn = {0780395085},
month = nov,
pages = {256--265},
title = {{An empirical investigation of the comprehensibility of requirements specifications}},
year = {2005}
}
@inproceedings{zit02,
abstract = {The Strength Pareto Evolutionary Algorithm(SPEA) (Zitzler and Thiele 1999) is a relatively recent technique for finding or approximating the Pareto-optimal set for multiobjective optimization problems. In different studies (Zitzler and Thiele 1999; Zitzler, Deb, and Thiele 2000) SPEA has shown very good performance in comparison to other multiobjective evolutionary algorithms, and therefore it has been a point of reference in various recent investigations, e.g., (Corne, Knowles, and Oates 2000). Furthermore, it has been used in different applications, e.g., (Lahanas, Milickovic, Baltas, and Zamboglou 2001). In this paper, an improved ver- sion, namely SPEA2, is proposed, which incorporates in contrast to its predecessor a fine-grained fitness assignment strategy, a density estimation technique, and an enhanced archive truncation method. The comparison of SPEA2 with SPEA and two other modern elitist methods, PESA and NSGA-II, on different test problems yields promising results. 1},
author = {Zitzler, Eckart and Laumanns, Marco and Thiele, Lothar},
booktitle = {Evolutionary Methods for Design Optimization and Control with Applications to Industrial Problems},
doi = {10.1.1.28.7571},
isbn = {TIK-Report No. 103},
pages = {95--100},
publisher = {CIMNE, Barcelona, Spain},
title = {{SPEA2: Improving the Strength Pareto Evolutionary Algorithm}},
year = {2001}
}
@article{storn97,
abstract = {A new heuristic approach for minimizing possibly nonlinear and non-differentiable continuous space functions is presented. By means of an extensive testbed it is demonstrated that the new method converges faster and with more certainty than many other acclaimed global optimization methods. The new method requires few control variables, is robust, easy to use, and lends itself very well to parallel computation.},
author = {Storn, R and Price, K},
doi = {10.1023/A:1008202821328},
file = {:Users/timm/svns/doc/97stornPriceDE.pdf:pdf},
isbn = {0925-5001},
issn = {0925-5001, 1573-2916},
journal = {Journal of Global Optimization},
keywords = {evolution strategy,genetic algorithm,global optimization,nonlinear optimization,stochastic optimization},
number = {4},
pages = {341--359},
publisher = {Kluwer Academic Publishers},
title = {{Differential evolution - A simple and efficient heuristic for global optimization over continuous spaces}},
url = {<Go to ISI>://A1997YF22800001},
volume = {11},
year = {1997}
}
@article{TecoloteResearch2005a,
author = {{Tecolote Research}},
file = {:Users/timm/svns/doc/cost/07Airforcehandbook.pdf:pdf},
pages = {204},
title = {{U.S. Air Force Cost Risk and Uncertainty Analysis Handbook}},
year = {2005}
}
@inproceedings{me02f,
abstract = { Software engineering (SE) truisms capture broadly-applicable principles of software construction. The trouble with truisms is that such general principles may not apply in specific cases. This paper tests the specificity of two SE truisms: (a) increasing software process level is a desirable goal; and (b) it is best to remove errors during the early parts of a software lifecycle. Our tests are based on two well-established SE models: (1) Boehm et.al.'s COCOMO II cost estimation model; and (2) Raffo's discrete event software process model of a software project life cycle. After extensive simulations of these models, the TAR2 treatment learner was applied to find the model parameters that most improved the potential performance of the real-world systems being modelled. The case studies presented here showed that these truisms are clearly sub-optimal for certain projects since other factors proved to be far more critical. Hence, we advise against truism-based process improvement. This paper offers a general alternative framework for model-based assessment of methods to improve software quality: modelling + validation + simulation + sensitivity. That is, after recording what is known in a model, that model should be validated, explored using simulations, then summarized to find the key factors that most improve model behavior.},
author = {Menzies, T. and Raffo, D. and Setamanit, S.-O. and Hu, Ying Hu Ying and Tootoonian, S.},
booktitle = {Proceedings 17th IEEE International Conference on Automated Software Engineering,},
doi = {10.1109/ASE.2002.1115012},
isbn = {0-7695-1736-6},
issn = {1527-1366},
title = {{Model-based tests of truisms}},
year = {2002}
}
@article{me03j,
abstract = {Chung et al. have proposed a graphical model that captures the interdependencies between design alternatives in terms of synergy and trade-offs. This model can assist in identifying quality/risk trade-offs early in the lifecycle of software development, such as architectural design and testing process choices. The Chung et al. method is an analysis framework only: their technique does not include an execution or analysis module. This paper presents a simulation tool developed to analyze such a model, and techniques to facilitate decision making by reducing the space of options worth considering. Our techniques combine Monte Carlo simulations to generate options with a machine learner to determine which option yields the most/least favorable outcome. Experiments based on the above methodology were performed on two case studies, and the results showed that treatment learning successfully pinpointed the key attributes among uncertainties in our test domains. Copyright Â© 2003 John Wiley \& Sons, Ltd.},
author = {Chiang, Eliza and Menzies, Tim},
doi = {10.1002/spip.161},
issn = {1099-1670},
journal = {Software Process: Improvement and Practice},
number = {3â4},
pages = {141--159},
title = {{Simulations for very early lifecycle quality evaluations}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/spip.161/abstract},
volume = {7},
year = {2002}
}
@misc{feh12,
annote = {From $\backslash$url\{http://gigaom.com/2012/01/31/the-era-of-the-100-mw-data-center/\}},
author = {Fehrenbacher, Katie},
month = jan,
title = {{The Era of the 100MW Data Center}},
url = {http://gigaom.com/2012/01/31/the-era-of-the-100-mw-data-center/},
year = {2012}
}
@inproceedings{come96,
author = {Connell, M and Menzies, T J},
booktitle = {Tools Pacific, 1996, Melbourne},
title = {{Quality Metrics: Test Coverage Analysis for Smalltalk}},
year = {1996}
}
@article{Aggarwal1998a,
abstract = {The problem of finding association rules in a large data- base of sales transactions has been widely studied in the literature, We discuss some of the weaknesses of the large itemset method for association rule generation. A differ- ent method for evaluating and finding itemsets referred to as otrongIyl collective itemsets is proposed. The concepts of âsupportâ of an itemset and correlation of the items within an itemset are related, though not quite the same. This cri- terion stresses the importance of the actual correlation of the items with one another rather than the absolute sup- port, Previously proposed methods to provide correlated itemsets are not necessarily applicable to very large data- bases, We provide an algorithm which provides very good computational efficiency, while maintaining statistical ro- buetneas, The fact that this algorithm relies on relative measures rather than absolute measures such as support also implies that the method can be applied to find association rules in datasets in which items may appear in a sizeable percentage of the transactions (dense datasets), datasets in which the items have varying density, or even negative as- sociation rules,},
author = {Aggarwal, Charu C. and Yu, Philip S.},
doi = {10.1145/275487.275490},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/aggarwal98.pdf:pdf},
isbn = {0897919963},
journal = {Proceedings of the seventeenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems - PODS '98},
pages = {18--24},
title = {{A new framework for itemset generation}},
url = {http://portal.acm.org/citation.cfm?doid=275487.275490},
year = {1998}
}
@inproceedings{Haiduc2013a,
abstract = {There are more than twenty distinct software engineering tasks addressed with text retrieval (TR) techniques, such as, traceability link recovery, feature location, refactoring, reuse, etc. A common issue with all TR applications is that the results of the retrieval depend largely on the quality of the query. When a query performs poorly, it has to be reformulated and this is a difficult task for someone who had trouble writing a good query in the first place. We propose a recommender (called Refoqus) based on machine learning, which is trained with a sample of queries and relevant results. Then, for a given query, it automatically recommends a reformulation strategy that should improve its performance, based on the properties of the query. We evaluated Refoqus empirically against four baseline approaches that are used in natural language document retrieval. The data used for the evaluation corresponds to changes from five open source systems in Java and C++ and it is used in the context of TR-based concept location in source code. Refoqus outperformed the baselines and its recommendations lead to query performance improvement or preservation in 84\% of the cases (in average).},
address = {San Francisco, USA},
annote = {Laura. Fixed on 10/16/2012 (missing fields - submitted)},
author = {Haiduc, Sonia and Bavota, Gabriele and Marcus, Andrian and Oliveto, Rocco and {De Lucia}, Andrea and Menzies, Tim},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2013.6606630},
isbn = {9781467330763},
issn = {02705257},
keywords = {Query Reformulation,Text Retrieval},
pages = {842--851},
title = {{Automatic query reformulations for text retrieval in software engineering}},
year = {2013}
}
@article{Tsai2009a,
abstract = {Many studies have shown that the total cost of employing joint replenishment for correlated items is less than the total cost of using single-item replenishment. Savings increase dramatically when the demand between items is closely related. Although the benefits of joint replenishment are significant, it is difficult to define the demand correlation among items, especially when the number of items increases. A large number of items reduces the efficiency and advantage of the multi-item inventory control. To overcome this difficulty, an association clustering algorithm this paper proposes to evaluate the correlated demands among items. The proposed algorithm utilizes the "support" concept in association rule analysis to measure the similarity among items. Based on these measurements a clustering method is developed to group items with close demand in a hierarchal way. The can-order policy is then applied to the optimal clustering result as decided by the proposed performance index. To illustrate the benefits of the proposed association clustering algorithm for replenishment systems, a set of simulations and a sensitivity analysis is conducted. The results of the experiments show that the proposed method outperforms several replenishment models. ?? 2008 Elsevier B.V. All rights reserved.},
author = {Tsai, Chieh Yuan and Tsai, Chi Yang and Huang, Po W.},
doi = {10.1016/j.ijpe.2008.08.056},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/tsai08.pdf:pdf},
issn = {09255273},
journal = {International Journal of Production Economics},
keywords = {Association clustering,Can-order polices,Inventory management,Joint replenishment},
number = {1},
pages = {30--41},
title = {{An association clustering algorithm for can-order policies in the joint replenishment problem}},
volume = {117},
year = {2009}
}
@article{VonMering2007a,
abstract = {Information on protein-protein interactions is still mostly limited to a small number of model organisms, and originates from a wide variety of experimental and computational techniques. The database and online resource STRING generalizes access to protein interaction data, by integrating known and predicted interactions from a variety of sources. The underlying infrastructure includes a consistent body of completely sequenced genomes and exhaustive orthology classifications, based on which interaction evidence is transferred between organisms. Although primarily developed for protein interaction analysis, the resource has also been successfully applied to comparative genomics, phylogenetics and network studies, which are all facilitated by programmatic access to the database backend and the availability of compact download files. As of release 7, STRING has almost doubled to 373 distinct organisms, and contains more than 1.5 million proteins for which associations have been pre-computed. Novel features include AJAX-based web-navigation, inclusion of additional resources such as BioGRID, and detailed protein domain annotation. STRING is available at http://string.embl.de/},
author = {von Mering, Christian and Jensen, Lars J. and Kuhn, Michael and Chaffron, Samuel and Doerks, Tobias and Kr\"{u}ger, Beate and Snel, Berend and Bork, Peer},
doi = {10.1093/nar/gkl825},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/vonMering06STRING.pdf:pdf},
isbn = {1362-4962 (Electronic)},
issn = {03051048},
journal = {Nucleic Acids Research},
number = {SUPPL. 1},
pages = {1--5},
pmid = {17098935},
title = {{STRING 7 - Recent developments in the integration and prediction of protein interactions}},
volume = {35},
year = {2007}
}
@article{shepperd12a,
abstract = {Context: Software engineering has a problem in that when we empirically evaluate competing prediction systems we obtain conflicting results. Objective: To reduce the inconsistency amongst validation study results and provide a more formal foundation to interpret results with a particular focus on continuous prediction systems. Method: A new framework is proposed for evaluating competing prediction systems based upon (1) an unbiased statistic, Standardised Accuracy, (2) testing the result likelihood relative to the baseline technique of random 'predictions', that is guessing, and (3) calculation of effect sizes. Results: Previously published empirical evaluations of prediction systems are re-examined and the original conclusions shown to be unsafe. Additionally, even the strongest results are shown to have no more than a medium effect size relative to random guessing. Conclusions: Biased accuracy statistics such as MMRE are deprecated. By contrast this new empirical validation framework leads to meaningful results. Such steps will assist in performing future meta-analyses and in providing more robust and usable recommendations to practitioners. ?? 2012 Elsevier B.V. All rights reserved.},
author = {Shepperd, Martin and MacDonell, Steve},
doi = {10.1016/j.infsof.2011.12.008},
isbn = {09505849},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Empirical validation,Prediction system,Randomisation techniques,Software engineering},
number = {8},
pages = {820--827},
title = {{Evaluating prediction systems in software project estimation}},
volume = {54},
year = {2012}
}
@inproceedings{marcus10,
author = {Marcus, Andrian and Menzies, Timothy},
booktitle = {Proceedings of the FSE/SDP workshop on Future of software engineering research - FoSER '10},
doi = {10.1145/1882362.1882410},
isbn = {9781450304276},
month = nov,
pages = {229},
title = {{Software is data too}},
url = {http://portal.acm.org/citation.cfm?doid=1882362.1882410},
year = {2010}
}
@article{me13c,
author = {Zimmermann, Thomas and Menzies, Tim},
journal = {IEEE Software},
number = {4},
pages = {31--37},
title = {{Software Analytics: So What?}},
volume = {30},
year = {2013}
}
@inproceedings{rich98zb,
author = {Richards, D and Menzies, T J},
booktitle = {Banff Workshop on Knowledge Acquisition},
title = {{Extending the SISYPHUS III Experiment from a Knowledge Engineering Task to a Requirements Engineering Task}},
year = {1998}
}
@article{me07e,
annote = {$\backslash$url\{http://menzies.us/pdf/07precision.pdf\}},
author = {Menzies, Tim and Menzies, Tim and Dekhtyar, Alex and Dekhtyar, Alex and Distefano, Justin and Distefano, Justin and Greenwald, Jeremy},
journal = {Engineering},
month = sep,
number = {1},
pages = {11--14},
title = {{Problems with Precision}},
volume = {6},
year = {2007}
}
@inproceedings{me91a,
abstract = {A major problem with building expert systems is that experts always communicate knowledge in a specific context. A knowledge acquisition methodology has been developed which restricts the use of knowledge to the context in which it was provided. This method, "ripple down rules" allows for extremely rapid and simple knowledge acquisition without the help of a knowledge engineer. An expert system based on this approach and built by experts is now in routine use. This paper reviews what has been achieved using the approach, its problems and potential.},
author = {Compton, Pea and Edwards, G and Kang, B and Lazarus, L and Malor, R and Menzies, T and Preston, P and Srinivasan, a and Sammut, C},
booktitle = {Proceedings of the Sixth AAAI Knowledge Acquisition for Knowledge-Based Systems Workshop, Calgary, Canada, University of Calgary},
pages = {1--6},
title = {{Ripple down rules: possibilities and limitations}},
year = {1991}
}
@article{turing39,
author = {Of, Systems and Eased, Logic and Ordinals, O N and Turing, By a M},
journal = {Proc. London Math. Soc},
number = {2239},
pages = {189--193},
title = {{SYSTEMS OF LOGIC BASED ON ORDINALSf}},
volume = {45},
year = {1938}
}
@article{Musen2013a,
abstract = {Intense interest in knowledge-acquisition research began 25 years ago, stimulated by the excitement about knowledge-based systems that emerged in the 1970s followed by the realities of the AI Winter that arrived in the 1980s. The knowledge-acquisition workshops that responded to this interest led to the formation of a vibrant research community that has achieved remarkable consensus on a number of issues. These viewpoints include (1) the rejection of the notion of knowledge as a commodity to be transferred from one locus to another, (2) an acceptance of the situated nature of human expertise, (3) emphasis on knowledge acquisition as the modeling of problem solving, and (4) the pursuit of reusable patterns in problem solving and in domain descriptions that can facilitate both modeling and system implementation. The Semantic Web community will benefit greatly by incorporating these perspectives in its work. ?? 2012 Elsevier Ltd.},
author = {Musen, Mark a.},
doi = {10.1016/j.ijhcs.2012.10.011},
file = {:Users/timm/svns/doc/25YearsofKaw.pdf:pdf},
issn = {10715819},
journal = {International Journal of Human Computer Studies},
keywords = {Knowledge acquisition,Knowledge-based systems,Semantic web,Workshops and conferences},
number = {2},
pages = {195--199},
publisher = {Elsevier},
title = {{The knowledge acquisition workshops: A remarkable convergence of ideas}},
url = {http://dx.doi.org/10.1016/j.ijhcs.2012.10.011},
volume = {71},
year = {2013}
}
@article{me06d,
abstract = {Effort estimation often requires generalizing from a small number of historical projects. Generalization from such limited experience is an inherently underconstrained problem. Hence, the learned effort models can exhibit large deviations that prevent standard statistical methods (e.g., t-tests) from distinguishing the performance of alternative effort-estimation methods. The COSEEKMO effort-modeling workbench applies a set of heuristic rejection rules to comparatively assess results from alternative models. Using these rules, and despite the presence of large deviations, COSEEKMO can rank alternative methods for generating effort models. Based on our experiments with COSEEKMO, we advise a new view on supposed "best practices" in model-based effort estimation: 1) Each such practice should be viewed as a candidate technique which may or may not be useful in a particular domain, and 2) tools like COSEEKMO should be used to help analysts explore and select the best method for a particular domain},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06coseekmo.pdf\}},
author = {Menzies, Tim and Chen, Zhihao and Hihn, Jairus and Lum, Karen},
doi = {10.1109/TSE.2006.114},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Menzies et al. - 2006 - Selecting Best Practices for Effort Estimation.pdf:pdf},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {COCOMO,Data mining,Deviation,Model-based effort estimation},
month = nov,
number = {11},
pages = {883--895},
title = {{Selecting best practices for effort estimation}},
volume = {32},
year = {2006}
}
@article{me97zg,
author = {Menzies, T},
journal = {The Knowledge Engineering Review},
number = {1},
pages = {1--46},
title = {{Knowledge Maintenance: The State of the Art}},
volume = {14},
year = {1999}
}
@article{me08i,
annote = {Avialable from $\backslash$url\{http://menzies.us/pdf/08promised.pdf\}},
author = {Menzies, Tim},
doi = {10.1007/s10664-008-9087-3},
issn = {13823256},
journal = {Empirical Software Engineering},
month = oct,
number = {5},
pages = {469--471},
title = {{Editorial, special issue, repeatable experiments in software engineering}},
volume = {13},
year = {2008}
}
@inproceedings{weissgerber07,
abstract = {Analyzing the check-in information of open source software projects which use a version control system such as CVS or SUBVERSION can yield interesting and important insights into the programming behavior of developers. As in every major project tasks are assigned to many developers, the development must be coordinated between these programmers. This paper describes three visualization techniques that help to examine how programmers work together, e.g. if they work as a team or if they develop their part of the software separate from each other. Furthermore, phases of stagnation in the lifetime of a project can be uncovered and thus, possible problems are revealed. To demonstrate the usefulness of these visualization techniques we performed case studies on two open source projects. In these studies interesting patterns of developers' behavior, e.g. the specialization on a certain module can be observed. Moreover, modules that have been changed by many developers can be identified as well as such ones that have been altered by only one programmer.},
author = {Wei\ss gerber, Peter and Pohl, Mathias and Burch, Michael},
booktitle = {Proceedings - ICSE 2007 Workshops: Fourth International Workshop on Mining Software Repositories, MSR 2007},
doi = {10.1109/MSR.2007.34},
isbn = {076952950X},
month = may,
pages = {9},
title = {{Visual data mining in software archives to detect how developers work together}},
year = {2007}
}
@article{Cooper1992a,
author = {Cooper, Gregory F and Herskovits, Edward},
doi = {10.1023/A:1022649401552},
file = {:Users/timm/svns/doc/02k2.pdf:pdf},
isbn = {0885-6125},
issn = {0885-6125},
journal = {Mach. Learn.},
keywords = { induction, machine learning, probabilistic networks,Bayesian belief networks},
number = {4},
pages = {309--347},
title = {{A Bayesian Method for the Induction of Probabilistic Networks from Data}},
url = {http://dx.doi.org/10.1023/A:1022649401552},
volume = {9},
year = {1992}
}
@article{Belli1990a,
author = {Belli, F},
file = {:Users/timm/svns/doc/ooprolog/p1153-schmidt.pdf:pdf},
isbn = {0897913728},
journal = {Brand},
pages = {1153--1161},
title = {{An Extension of PROLOG for Object-Oriented in Logic Programming}},
year = {1990}
}
@article{Vargha00,
abstract = {McGraw and Wong (1992) described an appealing index of effect size, called CL, which measures the difference between two populations in terms of the probability that a score sampled at random from the first population will be greater than a score sampled at random from the second. McGraw and Wong introduced this "common language effect size statistic" for normal distributions and then proposed an approximate estimation for any continuous distribution. In addition, they generalized CL to the n-group case, the correlated samples case, and the discrete values case. In the current paper a different generalization of CL, called the A measure of stochastic superiority, is proposed, which may be directly applied for any discrete or continuous variable that is at least ordinally scaled. Exact methods for point and interval estimation as well as the significance tests of the A = .5 hypothesis are provided. New generalizations ofCL are provided for the multi-group and correlated samples cases.},
author = {Vargha, a. and Delaney, H. D.},
doi = {10.3102/10769986025002101},
file = {:Users/timm/svns/doc/00varghaEffectSize.pdf:pdf},
isbn = {1076-9986},
issn = {1076-9986},
journal = {Journal of Educational and Behavioral Statistics},
number = {2},
pages = {101--132},
title = {{A Critique and Improvement of the CL Common Language Effect Size Statistics of McGraw and Wong}},
url = {http://jeb.sagepub.com/content/25/2/101.abstract},
volume = {25},
year = {2000}
}
@inproceedings{me96n,
author = {Menzies, T},
booktitle = {Proceedings of the ECAI '96 workshop on Validation, Verification, and Refinement of KBS},
title = {{Generalised Test = Generalised Inference}},
year = {1996}
}
@inproceedings{men93j,
author = {Menzies, T J and Spurret, R},
booktitle = {Tools Pacific 12},
pages = {213--224},
publisher = {Prentice Hall},
title = {{How to \{E\}dit $\backslash$"it$\backslash$"; or a \{B\}lack-Box \{C\}onstraint \{B\}ased \{F\}ramework for \{U\}ser \{I\}nteraction with \{A\}rbitrary \{S\}tructures}},
year = {1993}
}
@inproceedings{me10e,
abstract = {Insufficient risk analysis often leads to software system design defects and system failures. Assurance of software risk documents aims to increase the confidence that identified risks are complete, specific, and correct. Yet assurance methods rely heavily on manual analysis that requires significant knowledge of historical projects and subjective, perhaps biased judgment from domain experts. To address the issue, we have developed RARGen, a text mining-based approach based on well-established methods aiming to automatically create and maintain risk repositories to identify usable risk association rules (RARs) from a corpus of risk analysis documents. RARs are risks that have frequently occurred in historical projects. We evaluate RARGen on 20 publicly available e-service projects. Our evaluation results show that RARGen can effectively reason about RARs, increase confidence and cost-effectiveness of risk assurance, and support difficult-to-perform activities such as assuring complete-risk identification.},
author = {Huang, Lg and Port, D and Wang, L},
booktitle = {\ldots on Automated software \ldots},
doi = {10.1145/1858996.1859027},
isbn = {9781450301169},
keywords = {association rule,enables economical generation and,latent semantic analysis,maintenance of risk assurance,mining,mitigations into a repository,project risks and their,risk assurance,risk reduction,software repositories,text mining,that},
pages = {163--166},
title = {{Text mining in supporting software systems risk assurance}},
url = {http://dl.acm.org/citation.cfm?id=1859027},
year = {2010}
}
@misc{me97r,
author = {Menzies, T and Waugh, S and Goss, S and Cohen, Robert F},
howpublished = {Submitted to FOIS '97},
title = {{Evaluating a Temporal Causal Ontology}},
year = {1997}
}
@inproceedings{me99f,
author = {Menzies, T and Cukic, B},
booktitle = {Proceedings, AAAI '99 workshop on Intelligent Software Engineering, Orlando, Florida},
month = jul,
title = {{Intelligent Testing can be Very Lazy}},
year = {1999}
}
@misc{me09h,
author = {Menzies, Tim},
booktitle = {Journal of Software Engineering and Applications},
doi = {10.4236/jsea.2009.24030},
issn = {1945-3116},
month = nov,
number = {04},
pages = {221--236},
title = {{Explanation vs Performance in Data Mining: A Case Study with Predicting Runaway Projects}},
volume = {02},
year = {2009}
}
@inproceedings{noda99,
author = {Noda, Edgar and Noda, Edgar},
booktitle = {Evolutionary Computation, 1999. CEC 99. Proceedings of the 1999 Congress on},
isbn = {0780355369},
pages = {1322--1329},
title = {{Discovering Pnteresting Prediction Rules with a Genetic Algorithm}},
volume = {2},
year = {1999}
}
@inproceedings{he13,
abstract = {The fundamental issue in cross project defect prediction is selecting the most appropriate training data for creating quality defect predictors. Another concern is whether historical data of open-source projects can be used to create quality predictors for proprietary projects from a practical point-of-view. Current studies have proposed statistical approaches to finding these training data, however, thus far no apparent effort has been made to study their success on proprietary data. Also these methods apply brute force techniques which are computationally expensive. In this work we introduce a novel data selection procedure which takes into account the similarities between the distribution of the test and potential training data. Additionally we use feature subset selection to increase the similarity between the test and training sets. Our procedure provides a comparable and scalable means of solving the cross project defect prediction problem for creating quality defect predictors. To evaluate our procedure we conducted empirical studies with comparisons to the within company defect prediction and a relevancy filtering method. We found that our proposed method performs relatively better than the filtering method in terms of both computation cost and prediction performance.},
author = {He, Zhimin and Peters, Fayola and Menzies, Tim and Yang, Ye},
booktitle = {International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2013.20},
isbn = {978-0-7695-5056-5},
issn = {19493770},
keywords = {cross-project,data similarity,feature subset selection,instance selection,software defect prediction},
pages = {45--54},
title = {{Learning from open-source projects: An empirical study on defect prediction}},
year = {2013}
}
@misc{haaga08,
author = {Haaga, John},
number = {May},
title = {{Demographic and Socioeconomic Change in Appalachia EDUCATIONAL ATTAINMENT by}},
year = {2004}
}
@incollection{ruhe03,
author = {Ruhe, G.},
booktitle = {Lecture Notes in Computer Science},
editor = {Henninger, Scott and Maurer, Frank},
issn = {03029743},
number = {2640},
pages = {104--114},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Software Engineering Decision Support - A New Paradigm for Learning Software Organizations}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0347586877\&partnerID=tZOtx3y1},
year = {2003}
}
@article{Breiman2001,
abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148â156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
archivePrefix = {arXiv},
arxivId = {http://dx.doi.org/10.1023\%2FA\%3A1010933404324},
author = {Breiman, Leo},
doi = {10.1023/A:1010933404324},
eprint = {/dx.doi.org/10.1023\%2FA\%3A1010933404324},
isbn = {9781424444427},
issn = {08856125},
journal = {Machine Learning},
keywords = {Classification,Ensemble,Regression},
number = {1},
pages = {5--32},
pmid = {20142443},
primaryClass = {http:},
title = {{Random forests}},
url = {http://link.springer.com/article/10.1023/A:1010933404324},
volume = {45},
year = {2001}
}
@inproceedings{me91c,
author = {Menzies, T J},
booktitle = {Tools 3: Proceedings of the third International Technology of Object-Oriented Languages and; Systems conference},
publisher = {Prentice-Hall},
title = {{Beyond the MVC Triad: Quality Assurance via Interactive Specification Editors}},
year = {1991}
}
@article{me06d,
abstract = {Effort estimation often requires generalizing from a small number of historical projects. Generalization from such limited experience is an inherently underconstrained problem. Hence, the learned effort models can exhibit large deviations that prevent standard statistical methods (e.g., t-tests) from distinguishing the performance of alternative effort-estimation methods. The COSEEKMO effort-modeling workbench applies a set of heuristic rejection rules to comparatively assess results from alternative models. Using these rules, and despite the presence of large deviations, COSEEKMO can rank alternative methods for generating effort models. Based on our experiments with COSEEKMO, we advise a new view on supposed "best practices" in model-based effort estimation: 1) Each such practice should be viewed as a candidate technique which may or may not be useful in a particular domain, and 2) tools like COSEEKMO should be used to help analysts explore and select the best method for a particular domain},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06coseekmo.pdf\}},
author = {Menzies, Tim and Chen, Zhihao and Hihn, Jairus and Lum, Karen},
doi = {10.1109/TSE.2006.114},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Menzies et al. - 2006 - Selecting Best Practices for Effort Estimation.pdf:pdf},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {COCOMO,Data mining,Deviation,Model-based effort estimation},
month = nov,
number = {11},
pages = {883--895},
title = {{Selecting best practices for effort estimation}},
volume = {32},
year = {2006}
}
@article{Guan2009a,
abstract = {Traditional clustering models based on distance similarity are not always effective in capturing correlation among data objects, while pattern-based clustering can do well in identifying correlation hidden among data objects. However, the state-of-the-art pattern-based clustering methods are inefficient and provide no metric to measure the clustering quality. This paper presents a new pattern-based subspace clustering method, which can tackle the problems mentioned above. Observing the analogy between mining frequent itemsets and discovering subspace clusters, we apply pattern tree - a structure used in frequent itemsets mining to determining the target subspaces by scanning the database once, which can be done efficiently in large datasets. Furthermore, we introduce a general clustering quality evaluation model to guide the identifying of meaningful clusters. The proposed new method enables the users to set flexibly proper quality-control parameters to meet different needs. Experimental results on synthetic and real datasets show that our method outperforms the existing methods in both efficiency and effectiveness. ?? 2009 Elsevier B.V. All rights reserved.},
author = {Guan, Jihong and Gan, Yanglan and Wang, Hao},
doi = {10.1016/j.knosys.2009.02.011},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/Guan09.pdf:pdf},
isbn = {0950-7051},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Clustering analysis,Pattern similarity,Pattern tree,Subspace clustering},
number = {8},
pages = {569--579},
title = {{Discovering pattern-based subspace clusters by pattern tree}},
volume = {22},
year = {2009}
}
@inproceedings{koc12m,
author = {Kocaguneli, Ekrem and Menzies, T and Hihn, Jairus and Kang, Bh},
booktitle = {\ldots Models in Software \ldots},
doi = {10.1145/2365324.2365336},
isbn = {9781450312417},
keywords = {all or part of,analogy-,based estimation,function points,instance selection,k-nn,lines of code,or hard copies of,permission to make digital,popularity,this work for},
pages = {89--98},
title = {{Size Doesn â t Matter ? On the Value of Software Size Features for Effort Estimation}},
url = {http://dl.acm.org/citation.cfm?id=2365336},
year = {2012}
}
@article{Ruiz2005a,
author = {Ruiz, C},
file = {:Users/timm/svns/doc/k2.pdf:pdf},
journal = {Department of Computer Science},
pages = {1--7},
title = {{Illustration of the K2 algorithm for learning Bayes net structures}},
url = {http://web.cs.wpi.edu/~cs539/s07/Projects/k2\_algorithm.pdf},
year = {2005}
}
@article{Djordjevic2006c,
abstract = {SELEX (systematic evolution of ligands by exponential enrichment) is an experimental procedure that allows the extraction, from an initially random pool of DNA, of those oligomers with high affinity for a given DNA-binding protein. We address what is a suitable experimental and computational procedure to infer parameters of transcription factor-DNA interaction from SELEX experiments. To answer this, we use a biophysical model of transcription factor-DNA interactions to quantitatively model SELEX. We show that a standard procedure is unsuitable for obtaining accurate interaction parameters. However, we theoretically show that a modified experiment in which chemical potential is fixed through different rounds of the experiment allows robust generation of an appropriate dataset. Based on our quantitative model, we propose a novel bioinformatic method of data analysis for such a modified experiment and apply it to extract the interaction parameters for a mammalian transcription factor CTF/NFI. From a practical point of view, our method results in a significantly improved false positive/false negative trade-off, as compared to both the standard information theory based method and a widely used empirically formulated procedure.},
archivePrefix = {arXiv},
arxivId = {arXiv:q-bio/0512001v1},
author = {Djordjevic, Marko and Sengupta, Anirvan M},
doi = {10.1088/1478-3975/3/1/002},
eprint = {0512001v1},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Djordjevic05.pdf:pdf},
issn = {1478-3975},
journal = {Physical biology},
keywords = {protein-dna interactions,selex,transcription factor binding sites,weight ma-},
number = {1},
pages = {13--28},
pmid = {16582458},
primaryClass = {arXiv:q-bio},
title = {{Quantitative modeling and data analysis of SELEX experiments.}},
volume = {3},
year = {2006}
}
@inproceedings{me09a,
abstract = {Before performing drastic changes to a project, it is worthwhile to thoroughly explore the available options within the current structure of a project. An alternative to drastic change are internal changes that adjust current options within a software project. In this paper, we show that the effects of numerous internal changes can out-weigh the effects of drastic changes. That is, the benefits of drastic change can often be achieved without disrupting a project. The key to our technique is SEESAW, a novel stochastic stability tool that (a) considers a very large set of minor changes using stochastic sampling; and (b) carefully selects the right combination of effective minor changes. Our results show, using SEESAW, project managers have more project improvement options than they currently realize. This result should be welcome news to managers struggling to maintain control and continuity over their project in the face of multiple demands for drastic change.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08drastic.pdf\}},
author = {Menzies, T. and Williams, S. and El-Rawas, O. and Boehm, B. and Hihn, J.},
booktitle = {2009 IEEE 31st International Conference on Software Engineering},
doi = {10.1109/ICSE.2009.5070552},
isbn = {978-1-4244-3453-4},
issn = {0270-5257},
title = {{How to avoid drastic software process change (using stochastic stability)}},
year = {2009}
}
@inproceedings{me96i,
author = {Menzies, T J},
booktitle = {Proceedings of the Eighth International Conference on Software Engineering and Knowledge Engineering},
isbn = {0-9641699-3-2},
publisher = {Knowledge Systems Institute, Skokie, Illinois, USA},
title = {{Visual Programming, Knowledge Engineering, and Visual Programming}},
year = {1996}
}
@article{me12e,
abstract = {The goal of science is conclusion stability, i.e. to discover some effect X that holds in multiple situations. Sadly, there are all too few examples of stable conclusions in software engineering (SE). In fact, the typical result is conclusion instability where what is true for project one, does not hold for project two. We can find numerous studies of the following form: there is as much evidence for as against the argument that some aspect X adds value to a software project. Below are four examples of this type of problem which we believe to be endemic within SE.},
author = {Menzies, Tim and Shepperd, Martin},
doi = {10.1007/s10664-011-9193-5},
issn = {13823256},
journal = {Empirical Software Engineering},
number = {1-2},
pages = {1--17},
title = {{Special issue on repeatable results in software engineering prediction}},
volume = {17},
year = {2012}
}
@article{Shepperd2014a,
abstract = {Background. The ability to predict defect-prone software components would be valuable. Consequently, there have been many empirical studies to evaluate the performance of different techniques endeavouring to accomplish this effectively. However no one technique dominates and so designing a reliable defect prediction model remains problematic. Objective. We seek to make sense of the many conflicting experimental results and understand which factors have the largest effect onpredictive performance. Method. We conduct a meta-analysis of all relevant, high quality primary studies of defect prediction to determine what factors influence predictive performance. This is based on 42 primary studies that satisfy our inclusion criteria that collectively report 600 sets of empirical prediction results. By reverse engineering a common response variable we build arandom effects ANOVA model to examine the relative contribution of four model building factors (classifier, data set, input metrics and researcher group) to model prediction performance. Results. Surprisingly we find that the choice of classifier has little impact upon performance (1.3 percent) and in contrast the major (31 percent) explanatory factor is the researcher group. It matters more who does the work than what is done. Conclusion.  To overcome this high level of researcher bias, defect prediction researchers should (i) conduct blind analysis, (ii) improve reporting protocols and (iii) conduct more intergroup studies in order to alleviate expertise issues. Lastly, research is required to determine whether this bias is prevalent in other applications domains.},
author = {Shepperd, Martin and Bowes, David and Hall, Tracy},
doi = {10.1109/TSE.2014.2322358},
file = {:Users/timm/svns/doc/14shepperdResearcherBias.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Software defect prediction,meta-analysis,researcher bias},
number = {6},
pages = {603--616},
title = {{Researcher bias: The use of machine learning in software defect prediction}},
volume = {40},
year = {2014}
}
@misc{me09c,
author = {Gundy-Burlet, K and Schumann, J and Menzies, T and Barrett, T},
booktitle = {AIAA Aerospace, 2009},
title = {{Parametric Analysis of a Hover Test Vehicle Using Advanced Test Generation and Data Analysis}},
year = {2009}
}
@article{brady10a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/10w0.pdf\}},
author = {Brady, Adam},
doi = {10.4236/jsea.2010.311118},
issn = {1945-3116},
journal = {Journal of Software Engineering and Applications},
number = {11},
pages = {1005--1014},
title = {{Case-Based Reasoning for Reducing Software Development Effort}},
volume = {03},
year = {2010}
}
@inproceedings{me94z,
annote = {$\backslash$url\{http://menzies.us/pdf/banff94.pdf\}},
author = {Menzies, T J and Compton, P},
booktitle = {Proceedings of the 8th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge-Based Systems Workshop, Banff, Canada},
title = {{Knowledge Acquisition for Performance Systems; or: When can "tests" replace "tasks"?}},
year = {1994}
}
@inproceedings{me00v,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/00vp.pdf\}},
author = {Menzies, T J},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{Evaluation Issues for Problem Visual Programming Languages}},
year = {1998}
}
@incollection{zit04,
author = {Zitzler, Eckart and K\"{u}nzli, Simon},
booktitle = {Parallel Problem Solving from Nature - PPSN VIII},
doi = {10.1007/b100601},
editor = {Yao, Xin and Burke, EdmundK. and Lozano, Jos\'{e}A. and Smith, Jim and Merelo-Guerv\'{o}s, JuanJuli\'{a}n and Bullinaria, JohnA. and Rowe, JonathanE. and TiÅo, Peter and Kab\'{a}n, Ata and Schwefel, Hans-Paul},
file = {:Users/timm/svns/doc/04zitzlerIBEA.pdf:pdf},
isbn = {3-540-23092-0},
pages = {832--842},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Parallel Problem Solving from Nature -- PPSN VIII, Proc.\~{}Eighth Int'l Conf., Birmingham}},
url = {http://dx.doi.org/10.1007/978-3-540-30217-9\_84},
volume = {3242},
year = {2004}
}
@book{edgeworth1881,
abstract = {No abstract is available for},
author = {Edgeworth, Francis Ysidro},
booktitle = {Mind},
doi = {10.2307/2223848},
issn = {00130133},
pages = {581--583},
publisher = {P. Keagan, London, England},
title = {{Mathematical psychics}},
volume = {6},
year = {1881}
}
@inproceedings{bingham01,
abstract = {Random projections have recently emerged as a powerful  method for dimensionality reduction. Theoretical results  indicate that the method preserves distances quite nicely;  however, empirical results are sparse. We present experimental results on using random projection as a dimensionality reduction tool in a number of cases, where the high  dimensionality of the data would otherwise lead to burdensome computations. Our application areas are the processing of both noisy and noiseless images, and information retrieval in text documents. We show that projecting the  data onto a random lower-dimensional subspace yields results comparable to conventional dimensionality reduction  methods such as principal component analysis: the similarity of data vectors is preserved well under random projection. However, using random projections is computationally  signiï¬cantly less expensive than using, e.g., principal component analysis. We also show experimentally that using a  sparse random matrix gives additional computational savings in random projection. },
author = {Bingham, Ella and Bingham, Ella and Mannila, Heikki and Mannila, Heikki},
booktitle = {International Conference on Knowledge Discovery and Data Mining (KDD)},
doi = {10.1145/502512.502546},
file = {:Users/timm/svns/doc/01randomProj.pdf:pdf},
isbn = {158113391X},
pages = {245--250},
series = {KDD '01},
title = {{Random projection in dimensionality reduction: applications to image and text data}},
url = {http://www.cis.hut.fi/ella/publications/randproj\_kdd.pdf},
year = {2001}
}
@misc{sessions09,
annote = {Available from $\backslash$url\{http://goo.gl/Q0Xhs\}},
author = {Sessions, Roger},
title = {{Cost of \{IT\} Failure}},
year = {2009}
}
@article{Zimmermann2004a,
abstract = {Ordering and ranking items of different types (observations, web pages, etc.) are important tasks in various applications, such as query processing and scientific data mining. We consider different problems of inferring total or partial orders from data, with special emphasis on applications to the seriation problem in paleontology. Seriation can be viewed as the task of ordering rows of a 0-1 matrix so that certain conditions hold. We review different approaches to this task, including spectral ordering methods, techniques for finding partial orders, and probabilistic models using MCMC methods. Joint work with Antti Ukkonen, Aris Gionis, Mikael Fortelius, Kai Puolam\"{a}ki, and Jukka Jernvall.},
author = {Mannila, Heikki},
doi = {10.1007/978-3-540-88411-8},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/Zimmermann.pdf:pdf},
isbn = {978-3-540-88410-1},
issn = {0302-9743},
journal = {Discovery Science},
pages = {16--25},
title = {{Discovery Science}},
url = {http://www.springerlink.com/content/6014730541hr7236},
volume = {5255},
year = {2008}
}
@article{me99p,
abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article. ACM has opted to expose the complete List rather than only correct and linked references.},
author = {Menzies, Tim},
doi = {10.1145/318964.318969},
isbn = {1523-8822},
issn = {15238822},
journal = {Intelligence},
number = {3},
pages = {26--32},
title = {{Cost benefits of ontologies}},
volume = {10},
year = {1999}
}
@inproceedings{me04c,
author = {Menzies, Tim and Stefano, Justin S Di and Cunanan, Chris and Chapman, Robert Mike and Virginia, West},
booktitle = {IET Software},
doi = {10.1049/ic:20040480},
isbn = {0 86341 432 X},
title = {{Mining Repositories to Assist in Project Planning and Resource Allocation}},
year = {2004}
}
@article{zhang07:TEC,
abstract = {Decomposition is a basic strategy in traditional multiobjective optimization. However, it has not yet been widely used in multiobjective evolutionary optimization. This paper proposes a multiobjective evolutionary algorithm based on decomposition (MOEA/D). It decomposes a multiobjective optimization problem into a number of scalar optimization subproblems and optimizes them simultaneously. Each subproblem is optimized by only using information from its several neighboring subproblems, which makes MOEA/D have lower computational complexity at each generation than MOGLS and nondominated sorting genetic algorithm II (NSGA-II). Experimental results have demonstrated that MOEA/D with simple decomposition methods outperforms or performs similarly to MOGLS and NSGA-II on multiobjective 0-1 knapsack problems and continuous multiobjective optimization problems. It has been shown that MOEA/D using objective normalization can deal with disparately-scaled objectives, and MOEA/D with an advanced decomposition method can generate a set of very evenly distributed solutions for 3-objective test instances. The ability of MOEA/D with small population, the scalability and sensitivity of MOEA/D have also been experimentally investigated in this paper.},
author = {Zhang, Qingfu and Li, Hui},
doi = {10.1109/TEVC.2007.892759},
isbn = {1089-778X},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Computational complexity,Decomposition,Evolutionary algorithm,Multiobjective optimization,Pareto optimality},
month = dec,
number = {6},
pages = {712--731},
title = {{MOEA/D: A multiobjective evolutionary algorithm based on decomposition}},
volume = {11},
year = {2007}
}
@article{me02k,
abstract = { For original paper see ibid., p. 474. This is a clear example of how research in software engineering can progress when empirical methods are applied. Menzies and Di Stefano apply a number of data mining tools to the data set. While, inmost cases, their results are in agreement with ours, in some cases they are not. Our first and main observation is that our interpretation of the data set is based not only on the data set itself but also on the knowledge gathered during the interviews with project members. The main problem with the data set is its size: 23 data points. Although this data set is the largest one available about reuse projects, it is too limited to base analysis only on data mining techniques; data mining is usually applied to data sets with thousands if not millions of data points.},
author = {Morisio, Maurizio and Ezran, Michel and Tully, Colin},
doi = {10.1109/TSE.2003.1199077},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
month = may,
number = {5},
pages = {478},
title = {{Comments on "more success and failure factors in software reuse"}},
volume = {29},
year = {2003}
}
@article{Dai2012a,
abstract = {There are two crucial problems with statistical measures for sequence comparison: overlapping structures and background information of words in biological sequences. Word normalization in improved composition vector method took into account these problems and achieved better performance in evolutionary analysis. The word normalization is desirable, but not sufficient, because it assumes that the four bases A, C, T, and G occur randomly with equal chance. This paper proposed an improved word normalization which uses Markov model to estimate exact k-word distribution according to observed biological sequence and thus has the ability to adjust the background information of the k-word frequencies in biological sequences. The improved word normalization was tested with three experiments and compared with the existing word normalization. The experiment results confirm that the improved word normalization using Markov model to estimate the exact k-word distribution in biological sequences is more efficient.},
author = {Dai, Qi and Liu, Xiaoqing and Yao, Yuhua and Zhao, Fukun},
doi = {10.1007/s00726-011-0906-2},
file = {:Users/timm/svns/doc/erin/references/AlgsForDNA/MarkovWordNormAlgSequence2Dai2011.pdf:pdf},
isbn = {0072601109062},
issn = {09394451},
journal = {Amino Acids},
keywords = {Classification,Markov model,Phylogenetic analysis,Sequence comparison,Word normalization},
number = {5},
pages = {1867--1877},
pmid = {21505825},
title = {{Using Markov model to improve word normalization algorithm for biological sequence comparison}},
volume = {42},
year = {2012}
}
@inproceedings{memaco92,
author = {Menzies, T and Mahidadia, A and Compton, P},
booktitle = {Proceedings of the 7th \{AAAI\}-Sponsored \{B\}anff Knowledge Acquisition for Knowledge-Based Systems Workshop \{B\}anff, \{C\}anada, October 11-16},
title = {{Using \{C\}ausality as a \{G\}eneric \{K\}nowledge \{R\}epresentation, or \{W\}hy and \{H\}ow \{C\}entralised \{K\}nowledge \{S\}ervers \{C\}an \{U\}se \{C\}ausality}},
year = {1992}
}
@inproceedings{sculley10,
abstract = {We present two modifications to the popular k-means clus- tering algorithm to address the extreme requirements for latency, scalability, and sparsity encountered in user-facing web applications. First, we propose the use of mini-batch optimization for k-means clustering. This reduces computation cost by orders of magnitude compared to the classic batch algorithm while yielding significantly better solutions than online stochastic gradient descent. Second, we achieve sparsity with projected gradient descent, and give a fast Ïµ- accurate projection onto the L1-ball. Source code is freely available: http://code.google.com/p/sofia-ml},
author = {Sculley, D},
booktitle = {Proceedings of the 19th international conference on World wide web WWW 10},
doi = {10.1145/1772690.1772862},
file = {:Users/timm/svns/doc/10fastkmeans.pdf:pdf},
isbn = {9781605587998},
issn = {1605587990},
pages = {1177},
series = {WWW '10},
title = {{Web-scale k-means clustering}},
url = {http://portal.acm.org/citation.cfm?doid=1772690.1772862},
year = {2010}
}
@inproceedings{owen2b,
abstract = { In the development of high-assurance systems, formal modeling, analysis and verification techniques are playing an increasingly important role. In spite of significant advances, formal modeling and verification using model checking, still suffer from limited applicability. The main reason is the exponential runtime space growth exhibited, in the general case, by model checkers. We describe a less rigorous alternative to model checking. We propose an algorithm that automatically translates finite state machine models used by model checkers into a variation of AND-OR graphs. State space verification of AND-OR graphs does not suffer from state space explosion, but its exhaustive search is an NP complete problem. Hence, we demonstrate that random search of AND-OR graphs is a viable alternative to model checking, suitable for system debugging and fast analysis during system development. We support our conclusions through the studies of two models, Dekker's two process mutual exclusion algorithm and the Space Shuttle's liquid hydrogen subsystem.},
author = {Owen, D. and Cukic, B. and Menzies, T.},
booktitle = {7th IEEE International Symposium on High Assurance Systems Engineering, 2002. Proceedings.},
doi = {10.1109/HASE.2002.1173112},
isbn = {0-7695-1769-2},
issn = {1530-2059},
pages = {119},
title = {{An alternative to model checking: verification by random search of AND-OR graphs representing finite-state models}},
volume = {1},
year = {2002}
}
@inproceedings{me01g,
author = {Menzies, Tim and Hu, Ying},
booktitle = {First International Workshop on Model-based Requirements Engineering},
title = {{Constraining Discussions in Requirements Engineering via Models}},
year = {2001}
}
@inproceedings{me96m,
author = {Menzies, Tim},
booktitle = {Proceedings of the ECAI '96 workshop on Modelling Conflicts in AI},
title = {{Expert Systems Inference = Modeling Conflicts}},
year = {1996}
}
@article{Fung10,
author = {Fung, Benjamin C M and Chen, R and Yu, P S},
issn = {03600300},
journal = {Computing},
number = {4},
pages = {1--53},
title = {{Privacy-Preserving Data Publishing: A Survey on Recent Developments}},
volume = {V},
year = {2010}
}
@article{Technology2010a,
author = {Technology, Software and Analysis, Cost},
file = {:Users/timm/svns/doc/cost/10Stsgcahandbook.pdf:pdf},
number = {October},
title = {{Software Development Cost Estimating Guidebook Software Technology Support Center Cost Analysis Group}},
year = {2010}
}
@article{vines14,
abstract = {Policies ensuring that research data are available on public archives are increasingly being implemented at the government [1], funding agency [2-4], and journal [5, 6] level. These policies are predicated on the idea that authors are poor stewards of their data, particularly over the long term [7], and indeed many studies have found that authors are often unable or unwilling to share their data [8-11]. However, there are no systematic estimates of how the availability of research data changes with time since publication. We therefore requested data sets from a relatively homogenous set of 516 articles published between 2 and 22 years ago, and found that availability of the data was strongly affected by article age. For papers where the authors gave the status of their data, the odds of a data set being extant fell by 17\% per year. In addition, the odds that we could find a working e-mail address for the first, last, or corresponding author fell by 7\% per year. Our results reinforce the notion that, in the long term, research data cannot be reliably preserved by individual researchers, and further demonstrate the urgent need for policies mandating data sharing via public archives. Â© 2014 Elsevier Ltd.},
archivePrefix = {arXiv},
arxivId = {1312.5670},
author = {Vines, Timothy H. and Albert, Arianne Y K and Andrew, Rose L. and D\'{e}barre, Florence and Bock, Dan G. and Franklin, Michelle T. and Gilbert, Kimberly J. and Moore, Jean S\'{e}bastien and Renaut, S\'{e}bastien and Rennison, Diana J.},
doi = {10.1016/j.cub.2013.11.014},
eprint = {1312.5670},
isbn = {0960-9822},
issn = {09609822},
journal = {Current Biology},
number = {1},
pages = {94--97},
pmid = {24361065},
title = {{The availability of research data declines rapidly with article age}},
volume = {24},
year = {2014}
}
@article{Bohm2004a,
author = {B\"{o}hm, Christian and Kailing, Karin and Kr\"{o}ger, Peer and Zimek, Arthur},
doi = {10.1145/1007568.1007620},
file = {:Users/timm/svns/doc/04dbscanPCA.pdf:pdf},
isbn = {1581138598},
issn = {07308078},
journal = {Proceedings of the 2004 ACM SIGMOD international conference on Management of data - SIGMOD '04},
pages = {455},
title = {{Computing Clusters of Correlation Connected objects}},
url = {http://portal.acm.org/citation.cfm?doid=1007568.1007620},
year = {2004}
}
@article{me97m,
abstract = { We can test a theory of "X" by checking if that theory can reproduce known behavior of "'X." In the general case, this check for time-based simulations is only practical for short simulation runs. We show that, given certain reasonable language restrictions, the complexity of this check reduces to the granularity of the measurements. That is, provided a very long simulation run is only measured infrequently, this check is feasible.},
author = {Menzies, Tim and Cohen, Robert F. and Waugh, Sam and Goss, Simon},
doi = {10.1109/TKDE.2002.1047773},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Abduction,Complexity,Qualitative reasoning,Validation},
number = {6},
pages = {1362--1375},
title = {{Applications of abduction: Testing very long qualitative simulations}},
volume = {14},
year = {2002}
}
@inproceedings{me00r,
author = {Menzies, T and Easterbrook, S and Nuseibeh, B and Waugh, S},
booktitle = {Submitted for journal review},
title = {{Validating Inconsistent Requirements Models using Graph-based Abduction}},
year = {2001}
}
@inproceedings{me92l,
author = {Menzies, T and Mahidadia, a and Compton, P},
booktitle = {Proceedings of the 7th \{AAAI\}-Sponsored \{B\}anff Knowledge Acquisition for Knowledge-Based Systems Workshop \{B\}anff, \{C\}anada, October 11-16},
title = {{Using \{C\}ausality as a \{G\}eneric \{K\}nowledge \{R\}epresentation, or \{W\}hy and \{H\}ow \{C\}entralised \{K\}nowledge \{S\}ervers \{C\}an \{U\}se \{C\}ausality}},
year = {1992}
}
@article{me06e,
annote = {Available on-line at $\backslash$url\{http://menzies.us/pdf/06costs.pdf\}},
author = {Menzies, T and Hihn, J},
journal = {IEEE Software},
title = {{Evidence-Based Cost Estimation for Better Quality Software}},
year = {2006}
}
@inproceedings{me00w,
author = {Menzies, T J},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{Knowledge Elicitation: the State of the Art}},
year = {2002}
}
@article{Ben-Hur2003a,
abstract = {Clustering, principal component analysis, clustering stability, gene expression Clustering is one of the most commonly used tools in the analysis of gene expression data. The usage in grouping genes is based on the premise that co-expression is a result of co-regulation. It is thus a preliminary step in extracting gene networks and inference of gene function. Clustering is a form of unsupervised learning, i.e. no information on the class variable is assumed, and the objective is to find the "natural" groups in the data. However, most clustering algorithms generate a clustering even if the data has no inherent cluster structure, so external validation tools are required. The emergence of cluster structure depends on several choices: data representation and normalization, the choice of a similarity measure and clustering algorithm. In this chapter we extend the stability-based validation of cluster structure, and propose stability as a figure of merit that is useful for comparing clustering solutions, thus helping in making these choices. We use this framework to demonstrate the ability of principal component analysis (PCA) to extract features relavant to the cluster structure. We use stability as a tool for simultaneously choosing the number of principal components and the number of clusters.},
author = {Ben-Hur, Asa and Guyon, Isabelle},
doi = {10.1385/1-59259-364-X:159},
file = {:Users/timm/svns/doc/03BenHurPcaClustering.pdf:pdf},
issn = {1064-3745},
journal = {Methods in molecular biology (Clifton, N.J.)},
number = {1},
pages = {159--182},
pmid = {12710673},
title = {{Detecting stable clusters using principal component analysis.}},
volume = {224},
year = {2003}
}
@article{hertz03,
author = {Hertz, a and Widmer, M},
journal = {European Journal of Operational Research, Article in press},
number = {2},
pages = {247--252},
title = {{Preface: Guidelines for the Use of Meta Heuristics in Combinatorial Optimization}},
volume = {151},
year = {2003}
}
@article{ck94,
author = {Chidamber, S. and Kemerer, C.},
journal = {Software Engineering, IEEE Transactions on},
month = jun,
number = {6},
pages = {476 -- 493},
title = {{A Metrics Suite for Object Oriented Design. IEEE Transactions on Software Engineering, 20 (6)}},
volume = {20},
year = {1994}
}
@article{Ordonez2003a,
abstract = {Clustering data streams is an interesting Data Mining prob- lem. This article presents three variants of the K-means algorithm to cluster binary data streams. The variants in- clude On-line K-means, Scalable K-means, and Incremental K-means, a proposed variant introduced that finds higher quality solutions in less time. Higher quality of solutions are obtained with a mean-based initialization and incremen- tal learning. The speedup is achieved through a simplified set of sufficient statistics and operations with sparse matri- ces. A summary table of clusters is maintained on-line. The K-means variants are compared with respect to quality of results and speed. The proposed algorithms can be used to monitor transactions.},
author = {Ordonez, Carlos},
doi = {10.1145/882085.882087},
file = {:Users/timm/svns/doc/erin/references/BinarySparseClustering/Ordonez03.pdf:pdf},
journal = {Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery},
keywords = {binary data},
pages = {12--19},
title = {{Clustering binary data streams with K-means}},
url = {http://portal.acm.org/citation.cfm?doid=882082.882087},
year = {2003}
}
@inproceedings{port08,
abstract = {Agile and traditional plan-based approaches to software system development both agree that prioritizing requirements is an essential activity. They differ in basic strategy - when to prioritize, to what degree, and how to guide implementation. As with many software engineering methods, verifying the benefit of following a particular approach is a challenge. Industry and student/classroom based experimental studies are generally impractical to use for large numbers of controlled experiments and benefits are difficult to measure directly. We use simulation to validate the fundamental, yet typically intangible benefits of requirements prioritization strategies. Our simulation is directly based on detailed empirical studies of agile and plan-based requirements management studies. Our simulation shows, as many have claimed, that an agile strategy excels when requirements are highly volatile, whereas a plan-based strategy excels when requirements are stable, and that there exist mixed strategies that are better than either for typical development efforts.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08simrequire.pdf\}},
author = {Port, Dan and Olkov, Alexy and Menzies, Tim},
booktitle = {ASE 2008 - 23rd IEEE/ACM International Conference on Automated Software Engineering, Proceedings},
doi = {10.1109/ASE.2008.37},
isbn = {9781424421886},
issn = {1527-1366},
keywords = {Agile,Plan-based,Requirements,Simulation},
pages = {268--277},
title = {{Using simulation to investigate requirements prioritization strategies}},
year = {2008}
}
@inproceedings{me08f,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ispa.pdf\}},
author = {Hihn, J and Menzies, T and Lum, K and Baker, D and Jalali, O},
booktitle = {ISPA'08: International Society of Parametric Analysis},
title = {{\{2CEE\}, A \{T\}WENTY \{F\}IRST \{C\}ENTURY \{E\}FFORT \{E\}STIMATION \{M\}ETHODOLOGY}},
year = {2008}
}
@misc{menz85,
annote = {School of Econometrics, University of New England},
author = {Menzies, G D},
title = {{An Econometric Analysis of the Dark Figure of Crime}},
year = {1985}
}
@article{Du2008,
abstract = {Principal component analysis (PCA) is an effective tool for spectral decorrelation of hyperspectral imagery, and PCAbased spectral transforms have been employed successfully in conjunction with JPEG2000 for hyperspectral image compression. However, the computational cost of determining the data-dependent PCA transform is high because of its traditional eigendecomposition implementation which requires calculation of a covariance matrix across the data. Several strategies for reducing the computation burden of PCA are explored, including both spatial and spectral subsampling in the covariance calculation as well as an iterative algorithm that circumvents determination of the covariance matrix entirely. Experimental results investigate the impacts of such low-complexity PCA on JPEG2000 compression of hyperspectral images, focusing on rate-distortion performance as well as data-analysis performance at an anomaly-detection task.},
author = {Du, Q. and Fowler, J. E.},
doi = {10.1177/1094342007088380},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Du, Fowler - 2008 - Low-Complexity Principal Component Analysis for Hyperspectral Image Compression.pdf:pdf},
issn = {1094-3420},
journal = {International Journal of High Performance Computing Applications},
month = nov,
number = {4},
pages = {438--448},
title = {{Low-Complexity Principal Component Analysis for Hyperspectral Image Compression}},
volume = {22},
year = {2008}
}
@misc{mills13,
annote = {From $\backslash$url\{http://www.tech-pundit.com/wp-content/uploads/2013/07/Cloud\_Begins\_With\_Coal.pdf?c761ac\}},
author = {Mills, Mark},
month = aug,
title = {{Big Data, Big Networks, Big Infrastructure, and Big Power}},
year = {2013}
}
@book{fayol1916,
author = {Henri, Fayol},
publisher = {H. Dunod et E. Pinat, Paris, OCLC 40204128},
title = {{Administration industrielle et g\'{e}n\'{e}rale: pr\'{e}voyance, organisation, commandement, coordination, controle.}},
year = {1918}
}
@article{Rhinehart2012a,
abstract = {A novel optimization technique is introduced and demonstrated. Leapfrogging starts with a randomly located set of trial solutions (termed players) within the feasible decision variable (DV) space. At each iteration, the player with the worst objective function (OF) value is relocated to a random position within its DV-space reflection on the other side of the player with the best OF value. Test cases reveal that this simple algorithm has benefits over classic direct and gradient-based methods and particle swarm in speed of finding the optimum and in handling surface aberrations, including ridges, multi-optima, and stochastic objective functions. Potential limitations and analysis opportunities are discussed. ?? 2012 Elsevier Ltd.},
author = {Rhinehart, R. Russell and Su, Ming and Manimegalai-Sridhar, Upasana},
doi = {10.1016/j.compchemeng.2012.02.011},
file = {:Users/timm/svns/doc/12leapfrog.pdf:pdf},
issn = {00981354},
journal = {Computers and Chemical Engineering},
keywords = {Constraints,Direct search,Individuals,Nonlinear,Optimization,Stochastic},
pages = {67--81},
publisher = {Elsevier Ltd},
title = {{Leapfrogging and synoptic Leapfrogging: A new optimization approach}},
url = {http://dx.doi.org/10.1016/j.compchemeng.2012.02.011},
volume = {40},
year = {2012}
}
@article{andrews10,
author = {Andrews, James H and Menzies, Tim and Li, Felix C H},
journal = {IEEE Transactions on Software Engineering},
month = mar,
number = {1},
pages = {1--33},
title = {{Controlling Randomized Unit Testing With Genetic Algorithms}},
volume = {1},
year = {2001}
}
@inproceedings{MENZIES2005,
address = {New York, NY, USA},
author = {Menzies, Tim and Port, Dan and Chen, Zhihao and Hihn, Jairus},
booktitle = {ACM SIGSOFT Software Engineering Notes},
doi = {10.1145/1082983.1083170},
isbn = {-159593-125-2},
issn = {01635948},
number = {4},
pages = {1},
publisher = {ACM},
title = {{Simple software cost analysis}},
volume = {30},
year = {2005}
}
@article{me11a,
abstract = {Background: Despite decades of research, there is no consensus on which software effort estimation methods produce the most accurate models. Aim: Prior work has reported that, givenM estimation methods, no single method consistently outperforms all others. Perhaps rather than recommending one estimation method as best, it is wiser to generate estimates from ensembles of multiple estimation methods. Method: Nine learners were combined with 10 preprocessing options to generate 9î10 Â¼ 90 solo methods. These were applied to 20 datasets and evaluated using seven error measures. This identified the best n (in our case n Â¼ 13) solo methods that showed stable performance across multiple datasets and error measures. The top 2, 4, 8, and 13 solo methods were then combined to generate 12 multimethods, which were then compared to the solo methods. Results: 1) The top 10 (out of 12) multimethods significantly outperformed all 90 solo methods. 2) The error rates of the multimethods were significantly less than the solo methods. 3) The ranking of the best multimethod was remarkably stable. Conclusion: While there is no best single effort estimation method, there exist best combinations of such effort estimation methods.},
author = {Kocaguneli, Ekrem and Menzies, Tim and Keung, Jacky W.},
doi = {10.1109/TSE.2011.111},
file = {:Users/timm/svns/doc/cost/11comba.pdf:pdf},
isbn = {978-1-4577-2203-5},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Software cost estimation,analogy,ensemble,k-NN,machine learning,neural nets,regression trees,support vector machines},
number = {6},
pages = {1403--1416},
title = {{On the value of ensemble effort estimation}},
volume = {38},
year = {2012}
}
@inproceedings{me02n,
abstract = { Adaptive systems are systems whose function evolves while adapting to current environmental conditions, Due to the real-time adaptation, newly learned data have a significant impact on system behavior When online adaptation is included in system control, anomalies could cause abrupt loss of system functionality and possibly result in a failure. In this paper we present a framework for reasoning about the online adaptation problem. We describe a machine learning tool that sniffs data and detects anomalies before they are passed to the adaptive components for learning. Anomaly detection is based on distance computation. An algorithm for framework evaluation as well as sample implementation and empirical results are discussed. The method we propose is simple and reasonably effective, thus it can be easily adopted for testing.},
author = {Liu, Yan Liu Yan and Menzies, T. and Cukic, B.},
booktitle = {14th IEEE International Conference on Tools with Artificial Intelligence, 2002. (ICTAI 2002). Proceedings.},
doi = {10.1109/TAI.2002.1180783},
isbn = {0-7695-1849-4},
issn = {1082-3409},
title = {{Data sniffing - monitoring of machine learning for online adaptive systems}},
year = {2002}
}
@inproceedings{me96j,
author = {Menzies, T and Ramakrishnan, S},
booktitle = {Tools Pacific, Melbourne},
title = {{Comparing and Generalising Models for Metrics Repositories}},
year = {1996}
}
@inproceedings{Kocaguneli2009a,
author = {Kocaguneli, Ekrem and Kultur, Y. and a.B. Bener},
booktitle = {Issre '09},
file = {:Users/timm/svns/doc/ekrem09a.pdf:pdf},
title = {{Combining Multiple Learners Induced on Multiple Datasets for Software Effort Prediction}},
url = {http://www.issre2009.org/papers/issre2009\_245.pdf},
year = {2009}
}
@inproceedings{palma12,
abstract = {Software maintenance can become monotonous and expensive due to ignorance and misapplication of appropriate design patterns during the early phases of design and development. To have a good and reusable system, designers and developers must be aware of large information set and many quality concerns, e.g., design patterns. Systems with correct design pattern may ensure easy maintenance and evolution. However, without assistance, designing and development of software systems following certain design patterns is difficult for engineers. Recommendation systems for software engineering can assist designers and developers with a wide range of activities including suggesting design patterns. With the help of pattern recommenders, designers can come up with a reusable design. We provide a Design Pattern Recommender (DPR) process overview for software design to suggest design patterns, based on a simple Goal-Question-Metric (GQM) approach. Our prototype provides two-fold solution. In the primary-level, DPR only proposes one or more design patterns for a problem context, and in the secondary level, for a initial set of design, DPR refactors models and suggests design patterns. Our preliminary evaluation shows that DPR has a good trade-off between accuracy and procedural complexity, comparing to other state-of-the-art approaches. Â© 2012 IEEE.},
author = {Palma, Francis and Farzin, Hadi and Gu\'{e}h\'{e}neuc, Yann Ga\"{e}l and Moha, Naouel},
booktitle = {2012 3rd International Workshop on Recommendation Systems for Software Engineering, RSSE 2012 - Proceedings},
doi = {10.1109/RSSE.2012.6233399},
isbn = {9781467317597},
keywords = {Design pattern,Recommendation system,Software reuse},
pages = {1--5},
title = {{Recommendation system for design patterns in software development: An DPR overview}},
year = {2012}
}
@inproceedings{Scanniello2011,
abstract = {One of the most common comprehension activities undertaken by developers is concept location in source code. In the context of software change, concept location means finding locations in source code where changes are to be made in response to a modification request. Static techniques for concept location usually rely on searching the source code using textual information or on navigating the dependencies among software elements. In this paper we propose a novel static concept location technique, which leverages both the textual information present in the code and the structural dependencies between source code elements. The technique employs a textual search in that source code, which is clustered using the Border Flow algorithm, based on combining both structural and textual data. We evaluated the technique against a text search based baseline approach using data on almost 200 changes from five software systems. The results indicate that the new approach outperforms the baseline and that improvements are still possible.},
address = {Kingston, ON},
annote = {Laura. Fixed on 09/24/2012},
author = {Scanniello, Giuseppe and Marcus, Andrian},
booktitle = {IEEE International Conference on Program Comprehension},
doi = {10.1109/ICPC.2011.13},
isbn = {9780769543987},
issn = {1063-6897},
keywords = {Clustering,Concept Location,Lexical Analysis},
pages = {1--10},
title = {{Clustering support for static concept location in source code}},
year = {2011}
}
@inproceedings{keung2008c,
abstract = {We developed a novel method called Analogy-X to provide statistical inference procedures for analogy- based software effort estimation. Analogy-X is a method to statistically evaluate the relationship between useful project features and target features such as effort to be estimated, which ensures the dataset used is relevant to the prediction problem, and project features are selected based on their statistical contribution to the target variables. We hypothesize that this method can be (1) easily applied to a much larger dataset, and (2) also it can be used for incorporating joint effort and duration estimation into analogy, which was not previously possible with conventional analogy estimation. To test these two hypotheses, we conducted two experiments using different datasets. Our results show that Analogy-X is able to deal with ultra large datasets effectively and provides useful statistics to assess the quality of the dataset. In addition, our results show that feature selection for duration estimation differs from feature selection for joint-effort duration estimation. We conclude Analogy-X allows users to assess the best procedure for estimating duration given their specific requirements and dataset.},
address = {Washington, DC, USA},
author = {Keung, Jacky and Kitchenham, Barbara},
booktitle = {Proceedings of the Australian Software Engineering Conference, ASWEC},
doi = {10.1109/ASWEC.2008.4483211},
isbn = {0769531008},
issn = {1530-0803},
keywords = {Analogy,Analogy-X,Case-based reasoning,Duration prediction,ISBSG,Mantel's correlation,Software effort prediction},
pages = {229--238},
publisher = {IEEE Computer Society},
title = {{Experiments with analogy-X for software cost estimation}},
year = {2008}
}
@article{Devnani-Chulani1998a,
abstract = {This paper describes the calibration process$\backslash$nincorporated and summarizes the results obtained. The$\backslash$nEarly Design Model calibration is obtained by$\backslash$naggregating the calibrated Effort Multipliers of the$\backslash$nPost-Architecture Model as described in [USC-CSE1]. The$\backslash$nScale Factor calibration is the same in both the$\backslash$nmodels. The Applications Composition Model has not yet$\backslash$nbeen calibrated due to limitations in the availability$\backslash$nof project data. This paper describes our experience$\backslash$nand results of the first calibration of the$\backslash$nPostArchitecture model. The model determination process$\backslash$nbegan with an expert Delphi process to determine$\backslash$napriori values for the PostArchitecture model$\backslash$nparameters. A dataset of 83 projects was used in the$\backslash$nmultiple regression analysis. Projects with missing$\backslash$ndata or unexplainable anomalies were dropped. Model$\backslash$nparameters that exhibited high correlation were$\backslash$nconsolidated. Multiple regression analysis was used to$\backslash$nproduce coefficients. These coefficients were used to$\backslash$nadjust the previously assigned expertdetermined model$\backslash$nvalues. Stratification was used to improve model$\backslash$naccuracy. The resulting model produced estimates within$\backslash$n30\% of the actuals 52\% of the time for effort.$\backslash$nStratification by organization resulted in a model that$\backslash$nproduced estimates within 30\% of the actuals 64\% of the$\backslash$ntime for effort. It is therefore recommended that$\backslash$norganizations using the model calibrate it using their$\backslash$nown data. This increases model accuracy and produces a$\backslash$nlocal optimum estimate for similar type projects.$\backslash$nSection 2 of this paper describes the data used for$\backslash$ncalibration. Section 3 describes the calibration$\backslash$nprocedures, results, and future calibration strategy.},
author = {Devnani-Chulani, Sunita and Clark, Brad and Boehm, Barry and Steece, Bert},
file = {:Users/timm/svns/doc/cost/98Sunitaispapres.pdf:pdf},
journal = {Proceedings of the 20th},
title = {{Calibration approach and results of the COCOMO II postâarchitecture model}},
url = {http://sunset.usc.edu/Research\_Group/Sunita/down/ispadoc.pdf},
year = {1998}
}
@misc{me09g,
abstract = {Solutions to non-linear requirements engineering problems may be "brittle"; i.e. small changes may dramatically alter solution effectiveness. Hence, it is not enough to just generate solutions to requirements problems- we must also assess solution robustness. The KEYS2 algorithm can generate decision ordering diagrams. Once generated, these diagrams can assess solution robustness in linear time. In experiments with real-world requirements engineering models, we show that KEYS2 can generate decision ordering diagrams in O(N             2). When assessed in terms of terms of (a) reducing inference times, (b) increasing solution quality, and (c) decreasing the variance of the generated solution, KEYS2 out-performs other search algorithms (simulated annealing, ASTAR, MaxWalkSat).},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09keys2.pdf\}},
author = {Gay, Gregory and Menzies, Tim and Jalali, Omid and Mundy, Gregory and Gilkerson, Beau and Feather, Martin and Kiper, James},
booktitle = {Automated Software Engineering},
doi = {10.1007/s10515-009-0059-7},
isbn = {1051500900597},
issn = {09288910},
number = {1},
pages = {87--116},
title = {{Finding robust solutions in requirements models}},
volume = {17},
year = {2010}
}
@article{me12d,
author = {Menzies, Tim and Butcher, Andrew and Cok, David},
doi = {http://dx.doi.org/10.1109/TSE.2012.83},
journal = {Software Engineering, IEEE Transactions on},
number = {6},
pages = {822 -- 834},
title = {{Local versus Global Lessons for Defect Prediction and Effort Estimation}},
volume = {39},
year = {2013}
}
@article{me02k,
abstract = { For original paper see ibid., p. 474. This is a clear example of how research in software engineering can progress when empirical methods are applied. Menzies and Di Stefano apply a number of data mining tools to the data set. While, inmost cases, their results are in agreement with ours, in some cases they are not. Our first and main observation is that our interpretation of the data set is based not only on the data set itself but also on the knowledge gathered during the interviews with project members. The main problem with the data set is its size: 23 data points. Although this data set is the largest one available about reuse projects, it is too limited to base analysis only on data mining techniques; data mining is usually applied to data sets with thousands if not millions of data points.},
author = {Morisio, Maurizio and Ezran, Michel and Tully, Colin},
doi = {10.1109/TSE.2003.1199077},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
month = may,
number = {5},
pages = {478},
title = {{Comments on "more success and failure factors in software reuse"}},
volume = {29},
year = {2003}
}
@inproceedings{sayyad13a,
author = {Sayyad, Abdel Salam and Menzies, Tim and Ammar, Hany},
booktitle = {Proceedings of the 2013 International Conference on Software Engineering (ICSE '13)},
doi = {http://dx.doi.org/10.1109/ICSE.2013.6606595},
file = {:Users/timm/svns/doc/13ibea.pdf:pdf},
isbn = {9781467330749},
pages = {492--501},
series = {ICSE '13},
title = {{On the Value of User Preferences in Search-Based Software Engineering: A Case Study in Software Product Lines}},
year = {2013}
}
@article{Patrikainen2004a,
author = {Patrikainen, a. and Mannila, H.},
file = {:Users/timm/svns/doc/erin/references/BinarySparseClustering/Patrikainen04.pdf:pdf},
journal = {\ldots on Clustering High Dimensional Data and its \ldots},
pages = {57--65},
title = {{Subspace clustering of high-dimensional binary data-a probabilistic approach}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.3002\&rep=rep1\&type=pdf},
year = {2004}
}
@inproceedings{jureczko10,
abstract = {Background: This paper describes an analysisthat was conducted on newly collected repository with 92 versions of 38 proprietary, open-source and academic projects. A preliminary perfomed before showed the need for a further in-depth analysis study in order to identify project clusters. Aims: The goal of this research is to perform clustering on software projects in order to identify groups of software projects with similar characteristic from the defect prediction point of view. One defect prediction model should work well for all projects that belong to such group. The existence of those groups was investigated with statistical tests and by comparing the mean value of prediction efficiency. Method: Hierarchical and k-means clustering, as well obtained clusters were investigated with as Kohonenâs neural network was used to find groups of similar projects. The the discriminant analysis. For each of the identified group a statistical analysis has been conducted in order to distinguish whether this group really exists. Two defect prediction models were created for each of the identified groups. The first one was based on the projects that belong to a given group, and the second one - on all the projects. Then, both models were applied to all versions of projects from the investigated group. If the predictions from the model based on projects that belong to the identified group are significantly better than the all-projects model (the mean values were compared and statistical tests were used), we conclude that the group really exists. Results: Six different clusters were identified and the existence of two of them was statistically proven: 1) cluster proprietary B â T=19, p=0.035, r=0.40; 2) cluster proprietary/open â t(17)=3.18, p=0.05, r=0.59. The obtained effect sizes (r) represent large effects according to Cohenâs benchmark, which is a substantial finding. Conclusions: The two identified clusters were described and compared with results obtained by other researchers. The results of this work makes next step towards defining formal methods of reuse defect prediction models by identifying groups of projects within which the same defect prediction model may be used. Furthermore, a method of clustering was suggested and applied.},
author = {Jureczko, Marian and Madeyski, Lech},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering - PROMISE '10},
doi = {10.1145/1868328.1868342},
isbn = {9781450304047},
keywords = {clustering,defect prediction,design metrics,size metrics},
pages = {1},
publisher = {ACM},
series = {PROMISE '10},
title = {{Towards identifying software project clusters with regard to defect prediction}},
url = {http://portal.acm.org/citation.cfm?doid=1868328.1868342},
year = {2010}
}
@inproceedings{turhan08,
abstract = {Several research in defect prediction focus on building models with available local data (i.e. within company predictors). To employ these models, a company should have a data repository, where project metrics and defect information from past projects are stored. However, few companies apply this practice. In a recent work, we have shown that cross company data can be used for building predictors with the cost of increased false alarms. Thus, we argued that the practical application of cross-company predictors is limited to mission critical projects and companies should starve for local data. In this paper, we show that nearest neighbor (NN) sampling of cross-company data removes the increased false alarm rates. We conclude that cross company defect predictors can be practical tools with NN sampling, yet local predictors are still the best and companies should keep starving for local data. Copyright 2008 ACM.},
annote = {hW},
author = {Turhan, B and Bener, a and Menzies, T},
booktitle = {DEFECTS'08: 2008 International Symposium on Software Testing and Analysis - Proceedings of the 2008 Workshop on Defects in Large Software Systems 2008, DEFECTS'08},
doi = {10.1145/1390817.1390824},
isbn = {9781605580517 (ISBN)},
keywords = {Alarm systems,Building models,Computer software,Computer software selection and evaluation,Data repositories,Defect predictions,Defects,Errors,False Alarm rates,False alarms,Local datums,Mission critical,Nearest neighbors,Project metrics,Software testing,Technical presentations},
pages = {26},
title = {{Nearest neighbor sampling for cross company defect predictors (Abstract only)}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-57349150689\&partnerID=40\&md5=49e517a851134cb3ea7c5addee82d5e6},
year = {2008}
}
@article{me00d,
author = {Menzies, Tim and Cukic, Bojan},
doi = {10.1142/S0218213000000112},
issn = {0218-2130},
journal = {International Journal on Artificial Intelligence Tools},
month = jun,
number = {01},
pages = {153--172},
title = {{Adequacy of Limited Testing for Knowledge Based Systems}},
volume = {09},
year = {2000}
}
@inproceedings{me92m,
author = {Mahidadia, a J and Compton, P and Menzies, T J and Sammut, C and Smythe, G a},
booktitle = {AI '92, Horbart, Australia},
publisher = {World-Scientific},
title = {{Inventing Causal Qualitative Models: A Tool for Experimental Research}},
year = {1992}
}
@inproceedings{me12c,
annote = {Available from http://menzies.us/pdf/12idea.pdf},
author = {Borges, Raymond and Menzies, Tim},
booktitle = {Proceedings of the 8th International Conference on Predictive Models in Software Engineering - PROMISE '12},
doi = {10.1145/2365324.2365328},
isbn = {9781450312417},
keywords = {effort estimation,optimization},
pages = {11--18},
title = {{Learning to change projects}},
url = {http://dl.acm.org/citation.cfm?doid=2365324.2365328},
year = {2012}
}
@inproceedings{me01a,
author = {Menzies, Tim},
booktitle = {AAAI Stanford Spring Symposium on Model-based Validation of AI Systems},
pages = {0--5},
title = {{Average Case Coverage for Validation of AI Systems}},
year = {1995}
}
@article{me07b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06learnPredict.pdf\}},
author = {{Menzies T, Greenwald J}, FrankA},
journal = {IEEE Software},
month = jan,
title = {{Datamining static code attributes to learn defect predictors}},
year = {2007}
}
@inproceedings{hindle12,
author = {Hindle, A},
booktitle = {Proceedings, MSR'12},
title = {{Green Mining: A Methodology of Relating Software Change to Power Consumption}},
year = {2012}
}
@article{Dv2007a,
author = {Dv, Vroxwlrqv and Lqlwldo, D Q and Dqg, Srlqw and Rwkhuv, W K H and Jxlglqj, D V and Lpsohphqwdwlrq, Vrsklvwlfdwhg and Wkh, R I and Lq, Dssurdfk and Wkh, Idfw and Lq, Ryhudoo and Dqg, Klvwru and Qrw, Grhv and Wudfn, Nhhs and Wr, Hvvhqwldo and Wkh, Hqulfklqj and Lqwhooljhqfh, Vzdup and Gr, R Z},
file = {:Users/timm/svns/doc/pso/07psoScatter.pdf:pdf},
isbn = {1424413400},
journal = {Evolutionary Computation},
pages = {2289--2296},
title = {{6Fdwwhu 362 Â± \$ 0Ruh (Iihfwlyh )Rup Ri 3Duwlfoh 6Zdup 2Swlpl]Dwlrq}},
year = {2007}
}
@article{Jain2009,
author = {Jain, Anil K and Lansing, East},
file = {:Users/timm/svns/doc/50yearsofKmeans.pdf:pdf},
title = {{Jain, Lansing - 2009 - Data Clustering 50 Years Beyond K-Means 1 Anil K . Jain Michigan State University}},
year = {2009}
}
@inproceedings{Marcus2010b,
abstract = {Software systems are designed and engineered to process data. However, software is data too. The size and variety of today's software artifacts and the multitude of stakeholder activities result in so much data that individuals can no longer reason about all of it. We argue in this position paper that data mining, statistical analysis, machine learning, information retrieval, data integration, etc., are necessary solutions to deal with software data. New research is needed to adapt existing algorithms and tools for software engineering data and processes, and new ones will have to be created.
In order for this type of research to succeed, it should be supported with new approaches to empirical work, where data and results are shared globally among researchers and practitioners. Software engineering researchers can get inspired by other fields, such as, bioinformatics, where results of mining and analyzing biological data are often stored in databases shared across the world.},
address = {Santa Fe, NM},
annote = {Laura. Fixed on 10/01/2012},
author = {Marcus, Andrian and Menzies, Timothy},
booktitle = {Proceedings of the FSE/SDP workshop on Future of software engineering research - FoSER '10},
doi = {10.1145/1882362.1882410},
isbn = {9781450304276},
keywords = {data\_mining machine\_learning information\_retrieval},
pages = {229},
title = {{Software is data too}},
url = {http://portal.acm.org/citation.cfm?doid=1882362.1882410},
year = {2010}
}
@article{Harper2004a,
abstract = {In this paper we introduce a quantitative model that relates chemical structural similarity to biological activity, and in particular to the activity of lead series of compounds in high-throughput assays. From this model we derive the optimal screening collection make up for a given fixed size of screening collection, and identify the conditions under which a diverse collection of compounds or a collection focusing on particular regions of chemical space are appropriate strategies. We derive from the model a diversity function that may be used to assess compounds for acquisition or libraries for combinatorial synthesis by their ability to complement an existing screening collection. The diversity function is linked directly through the model to the goal of more frequent discovery of lead series from high-throughput screening. We show how the model may also be used to derive relationships between collection size and probabilities of lead discovery in high-throughput screening, and to guide the judicious application of structural filters.},
author = {Harper, G and Pickett, S D and Green, D V S},
doi = {10.2174/138620704772884832},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/HarperPickett04.pdf:pdf},
isbn = {1386-2073},
issn = {13862073},
journal = {Combinatorial chemistry \& high throughput screening},
keywords = {design of experiments,high throughput screening,library design,mathematical,optimization,statistical design},
number = {1},
pages = {63--70},
pmid = {14965262},
title = {{Design of a compound screening collection for use in high throughput screening.}},
volume = {7},
year = {2004}
}
@inproceedings{waugh97,
annote = {$\backslash$url\{http://www.cse.unsw.edu.au/\~{}timm/pub/docs\}},
author = {Waugh, S and Menzies, T J and Goss, S},
booktitle = {Advanced Topics in Artificial Intelligence: 10th Australian Joint Conference on AI},
editor = {Sattar, Abdul},
isbn = {3-540-63797-4},
publisher = {Springer-Verlag},
title = {{Evaluating a Qualitative Reasoner}},
year = {1997}
}
@article{mittas13,
abstract = {Software Cost Estimation can be described as the process of predicting the most realistic effort required to complete a software project. Due to the strong relationship of accurate effort estimations with many crucial project management activities, the research community has been focused on the development and application of a vast variety of methods and models trying to improve the estimation procedure. From the diversity of methods emerged the need for comparisons to determine the best model. However, the inconsistent results brought to light significant doubts and uncertainty about the appropriateness of the comparison process in experimental studies. Overall, there exist several potential sources of bias that have to be considered in order to reinforce the confidence of experiments. In this paper, we propose a statistical framework based on a multiple comparisons algorithm in order to rank several cost estimation models, identifying those which have significant differences in accuracy, and clustering them in nonoverlapping groups. The proposed framework is applied in a large-scale setup of comparing 11 prediction models over six datasets. The results illustrate the benefits and the significant information obtained through the systematic comparison of alternative methods.},
author = {Mittas, Nikolaos and Angelis, Lefteris},
doi = {10.1109/TSE.2012.45},
file = {:Users/timm/svns/doc/cost/13Mittas.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Cost estimation,management,metrics/measurement,statistical methods},
number = {4},
pages = {537--551},
title = {{Ranking and clustering software cost estimation models through a multiple comparisons algorithm}},
volume = {39},
year = {2013}
}
@article{Clark1998a,
abstract = {The COCOMO II model was created to meet the need for a cost model
that accounted for future software development practices. This paper
describes some of the experiences learned in calibrating COCOMO II
Post-Architecture model from eighty-three observations. The results of
the multiple regression analysis, their implications, and a future
calibration strategy are discussed},
author = {Clark, B. and Devnani-Chulani, S. and Boehm, B.},
doi = {10.1109/ICSE.1998.671610},
file = {:Users/timm/svns/doc/cost/98Sunita.pdf:pdf},
isbn = {0-8186-8368-6},
issn = {0270-5257},
journal = {Proceedings of the 20th International Conference on Software Engineering},
keywords = {cocomo ii,cost estimation,metrics,multiple regression},
title = {{Calibrating the COCOMO II Post-Architecture model}},
year = {1998}
}
@article{hall11,
abstract = {Background: The accurate prediction of where faults are likely to occur in code can help direct test effort, reduce costs and improve the quality of software. Objective: We investigate how the context of models, the independent variables used and the modelling techniques applied, influence the performance of fault prediction models. Method:We used a systematic literature review to identify 208 fault prediction studies published from January 2000 to December 2010. We synthesise the quantitative and qualitative results of 36 studies which report sufficient contextual and methodological information according to the criteria we develop and apply. Results: The models that perform well tend to be based on simple modelling techniques such as Na\"{\i}ve Bayes or Logistic Regression. Combinations of independent variables have been used by models that perform well. Feature selection has been applied to these combinations when models are performing particularly well. Conclusion: The methodology used to build models seems to be influential to predictive performance. Although there are a set of fault prediction studies in which confidence is possible, more studies are needed that use a reliable methodology and which report their context, methodology and performance comprehensively.},
author = {Hall, Tracy and Beecham, Sarah and Bowes, David and Gray, David and Counsell, Steve},
doi = {10.1109/TSE.2011.103},
isbn = {9781612081656},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
number = {PrePrints},
title = {{A Systematic Review of Fault Prediction Performance in Software Engineering}},
year = {2011}
}
@inproceedings{marcus10,
author = {Marcus, Andrian and Menzies, Timothy},
booktitle = {Proceedings of the FSE/SDP workshop on Future of software engineering research - FoSER '10},
doi = {10.1145/1882362.1882410},
isbn = {9781450304276},
month = nov,
pages = {229},
title = {{Software is data too}},
url = {http://portal.acm.org/citation.cfm?doid=1882362.1882410},
year = {2010}
}
@article{smith1988,
abstract = {The combined influences of boundary effects at large scales and nonzero nearest neighbor separations at small scales are used to compute intrinsic limits on the minimum size of a data set required for calculation of scaling exponents. A lower bound on the number of points required for a reliable estimation of the correlation exponent is given in terms of the dimension of the object and the desired accuracy. A method of estimating the correlation integral computed from a finite sample of a white noise signal is given.},
author = {Smith, Leonard a},
doi = {10.1016/0375-9601(88)90445-8},
isbn = {0375-9601},
issn = {03759601},
journal = {Physics Letters A},
number = {6},
pages = {283--288},
publisher = {Elsevier},
title = {{Intrinsic limits on dimension calculations}},
volume = {133},
year = {1988}
}
@article{Yang2001a,
author = {Yang, Cheng and Fayyad, Usama and Bradley, Paul S.},
doi = {10.1145/502512.502539},
file = {:Users/timm/svns/doc/erin/references/BinarySparseClustering/Yang01.pdf:pdf},
isbn = {158113391X},
journal = {Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '01},
keywords = {based on relaxing the,clustering,collaborative filtering,error-tolerant frequent itemset,exact,high dimensions,query,selectivity estimation,the frequent itemset generalization},
pages = {194--203},
title = {{Efficient discovery of error-tolerant frequent itemsets in high dimensions}},
url = {http://portal.acm.org/citation.cfm?doid=502512.502539},
year = {2001}
}
@misc{me09g,
abstract = {Solutions to non-linear requirements engineering problems may be "brittle"; i.e. small changes may dramatically alter solution effectiveness. Hence, it is not enough to just generate solutions to requirements problems- we must also assess solution robustness. The KEYS2 algorithm can generate decision ordering diagrams. Once generated, these diagrams can assess solution robustness in linear time. In experiments with real-world requirements engineering models, we show that KEYS2 can generate decision ordering diagrams in O(N             2). When assessed in terms of terms of (a) reducing inference times, (b) increasing solution quality, and (c) decreasing the variance of the generated solution, KEYS2 out-performs other search algorithms (simulated annealing, ASTAR, MaxWalkSat).},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09keys2.pdf\}},
author = {Gay, Gregory and Menzies, Tim and Jalali, Omid and Mundy, Gregory and Gilkerson, Beau and Feather, Martin and Kiper, James},
booktitle = {Automated Software Engineering},
doi = {10.1007/s10515-009-0059-7},
isbn = {1051500900597},
issn = {09288910},
number = {1},
pages = {87--116},
title = {{Finding robust solutions in requirements models}},
volume = {17},
year = {2010}
}
@article{me99j,
author = {Menzies, Tim},
doi = {10.1006/ijhc.1999.0329},
issn = {10715819},
journal = {International journal of human-computer studies},
month = oct,
number = {4},
pages = {783--799},
title = {{Critical success metrics: evaluation at the business level}},
url = {http://www.sciencedirect.com/science/article/pii/S1071581999903294},
volume = {51},
year = {1999}
}
@inproceedings{me02n,
abstract = { Adaptive systems are systems whose function evolves while adapting to current environmental conditions, Due to the real-time adaptation, newly learned data have a significant impact on system behavior When online adaptation is included in system control, anomalies could cause abrupt loss of system functionality and possibly result in a failure. In this paper we present a framework for reasoning about the online adaptation problem. We describe a machine learning tool that sniffs data and detects anomalies before they are passed to the adaptive components for learning. Anomaly detection is based on distance computation. An algorithm for framework evaluation as well as sample implementation and empirical results are discussed. The method we propose is simple and reasonably effective, thus it can be easily adopted for testing.},
author = {Liu, Yan Liu Yan and Menzies, T. and Cukic, B.},
booktitle = {14th IEEE International Conference on Tools with Artificial Intelligence, 2002. (ICTAI 2002). Proceedings.},
doi = {10.1109/TAI.2002.1180783},
isbn = {0-7695-1849-4},
issn = {1082-3409},
title = {{Data sniffing - monitoring of machine learning for online adaptive systems}},
year = {2002}
}
@inproceedings{hame93,
author = {Haynes, P and Menzies, T J},
booktitle = {Tools Pacific 1993},
organization = {Prentice Hall},
pages = {75--82},
title = {{C++ is \{B\}etter than \{S\}malltalk?}},
year = {1993}
}
@inproceedings{jalali08,
abstract = {Recent work with NASA's Jet Propulsion Laboratory has allowed for external access to five of JPL's real-world requirements models, anonymized to conceal proprietary information, but retaining their computational nature. Experimentation with these models, reported herein, demonstrates a dramatic speedup in the computations performed on them. These models have a well defined goal: select mitigations that retire risks which, in turn, increases the number of attainable requirements. Such a non-linear optimization is a well-studied problem. However identification of not only (a) the optimal solution(s) but also (b) the key factors leading to them is less well studied. Our technique, called KEYS, shows a rapid way of simultaneously identifying the solutions and their key factors. KEYS improves on prior work by several orders of magnitude. Prior experiments with simulated annealing or treatment learning took tens of minutes to hours to terminate. KEYS runs much faster than that; e.g for one model, KEYS ran 13,000 times faster than treatment learning (40 minutes versus 0.18 seconds). Processing these JPL models is a non-linear optimization problem: the fewest mitigations must be selected while achieving the most requirements. Non-linear optimization is a well studied problem. With this paper, we challenge other members of the PROMISE community to improve on our results with other techniques.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08keys.pdf\}},
author = {Jalali, Omid and Menzies, Tim and Feather, Martin},
booktitle = {Proceedings of the PROMISE 2008 Workshop (ICSE)},
doi = {10.1145/1370788.1370807},
isbn = {9781605580364},
issn = {02705257},
title = {{Optimizing Requirements Decisions with KEYS}},
year = {2008}
}
@article{raffo05b,
abstract = {In this paper, we present a 'forward-looking' decision support framework that integrates up-to-date metrics data with simulation models of the software development process in order to support the software project management control function. This forward-looking approach (called the PROMPT method) provides predictions of project performance and the impact of various management decisions. Tradeoffs among performance measures are accomplished using outcome based control limits (OBCLs) and are augmented using multi-criteria utility functions and financial measures of performance to evaluate various process alternatives. The decision support framework enables the program manager to plan, manage and track current software development activities in the short term and to take corrective action as necessary to bring the project back on track. The model provides insight on potential performance impacts of the proposed corrective actions. A real world example utilizing a software process simulation model is presented. ?? 2005 Elsevier B.V. All rights reserved.},
author = {Raffo, David M.},
doi = {10.1016/j.infsof.2005.09.004},
isbn = {0950-5849},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Control limits,Multi-criteria decision making,Project management,Simulation,Software measurement repositories,Software process modeling},
month = dec,
number = {15},
pages = {1009--1017},
title = {{Software project management using PROMPT: A hybrid metrics, modeling and utility framework}},
volume = {47},
year = {2005}
}
@misc{krill01,
author = {Krill, Paul},
month = oct,
title = {{Data quality issues plague CRM}},
year = {2001}
}
@article{jorgensen05a,
author = {Jorgensen, M},
journal = {IEEE Software},
number = {3},
title = {{Practical Guidelines for Expert Judgment Based-Software-Effort Estimation}},
volume = {22},
year = {2005}
}
@inproceedings{zhang10,
abstract = {BACKGROUND: Defect predictors learned from static code measures can isolate code modules with a higher than usual probability of defects. AIMS: To improve those learners by focusing on the defect-rich portions of the training sets. METHOD: Defect data CM1, KC1, MC1, PC1, PC3 was separated into components. A subset of the projects (selected at random) were set aside for testing. Training sets were generated for a NaiveBayes classifier in two ways. In sample the dense treatment, the components with higher than the median number of defective modules were used for training. In the standard treatment, modules from any component were used for training. Both samples were run against the test set and evaluated using recall, probability of false alarm, and precision. In addition, under sampling and over sampling was performed on the defect data. Each method was repeated in a 10-by-10 cross-validation experiment. RESULTS: Prediction models learned from defect dense components out-performed standard method, under sampling, as well as over sampling. In statistical rankings based on recall, probability of false alarm, and precision, models learned from dense components won 4-5 times more often than any other method, and also lost the least amount of times. CONCLUSIONS: Given training data where most of the defects exist in small numbers of components, better defect predictors can be trained from the defect dense components.},
author = {Zhang, Hongyu and Nelson, Adam and Menzies, Tim},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering - PROMISE '10},
doi = {10.1145/1868328.1868350},
isbn = {9781450304047},
keywords = {ceiling ef-,defect dense components,defect prediction,sampling},
pages = {1},
title = {{On the value of learning from defect dense components for software defect prediction}},
url = {http://portal.acm.org/citation.cfm?doid=1868328.1868350},
year = {2010}
}
@inproceedings{me00r,
author = {Menzies, T and Easterbrook, S and Nuseibeh, B and Waugh, S},
booktitle = {Submitted for journal review},
title = {{Validating Inconsistent Requirements Models using Graph-based Abduction}},
year = {2001}
}
@article{mkaouer:tosem15,
author = {{Wiem Mkaouer, Marouane Kessentini,; Slim Bechikh, Kalyanmoy Deb}, Ali Ouni and \'{U}\^{u}, \'{O}},
journal = {ACM Trans. Softw. Eng. Methodol.},
title = {{Many-Objective Software Remodularization using NSGA-III}},
volume = {to appear},
year = {2015}
}
@inproceedings{me03k,
abstract = { Traditional methods of generating quality code indicators (e.g. linear regression, decision tree induction) can be demonstrated to be inappropriate for IV\&amp;V purposes. IV\&amp;V is a unique aspect of the software lifecycle, and different methods are necessary to produce quick and accurate results. If quality code indicators could be produced on a per-project basis, then IV\&amp;V could proceed in a more straight-forward fashion, saving time and money. We present one case study on just such a project, showing that by using the proper metrics and machine learning algorithms, quality indicators can be found as early as 3 months into the IV\&amp;V process.},
author = {Menzies, T. and Stefano, J.S. Di and Chapman, M.},
booktitle = {Proceedings. 5th International Workshop on Enterprise Networking and Computing in Healthcare Industry (IEEE Cat. No.03EX717)},
doi = {10.1109/METRIC.2003.1232458},
isbn = {0-7695-1987-3},
issn = {1530-1435},
title = {{Learning early lifecycle IV \&amp;amp; V quality indicators}},
year = {2003}
}
@book{Subramaniama,
author = {Subramaniam, Venkat},
booktitle = {October},
file = {:Users/timm/svns/doc/Seven Languages in Seven Weeks A Pragmatic Guide to Learning Programming Languages.pdf:pdf},
isbn = {9781934356593},
title = {{What Readers Are Saying About Seven Languages in Seven Weeks}}
}
@article{Deb2005a,
abstract = {Since the suggestion of a computing procedure of multiple Pareto-optimal solutions in multi-objective optimization problems in the early Nineties, researchers have been on the look out for a procedure which is computationally fast and simultaneously capable of finding a well-converged and well-distributed set of solutions. Most multi-objective evolutionary algorithms (MOEAs) developed in the past decade are either good for achieving a well-distributed solutions at the expense of a large computational effort or computationally fast at the expense of achieving a not-so-good distribution of solutions. For example, although the Strength Pareto Evolutionary Algorithm or SPEA (Zitzler and Thiele, 1999) produces a much better distribution compared to the elitist non-dominated sorting GA or NSGA-II (Deb et al., 2002a), the computational time needed to run SPEA is much greater. In this paper, we evaluate a recently-proposed steady-state MOEA (Deb et al., 2003) which was developed based on the epsilon-dominance concept introduced earlier(Laumanns et al., 2002) and using efficient parent and archive update strategies for achieving a well-distributed and well-converged set of solutions quickly. Based on an extensive comparative study with four other state-of-the-art MOEAs on a number of two, three, and four objective test problems, it is observed that the steady-state MOEA is a good compromise in terms of convergence near to the Pareto-optimal front, diversity of solutions, and computational time. Moreover, the epsilon-MOEA is a step closer towards making MOEAs pragmatic, particularly allowing a decision-maker to control the achievable accuracy in the obtained Pareto-optimal solutions.},
author = {Deb, Kalyanmoy and Mohan, Manikanth and Mishra, Shikhar},
doi = {10.1162/106365605774666895},
file = {:Users/timm/svns/doc/05epsilonMoea.pdf:pdf},
isbn = {1063-6560},
issn = {1063-6560},
journal = {Evolutionary computation},
keywords = {-dominance,computational effort,convergence measure,evolutionary algorithms,genetic algorithms,hyper-volume metric,measure,multi-objective optimization,optimal solutions,pareto-,sparsity},
number = {4},
pages = {501--525},
pmid = {16297281},
title = {{Evaluating the epsilon-domination based multi-objective evolutionary algorithm for a quick computation of Pareto-optimal solutions.}},
volume = {13},
year = {2005}
}
@article{Verhein2008a,
author = {Verhein, Florian},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/FPGrowth.pdf:pdf},
journal = {Read},
title = {{Frequent Pattern Growth ( FP-Growth ) Algorithm An Introduction Outline Introduction FP-Tree data structure Step 1 : FP-Tree Construction Step 2 : Frequent Itemset Generation Discussion Introduction uses a generate-and-test approach generates candidate it}},
year = {2008}
}
@inproceedings{turhan10,
author = {Turhan, Burak and Bener, Ayse and Menzies, Tim},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-13792-1\_11},
isbn = {3642137911},
issn = {03029743},
keywords = {Code metrics,Cross-company,Defect prediction,Software quality},
pages = {116--130},
title = {{Regularities in learning defect predictors}},
volume = {6156 LNCS},
year = {2010}
}
@article{Minku2012a,
author = {Minku, Ll and Yao, Xin},
file = {:Users/timm/svns/doc/transfer/12minku.pdf:pdf},
isbn = {9781450312417},
journal = {\ldots Conference on Predictive Models in Software \ldots},
keywords = {bles of learning machines,chronological split,concept drift,cross-company estimation mod-,els,ensem-,online learning,software effort estimation},
title = {{Can cross-company data improve performance in software effort estimation?}},
url = {http://dl.acm.org/citation.cfm?id=2365334},
year = {2012}
}
@incollection{fea03a,
abstract = { We present an approach to matching software practitioners' needs to software researchers' activities. It uses an accepted taxonomical software classification scheme as intermediary, in terms of which practitioners express needs, and researchers express activities. A decision support tool is used to combine these expressions of needs/activities, and to assist in studying the implications of that combined knowledge. This enables identification of fruitful connections between researchers and practitioners, of areas of common interest among researchers, and practitioners, and of "gaps": areas of unfulfilled needs or unmotivated research. We discuss the software engineering underpinning this approach, illustrating its utility by reporting on experiments with a real-world dataset gathered from researchers and practitioners. We also suggest that this same approach would be applicable to understanding the distribution of interests represented by presenters and attendees of a conference such as APSEC.},
author = {Feather, M.S. and Menzies, T. and Connelly, J.R.},
booktitle = {Tenth Asia-Pacific Software Engineering Conference, 2003.},
doi = {10.1109/APSEC.2003.1254353},
isbn = {0-7695-2011-1},
month = dec,
title = {{Matching software practitioner needs to researcher activities}},
year = {2003}
}
@inproceedings{clancey96a,
abstract = {A continuing problem in business today is the design of humanÃcomputer systems that$\backslash$nrespect how work actually gets done. The overarching context of work consists of$\backslash$nactivities, which people conceive as ways of organizing their daily life and especially their$\backslash$ninteractions with each other. Activities include reading mail, going to workshops,$\backslash$nmeeting with colleagues over lunch, answering phone calls, and so on. Brahms is$\backslash$na multiagent simulation tool for modeling the activities of groups in diÂ¤erent locations$\backslash$nand the physical environment consisting of objects and documents, including especially$\backslash$ncomputer systems. A Brahms model of work practice reveals circumstantial, interactional$\backslash$nin\ss uences on how work actually gets done, especially how people involve each other in$\backslash$ntheir work. In particular, a model of practice reveals how people accomplish a collaboration$\backslash$nthrough multiple and alternative means of communication, such as meetings,$\backslash$ncomputer tools, and written documents. Choices of what and how to communicate are$\backslash$ndependent upon social beliefs and behaviorsÃwhat people know about each other\~{O}s$\backslash$nactivities, intentions, and capabilities and their understanding of the norms of the group.$\backslash$nAs a result, Brahms models can help humanÃcomputer system designers to understand$\backslash$nhow tasks and information actually \ss ow between people and machines, what work is$\backslash$nrequired to synchronize individual contributions, and how tools hinder or help this$\backslash$nprocess. In particular, work\ss ow diagrams generated by Brahms are the emergent product$\backslash$nof local interactions between agents and representational artifacts, not pre-ordained,$\backslash$nend-to-end paths built in by a modeler. We developed Brahms as a tool to support the$\backslash$ndesign of work by illuminating how formal \ss ow descriptions relate to the social systems$\backslash$nof work; we accomplish this by incorporating multiple viewsÃrelating people, information,$\backslash$nsystems, and geographyÃin one tool. Applications of Brahms could also include$\backslash$nsystem requirements analysis, instruction, implementing software agents, and a workbench$\backslash$nfor relating cognitive and social theories of human behavior.},
author = {Clancey, Wj and Sachs, P},
booktitle = {Int. J. HumanâComputer Studies},
doi = {10.1006/ijhc.1998.0229},
editor = {Compton, P and Mizoguchi, R and Motoda, H and Menzies, Tim},
isbn = {1071-5819},
issn = {10715819},
pages = {831--865},
publisher = {Department of Artificial Intelligence},
title = {{Brahms: Simulating practice for work systems design}},
url = {http://www.sciencedirect.com/science/article/pii/S1071581998902294},
volume = {49},
year = {1998}
}
@article{me07d,
abstract = {Although there are times when random search is dangerous and should be avoided, software analysis should start with random methods because they are so cheap, moving to the more complex methods only when random methods fail},
annote = {$\backslash$url\{http://menzies.us/pdf/07strange.pdf\}},
author = {Menzies, Tim and Owen, David and Richardson, Julian},
doi = {10.1109/MC.2007.37},
issn = {00189162},
journal = {Computer},
keywords = {Artificial intelligence,Data mining,LURCH,Software engineering,TAR3},
number = {1},
pages = {54--60},
title = {{The strangest thing about software}},
volume = {40},
year = {2007}
}
@article{Kamvar2003a,
abstract = {We present a simple, easily implemented spectral learning algorithm which applies equally whether we have no supervisory information, pairwise link constraints, or labeled examples. In the unsupervised case, it performs consistently with other spectral clustering algorithms. In the supervised case, our approach achieves high accuracy on the categorization of thousands of documents given only a few dozen labeled training documents for the 20 Newsgroups data set. Furthermore, its classification accuracy increases with the addition of unlabeled documents, demonstrating effective use of unlabeled data. By using normalized affinity matrices which are both symmetric and stochastic, we also obtain both a probabilistic interpretation of our method and certain guarantees of performance.},
author = {Kamvar, Sepandar D. and Klein, Dan and Manning, Christopher D.},
doi = {10.1.1.13.6919},
file = {:Users/timm/svns/doc/08spectralLearning.pdf:pdf},
isbn = {9789533070100},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {561--566},
title = {{Spectral learning}},
year = {2003}
}
@article{Bavota2012a,
abstract = {Changes during software evolution and poor design decisions often lead to packages that are hard to understand and maintain, because they usually group together classes with unrelated responsibilities. One way to improve such packages is to decompose them into smaller, more cohesive packages. The difficulty lies in the fact that most definitions and interpretations of cohesion are rather vague and the multitude of measures proposed by researchers usually capture only one aspect of cohesion. We propose a new technique for automatic re-modularization of packages, which uses structural and semantic measures to decompose a package into smaller, more cohesive ones. The paper presents the new approach as well as an empirical study, which evaluates the decompositions proposed by the new technique. The results of the evaluation indicate that the decomposed packages have better cohesion without a deterioration of coupling and the re-modularizations proposed by the tool are also meaningful from a functional point of view.},
annote = {Laura. Fixed on 10/16/2012},
author = {Bavota, Gabriele and {De Lucia}, Andrea and Marcus, Andrian and Oliveto, Rocco},
doi = {10.1007/s10664-012-9226-8},
isbn = {1066401292},
issn = {13823256},
journal = {Empirical Software Engineering},
keywords = {Conceptual coupling between classes,Empirical studies,Information-flow-based coupling,Software re-modularization},
number = {5},
pages = {901--932},
title = {{Using structural and semantic measures to improve software modularization}},
volume = {18},
year = {2013}
}
@inproceedings{Bavota2010,
abstract = {The structure of a software system has a major impact on its maintainability. To improve maintainability, software systems are usually organized into subsystems using the constructs of packages or modules. However, during software evolution the structure of the system undergoes continuous modifications, drifting away from its original design, often reducing its quality. In this paper we propose an approach for helping maintainers to improve the quality of software modularization. The proposed approach analyzes the (structural and semantic) relationships between classes in a package identifying chains of strongly related classes. The identified chains are used to define new packages with higher cohesion than the original package. The proposed approach has been empirical evaluated through a case study. The context of the study is represented by an open source system, JHotDraw, and two software systems developed by teams of students at the University of Salerno. The analysis of the results reveals that the proposed approach generates meaningful re-modularization of the studied systems, which can lead to higher quality.},
address = {Beverly, MA, USA},
annote = {Laura. Fixed on 06/16/2012},
author = {Bavota, Gabriele and {De Lucia}, Andrea and Marcus, Andrian and Oliveto, Rocco},
booktitle = {Proceedings - Working Conference on Reverse Engineering, WCRE},
doi = {10.1109/WCRE.2010.29},
isbn = {9780769541235},
issn = {10951350},
keywords = {Conceptual coupling between classes,Empirical studies,Information-flow-based coupling,Software re-modularization},
pages = {195--204},
title = {{Software re-modularization based on structural and semantic metrics}},
year = {2010}
}
@misc{me01c,
author = {Bonnett, Alastair},
isbn = {0130193240, 9780130193247},
pages = {116},
title = {{How to argue}},
year = {2001}
}
@inproceedings{me03n,
author = {Menzies, T and Kiper, J and Feather, M},
booktitle = {SEDECS'2003: the 2nd International Workshop on Software Engineering Decision Support (part of SEKE2003)},
month = jun,
title = {{Improved software engineering decision support through automatic argument reduction tools}},
year = {2003}
}
@inproceedings{me99a,
abstract = {Multiple viewpoints are often used in requirements engineering to
facilitate traceability to stakeholders, to structure the requirements
process, and to provide richer modelling by incorporating multiple
conflicting descriptions. In the latter case, the need to reason with
inconsistent models introduces considerable extra complexity. We
describe an empirical study of the utility of multiple world reasoning
(using abduction) for domain modelling. In the study we used a range of
different models (ranging from correct to very incorrect), different
fanouts, different amounts of data available from the domain, and
different modelling primitives for representing time. In the experiments
there was no significant change in the expressive power of models that
incorporate multiple conflicting viewpoints. Whilst this does not negate
the advantages of viewpoints during requirements elicitation it does
suggest some limits to the utility of viewpoints during requirements
modelling},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/99re.pdf\}},
author = {Menzies, T. and Easterbrook, S. and Nuseibeh, B. and Waugh, S.},
booktitle = {Proceedings IEEE International Symposium on Requirements Engineering (Cat. No.PR00188)},
doi = {10.1109/ISRE.1999.777990},
isbn = {0-7695-0188-5},
issn = {1090-705X},
title = {{An empirical investigation of multiple viewpoint reasoning in
requirements engineering}},
year = {1999}
}
@article{Heemstra1992a,
abstract = {This paper reports the results of an empirical investigation of the relationships between effort expended, time scales, and project size for software project development. The observed relationships were compared with those predicted by Lawrence Putnam's Rayleigh curve model and Barry Boehm's COCOMO model. The results suggested that although the form of the basic empirical relationships were consistent with the cost models, the COCOMO model was a poor estimator of cost for the current data set and the data did not follow the Rayleigh curve suggested by Putnam. However, the results did suggest that it was possible to develop cost models tailored to a particular environment and to improve the precision of the models as they are used during the development cycle by including additional information such as the known effort for the early development phases. The paper finishes by discussing some of the problems involved in developing useful cost models.},
author = {Heemstra, F.J.},
doi = {10.1016/0950-5849(92)90068-Z},
file = {:Users/timm/svns/doc/cost/02Jplhandbook.pdf:pdf},
isbn = {0818620781},
issn = {09505849},
journal = {Information and Software Technology},
number = {10},
pages = {627--639},
title = {{Software cost estimation}},
volume = {34},
year = {1992}
}
@article{eveleens10,
abstract = {This paper presents the chaos report figures that are often used to indicate problems in application software development project management, the reports contain major flaws.},
author = {Eveleens, Johan Laurenz and Verhoef, Chris},
doi = {10.1109/MS.2009.154},
isbn = {0740-7459},
issn = {07407459},
journal = {IEEE Software},
keywords = {Chaos report,Forecasting,Project success,Software,Software engineering,Standish group},
month = jan,
number = {1},
pages = {30--36},
publisher = {IEEE Computer Society Press},
title = {{The rise and fall of the Chaos report figures}},
volume = {27},
year = {2010}
}
@article{Dy2004b,
author = {Dy, J G and Brodley, C E},
doi = {10.1016/j.patrec.2014.11.006},
file = {:Users/timm/svns/doc/04dyUnsupervisedDiscretization.pdf:pdf},
isbn = {1532-4435},
issn = {01678655},
journal = {The Journal of Machine Learning Research},
keywords = {clustering,expectation-maximization,feature selection,unsupervised learning},
pages = {845--889},
title = {{Feature selection for unsupervised learning}},
volume = {5},
year = {2004}
}
@inproceedings{zheng14z,
author = {Zheng, Pengfei and Zhou, Yangfan and Lyu, Michael R. and Qi, Yong},
booktitle = {2014 IEEE International Conference on Services Computing},
doi = {10.1109/SCC.2014.76},
isbn = {978-1-4799-5066-9},
month = jun,
pages = {528--535},
title = {{Granger Causality-Aware Prediction and Diagnosis of Software Degradation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6930576},
year = {2014}
}
@article{Li2005a,
abstract = {Clustering is the problem of identifying the distribution of patterns and intrinsic correlations in large data sets by partitioning the data points into similarity classes. This paper studies the problem of clustering binary data. This is the case for market basket datasets where the transactions contain items and for document datasets where the documents contain âbag of wordsâ. The contribution of the paper is three-fold. First a general binary data clustering model is presented. The model treats the data and features equally, based on their symmetric association relations, and explicitly describes the data assignments as well as feature assignments. We character- ize several variations with different optimization procedures for the general model. Second, we also establish the connections between our clustering model with other existing clustering methods. Third, we also discuss the problem for determining the number of clusters for binary clustering. Experimental results show the effectiveness of the proposed clustering model.},
author = {Li, Tao},
doi = {10.1145/1081870.1081894},
file = {:Users/timm/svns/doc/erin/references/BinarySparseClustering/li05.pdf:pdf},
isbn = {159593135X},
issn = {159593135X},
journal = {Proceeding of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining - KDD '05},
keywords = {binary data,clustering,general model,matrix approximation},
pages = {188},
title = {{A general model for clustering binary data}},
url = {http://portal.acm.org/citation.cfm?doid=1081870.1081894},
year = {2005}
}
@inproceedings{me04h,
abstract = { COCONUT calibrates effort estimation models using an exhaustive search over the space of calibration parameters in a Cocomo I model. This technique is much simpler than other effort estimation method yet yields PRED levels comparable to those other methods. Also, it does so with less project data and fewer attributes (no scale factors). However, a comparison between COCONUT and other methods is complicated by differences in the experimental methods used for effort estimation. A review of those experimental methods concludes that software effort estimation models should be calibrated to local data using incremental holdout (not jack knife) studies, combined with randomization and hypothesis testing, repeated a statistically significant number of times.},
author = {Menzies, T. and Port, D. and Chen, Zhihao Chen Zhihao and Hihn, J.},
booktitle = {Proceedings. 27th International Conference on Software Engineering, 2005. ICSE 2005.},
doi = {10.1109/ICSE.2005.1553605},
isbn = {1-59593-963-2},
title = {{Validation methods for calibrating software effort models}},
year = {2005}
}
@inproceedings{me06f,
annote = {Available from $\backslash$url\{http://menzies.us/06deviations.pdf\}},
author = {Menies, T and Lum, K and Hihn, J},
booktitle = {Promise 2006},
pages = {1--5},
title = {{The Deviance Problem in Effort Estimation}},
year = {2006}
}
@inproceedings{hame94,
author = {Haynes, P and Menzies, T J},
booktitle = {Tools '94},
pages = {121--129},
publisher = {Prentice Hall},
title = {{The \{E\}ffects of \{C\}lass \{C\}oupling on \{C\}lass \{S\}ize in \{S\}malltalk \{S\}ystems}},
year = {1994}
}
@inproceedings{rich97za,
author = {Richards, D and Menzies, T J},
booktitle = {Third Australian Knowledge Acquisition Workshop, Perth},
editor = {Menzies, T J and Richards, D and Compton, P},
title = {{Extending Knowledge Engineering to Requirements Engineering from Multiple Perspectives}},
year = {1997}
}
@inproceedings{turhan10,
author = {Turhan, Burak and Bener, Ayse and Menzies, Tim},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-13792-1\_11},
isbn = {3642137911},
issn = {03029743},
keywords = {Code metrics,Cross-company,Defect prediction,Software quality},
pages = {116--130},
title = {{Regularities in learning defect predictors}},
volume = {6156 LNCS},
year = {2010}
}
@inproceedings{waugh98,
author = {Waugh, S and Blogs, J and Menzies, T},
booktitle = {Proceedings of the Australain AI '98 conference},
title = {{The Temporal Qualitative Compartmental Modeling Language}},
year = {1998}
}
@inproceedings{petersen09,
abstract = {In order to draw valid conclusions when aggregating evidence it is important to describe the context in which industrial studies were conducted. This paper structures the context for empirical industrial studies and provides a checklist. The aim is to aid researchers in making informed decisions concerning which parts of the context to include in the descriptions. Furthermore, descriptions of industrial studies were surveyed.},
author = {Petersen, Kai and Wohlin, Claes},
booktitle = {2009 3rd International Symposium on Empirical Software Engineering and Measurement, ESEM 2009},
doi = {10.1109/ESEM.2009.5316010},
isbn = {9781424448418},
issn = {1938-6451},
pages = {401--404},
title = {{Context in industrial software engineering research}},
year = {2009}
}
@inproceedings{me03m,
author = {Menzies, Tim and Ammar, Kareem},
booktitle = {Tech report, Computer Science, Portland State University},
keywords = {artificial intelligence,defect detectors,empirical studies and metrics,fault models,feature subset selection,learning,metrics,nents analysis,principal compo-,product metrics,software testing and verification},
pages = {1--28},
title = {{How Simple is Software Defect Detection ?}},
year = {2003}
}
@article{vandebrug86,
author = {de Brug, A Van and Bachant, J and McDermott, J},
journal = {IEEE Expert},
pages = {33--39},
title = {{The \{T\}aming of \{R1\}}},
year = {1986}
}
@article{couto14,
author = {Couto, C and Valente, M T and Pires, P and Hora, A and Anquetil, N and Bigonha, R},
journal = {Journal of Software Engineering Research and Development},
title = {{BugMaps-Granger: a tool for visualizing and predicting bugs using Granger causality tests}},
volume = {2},
year = {1024}
}
@inproceedings{me06f,
author = {Menies, T and Lum, K and Hihn, J},
booktitle = {Promise 2006},
pages = {1--5},
title = {{The Deviance Problem in Effort Estimation}},
year = {2006}
}
@article{Bouveyron2007a,
abstract = {Clustering in high-dimensional spaces is a difficult problem which is recurrent in many domains, for example in image analysis. The difficulty is due to the fact that high-dimensional data usually exist in different low-dimensional subspaces hidden in the original space. A family of Gaussian mixture models designed for high-dimensional data which combine the ideas of subspace clustering and parsimonious modeling are presented. These models give rise to a clustering method based on the expectation-maximization algorithm which is called high-dimensional data clustering (HDDC). In order to correctly fit the data, HDDC estimates the specific subspace and the intrinsic dimension of each group. Experiments on artificial and real data sets show that HDDC outperforms existing methods for clustering high-dimensional data. ?? 2007 Elsevier B.V. All rights reserved.},
author = {Bouveyron, C. and Girard, S. and Schmid, C.},
doi = {10.1016/j.csda.2007.02.009},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/Bouveyron07.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {Gaussian mixture models,High-dimensional data,Model-based clustering,Parsimonious models,Subspace clustering},
number = {1},
pages = {502--519},
title = {{High-dimensional data clustering}},
volume = {52},
year = {2007}
}
@article{Fowlkes2004a,
author = {Fowlkes, Charless and Belongie, Serge and Chung, Fan and Malik, Jitendra},
file = {:Users/timm/svns/doc/04SpectralNystromClustering.pdf:pdf},
journal = {Analysis},
number = {2},
pages = {214--225},
title = {{Â¨ m Method Spectral Grouping Using the Nystro}},
volume = {26},
year = {2004}
}
@article{Dasgupta2008b,
abstract = {Estrogen-related receptors (ERR), ERR alpha (ERR$\alpha$) and ERR gamma (ERR$\gamma$), are orphan nuclear receptors implicated in breast cancer that function similarly in the regulation of oxidative metabolism genes. Paradoxically, in clinical studies, high levels of ERR$\alpha$ are associated with poor outcomes whereas high levels of ERR$\gamma$ are associated with a favorable course. Recent studies suggest that ERR$\alpha$ may indeed promote breast tumor growth. The roles of ERR$\gamma$ in breast cancer progression and how ERR$\alpha$ and ERR$\gamma$ may differentially affect cancer growth are unclear. In mammary carcinoma cells that do not express endogenous ERR$\gamma$, we found that ectopic expression of ERR$\gamma$ enhanced oxidative metabolism in vitro and inhibited the growth of tumor xenografts in vivo. In contrast, ectopic expression of the ERR$\alpha$ coactivator PGC-1$\alpha$ enhanced oxidative metabolism but did not affect tumor growth. Notably, ERR$\gamma$ activated expression of a genetic program characteristic of mesenchymal-to-epithelial transition (MET). This program was apparent by changes in cellular morphology, upregulation of epithelial cell markers, downregulation of mesenchymal markers, and decreased cellular invasiveness. We determined that this program was also associated with upregulation of E-cadherin, which is activated directly by ERR$\gamma$. In contrast, PGC-1$\alpha$ activated only a subset of genes characteristic of the MET program and, unlike ERR$\gamma$, did not upregulate E-cadherin. In conclusion, these results show that ERR$\gamma$ induces E-cadherin, promotes MET, and suppresses breast cancer growth. Our findings suggest that ERR$\gamma$ agonists may have applications in the treatment of breast cancer.},
author = {Dasgupta, Sanjoy and Freund, Yoav},
doi = {10.1145/1374376.1374452},
file = {:Users/timm/svns/doc/08rptrees.pdf:pdf},
isbn = {9781605580470},
issn = {15387445},
journal = {Proceedings of the fourtieth annual ACM symposium on Theory of computing STOC 08},
number = {1},
pages = {537},
pmid = {21339306},
title = {{Random projection trees and low dimensional manifolds}},
url = {http://portal.acm.org/citation.cfm?doid=1374376.1374452},
volume = {6},
year = {2008}
}
@inproceedings{gel03a,
abstract = { Model-based software has become quite popular in recent years, making its way into a broad range of areas, including the aerospace industry. The models provide an easy graphical interface to develop systems, which can generate the sometimes tedious code that follows. While there are many tools available to assess standard procedural code, there are limits to the testing of model-based systems. A major problem with the models are that their internals often contain gray areas of unknown system behavior. These possible behaviors form what is known as a data cloud, which is an overwhelming range of possibilities of a system that can overload analysts (Menzies et al., 2003). With large data clouds, it is hard to demonstrate which particular decision leads to a particular outcome. Even if definite decisions can't be made, it is possible to reduce the variance of and condense the clouds (Menzies et al., 2003). This paper presents two case studies; one with a simple illustrative model and another with a more complex application. The TAR3 treatment learning tool summarizes the particular attribute ranges that selects for particular behaviors of interest, reducing the data clouds.},
author = {Geletko, D. and Menzies, T.},
booktitle = {28th Annual NASA Goddard Software Engineering Workshop, 2003. Proceedings.},
doi = {10.1109/SEW.2003.1270729},
isbn = {0-7695-2064-2},
title = {{Model-based software testing via incremental treatment learning}},
year = {2003}
}
@incollection{me10b,
author = {Menzies, Tim and Shull, Forrest},
booktitle = {Making Software: What really works, and why we believe it},
editor = {Oram, A and G.Wilson},
pages = {3--11},
publisher = {O'Reilly Books},
title = {{The Quest for Convincing Evidence}},
year = {2010}
}
@article{me08i,
annote = {Avialable from $\backslash$url\{http://menzies.us/pdf/08promised.pdf\}},
author = {Menzies, Tim},
doi = {10.1007/s10664-008-9087-3},
issn = {13823256},
journal = {Empirical Software Engineering},
month = oct,
number = {5},
pages = {469--471},
title = {{Editorial, special issue, repeatable experiments in software engineering}},
volume = {13},
year = {2008}
}
@misc{me98a,
author = {Menzies, T and Waugh, S and Goss, S},
howpublished = {Submitted to ECAI '98},
title = {{Taming Chatter with Relevant Envisionments}},
year = {1998}
}
@article{me06e,
annote = {Available on-line at $\backslash$url\{http://menzies.us/pdf/06costs.pdf\}},
author = {Menzies, T and Hihn, J},
journal = {IEEE Software},
title = {{Evidence-Based Cost Estimation for Better Quality Software}},
year = {2006}
}
@article{Garvey1995a,
author = {Garvey, Paul R.},
doi = {10.1080/08823871.1995.10462296},
file = {:Users/timm/svns/doc/cost/95Garvey.pdf:pdf},
issn = {0882-3871},
journal = {The Journal of Cost Analysis},
number = {1},
pages = {156--200},
title = {{Garvey: A Family of Joint Probability Models for Cost and Schedule Uncertainties}},
volume = {12},
year = {1995}
}
@article{Azuaje2003a,
abstract = {This article focuses on clustering techniques for the analysis of microarray data and discusses contributions and applications for the implementation of intelligent diagnostic systems and therapy design studies. Approaches to validating and visualising expression clustering results and software and other relevant resources to support clustering-based analyses are reviewed. Finally, this paper addresses current limitations and problems that need to be investigated for the development of an advanced generation of pattern discovery tools.},
author = {Azuaje, Francisco},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/Azuaje02.pdf:pdf},
isbn = {1467-5463 (Print)},
issn = {1467-5463},
journal = {Briefings in bioinformatics},
keywords = {annotation and visualisation,cluster,clustering,expression data},
number = {1},
pages = {31--42},
pmid = {12715832},
title = {{Clustering-based approaches to discovering and visualising microarray data patterns.}},
volume = {4},
year = {2003}
}
@inproceedings{me03c,
abstract = {To meet the needs of busy people who$\backslash$nonly want to know enough to achieve$\backslash$nthe most benefits, the TAR2 treatment$\backslash$nlearner generates easy-to-read and$\backslash$nimmediately useful data mining rules.},
author = {Menzies, Tim and Menzies, Tim and Hu, Ying and Hu, Ying},
booktitle = {IEEE Computer Society},
month = nov,
title = {{Data Mining for$\backslash$nVery Busy People}},
year = {2003}
}
@article{court93,
abstract = {Many software measures have been forwarded on the simple basis of a high linear correlation coefficient with some measurable quantities. The linear correlation coefficient is an unreliable statistic for deciding whether an observed correlation indicates significant association. Several published software measure experiments collected more than 20 different measurements, or have 14 or fewer observations. With considerable data from small samples, the probabilit of `discovering' a `significant' correlation is high. The authors present a computer simulation experiment where the correlation between sets of randomly generated numbers is calculated. They also look at randomly generated numbers in the ranges that would be expected in Halstead's software science measures. The results show that the average maximum linear correlation for randomly generated numbers is 0.70 or higher if the sample size is low compared to the number of variables. Alternative statistical approaches to obtaining meaningful significant results are presented},
author = {Courtney, Richard E. and Gustafson, David a.},
doi = {10.1049/sej.1993.0002},
issn = {02686961},
journal = {Software Engineering Journal},
month = jan,
number = {1},
pages = {5},
title = {{Shotgun correlations in software measures}},
volume = {8},
year = {1993}
}
@inproceedings{koc13b,
author = {Kocaguneli, Ekrem and Cukic, Bojan and Menzies, Tim and Lu, Huihua},
booktitle = {PROMSE'13},
month = oct,
title = {{Building a Second Opinion: Learning Cross-Company Data}},
year = {2013}
}
@article{Moise2009a,
abstract = {Subspace and projected clustering have emerged as a possible solution to the challenges associated with clustering in high-dimensional data. Numerous subspace and projected clustering techniques have been proposed in the literature. A comprehensive evaluation of their advantages and disadvantages is urgently needed. In this paper, we evaluate systematically state-of-the-art subspace and projected clustering techniques under a wide range of experimental settings. We discuss the observed performance of the compared techniques, and we make recommendations regarding what type of techniques are suitable for what kind of problems.},
author = {Moise, Gabriela and Zimek, Arthur and Kr\"{o}ger, Peer and Kriegel, Hans Peter and Sander, J\"{o}rg},
doi = {10.1007/s10115-009-0226-y},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/moise09.pdf:pdf},
issn = {02191377},
journal = {Knowledge and Information Systems},
keywords = {Projected clustering,Subspace clustering},
number = {3},
pages = {299--326},
title = {{Subspace and projected clustering: Experimental evaluation and analysis}},
volume = {21},
year = {2009}
}
@article{me97j,
author = {Menzies, Tim},
doi = {10.1002/(SICI)1097-024X(199712)27:12<1457::AID-SPE140>3.3.CO;2-0},
issn = {00380644},
journal = {Software: Practice and Experience},
keywords = {knowledge-level modelling,oo patterns expert systems},
month = dec,
number = {12},
pages = {1457--1478},
title = {{Objectâoriented patterns: lessons from expert systems}},
url = {http://doi.wiley.com/10.1002/(SICI)1097-024X(199712)27:12<1457::AID-SPE140>3.3.CO;2-0},
volume = {27},
year = {1997}
}
@article{Hill1965,
author = {Hill, Austin Bradford},
journal = {Proceedings of the Royal Society of Medicine},
number = {5},
pages = {295--300},
title = {{The Environment and Disease: Association or Causation?}},
volume = {58},
year = {1965}
}
@inproceedings{me12b,
abstract = {Gaming companies now routinely apply data mining to their user data in order to plan the next release of their software. We predict that such software development analytics will become commonplace, in the near future. For example, as large software systems migrate to the cloud, they are divided and sold as dozens of smaller apps; when shopping inside the cloud, users are free to mix and match their apps from multiple vendors (e.g. Google Docs' word processor with Zoho's slide manager); to extend, or even retain, market share cloud vendors must mine their user data in order to understand what features best attract their clients. This panel will address the open issues with analytics. Issues addressed will include the following. What is the potential for software development analytics? What are the strengths and weaknesses of the current generation of analytics tools? How best can we mature those tools?},
author = {Menzies, Tim and Zimmermann, Thomas},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2012.6227117},
isbn = {9781467310673},
issn = {02705257},
keywords = {analytics,empirical software engineering,industry,mining software repositories},
pages = {1032--1033},
title = {{Goldfish bowl panel: Software development analytics}},
year = {2012}
}
@article{peters12a,
abstract = {Background: Cross-company defect prediction (CCDP) is a field of study where an organization lacking enough local data can use data from other organizations for building defect predictors. To support CCDP, data must be shared. Such shared data must be privatized, but that privatization could severely damage the utility of the data. Aim: To enable effective defect prediction from shared data while preserving privacy. Method: We explore privatization algorithms that maintain class boundaries in a dataset. CLIFF is an instance pruner that deletes irrelevant examples. MORPH is a data mutator that moves the data a random distance, taking care not to cross class boundaries. CLIFF+MORPH are tested in a CCDP study among 10 defect datasets from the PROMISE data repository. Results: We find: 1) The CLIFFed+MORPHed algorithms provide more privacy than the state-of-the-art privacy algorithms; 2) in terms of utility measured by defect prediction, we find that CLIFF+MORPH performs significantly better. Conclusions: For the OO defect data studied here, data can be privatized and shared without a significant degradation in utility. To the best of our knowledge, this is the first published result where privatization does not compromise defect prediction. [ABSTRACT FROM AUTHOR]},
author = {Peters, Fayola and Menzies, Tim and Gong, Liang and Zhang, Hongyu},
doi = {10.1109/TSE.2013.6},
isbn = {0098-5589 VO  - 39},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Privacy,classification,defect prediction},
month = aug,
number = {8},
pages = {1054--1068},
title = {{Balancing privacy and utility in cross-company defect prediction}},
volume = {39},
year = {2013}
}
@article{Fukunaga1986a,
author = {Fukunaga, Koichi and Hirose, Shin-ichi},
doi = {10.1145/960112.28719},
file = {:Users/timm/svns/doc/ooprolog/p224-fukunaga.pdf:pdf},
isbn = {0897912047},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
number = {11},
pages = {224--231},
title = {{An experience with a Prolog-based object-oriented language}},
volume = {21},
year = {1986}
}
@article{Prelic2006a,
abstract = {MOTIVATION: In recent years, there have been various efforts to overcome the limitations of standard clustering approaches for the analysis of gene expression data by grouping genes and samples simultaneously. The underlying concept, which is often referred to as biclustering, allows to identify sets of genes sharing compatible expression patterns across subsets of samples, and its usefulness has been demonstrated for different organisms and datasets. Several biclustering methods have been proposed in the literature; however, it is not clear how the different techniques compare with each other with respect to the biological relevance of the clusters as well as with other characteristics such as robustness and sensitivity to noise. Accordingly, no guidelines concerning the choice of the biclustering method are currently available. RESULTS: First, this paper provides a methodology for comparing and validating biclustering methods that includes a simple binary reference model. Although this model captures the essential features of most biclustering approaches, it is still simple enough to exactly determine all optimal groupings; to this end, we propose a fast divide-and-conquer algorithm (Bimax). Second, we evaluate the performance of five salient biclustering algorithms together with the reference model and a hierarchical clustering method on various synthetic and real datasets for Saccharomyces cerevisiae and Arabidopsis thaliana. The comparison reveals that (1) biclustering in general has advantages over a conventional hierarchical clustering approach, (2) there are considerable performance differences between the tested methods and (3) already the simple reference model delivers relevant patterns within all considered settings.},
author = {Preli\'{c}, Amela and Bleuler, Stefan and Zimmermann, Philip and Wille, Anja and B\"{u}hlmann, Peter and Gruissem, Wilhelm and Hennig, Lars and Thiele, Lothar and Zitzler, Eckart},
doi = {10.1093/bioinformatics/btl060},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/Prelic06.pdf:pdf},
isbn = {1460-2059},
issn = {13674803},
journal = {Bioinformatics},
number = {9},
pages = {1122--1129},
pmid = {16500941},
title = {{A systematic comparison and evaluation of biclustering methods for gene expression data}},
volume = {22},
year = {2006}
}
@article{Rosenwald2002a,
abstract = {A chance encounter between members of a random repertoire and a molecular target is characteristic of different biological systems, including the immune and olfactory pathways as well as combinatorial libraries. In such systems, the affinity between the target and members of the repertoire is distributed with a probability function describing the propensity of obtaining a particular affinity value. We have previously proposed a phenomenological receptor affinity distribution (RAD) formalism, which describes this probability function based on simple statistical considerations. In the present analysis, we use published data from diverse experimental systems, including phage display libraries, immunoglobulins and enzymes, to test the RAD model and to compare it to other affinity distribution formalisms. The RAD model is found to provide the best description for binding data for over eight orders of magnitude on the affinity scale, and to account for a relationship between repertoire size and the maximal obtainable affinity within different repertoires. This approach points to a potential universality of the rules that govern affinity distributions in biology.},
author = {Rosenwald, Shai and Kafri, Ran and Lancet, Doron},
doi = {10.1006/jtbi.2002.2538},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Rosenwald02.pdf:pdf},
isbn = {0022-5193 (Print)},
issn = {0022-5193},
journal = {Journal of theoretical biology},
number = {3},
pages = {327--336},
pmid = {12183121},
title = {{Test of a statistical model for molecular recognition in biological repertoires.}},
volume = {216},
year = {2002}
}
@inproceedings{levina04,
abstract = {We propose a new method for estimating intrinsic dimension of a dataset derived by applying the principle of maximum likelihood to the distances between close neighbors. We derive the estimator by a Poisson process approximation, assess its bias and variance theoretically and by simulations, and apply it to a number of simulated and real datasets. We also show it has the best overall performance compared with two other intrinsic dimension estimators.},
author = {Levina, E and Bickel, Pj},
booktitle = {Advances in neural information \ldots},
doi = {10.2307/2335172},
file = {:Users/timm/svns/doc/04intrinsicDimension.pdf:pdf},
isbn = {0262195348},
issn = {10495258},
pages = {777--784},
title = {{Maximum likelihood estimation of intrinsic dimension}},
url = {http://machinelearning.wustl.edu/mlpapers/paper\_files/NIPS2005\_94.pdf$\backslash$nhttp://www.inference.phy.cam.ac.uk/mackay/dimension/},
volume = {17},
year = {2004}
}
@inproceedings{me98f,
author = {Menzies, T J and Waugh, S},
booktitle = {Proceedings, Pacific Rim Conference on Artificial Intelligence, Singapore},
publisher = {Springer-Verlag},
title = {{On the Practicality of Viewpoint-based Requirements Engineering}},
year = {1998}
}
@incollection{me95g,
author = {Menzies, T J},
booktitle = {Proceedings of the Melbourne Workshop on Intelligent Decision Support},
publisher = {Department of Information Systems, Monash University, Melbourne},
title = {{Applications of Abduction: Intelligent Decision Support Systems}},
year = {1996}
}
@inproceedings{me96l,
author = {Ramakrishnan, S and Menzies, T and Hasslinger, M and Bok, P and Mccarthy, H and Devakadadcham, B and Moulder, D},
booktitle = {Proceedings of Tools-Pacific, Melbourne},
publisher = {Prentice-Hall},
title = {{On Building an Effective Measurement System for OO Software Process}},
year = {1996}
}
@article{koc11b,
abstract = {Background: There are too many design options for software effort estimators. How can we best explore them all? Aim: We seek aspects on general principles of effort estimation that can guide the design of effort estimators. Method: We identified the essential assumption of analogy-based effort estimation, i.e., the immediate neighbors of a project offer stable conclusions about that project. We test that assumption by generating a binary tree of clusters of effort data and comparing the variance of supertrees versus smaller subtrees. Results: For 10 data sets (from Coc81, Nasa93, Desharnais, Albrecht, ISBSG, and data from Turkish companies), we found: 1) The estimation variance of cluster subtrees is usually larger than that of cluster supertrees; 2) if analogy is restricted to the cluster trees with lower variance, then effort estimates have a significantly lower error (measured using MRE, AR, and Pred(25) with a Wilcoxon test, 95 percent confidence, compared to nearest neighbor methods that use neighborhoods of a fixed size). Conclusion: Estimation by analogy can be significantly improved by a dynamic selection of nearest neighbors, using only the project data from regions with small variance.},
author = {Kocaguneli, Ekrem and Menzies, Tim and Bener, Ayse Basar and Keung, Jacky W.},
doi = {10.1109/TSE.2011.27},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Software cost estimation,analogy,k-NN},
number = {2},
pages = {425--438},
title = {{Exploiting the essential assumptions of analogy-based effort estimation}},
volume = {38},
year = {2012}
}
@inproceedings{me04b,
author = {Menzies, T and Di\~{}Stefano, Justin S and Cunanan, Chris and Chapman, Robert (Mike)},
booktitle = {IEEE Transactions Software Engineering (in preperation)},
title = {{The Business Case for Defect Logging}},
year = {2004}
}
@article{me11f,
abstract = {Recent research has shown the value of social metrics for defect prediction. Yet many repositories lack the information required for a social analysis. So, what other means exist to infer how developers interact around their code? One option is static code metrics that have already demonstrated their usefulness in analyzing change in evolving software systems. But do they also help in defect prediction? To address this question we selected a set of static code metrics to determine what classes are most "active" (i.e., the classes where the developers spend much time interacting with each other's design and implementation decisions) in 33 open-source Java systems that lack details about individual developers. In particular, we assessed the merit of these activity-centric measures in the context of "inspection optimization" a technique that allows for reading the fewest lines of code in order to find the most defects. For the task of inspection optimization these activity measures perform as well as (usually, within 4\%) a theoretical upper bound on the performance of any set of measures. As a result, we argue that activity-centric static code metrics are an excellent predictor for defects. Â© 2012 World Scientific Publishing Company.},
author = {Lumpe, Markus and Vasa, Rajesh and Menzies, Tim and Rush, Rebecca and Turhan, Burak},
doi = {10.1142/S0218194012500179},
issn = {0218-1940},
journal = {International Journal of Software Engineering and Knowledge Engineering},
number = {05},
pages = {621--644},
title = {{Learning Better Inspection Optimization Policies}},
volume = {22},
year = {2012}
}
@article{Roulet2002a,
abstract = {The ability to determine the location and relative strength of all transcription-factor binding sites in a genome is important both for a comprehensive understanding of gene regulation and for effective promoter engineering in biotechnological applications. Here we present a bioinformatically driven experimental method to accurately define the DNA-binding sequence specificity of transcription factors. A generalized profile was used as a predictive quantitative model for binding sites, and its parameters were estimated from in vitro-selected ligands using standard hidden Markov model training algorithms. Computer simulations showed that several thousand low- to medium-affinity sequences are required to generate a profile of desired accuracy. To produce data on this scale, we applied high-throughput genomics methods to the biochemical problem addressed here. A method combining systematic evolution of ligands by exponential enrichment (SELEX) and serial analysis of gene expression (SAGE) protocols was coupled to an automated quality-controlled sequence extraction procedure based on Phred quality scores. This allowed the sequencing of a database of more than 10,000 potential DNA ligands for the CTF/NFI transcription factor. The resulting binding-site model defines the sequence specificity of this protein with a high degree of accuracy not achieved earlier and thereby makes it possible to identify previously unknown regulatory sequences in genomic DNA. A covariance analysis of the selected sites revealed non-independent base preferences at different nucleotide positions, providing insight into the binding mechanism.},
author = {Roulet, Emmanuelle and Busso, St\'{e}phane and Camargo, Anamaria a and Simpson, Andrew J G and Mermod, Nicolas and Bucher, Philipp},
doi = {10.1038/nbt718},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Roulet02.pdf:pdf},
isbn = {1087-0156},
issn = {1087-0156},
journal = {Nature biotechnology},
number = {8},
pages = {831--835},
pmid = {12101405},
title = {{High-throughput SELEX SAGE method for quantitative modeling of transcription-factor binding sites.}},
volume = {20},
year = {2002}
}
@article{Rashedi2009a,
abstract = {In recent years, various heuristic optimization methods have been developed. Many of these methods are inspired by swarm behaviors in nature. In this paper, a new optimization algorithm based on the law of gravity and mass interactions is introduced. In the proposed algorithm, the searcher agents are a collection of masses which interact with each other based on the Newtonian gravity and the laws of motion. The proposed method has been compared with some well-known heuristic search methods. The obtained results confirm the high performance of the proposed method in solving various nonlinear functions. ?? 2009 Elsevier Inc. All rights reserved.},
author = {Rashedi, Esmat and Nezamabadi-pour, Hossein and Saryazdi, Saeid},
doi = {10.1016/j.ins.2009.03.004},
file = {:Users/timm/svns/doc/pso/00psoVSgsaCluster.pdf:pdf},
isbn = {0020-0255},
issn = {00200255},
journal = {Information Sciences},
keywords = {Gravitational Search Algorithm,Heuristic search algorithms,Law of gravity,Optimization},
number = {13},
pages = {2232--2248},
publisher = {Elsevier Inc.},
title = {{GSA: A Gravitational Search Algorithm}},
url = {http://dx.doi.org/10.1016/j.ins.2009.03.004},
volume = {179},
year = {2009}
}
@article{Harman2009,
abstract = {In the past five years there has been a dramatic increase in work on Search Based Software Engineering (SBSE), an approach to software engineering in which search based optimisation algorithms are used to address problems in Software Engineering. SBSE has been applied to problems throughout the Software Engineering lifecycle, from requirements and project planning to maintenance and re-engineering. The approach is attractive because it offers a suite of adaptive automated and semi-automated solutions in situations typified by large complex problem spaces with multiple competing and conflicting objectives. This paper provides a review and classification of literature on SBSE. The paper identifies research trends and relationships between the techniques applied and the applications to which they have been applied and highlights gaps in the literature and avenues for further research.},
author = {Harman, M and Mansouri, Sa and Zhang, Y},
doi = {10.1016/S0950-5849(01)00189-6},
file = {:Users/timm/svns/doc/TR-09-03.pdf:pdf},
issn = {09505849},
journal = {Engineering},
pages = {1--78},
title = {{Search Based Software Engineering: A Comprehensive Analysis and Review of Trends Techniques and Applications}},
url = {http://discovery.ucl.ac.uk/170689/},
year = {2009}
}
@misc{me07c,
annote = {$\backslash$url\{http://promisedata.org/repository\}},
author = {Boetticher, G and Menzies, T and Ostrand, T},
institution = {West Virginia University, Lane Department of Computer Science and Electrical Engineering},
title = {{The \{PROMISE\} \{R\}epository of \{E\}mpirical \{S\}oftware \{E\}ngineering \{D\}ata}},
year = {2007}
}
@article{Arif2009b,
abstract = {Current systems for similarity-based virtual screening use similarity measures in which all the fragments in a fingerprint contribute equally to the calculation of structural similarity. This paper discusses the weighting of fragments on the basis of their frequencies of occurrence in molecules. Extensive experiments with sets of active molecules from the MDL Drug Data Report and the World of Molecular Bioactivity databases, using fingerprints encoding Tripos holograms, Pipeline Pilot ECFC\_4 circular substructures and Sunset Molecular keys, demonstrate clearly that frequency-based screening is generally more effective than conventional, unweighted screening. The results suggest that standardising the raw occurrence frequencies by taking the square root of the frequencies will maximise the effectiveness of virtual screening. An upper-bound analysis shows the complex interactions that can take place between representations, weighting schemes and similarity coefficients when similarity measures are computed, and provides a rationalisation of the relative performance of the various weighting schemes.},
author = {Arif, Shereena M. and Holliday, John D. and Willett, Peter},
doi = {10.1007/s10822-009-9285-0},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Arif2009.pdf:pdf},
issn = {0920654X},
journal = {Journal of Computer-Aided Molecular Design},
keywords = {Fingerprint,Fragment occurrences,Ligand-based virtual screening,Similarity searching,Substructural fragment,Tanimoto coefficient,Virtual screening,Weighting scheme},
number = {9},
pages = {655--668},
pmid = {19536456},
title = {{Analysis and use of fragment-occurrence data in similarity-based virtual screening}},
volume = {23},
year = {2009}
}
@article{Meng2011a,
abstract = {For applications of data mining techniques in geosciences, through mining spatial databases which are constructed with geophysical and geochemical data measured in fields, critical knowledge, such as the spatial distribution of geological targets, the geophysical and geochemical characteristics of geological targets, the differentiation among the geological targets, and the relationship among geophysical and geochemical data, can be discovered. Due to the complexity of geophysical and geochemical data, traditional mining methods of cluster analysis and association analysis have limitations in processing complex data. In this paper, a clustering algorithm based on density and adaptive density-reachable is presented which has the ability to handle clusters of arbitrary shapes, sizes, and densities. For association analysis, mining the continuous attributes may reveal useful and interesting insights about the data objects in geoscientific applications. An approach for distance-based quantitative association analysis is presented in this paper. Experiments and applications indicate that the algorithm and approach are effective in real-world applications. },
author = {Meng, Hai-Dong and Song, Yu-Chen and Song, Fei-Yan and Shen, Hai-Tao},
doi = {10.1007/s10596-010-9199-x},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/meng11.pdf:pdf},
isbn = {1420-0597},
issn = {1420-0597},
journal = {Computational Geosciences},
keywords = {association analysis,cluster analysis,geo-spatial database,geochemical data},
number = {1},
pages = {87--98},
title = {{Research and application of cluster and association analysis in geochemical data processing}},
volume = {15},
year = {2011}
}
@inproceedings{delaVega03,
author = {de la Vega, W.F. and Karpinski, M. and Kenyon, C. and Rabani, Y.},
booktitle = {Proceedings of the thirty-fifth annual ACM symposium on Theory of computing},
doi = {10.1080/03088830210132605},
isbn = {1581136749},
issn = {07349025},
number = {3},
pages = {50--58},
series = {STOC '03},
title = {{Approximation schemes for clustering problems}},
url = {http://portal.acm.org/citation.cfm?id=780542.780550},
volume = {29},
year = {2003}
}
@article{jorg04uncertainty,
abstract = { Traditionally, software professionals are requested to provide minimum-maximum intervals to indicate the uncertainty of their effort estimates. We claim that the traditional request is not optimal and leads to overoptimistic views about the level of estimation uncertainty. Instead, we propose that it is better to frame the request for uncertainty assessment: "How likely is it that the actual effort will be more than/less than X?" Our claim is based on the results of a previously reported-experiment and field studies in two companies. The two software companies were instructed to apply the traditional and our alternative framing on random samples of their projects. In total, we collected information about 47 projects applying the traditional-framing and 23 projects applying the alternative framing.},
address = {Piscataway, NJ, USA},
author = {J\o rgensen, Magne},
doi = {10.1109/TSE.2004.1274041},
isbn = {00985589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Cost estimation,Risk management,Software psychology},
number = {4},
pages = {209--217},
publisher = {IEEE Press},
title = {{Realism in assessment of effort estimation uncertainty: It matters how you ask}},
volume = {30},
year = {2004}
}
@misc{me96c,
author = {Menzies, T and Haynes, P},
title = {{Empirical Observations of Class-level Encapsulation and Inheritance}},
year = {1996}
}
@inproceedings{me00q,
abstract = {Early testing of requirements can decrease the cost of removing errors in software projects. However unless done carefully, that testing process can significantly add to the cost of requirements analysis. We show that requirements expressed as topoi diagrams can be built and tested cheaply <sup>s</sup>ing our SP2 algorithm, the formal temporal properties of a large class of topoi can be proven very quickly, in time nearly linear in the number of nodes and edges in the diagram. There are two limitations to our approach. Firstly, topoi diagrams cannot express certain complex concepts such as iteration and sub-routine calls. Hence, our approach is more useful for requirements engineering than for traditional model checking domains. Secondly, our approach is better for exploring the temporal occurrence of properties than the temporal ordering of properties. Within these restrictions, we can express a useful range of concepts currently seen in requirements engineering, and a wide range of interesting temporal properties.},
author = {Menzies, T and Powell, J and Houle, M E},
booktitle = {Software Engineering, 2001. ICSE 2001. Proceedings of the 23rd International Conference on},
doi = {10.1109/ICSE.2001.919112},
isbn = {0270-5257   VO  -},
issn = {02705257},
keywords = {SP2 algorithm,fast formal requirements analysis,formal specification,formal temporal properties,program verification,requirements engineering,software projects,testing process,topoi diagrams},
pages = {391--400},
title = {{Fast formal analysis of requirements via "topoi diagrams"}},
year = {2001}
}
@inproceedings{me90,
author = {Menzies, T J},
booktitle = {Proceedings \{AI\} '90},
title = {{Isa Object Part-of Knowledge Representation?}},
year = {1990}
}
@inproceedings{owen04a,
annote = {Tech report, Computer Science, West Virginia University},
author = {Owen, David and Menzies, Tim},
title = {{Experiments with LURCH}},
year = {2004}
}
@inproceedings{cooper01,
author = {{Kendra Cooper Tim Menzies}, Mabo Ito},
booktitle = {UBC ECE tech report},
title = {{Assessment of a Lightweight Formal Method for Specifying and Analyzing Requirements}},
year = {2001}
}
@article{Vendorsa,
author = {Vendors, How and Capitalize, Can and Models, New Revenue},
file = {:Users/timm/svns/doc/cost/07Pwc.pdf:pdf},
journal = {Technology},
title = {{Software Pricing Trends * How Vendors Can Capitalize on the}}
}
@article{minku13,
abstract = {Context: Ensembles of learning machines and locality are considered two important topics for the next research frontier on Software Effort Estimation (SEE). Objectives We aim at (1) evaluating whether existing automated ensembles of learning machines generally improve SEEs given by single learning machines and which of them would be more useful; (2) analysing the adequacy of different locality approaches; and getting insight on (3) how to improve SEE and (4) how to evaluate/choose machine learning (ML) models for SEE. Method A principled experimental framework is used for the analysis and to provide insights that are not based simply on intuition or speculation. A comprehensive experimental study of several automated ensembles, single learning machines and locality approaches, which present features potentially beneficial for SEE, is performed. Additionally, an analysis of feature selection and regression trees (RTs), and an investigation of two tailored forms of combining ensembles and locality are performed to provide further insight on improving SEE. Results Bagging ensembles of RTs show to perform well, being highly ranked in terms of performance across different data sets, being frequently among the best approaches for each data set and rarely performing considerably worse than the best approach for any data set. They are recommended over other learning machines should an organisation have no resources to perform experiments to chose a model. Even though RTs have been shown to be more reliable locality approaches, other approaches such as k-Means and k-Nearest Neighbours can also perform well, in particular for more heterogeneous data sets. Conclusion Combining the power of automated ensembles and locality can lead to competitive results in SEE. By analysing such approaches, we provide several insights that can be used by future research in the area. ?? 2012 Elsevier B.V. All rights reserved.},
author = {Minku, Leandro L. and Yao, Xin},
doi = {10.1016/j.infsof.2012.09.012},
isbn = {0950-5849},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Empirical validation,Ensembles of learning machines,Keywords,Locality,Software effort estimation},
number = {8},
pages = {1512--1528},
title = {{Ensembles and locality: Insight on improving software effort estimation}},
volume = {55},
year = {2013}
}
@inproceedings{bobntim1,
author = {Cohen, R F and Menzies, T J},
booktitle = {Software Education Conference (SRIG-ET'94)},
pages = {71--76},
title = {{Providing \{S\}oftware \{E\}ngineering \{S\}tudents with an \{E\}xperience in "\{B\}ig-\{C\}omputing"}},
year = {1995}
}
@inproceedings{aranda07,
abstract = {If designers of modelling languages want their creations to be used in real software projects, the communication qualities of their languages need to be evaluated, and their proposals must evolve as a result of these evaluations. A key quality of communication artifacts is their comprehensibility. We present a flexible framework to evaluate the comprehensibility of model representations that is grounded on the underlying theory of the language to be evaluated, and on theoretical frameworks in cognitive science.},
address = {Washington, DC, USA},
author = {Aranda, J. and Ernst, N. and Horkoff, J. and Easterbrook, S.},
booktitle = {International Workshop on Modeling in Software Engineering (MISE'07: ICSE Workshop 2007)},
doi = {10.1109/MISE.2007.2},
file = {:Users/timm/svns/doc/xplain/07aranda.pdf:pdf},
isbn = {0-7695-2953-4},
pages = {7----},
publisher = {IEEE Computer Society},
series = {MISE '07},
title = {{A Framework for Empirical Evaluation of Model Comprehensibility}},
url = {http://dx.doi.org/10.1109/MISE.2007.2},
year = {2007}
}
@inproceedings{sayyad12,
abstract = {Feature Models are popular tools for describing software product lines. Analysis of feature models has traditionally focused on consistency checking (yielding a yes/no answer) and product selection assistance, interactive or offline. In this paper, we describe a novel approach to identify the most critical decisions in product selection/configuration by taking advantage of a large pool of randomly generated, generally inconsistent, product variants. Range Ranking, a data mining technique, is utilized to single out the most critical design choices, reducing the job of the human designer to making less consequential decisions. A large feature model is used as a case study; we show preliminary results of the new approach to illustrate its usefulness for practical product derivation.},
author = {Sayyad, Abdel Salam and Ammar, Hany and Menzies, Tim},
booktitle = {2012 3rd International Workshop on Recommendation Systems for Software Engineering, RSSE 2012 - Proceedings},
doi = {10.1109/RSSE.2012.6233409},
isbn = {9781467317597},
keywords = {Feature Models,design decisions,range ranking},
pages = {47--51},
title = {{Software feature model recommendations using data mining}},
year = {2012}
}
@article{Durillo2011,
author = {Durillo, Juan J and Nebro, Antonio J},
doi = {DOI: 10.1016/j.advengsoft.2011.05.014},
issn = {0965-9978},
journal = {Advances in Engineering Software},
keywords = {Experimentation,Metaheuristics,Multi-objective optimization,Object-oriented architecture,Performance assessment support,Software tool},
pages = {760--771},
title = {{jMetal: A Java framework for multi-objective optimization}},
url = {http://www.sciencedirect.com/science/article/pii/S0965997811001219},
volume = {42},
year = {2011}
}
@article{keung12,
abstract = {Background: Conclusion Instability in software effort estimation (SEE) refers to the inconsistent results produced by a diversity of predictors using different datasets. This is largely due to the âranking instabilityâ problem, which is highly related to the evaluation criteria and the subset of the data being used. Aim: To determine stable rankings of different predictors. Method: 90 predictors are used with 20 datasets and evaluated using 7 performance measures, whose results are subject to Wilcoxon rank test (95 \%). These results are called the âaggregate resultsâ. The aggregate results are challenged by a sanity check, which focuses on a single error measure (MRE) and uses a newly developed evaluation algorithm called CLUSTER. These results are called the âspecific results.â Results: Aggregate results show that: (1) It is now possible to draw stable conclusions about the relative performance of SEE predictors; (2) Regression trees or analogy-based methods are the best performers. The aggregate results are also confirmed by the specific results of the sanity check. Conclusion: This study offers means to address the conclusion instability issue in SEE, which is an important finding for empirical software engineering.},
author = {Keung, Jacky and Kocaguneli, Ekrem and Menzies, Tim},
doi = {10.1007/s10515-012-0108-5},
issn = {09288910},
journal = {Automated Software Engineering},
keywords = {Analogy,Data mining,Effort estimation,Evaluation criteria,Linear regression,MMRE,Neural nets,Regression trees,Stability},
month = may,
number = {4},
pages = {543--567},
title = {{Finding conclusion stability for selecting the best effort predictor in software effort estimation}},
volume = {20},
year = {2013}
}
@article{boehm76,
abstract = {Software engineering has become both more and less simple since
1993 and 1994, when many questions were posed. Unfortunately, the
answers that emerged in 1995 were less satisfying than many people had
hoped they would be. The field is now simpler because, among other
reasons, the purchasing clout of 70 million Windows users has made
Microsoft's proprietary application program interfaces (APIs) a standard
to which the rest of the software industry-or at least that portion
dependent on Windows for its bread and butter-must adhere. An API is a
set of rules for writing function calls that access functions in a
library; programs that use API-compliant calls can communicate with any
others that use the API, regardless of the others' specifics. In the
past, several APIs would compete for market share. After a shakeout, the
survivors would merge their APIs into a single industry standard
controlled by a standards organization. But Microsoft's successes in
operating systems and applications have transformed its Messaging API
(MAPI), its OLE (formerly an acronym for Object Linking and Embedding
but now treated as a word in its own right), and its Win32 (the API
common to Windows NT and 95) into de facto standards that most
developers know. Whether Microsoft's dominance is a boon or curse, it is
a fact that they must accept},
author = {Hines, J.R.},
doi = {10.1109/6.476732},
isbn = {9781467356374},
issn = {0018-9235},
journal = {IEEE Spectrum},
month = dec,
number = {1},
pages = {1226--1241},
pmid = {16044975},
title = {{Software engineering}},
volume = {33},
year = {1996}
}
@article{me11n,
author = {Haapio, Topi and Menzies, Tim},
doi = {10.1142/S0218194011005438},
issn = {0218-1940},
journal = {International Journal of Software Engineering and Knowledge Engineering},
number = {05},
pages = {725--753},
title = {{Exploring the Effort of General Software Project Activities With Data Mining}},
volume = {21},
year = {2011}
}
@article{Song2010,
abstract = {BACKGROUND\&\#x02014;Predicting defect-prone software components is an economically important activity and so has received a good deal of attention. However, making sense of the many, and sometimes seemingly inconsistent, results is difficult. OBJECTIVE\&\#x02014;We propose and evaluate a general framework for software defect prediction that supports 1) unbiased and 2) comprehensive comparison between competing prediction systems. METHOD\&\#x02014;The framework is comprised of 1) scheme evaluation and 2) defect prediction components. The scheme evaluation analyzes the prediction performance of competing learning schemes for given historical data sets. The defect predictor builds models according to the evaluated learning scheme and predicts software defects with new data according to the constructed model. In order to demonstrate the performance of the proposed framework, we use both simulation and publicly available software defect data sets. RESULTS\&\#x02014;The results show that we should choose different learning schemes for different data sets (i.e., no scheme dominates), that small details in conducting how evaluations are conducted can completely reverse findings, and last, that our proposed framework is more effective and less prone to bias than previous approaches. CONCLUSIONS\&\#x02014;Failure to properly or fully evaluate a learning scheme can be misleading; however, these problems may be overcome by our proposed framework.},
author = {Song, Qinbao and Jia, Zihan and Shepperd, Martin and Ying, Shi and Liu, Jin},
doi = {10.1109/TSE.2010.90},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework.pdf:pdf;:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework(2).pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Machine learning,Scheme evaluation,Software defect prediction,Software defect-proneness prediction},
number = {3},
pages = {356--370},
title = {{A general software defect-proneness prediction framework}},
volume = {37},
year = {2011}
}
@inproceedings{bhat!icse12,
abstract = {We exploit recent advances in analysis of graph topology to better understand software evolution, and to construct predictors that facilitate software development and maintenance. Managing an evolving, collaborative software system is a complex and expensive process, which still cannot ensure software reliability. Emerging techniques in graph mining have revolutionized the modeling of many complex systems and processes. We show how we can use a graph-based characterization of a software system to capture its evolution and facilitate development, by helping us estimate bug severity, prioritize refactoring efforts, and predict defect-prone releases. Our work consists of three main thrusts. First, we construct graphs that capture software structure at two different levels: (a) the product, i.e., source code and module level, and (b) the process, i.e., developer collaboration level. We identify a set of graph metrics that capture interesting properties of these graphs. Second, we study the evolution of eleven open source programs, including Firefox, Eclipse, MySQL, over the lifespan of the programs, typically a decade or more. Third, we show how our graph metrics can be used to construct predictors for bug severity, high-maintenance software parts, and failure-prone releases. Our work strongly suggests that using graph topology analysis concepts can open many actionable avenues in software engineering research and practice.},
address = {Piscataway, NJ, USA},
author = {Bhattacharya, Pamela and Iliofotou, Marios and Neamtiu, Iulian and Faloutsos, Michalis},
booktitle = {Proceedings of the 34th International Conference on Software Engineering},
isbn = {978-1-4673-1067-3},
pages = {419--429},
publisher = {IEEE Press},
series = {ICSE '12},
title = {{Graph-based Analysis and Prediction for Software Evolution}},
url = {http://dl.acm.org/citation.cfm?id=2337223.2337273},
year = {2012}
}
@inproceedings{me95m,
author = {Menzies, T J and Goss, S},
booktitle = {AI in Defence Workshop, Australian AI'95, also Technical Report TR95-31, Department of Software Development, Monash University},
title = {{Applications of Abduction \#3: ``Black-Box'' to ``Gray-Box'' Model}},
year = {1995}
}
@misc{schmann07,
author = {Schumann, J and Gundy-Burlet, K and Menzies, T},
institution = {Computer Science, West Virginia University},
title = {{Learning Predictors \& Controllers for Software Functional Requirements}},
year = {2007}
}
@misc{me96c,
author = {Menzies, T and Haynes, P},
title = {{Empirical Observations of Class-level Encapsulation and Inheritance}},
year = {1996}
}
@article{me07b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06learnPredict.pdf\}},
author = {{Menzies T, Greenwald J}, FrankA},
journal = {IEEE Software},
month = jan,
title = {{Datamining static code attributes to learn defect predictors}},
year = {2007}
}
@article{me03f,
author = {Menzies, T},
journal = {Requirements Engineering},
title = {{Editorial, Requirements Engineering Journal, Special Issue on Model-based Requirements Engineering}},
year = {2003}
}
@article{Liu2005b,
abstract = {This paper introduces concepts and algorithms of feature selection, surveys existing feature selection algorithms for classification and clustering, groups and compares different algorithms with a categorizing framework based on search strategies, evaluation criteria, and data mining tasks, reveals unattempted combinations, and provides guidelines in selecting feature selection algorithms. With the categorizing framework, we continue our efforts toward-building an integrated system for intelligent feature selection. A unifying platform is proposed as an intermediate step. An illustrative example is presented to show how existing feature selection algorithms can be integrated into a meta algorithm that can take advantage of individual algorithms. An added advantage of doing so is to help a user employ a suitable algorithm without knowing details of each algorithm. Some real-world applications are included to demonstrate the use of feature selection in data mining. We conclude this work by identifying trends and challenges of feature selection research and development.},
author = {Liu, Huan and Yu, Lei},
doi = {10.1109/TKDE.2005.66},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/Liu05.pdf:pdf},
isbn = {1041-4347},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Categorizing framework,Classification,Clustering,Feature selection,Real-world applications,Unifying platform},
number = {4},
pages = {491--502},
title = {{Toward integrating feature selection algorithms for classification and clustering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1401889},
volume = {17},
year = {2005}
}
@article{me96a,
author = {Menzies, T J},
journal = {International Journal of Human Computer Studies},
pages = {305--355},
title = {{Applications of Abduction: Knowledge Level Modeling}},
volume = {45},
year = {1996}
}
@inproceedings{me98e,
author = {Menzies, T J and Waugh, S},
booktitle = {Proceedings Pacific Knowledge Acquisition Workshop, Singapore, November, 1998},
title = {{More Results on the Practical Lower Limits of Test Set Size}},
year = {1998}
}
@article{wilson00,
abstract = {Instance-based learning algorithms are often faced with the problem of deciding which instances to store for use during generalization. Storing too many instances can result in large memory requirements and slow execution speed, and can cause an oversensitivity to noise. This paper has two main purposes. First, it provides a survey of existing algorithms used to reduce storage requirements in instance-based learning algorithms and other exemplar-based algorithms. Second, it proposes six additional reduction algorithms called DROP1DROP5 and DEL (three of which were first described inWilson \& Martinez, 1997c, as RT1RT3) that can be used to remove instances from the concept description. These algorithms and 10 algorithms from the survey are compared on 31 classification tasks. Of those algorithms that provide substantial storage reduction, the DROP algorithms have the highest average generalization accuracy in these experiments, especially in the presence of uniform class noise.},
author = {{Randall Wilson}, D. and Martinez, Tony R.},
doi = {10.1023/A:1007626913721},
isbn = {0885-6125},
issn = {08856125},
journal = {Machine Learning},
number = {3},
pages = {257--286},
title = {{Reduction techniques for instance-based learning algorithms}},
volume = {38},
year = {2000}
}
@article{langley86,
author = {Langley, Pat and Langley, Pat},
journal = {Machine Learning},
number = {1},
pages = {5--10},
title = {{On Machine Learning}},
volume = {1},
year = {1986}
}
@inproceedings{owen01,
author = {Owen, D and Menzies, T},
booktitle = {Proceedings of the First International Workshop on Model-based Requirements Engineering},
title = {{Random Search of AND-OR Graphs Representing Finite-State Models}},
year = {2001}
}
@article{Berezovski2006a,
abstract = {Aptamers are typically selected from libraries of random DNA (or RNA) sequences through systematic evolution of ligands by exponential enrichment (SELEX), which involves several rounds of alternating steps of partitioning of candidate oligonucleotides and their PCR amplification. Here we describe a protocol for non-SELEX selection of aptamers--a process that involves repetitive steps of partitioning with no amplification between them. Non-equilibrium capillary electrophoresis of equilibrium mixtures (NECEEM), which is a highly efficient affinity method, is used for partitioning. NECEEM also facilitates monitoring of bulk affinity of enriched libraries at every step of partitioning and screening of individual clones for their affinity to the target. NECEEM allows all clones to be screened prior to sequencing, so that only clones with suitable binding parameters are sequenced. The entire protocol can be completed in 1 wk, whereas conventional SELEX protocols take several weeks even in a specialized industrial facility.},
author = {Berezovski, Maxim and Musheev, Michael and Drabovich, Andrei and Krylov, Sergey N.},
doi = {10.1021/ja056943j},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Berezovski05.pdf:pdf},
isbn = {1750-2799 (Electronic)},
issn = {00027863},
journal = {Journal of the American Chemical Society},
number = {5},
pages = {1410--1411},
pmid = {17406423},
title = {{Non-SELEX selection of aptamers}},
volume = {128},
year = {2006}
}
@article{Dasgupta2008,
address = {New York, New York, USA},
author = {Dasgupta, S and Hsu, D},
journal = {International Conference on Machine Learning},
pages = {208--215},
publisher = {ACM Press},
title = {{Heierarchical Sampling for Active Learning}},
year = {2008}
}
@article{Song2010,
abstract = {BACKGROUND\&\#x02014;Predicting defect-prone software components is an economically important activity and so has received a good deal of attention. However, making sense of the many, and sometimes seemingly inconsistent, results is difficult. OBJECTIVE\&\#x02014;We propose and evaluate a general framework for software defect prediction that supports 1) unbiased and 2) comprehensive comparison between competing prediction systems. METHOD\&\#x02014;The framework is comprised of 1) scheme evaluation and 2) defect prediction components. The scheme evaluation analyzes the prediction performance of competing learning schemes for given historical data sets. The defect predictor builds models according to the evaluated learning scheme and predicts software defects with new data according to the constructed model. In order to demonstrate the performance of the proposed framework, we use both simulation and publicly available software defect data sets. RESULTS\&\#x02014;The results show that we should choose different learning schemes for different data sets (i.e., no scheme dominates), that small details in conducting how evaluations are conducted can completely reverse findings, and last, that our proposed framework is more effective and less prone to bias than previous approaches. CONCLUSIONS\&\#x02014;Failure to properly or fully evaluate a learning scheme can be misleading; however, these problems may be overcome by our proposed framework.},
author = {Song, Qinbao and Jia, Zihan and Shepperd, Martin and Ying, Shi and Liu, Jin},
doi = {10.1109/TSE.2010.90},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework.pdf:pdf;:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework(2).pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Machine learning,Scheme evaluation,Software defect prediction,Software defect-proneness prediction},
number = {3},
pages = {356--370},
title = {{A general software defect-proneness prediction framework}},
volume = {37},
year = {2011}
}
@inproceedings{gordon00,
abstract = {The increased prevalence of agents raises numerous practical considerations. This paper addresses three of these - adaptability to unforeseen conditions, behavioral assurance, and timeliness of agent responses. Although these requirements appear contradictory, this paper introduces a paradigm in which all three are simultaneously satisfied. Agent strategies are initially verified. Then they are adapted by learning and formally reverified for behavioral assurance. This paper focuses on improving the time efficiency of reverification after learning. A priori proofs are presented that certain learning operators are guaranteed to preserve important classes of properties. In this case, efficiency is maximal because no reverification is needed. For those learning operators with negative a priori results, we present incremental algorithms that can substantially improve the efficiency of reverification.},
author = {Gordon, Diana F.},
booktitle = {Formal Approaches to Agent-Based Systems},
isbn = {978-3-540-42716-2},
pages = {278--293},
title = {{APT Agents: Agents That Are Adaptive, Predictable and Timely}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.29.5181$\backslash$nhttp://www.springerlink.com/index/Q9TQ8GJ95827M7T7.pdf},
year = {2001}
}
@misc{ithink94,
author = {Inc., High Performance Software},
title = {{iThink 3.0.5}},
year = {1994}
}
@article{verbeke11,
abstract = {Customer churn prediction models aim to detect customers with a high propensity to attrite. Predictive accuracy, comprehensibility, and justifiability are three key aspects of a churn prediction model. An accurate model permits to correctly target future churners in a retention marketing campaign, while a comprehensible and intuitive rule-set allows to identify the main drivers for customers to churn, and to develop an effective retention strategy in accordance with domain knowledge. This paper provides an extended overview of the literature on the use of data mining in customer churn prediction modeling. It is shown that only limited attention has been paid to the comprehensibility and the intuitiveness of churn prediction models. Therefore, two novel data mining techniques are applied to churn prediction modeling, and benchmarked to traditional rule induction techniques such as C4.5 and RIPPER. Both AntMiner+ and ALBA are shown to induce accurate as well as comprehensible classification rule-sets. AntMiner+ is a high performing data mining technique based on the principles of Ant Colony Optimization that allows to include domain knowledge by imposing monotonicity constraints on the final rule-set. ALBA on the other hand combines the high predictive accuracy of a non-linear support vector machine model with the comprehensibility of the rule-set format. The results of the benchmarking experiments show that ALBA improves learning of classification techniques, resulting in comprehensible models with increased performance. AntMiner+ results in accurate, comprehensible, but most importantly justifiable models, unlike the other modeling techniques included in this study. ?? 2010 Elsevier Ltd. All rights reserved.},
author = {Verbeke, Wouter and Martens, David and Mues, Christophe and Baesens, Bart},
doi = {10.1016/j.eswa.2010.08.023},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {ALBA,Ant Colony Optimization,Churn prediction,Classification,Comprehensible rule induction,Data mining},
number = {3},
pages = {2354--2364},
title = {{Building comprehensible customer churn prediction models with advanced rule induction techniques}},
volume = {38},
year = {2011}
}
@book{Hetland2010a,
abstract = {Python Algorithms explains the Python approach to algorithm analysis and design. Written by Magnus Lie Hetland, author of Beginning Python, this book is sharply focused on classical algorithms, but it also gives a solid understanding of fundamental algorithmic problem-solving techniques. The book deals with some of the most important and challenging areas of programming and computer science, but in a highly pedagogic and readable manner. The book covers both algorithmic theory and programming practice, demonstrating how theory is reflected in real Python programs. Well-known algorithms and data structures that are built into the Python language are explained, and the user is shown how to implement and evaluate others himself.},
author = {Hetland, Magnus Lie},
booktitle = {Python Algorithms: Mastering Basic Algorithms in the Python Language},
doi = {10.1007/978-1-4302-3238-4},
file = {:Users/timm/svns/doc/python-algorithms.pdf:pdf},
isbn = {9781430232377},
issn = {09242244},
pages = {1--316},
pmid = {15466169},
title = {{Python algorithms: Mastering basic algorithms in the python language}},
url = {http://books.google.com/books?id=9\_AXCmGDiz8C\&printsec=frontcover\&dq=intitle:Python+Algorithms\&hl=\&cd=1\&source=gbs\_api$\backslash$npapers2://publication/uuid/3D337050-3F0A-44F8-9602-0C3E9A7D6ACE},
year = {2010}
}
@misc{me02b,
author = {Houle, M and Menzies, T and Powell, J},
booktitle = {IEEE Trans. Sofw. Eng. (submitted)},
title = {{A Fast Search for Temporal Properties of Requirements}},
year = {2002}
}
@incollection{fea03b,
abstract = { Many organizations look to research to yield new and improved products and practices. Connecting practitioners who have the need for research results to the researchers producing those results is important to guiding research and utilizing its results. Likewise, connecting researchers working on related topics to one another, and connecting practitioners with related needs to one another, is important to establishing communities of shared interests. We present an approach that helps identify fruitful such connections.},
author = {Feather, M.S. and Menzies, T. and Connelly, J.R.},
booktitle = {IEMC '03 Proceedings. Managing Technologically Driven Organizations: The Human Side of Innovation and Change},
doi = {10.1109/IEMC.2003.1252313},
isbn = {0-7803-8150-5},
month = nov,
pages = {451--455},
title = {{Identifying fruitful connections between and among researchers and practitioners}},
year = {2003}
}
@inproceedings{me09m,
abstract = {The next challenge for the PROMISE community is scaling up and speeding up model generation to meet the size and time constraints of modern software development projects. There will always be a trade-off between completeness and runtime speed. Here we explore that trade-off in the context of using genetic algorithms to learn coverage models; i.e. biases in the control structures for randomized test generators. After applying feature subset selection to logs of the GA output, we find we can generate the coverage model and run the resulting test suite ten times faster while only losing 6\% of the test case coverage.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09fssga.pdf\}},
author = {Andrews, Jh and Menzies, Tim},
booktitle = {5th International Conference on Predictor Models in Software Engineering},
doi = {10.1145/1540438.1540456},
isbn = {9781605586342},
keywords = {feature subset selection,genetic algorithms,software testing},
pages = {13},
title = {{On the value of combining feature subset selection with genetic algorithms: faster learning of coverage models}},
url = {http://dl.acm.org/citation.cfm?id=1540456},
year = {2009}
}
@misc{me02b,
author = {Houle, M and Menzies, T and Powell, J},
booktitle = {IEEE Trans. Sofw. Eng. (submitted)},
title = {{A Fast Search for Temporal Properties of Requirements}},
year = {2002}
}
@article{Chen2008b,
abstract = {Structure learning of Bayesian networks is a well-researched but computationally hard task. We present an algorithm that integrates an information-theory-based approach and a scoring-function-based approach for learning structures of Bayesian networks. Our algorithm also makes use of basic Bayesian network concepts like d-separation and condition independence. We show that the proposed algorithm is capable of handling networks with a large number of variables. We present the applicability of the proposed algorithm on four standard network data sets and also compare its performance and computational efficiency with other standard structure-learning methods. The experimental results show that our method can efficiently and accurately identify complex network structures from data.},
author = {Chen, Xue Wen and Anantha, Gopalakrishna and Lin, Xiaotong},
doi = {10.1109/TKDE.2007.190732},
file = {:Users/timm/svns/doc/08k2.pdf:pdf},
isbn = {1041-4347},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Classification,Data mining,Machine learning},
number = {5},
pages = {628--640},
title = {{Improving bayesian network structure learning with mutual information-based node ordering in the K2 algorithm}},
volume = {20},
year = {2008}
}
@inproceedings{me96e,
author = {Menzies, T J},
booktitle = {Proceedings of the 10th Knowledge Acquisition Workshop for Knowledge-Based Systems, Banff,Canada},
title = {{Assessing Responses to Situated Congition}},
year = {1996}
}
@article{koc13a,
abstract = {Context: More than half the literature on software effort estimation (SEE) focuses on model comparisons. Each of those requires a sampling method (SM) to generate the train and test sets. Different authors use different SMs such as leave-one-out (LOO), 3Way and 10Way cross-validation. While LOO is a deterministic algorithm, the N-way methods use random selection to build their train and test sets. This introduces the problem of conclusion instability where different authors rank effort estimators in different ways. Objective: To reduce conclusion instability by removing the effects of a sampling method's random test case generation. Method: Calculate bias and variance (B\&V) values following the assumption that a learner trained on the whole dataset is taken as the true model; then demonstrate that the B\&V and runtime values for LOO are similar to N-way by running 90 different algorithms on 20 different SEE datasets. For each algorithm, collect runtimes, B\&V values under LOO, 3Way and 10Way. Results: We observed that: (1) the majority of the algorithms have statistically indistinguishable B\&V values under different SMs and (2) different SMs have similar run times. Conclusion: In terms of their generated B\&V values and runtimes, there is no reason to prefer N-way over LOO. In terms of reproducibility, LOO removes one cause of conclusion instability (the random selection of train and test sets). Therefore, we depreciate N-way and endorse LOO validation for assessing effort models. ?? 2013 Elsevier Inc. All rights reserved.},
author = {Kocaguneli, Ekrem and Menzies, Tim},
doi = {10.1016/j.jss.2013.02.053},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {Bias,Prediction system,Software cost estimation,Variance},
number = {7},
pages = {1879--1890},
title = {{Software effort models should be assessed via leave-one-out validation}},
volume = {86},
year = {2013}
}
@inproceedings{me95c,
author = {Menzies, T J},
booktitle = {Proceedings of AI '95, Australia},
publisher = {World-Scientific},
title = {{\{L\}imits to \{K\}nowledge \{L\}evel-\{B\} \{M\}odeling (and \{KADS\})}},
year = {1995}
}
@inproceedings{me95a,
author = {Menzies, T J},
booktitle = {Australian Cognitive Science Society, 3rd Conference},
title = {{Situated \{S\}emantics is a \{S\}ide-\{E\}ffect of the \{C\}omputational \{C\}omplexity of \{A\}bduction}},
year = {1995}
}
@inproceedings{bayana03,
author = {Bayana, S and Owen, D and Menzies, T and Mukhopadhyay, S},
title = {{God Does Play Dice: Diagnosis and Validation for Autonomous Systems}},
year = {2004}
}
@misc{penix13,
author = {Penix, John},
title = {{No Title}},
year = {2013}
}
@article{Vigder1994a,
author = {Vigder, M.R. and a.W. Kark},
file = {:Users/timm/svns/doc/cost/94Vigder.pdf:pdf},
journal = {\ldots National Research Council Canada, Ottowa, Ontario \ldots},
number = {37116},
title = {{Software cost estimation and control}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.45.9301\&rep=rep1\&type=pdf},
year = {1994}
}
@article{Das2008a,
abstract = {Differential evolution (DE) has emerged as one of the fast, robust, and efficient global search heuristics of current interest. This paper describes an application of DE to the automatic clustering of large unlabeled data sets. In contrast to most of the existing clustering techniques, the proposed algorithm requires no prior knowledge of the data to be classified. Rather, it determines the optimal number of partitions of the data "on the run." Superiority of the new method is demonstrated by comparing it with two recently developed partitional clustering techniques and one popular hierarchical clustering algorithm. The partitional clustering algorithms are based on two powerful well-known optimization algorithms, namely the genetic algorithm and the particle swarm optimization. An interesting real-world application of the proposed method to automatic segmentation of images is also reported.},
author = {Das, S. and Abraham, a. and Konar, a.},
doi = {10.1109/TSMCA.2007.909595},
file = {:Users/timm/svns/doc/08clusterDE.pdf:pdf},
isbn = {9780470404614},
issn = {1083-4427},
journal = {IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},
keywords = {Differential evolution (DE),genetic algorithms (GAs),particle swarm optimization (PSO),partitional clustering},
number = {1},
pages = {218--237},
title = {{Automatic Clustering Using an Improved Differential Evolution Algorithm}},
volume = {38},
year = {2008}
}
@inproceedings{lum06,
author = {Lum, Karen and Menzies, Tim and Hihn, Jairus},
booktitle = {ISPA Conference Proceedings},
title = {{Studies in Software Cost Model Behavior: Do We Really Understand Cost Model Performance?}},
url = {http://trs-new.jpl.nasa.gov/dspace/handle/2014/41450},
year = {2006}
}
@book{Sedgewicka,
author = {Sedgewick, Robert and Wayne, Kevin},
file = {:Users/timm/svns/doc/11sedgewick.pdf:pdf},
isbn = {9780321573513},
title = {{Algorithms (Java)}}
}
@inproceedings{horvitz05,
abstract = {We present research on developing models that forecast traffic flow and congestion in the Greater Seattle area. The research has led to the deployment of a service named JamBayes, that is being actively used by over 2,500 users via smartphones and desktop versions of the system. We review the modeling effort and describe experiments probing the predictive accuracy of the models. Finally, we present research on building models that can identify current and future surprises, via efforts on modeling and forecasting unexpected situations.},
archivePrefix = {arXiv},
arxivId = {1207.1352},
author = {Horvitz, Eric and Apacible, Johnson and Sarin, Raman and Liao, Lin},
booktitle = {Proceedings of the 21st Conference on Uncertainty in Artificial Intelligence (UAI '05)},
eprint = {1207.1352},
isbn = {0-9749039-1-4},
pages = {275--283},
title = {{Prediction, expectation, and surprise: Methods, designs, and study of a deployed traffic forecasting service}},
url = {http://arxiv.org/abs/1207.1352},
year = {2005}
}
@inproceedings{koc11c,
abstract = {Background: Building effort estimators requires the training data. How can we find that data? It is tempting to cross the boundaries of development type, location, language, application and hardware to use existing datasets of other organizations. However, prior results caution that using such cross data may not be useful. Aim: We test two conjectures: (1) instance selection can automatically prune irrelevant instances and (2) retrieval from the remaining examples is useful for effort estimation, regardless of their source. Method: We selected 8 cross-within divisions (21 pairs of within-cross subsets) out of 19 datasets and evaluated these divisions under different analogy-based estimation (ABE) methods. Results: Between the within \&\#x0026; cross experiments, there were few statistically significant differences in (i) the performance of effort estimators, or (ii) the amount of instances retrieved for estimation. Conclusion: For the purposes of effort estimation, there is little practical difference between cross and within data. After applying instance selection, the remaining examples (be they from within or from cross source divisions) can be used for effort estimation.},
author = {Kocaguneli, Ekrem and Menzies, Tim},
booktitle = {2011 International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2011.34},
isbn = {978-0-7695-4604-9},
issn = {1938-6451},
keywords = {cross resource,k-NN,software cost estimation,within resource},
pages = {255--264},
title = {{How to Find Relevant Data for Effort Estimation?}},
year = {2011}
}
@inproceedings{kim12,
author = {Kim, Yang Sok and Kang, Byeong Ho and Ryu, Seung Hwan and Compton, Paul and Han, Soyeon Caren and Menzies, Tim},
booktitle = {Knowledge Management and Acquisition for Intelligent Systems Lecture Notes in Computer Science},
pages = {258--271},
title = {{Crowd-Sourced Knowledge Bases}},
volume = {7457},
year = {2012}
}
@inproceedings{me96m,
author = {Menzies, Tim},
booktitle = {Proceedings of the ECAI '96 workshop on Modelling Conflicts in AI},
title = {{Expert Systems Inference = Modeling Conflicts}},
year = {1996}
}
@article{me98d,
author = {Menzies, T J and Clancey, B},
journal = {International Journal of Human-Computer Studies},
title = {{Editorial, Special Issue on Situated Cognition}},
volume = {49},
year = {1998}
}
@article{Nakanishi2006a,
author = {Nakanishi, Kotaro and Washio, Takashi and Mitsunaga, Yuki and Fujimoto, Atsushi and Motoda, Hiroshi},
doi = {10.1527/tjsai.21.526},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/washio07.pdf:pdf},
issn = {1346-0714},
journal = {Transactions of the Japanese Society for Artificial Intelligence},
keywords = {classification,lsc-caep,quan-,quantitative class association rule,subspace clustering,titative frequent itemset},
pages = {526--536},
title = {{A Classification Method Based on Subspace Clustering and Association Rules}},
volume = {21},
year = {2006}
}
@article{martens11,
abstract = {This paper proposes a complete framework to assess the overall performance of classification models from a user perspective in terms of accuracy, comprehensibility, and justifiability. A review is provided of accuracy and comprehensibility measures, and a novel metric is introduced that allows one to measure the justifiability of classification models. Furthermore, taxonomy of domain constraints is introduced, and an overview of the existing approaches to impose constraints and include domain knowledge in data mining techniques is presented. Finally, justifiability metric is applied to a credit scoring and customer churn prediction case. ?? 2011 Elsevier B.V. All rights reserved.},
author = {Martens, David and Vanthienen, Jan and Verbeke, Wouter and Baesens, Bart},
doi = {10.1016/j.dss.2011.01.013},
isbn = {0167-9236},
issn = {01679236},
journal = {Decision Support Systems},
keywords = {Classification,Comprehensibility,Data mining,Justifiability,Metrics},
number = {4},
pages = {782--793},
title = {{Performance of classification models from a user perspective}},
url = {http://www.sciencedirect.com/science/article/pii/S016792361100042X},
volume = {51},
year = {2011}
}
@article{me00o,
author = {Menzies, T and Althoff, K D and Kalfoglou, Y and Motta, E},
journal = {International Journal of Software Engineering and Knowledge Engineering},
month = aug,
number = {4},
title = {{Issues with Meta-Knowledge}},
volume = {10},
year = {2000}
}
@article{Foster2001a,
abstract = {Evolution does not require DNA, or even living organisms. In computer science, the field known as 'evolutionary computation' uses evolution as an algorithmic tool, implementing random variation, reproduction and selection by altering and moving data within a computer. This harnesses the power of evolution as an alternative to the more traditional ways to design software or hardware. Research into evolutionary computation should be of interest to geneticists, as evolved programs often reveal properties - such as robustness and non-expressed DNA - that are analogous to many biological phenomena.},
author = {Foster, J a},
doi = {10.1038/35076523},
file = {:Users/timm/svns/doc/01babu.pdf:pdf},
isbn = {1471-0056 (Print)},
issn = {1471-0056},
journal = {Nature reviews. Genetics},
keywords = {algorithms,differential evolution,evolutionary computation,genetic,himmelblau function,optimization},
number = {6},
pages = {428--436},
pmid = {11389459},
title = {{Evolutionary computation.}},
volume = {2},
year = {2001}
}
@misc{Sayyad-Shirabad+Menzies:2005,
author = {{Sayyad Shirabad, J., Menzies}, T.J.},
booktitle = {University of Ottawa, Canada .},
howpublished = {School of Information Technology and Engineering, University of Ottawa, Canada},
title = {{The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering}},
url = {http://promise.site.uottawa.ca/SERepository},
year = {2005}
}
@article{jorgensen04,
author = {J\o rgensen, M and Mol\o kken-\O stvold, K},
journal = {IEEE Transactions on Software Engineering},
month = dec,
number = {12},
pages = {993--1007},
title = {{Reasons for software effort estimation error: impact of respondent role, information collection approach, and data analysis method}},
volume = {32},
year = {2004}
}
@online{promise12,
author = {Menzies, T. and Caglayan, B. and Kocaguneli, E. and Krall, J. and Peters, F. and {B. Turhan}},
month = jun,
title = {{The PROMISE Repository of empirical software engineering data}},
url = {http://promisedata.googlecode.com},
year = {2012}
}
@inproceedings{ostrand10,
abstract = {Background: Previous research has provided evidence that a combination of static code metrics and software history metrics can be used to predict with surprising success which files in the next release of a large system will have the largest numbers of defects. In contrast, very little research exists to indicate whether information about individual developers can profitably be used to improve predictions. Aims: We investigate whether files in a large system that are modified by an individual developer consistently con- tain either more or fewer faults than the average of all files in the system. The goal of the investigation is to deter- mine whether information about which particular developer modified a file is able to improve defect predictions. We also continue an earlier study to evaluate the use of counts of the number of developers who modified a file as predictors of the fileâs future faultiness. Method: We analyzed change reports filed by 107 pro- grammers for 16 releases of a system with 1,400,000 LOC and 3100 files. A âbug ratioâ was defined for programmers, measuring the proportion of faulty files in release R out of all files modified by the programmer in release R-1. The study compares the bug ratios of individual programmers to the average bug ratio, and also assesses the consistency of the bug ratio across releases for individual programmers. Results: Bug ratios varied widely among all the program- mers, as well as for many individual programmers across all the releases that they participated in. We found a sta- tistically significant correlation between the bug ratios for programmers for the first half of changed files versus the ratios for the second half, indicating a measurable degree of persistence in the bug ratio. However, when the compu- tation was repeated with the bug ratio controlled not only by release, but also by file size, the correlation disappeared. In addition to the bug ratios, we confirmed that counts of the cumulative number of different developers changing a file over its lifetime can help to improve predictions, while other developer counts are not helpful. Conclusions: The results from this preliminary study indicate that adding information to a model about which particular developer modified a file is not likely to improve defect predictions. The study is limited to a single large sys- tem, and its resultsmay not hold more widely. The bug ratio is only one way of measuring the âfault-pronenessâ of an in- dividual programmerâs coding, and we intend to investigate other ways of evaluating bug introduction by individuals.},
author = {Ostrand, Thomas J and Weyuker, Elaine J and Bell, Robert M and Avenue, Park and Park, Florham},
booktitle = {Promise 2010},
doi = {10.1145/1868328.1868357},
isbn = {9781450304047},
keywords = {bug ratio,empirical study,fault-prone,predic-,regression model,software faults,tion},
pages = {1--10},
series = {PROMISE '10},
title = {{Programmer-based Fault Prediction}},
year = {2010}
}
@inproceedings{Haiduc2012b,
abstract = {Text retrieval approaches have been used to address many software engineering tasks. In most cases, their use involves issuing a textual query to retrieve a set of relevant software artifacts from the system. The performance of all these approaches depends on the quality of the given query (i.e., its ability to describe the information need in such a way that the relevant software artifacts are retrieved during the search). Currently, the only way to tell that a query failed to lead to the expected software artifacts is by investing time and effort in analyzing the search results. In addition, it is often very difficult to ascertain what part of the query leads to poor results. We propose a novel pre-retrieval metric, which reflects the quality of a query by measuring the specificity of its terms. We exemplify the use of the new specificity metric on the task of concept location in source code. A preliminary empirical study shows that our metric is a good effort predictor for text retrieval-based concept location, outperforming existing techniques from the field of natural language document retrieval.  2012 IEEE.},
address = {Zurich, Switzerland},
annote = {Laura. Fixed on 09/24/2012},
author = {Haiduc, Sonia and Bavota, Gabriele and Oliveto, Rocco and Marcus, Andrian and {De Lucia}, Andrea},
booktitle = {34th IEEE/ACM International Conference on Software Engineering (ICSE'12)},
keywords = {Information retrieval; Software engineering},
pages = {1273--1276},
publisher = {IEEE},
title = {{Evaluating the specificity of text retrieval queries to support software engineering tasks BT  - 34th International Conference on Software Engineering, ICSE 2012, June 2, 2012 - June 9, 2012}},
year = {2012}
}
@inproceedings{me97c,
author = {Menzies, T J and Cohen, R E},
booktitle = {European Symposium on the Validation and Verification of Knowledge Based Systems, Leuven, Belgium},
title = {{A Graph-Theoretic Optimisation of Temporal Abductive Validation}},
year = {1997}
}
@book{Hesterberg2005a,
abstract = {This article provides an introduction to the bootstrap. The bootstrap provides statistical inferencesâstandard error and bias estimates, confidence intervals, and hypothesis testsâwithout assumptions such as Normal distributions or equal variances. As such, bootstrap methods can be remarkably more accurate than classical inferences based on Normal or t distributions. The bootstrap uses the same basic procedure regardless of the statistic being calculated, without requiring the use of application-specific formulae. This article may provide two big surprises for many readers. The first is that the bootstrap shows that common t confidence intervals are woefully inaccurate when populations are skewed, with one-sided coverage levels off by factors of two or more, even for very large samples. The second is that the number of bootstrap samples required is much larger than generally realized. WIREs Comp Stat 2011 3 497â526 DOI: 10.1002/wics.182 For further resources related to this article, please visit the WIREs website},
author = {Hesterberg, Tim},
booktitle = {Wiley Interdisciplinary Reviews: Computational Statistics},
doi = {10.1002/wics.182},
file = {:Users/timm/svns/doc/03bootstrap.pdf:pdf},
isbn = {1939-0068},
issn = {19395108},
keywords = {Bias,Inference,Permutation tests,Resampling,Standard error},
number = {6},
pages = {497--526},
title = {{Bootstrap}},
url = {http://seongjoon.com/drupal/files/Bootstrap methods and permutation tests\_PBS18.pdf},
volume = {3},
year = {2011}
}
@article{Verbeke2011a,
abstract = {Customer churn prediction models aim to detect customers with a high propensity to attrite. Predictive accuracy, comprehensibility, and justifiability are three key aspects of a churn prediction model. An accurate model permits to correctly target future churners in a retention marketing campaign, while a comprehensible and intuitive rule-set allows to identify the main drivers for customers to churn, and to develop an effective retention strategy in accordance with domain knowledge. This paper provides an extended overview of the literature on the use of data mining in customer churn prediction modeling. It is shown that only limited attention has been paid to the comprehensibility and the intuitiveness of churn prediction models. Therefore, two novel data mining techniques are applied to churn prediction modeling, and benchmarked to traditional rule induction techniques such as C4.5 and RIPPER. Both AntMiner+ and ALBA are shown to induce accurate as well as comprehensible classification rule-sets. AntMiner+ is a high performing data mining technique based on the principles of Ant Colony Optimization that allows to include domain knowledge by imposing monotonicity constraints on the final rule-set. ALBA on the other hand combines the high predictive accuracy of a non-linear support vector machine model with the comprehensibility of the rule-set format. The results of the benchmarking experiments show that ALBA improves learning of classification techniques, resulting in comprehensible models with increased performance. AntMiner+ results in accurate, comprehensible, but most importantly justifiable models, unlike the other modeling techniques included in this study. ?? 2010 Elsevier Ltd. All rights reserved.},
author = {Verbeke, Wouter and Martens, David and Mues, Christophe and Baesens, Bart},
doi = {10.1016/j.eswa.2010.08.023},
file = {:Users/timm/svns/doc/xplain/11Verbeke.pdf:pdf},
isbn = {0957-4174},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {ALBA,Ant Colony Optimization,Churn prediction,Classification,Comprehensible rule induction,Data mining},
number = {3},
pages = {2354--2364},
publisher = {Elsevier Ltd},
title = {{Building comprehensible customer churn prediction models with advanced rule induction techniques}},
url = {http://dx.doi.org/10.1016/j.eswa.2010.08.023},
volume = {38},
year = {2011}
}
@inproceedings{mebfd92,
author = {Menzies, T J and Black, J and Fleming, J and Dean, M},
booktitle = {The first Conference on Practical Applications of Prolog},
title = {{An Expert System for Raising Pigs}},
year = {1992}
}
@inproceedings{me13f,
author = {Menzies, Tim},
booktitle = {PROMISE '13},
title = {{Beyond Data Mining; Towards "Idea Engineering"}},
year = {2013}
}
@article{me89zb,
author = {Menzies, T J},
journal = {AI Expert},
title = {{Domain-Specific Knowledge Representations}},
year = {1989}
}
@inproceedings{me98c,
author = {Menzies, T J and Waugh, S},
booktitle = {Proceedings of the Australian AI '98 conference},
publisher = {World-Scientific},
title = {{Lower Limits on the Size of Test Data Sets}},
year = {1998}
}
@inproceedings{owen03a,
abstract = {Formal methods, including model checking, is pow- erful but can be costly, in terms of memory, time, and modeling effort. Difficult problems, similar to the verification problem addressed by model checking, have been shown to exhibit a phase transition, suggesting that an easy range of problem instances might be solved much faster and with much less memory using a new type of model checker based on partial, random search. Here we compare the performance of Lurch, our pro- totype random search model checker, to the popular tools SMV and SPIN. The toolsâ performance is com- pared for a range of randomly generated models based on a simple tic-tac-toe game. Our results suggest that Lurch might be used in place of existing tools for sys- tems too large or too difficult to model small enough for conventional model checking.},
author = {Owen, David and Menzies, Tim},
booktitle = {Proc. of the 15th International Conference on Software Engineering \& Knowledge Engineering (SEKE 2003)},
pages = {158--165},
title = {{Lurch: a Lightweight Alternative to Model Checking}},
year = {2003}
}
@article{me00d,
author = {Menzies, Tim and Cukic, Bojan},
doi = {10.1142/S0218213000000112},
issn = {0218-2130},
journal = {International Journal on Artificial Intelligence Tools},
month = jun,
number = {01},
pages = {153--172},
title = {{Adequacy of Limited Testing for Knowledge Based Systems}},
volume = {09},
year = {2000}
}
@article{Das2005a,
abstract = {Differential evolution (DE) is well known as a simple and efficient scheme for global optimization over continuous spaces. In this paper we present two new, improved variants of DE. Performance comparisons of the two proposed methods are provided against (a) the original DE, (b) the canonical particle swarm optimization (PSO), and (c) two PSO-variants. The new DE-variants are shown to be statistically significantly better on a seven-function test bed for the following performance measures: solution quality, time to find the solution, frequency of finding the solution, and scalability.},
author = {Das, Swagatam and Konar, Amit and Chakraborty, Uday K.},
doi = {10.1145/1068009.1068177},
file = {:Users/timm/svns/doc/pso/07aDEvariantBeatsOthers.pdf:pdf},
isbn = {1595930108},
journal = {Proceedings of the 2005 conference on Genetic and evolutionary computation - GECCO '05},
keywords = {differential evolution,evolutionary,particle swarm optimization},
pages = {991},
title = {{Two improved differential evolution schemes for faster global search}},
url = {http://portal.acm.org/citation.cfm?doid=1068009.1068177},
year = {2005}
}
@incollection{me10e,
author = {Menzies, Tim and Shull, Forrest},
booktitle = {Making Software: What really works, and why we believe it},
editor = {Oram, A and Wilson, G},
pages = {3--11},
publisher = {O'Reilly},
title = {{The Quest for Convincing Evidence}},
year = {2010}
}
@article{me11d,
abstract = {Analogy based estimation (ABE) generates an effort estimate for a new software project through adaptation of similar past projects (a.k.a. analogies). Majority of ABE methods follow uniform weighting in adaptation procedure. In this research we investigated non-uniform weighting through kernel density estimation. After an extensive experimentation of 19 datasets, 3 evaluation criteria, 5 kernels, 5 bandwidth values and a total of 2090 ABE variants, we found that: (1) non-uniform weighting through kernel methods cannot outperform uniform weighting ABE and (2) kernel type and bandwidth parameters do not produce a definite effect on estimation performance. In summary simple ABE approaches are able to perform better than much more complex approaches. Hence,âprovided that similar experimental settings are adoptedâwe discourage the use of kernel methods as a weighting strategy in ABE.},
author = {Kocaguneli, Ekrem and Menzies, Tim and Keung, Jacky W.},
doi = {10.1007/s10664-011-9189-1},
issn = {1382-3256},
journal = {Empirical Software Engineering},
pages = {1--24},
publisher = {Springer Netherlands},
title = {{Kernel methods for software effort estimation}},
year = {2011}
}
@article{Das2009a,
abstract = {Differential evolution (DE) is well known as a simple and efficient scheme for global optimization over continuous spaces. It has reportedly outperformed a few evolutionary algorithms (EAs) and other search heuristics like the particle swarm optimization (PSO) when tested over both benchmark and real-world problems. DE, however, is not completely free from the problems of slow and/or premature convergence. This paper describes a family of improved variants of the DE/target-to-best/1/bin scheme, which utilizes the concept of the neighborhood of each population member. The idea of small neighborhoods, defined over the index-graph of parameter vectors, draws inspiration from the community of the PSO algorithms. The proposed schemes balance the exploration and exploitation abilities of DE without imposing serious additional burdens in terms of function evaluations. They are shown to be statistically significantly better than or at least comparable to several existing DE variants as well as a few other significant evolutionary computing techniques over a test suite of 24 benchmark functions. The paper also investigates the applications of the new DE variants to two real-life problems concerning parameter estimation for frequency modulated sound waves and spread spectrum radar poly-phase code design.},
author = {Das, Swagatam and Abraham, Ajith and Chakraborty, Uday K. and Konar, Amit},
doi = {10.1109/TEVC.2008.2009457},
file = {:Users/timm/svns/doc/09-de-neighbors.pdf:pdf},
isbn = {1089-778X},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Differential evolution,Evolutionary algorithms,Meta-heuristics,Numerical optimization,Particle swarm optimization},
number = {3},
pages = {526--553},
title = {{Differential evolution using a neighborhood-based mutation operator}},
volume = {13},
year = {2009}
}
@inproceedings{brady10b,
author = {Brady, Adam and Menzies, Tim},
booktitle = {The 6th International Conference on Predictive Models in Software Engineering (PROMISE '10)},
doi = {http://dx.doi.org/10.1145/1868328.1868333},
title = {{Case-Based Reasoning vs Parametric Models for Software Quality Optimization}},
year = {2010}
}
@inproceedings{me03q,
abstract = { Assessing software costs money and better assessment costs exponentially more money. Given finite budgets, assessment resources are typically skewed towards areas that are believed to be mission critical. This leaves blind spots: portions of the system that may contain defects which may be missed. Therefore, in addition to rigorously assessing mission critical areas, a parallel activity should sample the blind spots. This paper assesses defect detectors based on static code measures as a blind spot sampling method. In contrast to previous results, we find that such defect detectors yield results that are stable across many applications. Further, these detectors are inexpensive to use and can be tuned to the specifics of the current business situations.},
author = {Menzies, T. and Stefano, J.S. Di},
booktitle = {Eighth IEEE International Symposium on High Assurance Systems Engineering, 2004. Proceedings.},
doi = {10.1109/HASE.2004.1281737},
isbn = {0-7695-2094-4},
issn = {1530-2059},
title = {{How good is your blind spot sampling policy}},
year = {2004}
}
@article{Krink2005a,
abstract = {In recent years, many partitional clustering algorithms based on genetic algorithms (GA) have been proposed to tackle the problem of finding the optimal partition of a data set. Surprisingly, very few studies considered alternative stochastic search heuristics other than GAs or simulated annealing. Two promising algorithms for numerical optimization, which are hardly known outside the heuristic search field, are particle swarm optimisation (PSO) and differential evolution (DE). In this study, we compared the performance of GAs with PSO and DE for a medoid evolution approach to clustering. Moreover, we compared these results with the nominal classification, k-means and random search (RS) as a lower bound. Our results show that DE is clearly and consistently superior compared to GAs and PSO for hard clustering problems, both in respect to precision as well as robustness (reproducibility) of the results. Only for trivial problems all algorithms can obtain comparable results. Apart from superior performance, DE is very easy to implement and requires hardly any parameter tuning compared to substantial tuning for GAs and PSOs. Our study shows that DE rather than GAs should receive primary attention in partitional cluster algorithms.},
author = {Krink, Thiermo},
file = {:Users/timm/svns/doc/pso/06psoVSdeClustering.pdf:pdf},
pages = {1--27},
title = {{Differential Evolution and Particle Swarm Optimization in Partitional Clustering}},
url = {http://videolectures.net/solomon\_krink\_depso/},
year = {2005}
}
@article{Abts1997a,
author = {Abts, Christopher M},
file = {:Users/timm/svns/doc/cost/00USAFReport.pdf:pdf},
number = {June},
title = {{COTS Software Integration Cost Modeling Study Center for Software Engineering}},
year = {1997}
}
@inproceedings{Brickell08,
abstract = {Re-identification is a major privacy threat to public datasets containing individual records. Many privacy protection algorithms rely on generalization and suppression of "quasi-identifier" attributes such as ZIP code and birthdate. Their objective is usually syntactic sanitization: for example, k-anonymity requires that each "quasi-identifier" tuple appear in at least k records, while l-diversity requires that the distribution of sensitive attributes for each quasi-identifier have high entropy. The utility of sanitized data is also measured syntactically, by the number of generalization steps applied or the number of records with the same quasi-identifier. In this paper, we ask whether generalization and suppression of quasi-identifiers offer any benefits over trivial sanitization which simply separates quasi-identifiers from sensitive attributes. Previous work showed that k-anonymous databases can be useful for data mining, but k-anonymization does not guarantee any privacy. By contrast, we measure the tradeoff between privacy (how much can the adversary learn from the sanitized records?) and utility, measured as accuracy of data-mining algorithms executed on the same sanitized records. For our experimental evaluation, we use the same datasets from the UCI machine learning repository as were used in previous research on generalization and suppression. Our results demonstrate that even modest privacy gains require almost complete destruction of the data-mining utility. In most cases, trivial sanitization provides equivalent utility and better privacy than k-anonymity, l-diversity, and similar methods based on generalization and suppression.},
address = {New York, NY, USA},
author = {Brickell, Justin and Shmatikov, Vitaly},
booktitle = {Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining},
doi = {http://doi.acm.org/10.1145/1401890.1401904},
isbn = {978-1-60558-193-4},
keywords = {anonymity,data mining,privacy,utility},
pages = {70--78},
publisher = {ACM},
series = {KDD '08},
title = {{The cost of privacy: destruction of data-mining utility in anonymized data publishing}},
url = {http://doi.acm.org/10.1145/1401890.1401904},
year = {2008}
}
@inproceedings{me94,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/ai94.pdf\}},
author = {Menzies, T J and Compton, P},
booktitle = {Proceedings of Australian AI'94},
editor = {Zhang, C and Debenham, J and Lukose, D},
pages = {149--156},
publisher = {World Scientific},
title = {{A \{P\}recise \{S\}emantics for \{V\}ague \{D\}iagrams}},
year = {1994}
}
@inproceedings{owen04a,
annote = {Tech report, Computer Science, West Virginia University},
author = {Owen, David and Menzies, Tim},
title = {{Experiments with LURCH}},
year = {2004}
}
@inproceedings{me00t,
author = {Menzies, Tim and Singh, Harhsinder},
booktitle = {2nd International Workshop on Soft Computing applied to Software Engineering (Netherlands), February},
pages = {1--24},
title = {{Many Maybes Mean ( Mostly ) the Same Thing}},
year = {2001}
}
@inproceedings{men93j,
author = {Menzies, T J and Spurret, R},
booktitle = {Tools Pacific 12},
pages = {213--224},
publisher = {Prentice Hall},
title = {{How to \{E\}dit $\backslash$"it$\backslash$"; or a \{B\}lack-Box \{C\}onstraint \{B\}ased \{F\}ramework for \{U\}ser \{I\}nteraction with \{A\}rbitrary \{S\}tructures}},
year = {1993}
}
@article{me99m,
author = {Menzies, T and van Harmelen, Frank},
doi = {10.1006/ijhc.1999.0336},
issn = {1071-5819},
journal = {International Journal of HumanComputer Studies special issue on evaluation of Knowledge Engineering Techniques},
month = oct,
number = {4},
pages = {717--727},
title = {{Editorial: Evaluating Knowledge Engineering Techniques}},
volume = {51},
year = {1999}
}
@article{Yangyuoru2012a,
abstract = {Aptamers that bind small molecules can serve as basic biosensing platforms. Evaluation of the binding constant between an aptamer and a small molecule helps to determine the effectiveness of the aptamer-based sensors. Binding constants are often measured by a series of experiments with varying ligand or aptamer concentrations. Such experiments are time-consuming, material nonprudent, and prone to low reproducibility. Here, we use laser tweezers to determine the dissociation constant for aptamer-ligand interactions at the single-molecule level from only one ligand concentration. Using an adenosine 5'-triphosphate disodium salt (ATP) binding aptamer as an example, we have observed that the mechanical stabilities of aptamers bound with ATP are higher than those without a ligand. Comparison of the change in free energy of unfolding ($\Delta$G(unfold)) between these two aptamers yields a $\Delta$G of 33 Â± 4 kJ/mol for the binding. By applying a Hess-like cycle at room temperature, we obtained a dissociation constant (K(d)) of 2.0 Â± 0.2 $\mu$M, a value consistent with the K(d) obtained from our equilibrated capillary electrophoresis (CE) (2.4 Â± 0.4 $\mu$M) and close to that determined by affinity chromatography in the literature (6 Â± 3 $\mu$M). We anticipate that our laser tweezers and CE methodologies may be used to more conveniently evaluate the binding between receptors and ligands and also serve as analytical tools for force-based biosensing.},
author = {Yangyuoru, Philip M. and Dhakal, Soma and Yu, Zhongbo and Koirala, Deepak and Mwongela, Simon M. and Mao, Hanbin},
doi = {10.1021/ac300427d},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Yangyuoru12.pdf:pdf},
isbn = {0003-2700},
issn = {00032700},
journal = {Analytical Chemistry},
number = {12},
pages = {5298--5303},
pmid = {22702719},
title = {{Single-molecule measurements of the binding between small molecules and DNA aptamers}},
volume = {84},
year = {2012}
}
@article{Storn1996a,
abstract = {Differential evolution (DE) has recently proven to be an efficient method for optimizing real-valued multi-modal objective functions. Besides its good convergence properties and suitability for parallelization, DE's main assets are its conceptual simplicity and ease of use. This paper describes several variants of DE and elaborates on the choice of DE's control parameters, which corresponds to the application of fuzzy rules. Finally, the design of a howling removal unit with DE is described to provide a real-world example for DE's applicability},
author = {Storn, R.},
doi = {10.1109/NAFIPS.1996.534789},
file = {:Users/timm/svns/doc/96stornDE.pdf:pdf},
isbn = {0-7803-3225-3},
issn = {15205118},
journal = {Proceedings of North American Fuzzy Information Processing NAFIPS'96},
pages = {519--523},
pmid = {21476566},
title = {{On the usage of differential evolution for function optimization}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=534789},
year = {1996}
}
@inproceedings{krall14b,
author = {Krall, J and Menzies, T and Davies, M},
booktitle = {Modeling in Human Machine Systems: Challenges for Formal Verification, an AAAI 2014 Spring Symposium},
title = {{Learning the Task Management Space of an Aircraft Approach Model}},
year = {2014}
}
@article{Garvey1997a,
author = {Garvey, Paul R. and Taub, Audrey E.},
doi = {10.1080/08823871.1997.10462305},
file = {:Users/timm/svns/doc/cost/97Garvey.pdf:pdf},
issn = {0882-3871},
journal = {The Journal of Cost Analysis},
number = {1},
pages = {3--27},
title = {{A Joint Probability Model for Cost and Schedule Uncertainties}},
volume = {14},
year = {1997}
}
@article{VanDerMerwe2003c,
abstract = { This paper proposes two new approaches to using PSO to cluster data. It is shown how PSO can be used to find the centroids of a user specified number of clusters. The algorithm is then extended to use K-means clustering to seed the initial swarm. This second algorithm basically uses PSO to refine the clusters formed by K-means. The new PSO algorithms are evaluated on six data sets, and compared to the performance of K-means clustering. Results show that both PSO clustering techniques have much potential.},
author = {Merwe, D.W. Van Der and a.P. Engelbrecht},
doi = {10.1109/CEC.2003.1299577},
file = {:Users/timm/svns/doc/pso/01psoKmeansCluster.pdf:pdf},
isbn = {0-7803-7804-0},
journal = {The 2003 Congress on Evolutionary Computation, 2003. CEC '03.},
pages = {215--220},
title = {{Data clustering using particle swarm optimization}},
volume = {1},
year = {2003}
}
@inproceedings{hameph95,
author = {Haynes, P and Menzies, T and Phipps, G},
booktitle = {OOPSLA Workshop on OO Process and Metrics for Effort Estimation},
title = {{Using The Size of Classes and Methods as the Basis for Early Effort Prediction; Empirical Observations, Initial Application; A Practitioners Experience Report}},
year = {1995}
}
@article{Glokler2010a,
abstract = {Automation in combination with high throughput screening methods has revolutionised molecular biology in the last two decades. Today, many combinatorial libraries as well as several systems for automation are available. Depending on scope, budget and time, a different combination of library and experimental handling might be most effective. In this review we will discuss several concepts of combinatorial libraries and provide information as what to expect from these depending on the given context.},
author = {Gl\"{o}kler, J\"{o}rn and Sch\"{u}tze, Tatjana and Konthur, Zolt\'{a}n},
doi = {10.3390/molecules15042478},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/GloklerSchutzeReview10.pdf:pdf},
issn = {14203049},
journal = {Molecules},
keywords = {Automation,In vitro evolution,Phage display,Random combinatorial library,SELEX},
number = {4},
pages = {2478--2490},
pmid = {20428057},
title = {{Automation in the high-throughput selection of random combinatorial libraries-different approaches for select applications}},
volume = {15},
year = {2010}
}
@phdthesis{me95,
author = {Menzies, T J},
school = {University of New South Wales},
title = {{Principles for Generalised Testing of Knowledge Bases}},
year = {1995}
}
@inproceedings{me03n,
author = {Menzies, T and Kiper, J and Feather, M},
booktitle = {SEDECS'2003: the 2nd International Workshop on Software Engineering Decision Support (part of SEKE2003)},
month = jun,
title = {{Improved software engineering decision support through automatic argument reduction tools}},
year = {2003}
}
@inproceedings{li07,
author = {Li, Ninghui and Li, Tiancheng and Venkatasubramanian, Suresh},
booktitle = {ICDE},
pages = {106--115},
title = {{t-Closeness: Privacy Beyond k-Anonymity and l-Diversity}},
year = {2007}
}
@book{pareto1906,
author = {Mornati, F.},
booktitle = {History of Political Economy},
doi = {10.1215/00182702-2008-035},
issn = {0018-2702},
number = {4},
pages = {714--715},
publisher = {MacMillian},
title = {{Manuale di economia politica}},
volume = {40},
year = {2008}
}
@article{Xiong2009a,
abstract = {This paper describes a new approach for clusteringâpattern preserving clusteringâwhich produces more easily interpretable and usable clusters. This approach is motivated by the following observation: while there are usually strong patterns in the dataâpatterns that may be key for the analysis and description of the dataâthese patterns are often split among different clusters by current clustering approaches. This is, perhaps, not surprising, since clustering algorithms have no built-in knowledge of these patterns and may often have goals that are in conflict with preserving patterns, e.g., minimize the distance of points to their nearest cluster centroids. In this paper, our focus is to characterize (1) the benefits of pattern preserving clustering and (2) the most effective way of performing pattern preserving clustering. To that end, we propose and evaluate two clustering algorithms, HIerarchical Clustering with pAttern Preservation (HICAP) and bisecting K-means Clustering with pAttern Preservation (K-CAP). Experimental results on document data show that HICAP can produce overlapping clusters that preserve useful patterns, but has relatively worse clustering performance than bisecting K-means with respect to the clustering evaluation criterion of entropy. By contrast, in terms of entropy, K-CAP can perform substantially better than the bisecting K-means algorithm when data sets contain clusters of widely different sizesâa common situation in the real-world. Most importantly, we also illustrate how patterns, if preserved, can aid cluster interpretation. [ABSTRACT FROM AUTHOR] Copyright of Knowledge \& Information Systems is the property of Springer Science \& Business Media B.V. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
author = {Xiong, Hui and Steinbach, Michael and Ruslim, Arifin and Kumar, Vipin},
doi = {10.1007/s10115-008-0148-0},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/xiong09.pdf:pdf},
isbn = {02191377},
issn = {02191377},
journal = {Knowledge and Information Systems},
keywords = {Hierarchical clustering,Hyperclique pattern,K-means clustering,Pattern preserving clustering},
number = {3},
pages = {311--336},
pmid = {40211436},
title = {{Characterizing pattern preserving clustering}},
volume = {19},
year = {2009}
}
@inproceedings{chen05,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05/fsscocomo.pdf\}},
author = {Chen, Zhihao and Menzies, Tim and Port, Dan and Boehm, Barry},
booktitle = {ACM SIGSOFT Software Engineering Notes},
doi = {10.1145/1082983.1083171},
isbn = {-159593-125-2},
issn = {01635948},
number = {4},
pages = {1},
title = {{Feature subset selection can improve software cost estimation accuracy}},
volume = {30},
year = {2005}
}
@incollection{me10e,
author = {Menzies, Tim and Shull, Forrest},
booktitle = {Making Software: What really works, and why we believe it},
editor = {Oram, A and Wilson, G},
pages = {3--11},
publisher = {O'Reilly},
title = {{The Quest for Convincing Evidence}},
year = {2010}
}
@inproceedings{me99h,
author = {Menzies, T and Cukic, B and Coiera, E},
booktitle = {AAAI'99 workshop on Conflicts and Identifying Opportunities.},
title = {{Smaller, Faster Dialogues via Conversational Probing}},
year = {1999}
}
@inproceedings{me99g,
author = {Menzies, T and Michael, C C},
booktitle = {SEKE '99, June 17-19, Kaiserslautern, Germany.},
title = {{Fewer Slices of PIE: Optimising Mutation Testing via Abduction}},
year = {1999}
}
@inproceedings{me96b,
annote = {Available from $\backslash$url\{http:/menzies.us/pdf/96ok.pdf\}},
author = {Menzies, T J},
booktitle = {Ecai '96},
title = {{On the Practicality of Abductive Validation}},
year = {1996}
}
@article{Altshuler2013a,
author = {Allen, Rachel and Cooke, Anne},
doi = {10.1016/B978-0-12-138120-2.50013-7},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/IntroCheminformatics-VirtualScreening2007.pdf:pdf},
isbn = {0131470469},
journal = {Biennials and Beyond},
title = {{Chapter 8}},
year = {2005}
}
@misc{schmann07,
author = {Schumann, J and Gundy-Burlet, K and Menzies, T},
institution = {Computer Science, West Virginia University},
title = {{Learning Predictors \& Controllers for Software Functional Requirements}},
year = {2007}
}
@inproceedings{me02e,
abstract = { Within NASA, there is an increasing awareness that software is of growing importance to the success of missions. Much data has been collected, and many theories have been advanced on how to reduce or eliminate errors in code. However, learning requires experience. We document a new NASA initiative to build a centralized repository of software defect data; in particular, we document one specific case study on software metrics. Software metrics are used as a basis for prediction of errors in code modules, but there are many different metrics available. McCabe is one of the more popular tools used to produce metrics, but, other metrics can be more significant.},
author = {Menzies, T. and Stefano, J.S. Di and Chapman, M. and McGill, K.},
booktitle = {27th Annual NASA Goddard/IEEE Software Engineering Workshop, 2002. Proceedings.},
doi = {10.1109/SEW.2002.1199449},
isbn = {0-7695-1855-9},
issn = {0021-8499},
title = {{Metrics that matter}},
year = {2002}
}
@article{6175912,
abstract = {Software testing is a crucial activity during software development and fault prediction models assist practitioners herein by providing an upfront identification of faulty software code by drawing upon the machine learning literature. While especially the Naive Bayes classifier is often applied in this regard, citing predictive performance and comprehensibility as its major strengths, a number of alternative Bayesian algorithms that boost the possibility of constructing simpler networks with fewer nodes and arcs remain unexplored. This study contributes to the literature by considering 15 different Bayesian Network (BN) classifiers and comparing them to other popular machine learning techniques. Furthermore, the applicability of the Markov blanket principle for feature selection, which is a natural extension to BN theory, is investigated. The results, both in terms of the AUC and the recently introduced H-measure, are rigorously tested using the statistical framework of DemsÌar. It is concluded that simple and comprehensible networks with less nodes can be constructed using BN classifiers other than the Naive Bayes classifier. Furthermore, it is found that the aspects of comprehensibility and predictive performance need to be balanced out, and also the development context is an item which should be taken into account during model selection.},
author = {Dejaeger, Karel and Verbraken, Thomas and Baesens, Bart},
doi = {10.1109/TSE.2012.20},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Bayesian networks,Software fault prediction,classification,comprehensibility},
month = feb,
number = {2},
pages = {237--257},
title = {{Toward comprehensible software fault prediction models using bayesian network classifiers}},
volume = {39},
year = {2013}
}
@incollection{me10b,
author = {Menzies, Tim and Shull, Forrest},
booktitle = {Making Software: What really works, and why we believe it},
editor = {Oram, A and G.Wilson},
pages = {3--11},
publisher = {O'Reilly Books},
title = {{The Quest for Convincing Evidence}},
year = {2010}
}
@article{me09d,
annote = {Avialable from $\backslash$url\{http://menzies.us/pdf/09ir4pc.pdf\}},
author = {Etzkorn, L and Menzies, T},
journal = {Empirical Software Engineering},
number = {1},
pages = {1--4},
title = {{Editorial, Special issue on information retrieval for program comprehension}},
volume = {14},
year = {2009}
}
@inproceedings{jiang07,
abstract = {The prediction of fault-prone modules in a software project has been the topic of many studies. In this paper, we investigate whether metrics available early in the development lifecycle can be used to identify fault-prone software modules. More precisely, we build predictive models using the metrics that characterize textual requirements. We compare the performance of requirements-based models against the performance of code-based models and models that combine requirement and code metrics. Using a range of modeling techniques and the data from three NASA projects, our study indicates that the early lifecycle metrics can play an important role in project management, either by pointing to the need for increased quality monitoring during the development or by using the models to assign verification and validation activities.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07issre.pdf\}},
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim},
booktitle = {The 18th IEEE International Symposium on Software Reliability (ISSRE '07)},
doi = {10.1109/ISSRE.2007.24},
isbn = {978-0-7695-3024-6},
issn = {1071-9458},
title = {{Fault Prediction using Early Lifecycle Data}},
year = {2007}
}
@inproceedings{zhang10,
abstract = {BACKGROUND: Defect predictors learned from static code measures can isolate code modules with a higher than usual probability of defects. AIMS: To improve those learners by focusing on the defect-rich portions of the training sets. METHOD: Defect data CM1, KC1, MC1, PC1, PC3 was separated into components. A subset of the projects (selected at random) were set aside for testing. Training sets were generated for a NaiveBayes classifier in two ways. In sample the dense treatment, the components with higher than the median number of defective modules were used for training. In the standard treatment, modules from any component were used for training. Both samples were run against the test set and evaluated using recall, probability of false alarm, and precision. In addition, under sampling and over sampling was performed on the defect data. Each method was repeated in a 10-by-10 cross-validation experiment. RESULTS: Prediction models learned from defect dense components out-performed standard method, under sampling, as well as over sampling. In statistical rankings based on recall, probability of false alarm, and precision, models learned from dense components won 4-5 times more often than any other method, and also lost the least amount of times. CONCLUSIONS: Given training data where most of the defects exist in small numbers of components, better defect predictors can be trained from the defect dense components.},
author = {Zhang, Hongyu and Nelson, Adam and Menzies, Tim},
booktitle = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering - PROMISE '10},
doi = {10.1145/1868328.1868350},
isbn = {9781450304047},
keywords = {ceiling ef-,defect dense components,defect prediction,sampling},
pages = {1},
title = {{On the value of learning from defect dense components for software defect prediction}},
url = {http://portal.acm.org/citation.cfm?doid=1868328.1868350},
year = {2010}
}
@misc{me01b,
author = {Menzies, T},
booktitle = {ASERC workshop on Quantiative Software Engineering},
title = {{Applictions of Computational Intelligence to Quantitative Software Engineering}},
year = {2001}
}
@inproceedings{me02f,
abstract = { Software engineering (SE) truisms capture broadly-applicable principles of software construction. The trouble with truisms is that such general principles may not apply in specific cases. This paper tests the specificity of two SE truisms: (a) increasing software process level is a desirable goal; and (b) it is best to remove errors during the early parts of a software lifecycle. Our tests are based on two well-established SE models: (1) Boehm et.al.'s COCOMO II cost estimation model; and (2) Raffo's discrete event software process model of a software project life cycle. After extensive simulations of these models, the TAR2 treatment learner was applied to find the model parameters that most improved the potential performance of the real-world systems being modelled. The case studies presented here showed that these truisms are clearly sub-optimal for certain projects since other factors proved to be far more critical. Hence, we advise against truism-based process improvement. This paper offers a general alternative framework for model-based assessment of methods to improve software quality: modelling + validation + simulation + sensitivity. That is, after recording what is known in a model, that model should be validated, explored using simulations, then summarized to find the key factors that most improve model behavior.},
author = {Menzies, T. and Raffo, D. and Setamanit, S.-O. and Hu, Ying Hu Ying and Tootoonian, S.},
booktitle = {Proceedings 17th IEEE International Conference on Automated Software Engineering,},
doi = {10.1109/ASE.2002.1115012},
isbn = {0-7695-1736-6},
issn = {1527-1366},
title = {{Model-based tests of truisms}},
year = {2002}
}
@article{Heikkila2013a,
author = {Heikkila, Ville T. and Paasivaara, Maria and Lassenius, Casper},
doi = {10.1109/ESEM.2013.27},
file = {:Users/timm/svns/doc/finland.pdf:pdf},
isbn = {978-0-7695-5056-5},
issn = {19493770},
journal = {International Symposium on Empirical Software Engineering and Measurement},
keywords = {Scrum,large-scale agile software development,release planning,software engineering},
pages = {85--94},
title = {{ScrumBut, but does it matter? A mixed-method study of the planning process of a multi-team scrum organization}},
year = {2013}
}
@inproceedings{me95m,
author = {Menzies, T J and Goss, S},
booktitle = {AI in Defence Workshop, Australian AI'95, also Technical Report TR95-31, Department of Software Development, Monash University},
title = {{Applications of Abduction \#3: ``Black-Box'' to ``Gray-Box'' Model}},
year = {1995}
}
@article{Webb2005a,
author = {Raghavan, Prabhakar and Gehrke, Johannes and Agrawal, Rakesh and Gunopulos, Dimitrios},
doi = {http://dx.doi.org/10.1007/s10618-005-1396-1},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/agrawal05.pdf:pdf},
issn = {1384-5810},
journal = {Data Mining and Knowledge Discovery},
keywords = {clustering,dimensionality reduction,subspace clustering},
number = {1},
pages = {5--33},
title = {{Automatic Subspace Clustering of High Dimensional Data}},
url = {http://dx.doi.org/10.1007/s10618-005-1396-1},
volume = {11},
year = {2005}
}
@article{mckelvey05,
abstract = {Organizational researchers presume Gaussian (normal) distributions, with stable means and finite variances, with appropriate statistics to match. For evidence, study any random sample of current quantitative research papers. It follows that nearly all of our research-based lessons to managers stem from Gaussian-based research. Suppose this premise is mostly wrong. What then?},
author = {McKelvey, B. and Andriani, P.},
doi = {10.1177/1476127005052700},
isbn = {1476-1270},
issn = {1476-1270},
journal = {Strategic Organization},
number = {2},
pages = {219--228},
publisher = {Edward Elgar},
title = {{Why Gaussian statistics are mostly wrong for strategic organization ?}},
url = {http://dx.doi.org/10.1177/1476127005052700},
volume = {3},
year = {2005}
}
@inproceedings{me99k,
abstract = {Knowledge-based engineering and computational intelligence are
expected to become core technologies in the design and manufacturing for
the next generation of space exploration missions. Yet, if one is
concerned with the reliability of knowledge based systems, studies
indicate significant disagreement regarding the amount of testing needed
for system assessment. The sizes of standard black-box test suites are
impracticably large since the black-box approach neglects the internal
structure of knowledge-based systems. On the contrary, practical results
repeatedly indicate that only a few tests are needed to sample the range
of behaviors of a knowledge-based program. In this paper, we model
testing as a search process over the internal state space of the
knowledge-based system. When comparing different test suites, the test
suite that examines larger portion of the state space is considered more
complete. Our goal is to investigate the trade-off between the
completeness criterion and the size of test suites. The results of
testing experiment on tens of thousands of mutants of real-world
knowledge based systems indicate that a very limited gain in
completeness can be achieved through prolonged testing. The use of
simple (or random) search strategies for testing appears to be as
powerful as testing by more thorough search algorithms},
author = {Menzies, T. and Cukic, B.},
booktitle = {Proceedings 11th International Conference on Tools with Artificial Intelligence},
doi = {10.1109/TAI.1999.809838},
isbn = {0-7695-0456-6},
issn = {1082-3409},
title = {{On the sufficiency of limited testing for knowledge based systems}},
year = {1999}
}
@inproceedings{me95c,
author = {Menzies, T J},
booktitle = {Proceedings of AI '95, Australia},
publisher = {World-Scientific},
title = {{\{L\}imits to \{K\}nowledge \{L\}evel-\{B\} \{M\}odeling (and \{KADS\})}},
year = {1995}
}
@inproceedings{raffo05c,
author = {Raffo, D and Menzies, T},
booktitle = {Proceedings of the 6th International Workshop on Software Process Simulation Modeling (ProSim'05)},
title = {{Evaluating the Impact of a New Technology Using Simulation: The Case for Mining Software Repositories}},
year = {2005}
}
@article{harman13,
author = {Harman, M. and Lakhotia, K. and Singer, J. and White, D. and Shin, Y.},
title = {{Cloud engineering is search based optimization too}},
url = {http://eprints.gla.ac.uk/71317/},
year = {2012}
}
@misc{Chib1995a,
abstract = {Abstract We provide a detailed, introductory exposition of the Metropolis-Hastings algorithm, a powerful Markov chain method to simulate multivariate distributions. A simple, intuitive derivation of this method is given along with guidance on implementation. Also discussed are two applications of the algorithm, one for implementing acceptance-rejection sampling when a blanketing function is not available and the other for implementing the algorithm with block-at-a-time scans. In the latter situation, many different algorithms, including the Gibbs sampler, are shown to be special cases of the Metropolis-Hastings algorithm. The methods are illustrated with examples.},
author = {Chib, Siddhartha and Greenberg, Edward},
booktitle = {Journal of the American Statistical Association},
doi = {10.2307/2684568},
file = {:Users/timm/svns/doc/dataFarm/95chibMetropolis.pdf:pdf},
isbn = {00031305},
issn = {00031305},
keywords = {Gibbs sampling,Markov chain Monte Carlo,Multivariate density simulation,Reversible Markov chains},
number = {4},
pages = {327--335},
pmid = {64},
title = {{Understanding the Metropolis-Hastings algorithm}},
url = {http://amstat.tandfonline.com/doi/abs/10.1080/00031305.1995.10476177\#.U5sEzXVdVcY},
volume = {49},
year = {1995}
}
@inproceedings{barr10,
abstract = {This paper discusses the history of IEEE since the formation of American Institute of Electrical Engineers (AIEE) in 1884 to the formation of Institute of Radio Engineers (IRE). There are always new frontiers opening up to be explored, and IEEE, with a wealth of resources in its volunteers and staff and its international membership, will be there to promote technology and support its advancement.},
archivePrefix = {arXiv},
arxivId = {arXiv:0810.3192v3},
author = {Pickering, Alan D. and Cooper, Andrew J. and Smillie, Luke D. and Corr, Philip J.},
booktitle = {Psychologist},
doi = {10.1044/leader.FMP.19082014.10},
eprint = {arXiv:0810.3192v3},
isbn = {0309537045},
issn = {09528229},
month = nov,
number = {1},
pages = {22--25},
pmid = {7818268},
title = {{On the shoulders of giants}},
volume = {26},
year = {2013}
}
@article{shull08,
abstract = {If we're going to have a column about evidence in software engineering, we're going to need to talk about inspections sooner or later. Inspections are among the most mature and perhaps best-studied practices in software engineering. In short, software inspection was one of those rare software engineering innovations that had the ability to effect real process change.},
author = {Shull, Forrest and Seaman, Carolyn},
doi = {10.1109/MS.2008.7},
issn = {07407459},
journal = {IEEE Software},
keywords = {Software inspections},
number = {1},
pages = {88--90},
title = {{Inspecting the history of inspections: An example of evidence-based technology diffusion}},
volume = {25},
year = {2008}
}
@article{Hasselblad1995a,
abstract = {Screening and diagnostic tests are common in the fields of psychology, medicine, and education. Often there are several competing tests, and decisions must be made about the relative accuracy of those tests. This article describes a general measure that can be used for both continuous and dichotomous outcome measures. It is the standardized distance between the means of the 2 populations. For continuous measures, it is the effect size measure. For dichotomous measures, it is proportional to the logarithm of the odds of the sensitivity plus the logarithm of the odds of the specificity. The measure is easily computed for both kinds of outcomes. Properties of this measure are discussed, and examples are given. Ths use of this measure to compare the average performance of different tests is described.},
author = {Hasselblad, V and Hedges, L V},
doi = {10.1037/0033-2909.117.1.167},
file = {:Users/timm/svns/doc/erin/references/ClusterQuality/Hasselblad95.pdf:pdf},
isbn = {0033-2909 (Print)},
issn = {0033-2909},
journal = {Psychological bulletin},
number = {1},
pages = {167--178},
pmid = {7870860},
title = {{Meta-analysis of screening and diagnostic tests.}},
volume = {117},
year = {1995}
}
@inproceedings{cooper01,
author = {{Kendra Cooper Tim Menzies}, Mabo Ito},
booktitle = {UBC ECE tech report},
title = {{Assessment of a Lightweight Formal Method for Specifying and Analyzing Requirements}},
year = {2001}
}
@incollection{hameco95,
abstract = {The field of software visualization (SV) investigates approaches and techniques for static and dynamic graphical representations of algorithms, programs (code), and processed data. SV is concerned primarily with the analysis of programs and their development. The goal is to improve our understanding of inherently invisible and intangible software, particularly when dealing with large information spaces that characterize domains like software maintenance, reverse engineering, and collaborative development. The main challenge is to find effective mappings from different software aspects to graphical representations using visual metaphors. This paper provides an overview of the SV research, describes current research directions, and includes an extensive list of recommended readings.},
author = {Gra\v{c}anin, Denis and Matkovi\'{c}, Kre\v{s}imir and Eltoweissy, Mohamed},
booktitle = {Innov. Syst. Softw. Eng.},
chapter = {Visualisat},
doi = {10.1007/s11334-005-0019-8},
issn = {1614-5046},
keywords = {Software Visualization},
number = {2},
pages = {221--230},
publisher = {World-Scientific},
title = {{Software Visualization}},
url = {http://www.springerlink.com/content/q4r0t56w726620u4/},
volume = {1},
year = {2005}
}
@inproceedings{owen02a,
abstract = { This paper studies how details of a particular model can effect the efficacy of a search for detects. We find that if the test method is fixed, we can identity classes of software that are more or less testable. Using a combination of model mutators and machine learning, we find that we can isolate topological features that significantly change the effectiveness of a defect detection tool. More specifically, we show that for one defect detection tool (a stochastic search engine) applied to a certain representation (finite state machines), we can increase the average odds of finding a defect from 69\% to 91\%. The method used to change those odds is quite general and should apply to other defect detection tools being applied to other representations.},
author = {Owen, D. and Menzies, T. and Cukic, B.},
booktitle = {Proceedings 17th IEEE International Conference on Automated Software Engineering,},
doi = {10.1109/ASE.2002.1115019},
isbn = {0-7695-1736-6},
issn = {1527-1366},
title = {{What makes finite-state models more (or less) testable?}},
year = {2002}
}
@book{Society2008a,
author = {Society, International},
file = {:Users/timm/svns/doc/cost/07Ispahandbook.pdf:pdf},
isbn = {0972020470},
keywords = {Cost Estimating$\backslash$r$\backslash$nParametrics$\backslash$r$\backslash$nCost Analysis},
number = {April},
title = {{Parametric Estimating}},
year = {2008}
}
@inproceedings{me04d,
author = {Owen, D and Menzies, T},
booktitle = {IEEE Trans. Sofw. Eng. (in preperation)},
title = {{Random Serial World Generation}},
year = {2004}
}
@article{krall12,
author = {Krall, Joseph},
doi = {10.4236/jsea.2012.57052},
issn = {1945-3116},
journal = {Journal of Software Engineering and Applications},
number = {07},
pages = {459--466},
title = {{Aspects of Replayability and Software Engineering: Towards a Methodology of Developing Games}},
volume = {05},
year = {2012}
}
@article{5601760,
abstract = {Differential evolution (DE) is arguably one of the most powerful stochastic real-parameter optimization algorithms in current use. DE operates through similar computational steps as employed by a standard evolutionary algorithm (EA). However, unlike traditional EAs, the DE-variants perturb the current-generation population members with the scaled differences of randomly selected and distinct population members. Therefore, no separate probability distribution has to be used for generating the offspring. Since its inception in 1995, DE has drawn the attention of many researchers all over the world resulting in a lot of variants of the basic algorithm with improved performance. This paper presents a detailed review of the basic concepts of DE and a survey of its major variants, its application to multiobjective, constrained, large scale, and uncertain optimization problems, and the theoretical studies conducted on DE so far. Also, it provides an overview of the significant engineering applications that have benefited from the powerful nature of DE.},
author = {Das, Swagatam and Suganthan, Ponnuthurai Nagaratnam},
doi = {10.1109/TEVC.2010.2059031},
file = {:Users/timm/svns/doc/11de-state-of-the-art.pdf:pdf},
isbn = {1089-778X VO  - 15},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Derivative-free optimization,differential evolution (DE),direct search,evolutionary algorithms (EAs),genetic algorithms (GAs),metaheuristics,particle swarm optimization (PSO)},
month = feb,
number = {1},
pages = {4--31},
title = {{Differential evolution: A survey of the state-of-the-art}},
volume = {15},
year = {2011}
}
@article{Storn1999a,
abstract = {A simple optimization procedure for constraint-based problems is
described which works with a simplified cost function or even without
one. The simplification of the problem formulation makes this method
particularly attractive. The new method lends itself to parallel
computation and is well suited for constraint satisfaction, constrained
optimization, and design centering problems. A further asset is its
self-steering property which makes the new method easy to use},
author = {Storn, Rainer},
doi = {10.1109/4235.752918},
file = {:Users/timm/svns/doc/99de.pdf:pdf},
isbn = {1089-778X},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
number = {1},
pages = {22--34},
pmid = {2016},
title = {{System design by constraint adaptation and differential evolution}},
volume = {3},
year = {1999}
}
@article{Lipkin2008a,
abstract = {Increasingly, chemical libraries are being produced which are focused on a biological target or group of related targets, rather than simply being constructed in a combinatorial fashion. A screening collection compiled from such libraries will contain multiple analogues of a number of discrete series of compounds. The question arises as to how many analogues are necessary to represent each series in order to ensure that an active series will be identified. Based on a simple probabilistic argument and supported by in-house screening data, guidelines are given for the number of compounds necessary to achieve a "hit", or series of hits, at various levels of certainty. Obtaining more than one hit from the same series is useful since this gives early acquisition of SAR (structure-activity relationship) and confirms a hit is not a singleton. We show that screening collections composed of only small numbers of analogues of each series are sub-optimal for SAR acquisition. Based on these studies, we recommend a minimum series size of about 200 compounds. This gives a high probability of confirmatory SAR (i.e. at least two hits from the same series). More substantial early SAR (at least 5 hits from the same series) can be gained by using series of about 650 compounds each. With this level of information being generated, more accurate assessment of the likely success of the series in hit-to-lead and later stage development becomes possible.},
author = {Lipkin, Michael J and Stevens, Adrian P and Livingstone, David J and Harris, C John},
doi = {10.2174/138620708784911492},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/LipkinStevens08.pdf:pdf},
isbn = {1386-2073},
issn = {13862073},
journal = {Combinatorial chemistry \& high throughput screening},
keywords = {chemotype,combinatorial chemistry,diversity,hit rate,library size,parallel array,series,structure activity rela-},
number = {6},
pages = {482--493},
pmid = {18673276},
title = {{How large does a compound screening collection need to be?}},
volume = {11},
year = {2008}
}
@inproceedings{me00f,
abstract = {Modern software is often constructed using \&amp;ldquo;spiral
specification\&amp;rdquo;; i.e. the specification is a dynamic document that
is altered by experience with the current version of the system.
Mathematically, many of the sub-tasks within spiral specification belong
to the NP-complete class of tasks. In the traditional view of computer
science, such tasks are fundamentally intractable and only solvable
using incomplete, approximate methods that can be undependable. This
traditional view suggests that we should routinely expect spiral
specification to always be performed very poorly. This paper is an
antidote to such pessimism. Contrary to the traditional view, we can
expect that spiral specification can usually be performed adequately,
providing that analysts augment their current tools with random probing
},
author = {Menzies, T.},
booktitle = {Tenth International Workshop on Software Specification and Design. IWSSD-10 2000},
doi = {10.1109/IWSSD.2000.891157},
isbn = {0-7695-0884-7},
title = {{The complexity of TRMCS-like spiral specification}},
year = {2000}
}
@article{me98b,
abstract = {Situated cognition is not a mere philosophical concern: it has pragmatic implications for current practice in knowledge acquisition. Tools must move from being design-focused to being maintenance-focused. Reuse-based approaches (e.g. using problem-solving methods) will fail unless the reused descriptions can be extensively modified to suit the new situation. Knowledge engineers must model not only descriptions of expert knowledge, but also the environment in which a knowledge base will perform. Descriptions of knowledge must be constantly re-evaluated. This re-evaluation process has implications for assessing representations},
author = {Menzies, T I M},
doi = {10.1006/ijhc.1998.0230},
isbn = {1071-5819},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
number = {6},
pages = {867--893},
title = {{Towards situated knowledge acquisition}},
url = {http://www.sciencedirect.com/science/article/B6WGR-45J548X-6/2/d7a982a694598b232b8c2e7ec4c0263f},
volume = {49},
year = {1998}
}
@inproceedings{me04a,
author = {Menzies, T and Setamanit, S and Raffo, D},
booktitle = {Prosim 2004},
title = {{Data Mining from Process Models}},
year = {2004}
}
@book{dyson12,
abstract = {Legendary historian and philosopher of science George$\backslash$nDyson vividly re-creates the scenes of focused$\backslash$nexperimentation, incredible mathematical insight, and$\backslash$npure creative genius that gave us computers, digital$\backslash$ntelevision, modern genetics, models of stellar$\backslash$nevolution--in other words, computer code. In the 1940s$\backslash$nand '50s, a group of eccentric geniuses--led by John$\backslash$nvon Neumann--gathered at the newly created Institute$\backslash$nfor Advanced Study in Princeton, New Jersey. Their$\backslash$njoint project was the realization of the theoretical$\backslash$nuniversal machine, an idea that had been put forth by$\backslash$nmathematician Alan Turing. This group of brilliant$\backslash$nengineers worked in isolation, almost entirely$\backslash$nindependent from industry and the traditional academic$\backslash$ncommunity. But because they relied exclusively on$\backslash$ngovernment funding, the government wanted its share of$\backslash$nthe results: the computer that they built also led$\backslash$ndirectly to the hydrogen bomb. George Dyson has$\backslash$nuncovered a wealth of new material about this project,$\backslash$nand in bringing the story of these men and women and$\backslash$ntheir ideas to life, he shows how the crucial$\backslash$nadvancements that dominated twentieth-century$\backslash$ntechnology emerged from one computer in one laboratory,$\backslash$nwhere the digital universe as we know it was born.},
author = {Dyson, George},
booktitle = {\{Turing\}'s cathedral: the origins of the digital universe},
doi = {1946...},
isbn = {0-375-42277-3 (hardcover)},
pages = {xxii + 401},
publisher = {Pantheon},
title = {{\{Turing\}'s cathedral: the origins of the digital universe}},
year = {2012}
}
@book{Burnham2011b,
abstract = {CoffeeScript: Accelerated JavaScript Development offers a thorough introduction to this new language, starting from the basics. Youll learn to use time-saving features like list comprehensions and splats, organize your code into modules with extensible classes, and see how to deploy your work to multiple environments. Each chapter is example-driven and includes challenging exercises to push your CoffeeScript know-how further. Through the course of the book, youll build a fast-paced multiplayer word game writing both the client (with jQuery) and server (with Node.js) in CoffeeScript. And because the two languages are so deeply intertwined, youll deepen your understanding of JavaScript along the way. CoffeeScript makes it easier than ever to write powerful, standards-compliant JavaScript code. This book lets you start doing it today.},
author = {Burnham, Trevor},
booktitle = {Managing},
file = {:Users/timm/svns/doc/coffeescript.pdf:pdf},
isbn = {9781934356784},
pages = {136},
title = {{CoffeeScript : Accelerated JavaScript Development}},
url = {http://pragprog.com/book/tbcoffee/coffeescript},
year = {2011}
}
@inproceedings{me03g,
author = {{T. Menzies J. Smith}, D Raffo},
title = {{When is Pair Programming Better?}},
year = {2003}
}
@article{glover86,
abstract = {The general employee scheduling problem extends the standard shift scheduling problem by discarding key limitations such as employee homogeneity and the absence of connections across time period blocks. The resulting increased generality yields a scheduling model that applies to real world problems confronted in a wide variety of areas. The price of the increased generality is a marked increase in size and complexity over related models reported in the literature. The integer programming formulation for the general employee scheduling problem, arising in typical real world settings, contains from one million to over four million zero-one variables. By contrast, studies of special cases reported over the past decade have focused on problems involving between 100 and 500 variables. We characterize the relationship between the general employee scheduling problem and related problems, reporting computational results for a procedure that solves these more complex problems within 98â99\% optimality and runs on a microcomputer. We view our approach as an integration of management science and artificial intelligence techniques. The benefits of such an integration are suggested by the fact that other zero-one scheduling implementations reported in the literature, including the one awarded the Lancaster Prize in 1984, have obtained comparable approximations of optimality only for problems from two to three orders of magnitude smaller, and then only by the use of large mainframe computers.},
author = {Glover, Fred and McMillan, Claude},
doi = {10.1016/0305-0548(86)90050-X},
isbn = {0305-0548},
issn = {03050548},
journal = {Computers \& Operations Research},
number = {5},
pages = {563--573},
title = {{The general employee scheduling problem. An integration of MS and AI}},
volume = {13},
year = {1986}
}
@inproceedings{me96b,
annote = {Available from $\backslash$url\{http:/menzies.us/pdf/96ok.pdf\}},
author = {Menzies, T J},
booktitle = {Ecai '96},
title = {{On the Practicality of Abductive Validation}},
year = {1996}
}
@inproceedings{me10c,
author = {Kocaguneli, Ekrem and Gay, Gregory and Menzies, Tim and Yang, Ye and Keung, Jacky W.},
booktitle = {Proceedings of the IEEE/ACM international conference on Automated software engineering - ASE '10},
doi = {10.1145/1858996.1859061},
isbn = {9781450301169},
pages = {321},
title = {{When to use data from other projects for effort estimation}},
url = {http://portal.acm.org/citation.cfm?doid=1858996.1859061},
year = {2010}
}
@inproceedings{owen03d,
author = {Owen, David and Menzies, Tim and Heimdahl, Mats and Gao, Jimin},
title = {{Finding \{F\}aults \{Q\}uickly in \{F\}ormal \{M\}odels \{U\}sing \{R\}andom \{S\}earch}},
year = {2004}
}
@inproceedings{me00x,
author = {Menzies, T J},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{SE/KE Reuse Research: Common Themes and Empirical Results}},
year = {2002}
}
@inproceedings{stokely09,
abstract = {We present a practical, market-based solution to the resource provisioning problem in a set of heterogeneous resource clusters. We focus on provisioning rather than immediate scheduling decisions to allow users to change long-term job specifications based on market feedback. Users enter bids to purchase quotas, or bundles of resources for long-term use. These requests are mapped into a simulated clock auction which determines uniform, fair resource prices that balance supply and demand. The reserve prices for resources sold by the operator in this auction are set based on current utilization, thus guiding the users as they set their bids towards under-utilized resources. By running these auctions at regular time intervals, prices fluctuate like those in a real-world economy and provide motivation for users to engineer systems that can best take advantage of available resources. These ideas were implemented in an experimental resource market at Google. Our preliminary results demonstrate an efficient transition of users from more congested resource pools to less congested resources. The disparate engineering costs for users to reconfigure their jobs to run on less expensive resource pools was evidenced by the large price premiums some users were willing to pay for more expensive resources. The final resource allocations illustrated how this framework can lead to significant, beneficial changes in user behavior, reducing the excessive shortages and surpluses of more traditional allocation methods.},
author = {Stokely, Murray and Winget, Jim and Keyes, Ed and Grimes, Carrie and Yolken, Benjamin},
booktitle = {IPDPS 2009 - Proceedings of the 2009 IEEE International Parallel and Distributed Processing Symposium},
doi = {10.1109/IPDPS.2009.5160966},
isbn = {9781424437504},
issn = {1530-2075},
pages = {1--8},
title = {{Using a market economy to provision compute resources across planet-wide clusters}},
url = {http://www.stokely.org/papers/google-cluster-auctions.pdf},
year = {2009}
}
@misc{me99i,
annote = {NASA IVV Facility Technical Report},
author = {Menzies, T and Houle, M E and Powell, J},
title = {{RAPTURE/SP2: Efficient Testing of Temporal Properties Without Search Space Explosion}},
year = {1999}
}
@inproceedings{me99g,
author = {Menzies, T and Michael, C C},
booktitle = {SEKE '99, June 17-19, Kaiserslautern, Germany.},
title = {{Fewer Slices of PIE: Optimising Mutation Testing via Abduction}},
year = {1999}
}
@book{jones07,
author = {Jones, C},
publisher = {McGraw-Hill},
title = {{Estimating Software Costs, 2nd Edition}},
year = {2007}
}
@article{me13d,
abstract = {Background: Given information on just a few prior projects, how do we learn the best and fewest changes for current projects? Aim: To conduct a case study comparing two ways to recommend project changes. 1) Data farmers use Monte Carlo sampling to survey and summarize the space of possible outcomes. 2) Case-based reasoners (CBR) explore the neighborhood around test instances. Method: We applied a state-of-the data farmer (SEESAW) and a CBR tool ()'V2) to software project data. Results: CBR with )'V2 was more effective than SEESAW's data farming for learning best and recommended project changes, effectively reducing runtime, effort, and defects. Further, CBR with )'V2 was comparably easier to build, maintain, and apply in novel domains, especially on noisy data sets. Conclusion: Use CBR tools like )'V2 when data are scarce or noisy or when project data cannot be expressed in the required form of a data farmer. Future Work: This study applied our own CBR tool to several small data sets. Future work could apply other CBR tools and data farmers to other data (perhaps to explore other goals such as, say, minimizing maintenance effort).},
author = {Menzies, T and Brady, a and Keung, J and Hihn, J and Williams, S and El-Rawas, O and Green, P and Boehm, B},
doi = {10.1109/TSE.2013.43},
isbn = {0098-5589 VO  - 39},
issn = {0098-5589},
journal = {Software Engineering, IEEE Transactions on},
keywords = {CBR,COCOMO,Data models,Mathematical model,Monte Carlo methods,Monte Carlo sampling,Project management,SEESAW,Search methods,Search-based software engineering,Software engineering,case-based reasoning,data farming,data handling,learning (artificial intelligence),project management,project management decision learning,sampling methods,software management,software project data},
number = {12},
pages = {1698--1713},
title = {{Learning Project Management Decisions: A Case Study with Case-Based Reasoning versus Data Farming}},
volume = {39},
year = {2013}
}
@inproceedings{sayyad12,
abstract = {Feature Models are popular tools for describing software product lines. Analysis of feature models has traditionally focused on consistency checking (yielding a yes/no answer) and product selection assistance, interactive or offline. In this paper, we describe a novel approach to identify the most critical decisions in product selection/configuration by taking advantage of a large pool of randomly generated, generally inconsistent, product variants. Range Ranking, a data mining technique, is utilized to single out the most critical design choices, reducing the job of the human designer to making less consequential decisions. A large feature model is used as a case study; we show preliminary results of the new approach to illustrate its usefulness for practical product derivation.},
author = {Sayyad, Abdel Salam and Ammar, Hany and Menzies, Tim},
booktitle = {2012 3rd International Workshop on Recommendation Systems for Software Engineering, RSSE 2012 - Proceedings},
doi = {10.1109/RSSE.2012.6233409},
isbn = {9781467317597},
keywords = {Feature Models,design decisions,range ranking},
pages = {47--51},
title = {{Software feature model recommendations using data mining}},
year = {2012}
}
@inproceedings{cormode05,
author = {Cormode, Graham and Korn, Flip and Muthukrishnan, S and Srivastava, Divesh},
booktitle = {Proceedings of the 21st International Conference on Data Engineering},
issn = {1084-4627},
pages = {20--31},
series = {ICDE '05},
title = {{Effective computation of biased quantiles over data streams Data Engineering, 2005. ICDE 2005. Proceedings. 21st International Conference on}},
year = {2005}
}
@misc{boehm09a,
annote = {Keynote address, PROMISE'09},
author = {Boehm, B},
title = {{No Title}},
year = {2009}
}
@article{tosun2010,
author = {Tosun, A and Bener, A and Turhan, B and Menzies, T},
title = {{No Title}}
}
@misc{me02j,
author = {T.Menzies},
institution = {Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{V and V of adaptive systems}},
year = {2002}
}
@inproceedings{me00u,
author = {Menzies, T and Singh, H},
booktitle = {Advances in Artificial Intelligence, 14th Biennial Conference of the Canadian Society for Computational Studies of Intelligence, AI 2001, Ottawa, Canada, June 7-9, 2001, Proceedings},
pages = {100--110},
title = {{How AI Can Help SE; or: Randomized Search Not Considered Harmful}},
year = {2001}
}
@inproceedings{owen03a,
abstract = {Formal methods, including model checking, is pow- erful but can be costly, in terms of memory, time, and modeling effort. Difficult problems, similar to the verification problem addressed by model checking, have been shown to exhibit a phase transition, suggesting that an easy range of problem instances might be solved much faster and with much less memory using a new type of model checker based on partial, random search. Here we compare the performance of Lurch, our pro- totype random search model checker, to the popular tools SMV and SPIN. The toolsâ performance is com- pared for a range of randomly generated models based on a simple tic-tac-toe game. Our results suggest that Lurch might be used in place of existing tools for sys- tems too large or too difficult to model small enough for conventional model checking.},
author = {Owen, David and Menzies, Tim},
booktitle = {Proc. of the 15th International Conference on Software Engineering \& Knowledge Engineering (SEKE 2003)},
pages = {158--165},
title = {{Lurch: a Lightweight Alternative to Model Checking}},
year = {2003}
}
@inproceedings{owen01,
author = {Owen, D and Menzies, T},
booktitle = {Proceedings of the First International Workshop on Model-based Requirements Engineering},
title = {{Random Search of AND-OR Graphs Representing Finite-State Models}},
year = {2001}
}
@inproceedings{me09k,
abstract = {Concept location is a critical activity during software evolution as it produces the location where a change is to start in response to a modification request, such as, a bug report or a new feature request. Lexical-based concept location techniques rely on matching the text embedded in the source code to queries formulated by the developers. The efficiency of such techniques is strongly dependent on the ability of the developer to write good queries. We propose an approach to augment information retrieval (IR) based concept location via an explicit relevance feedback (RF) mechanism. RF is a two-part process in which the developer judges existing results returned by a search and the IR system uses this information to perform a new search, returning more relevant information to the user. A set of case studies performed on open source software systems reveals the impact of RF on IR based concept location.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09irrf.pdf\}},
author = {Gay, Gregory and Haiduc, Sonia and Marcus, Andrian and Menzies, Tim},
booktitle = {IEEE International Conference on Software Maintenance, ICSM},
doi = {10.1109/ICSM.2009.5306315},
isbn = {9781424448289},
issn = {1063-6773},
pages = {351--360},
title = {{On the use of relevance feedback in IR-based concept location}},
year = {2009}
}
@article{Menzies2013c,
author = {Menzies, Tim and Butcher, Andrew and Cok, David},
doi = {http://dx.doi.org/10.1109/TSE.2012.83},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/gense-v13.pdf:pdf},
journal = {Software Engineering, IEEE Transactions on},
number = {6},
pages = {822 -- 834},
title = {{Local versus Global Lessons for Defect Prediction and Effort Estimation}},
volume = {39},
year = {2013}
}
@inproceedings{me00x,
author = {Menzies, T J},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{SE/KE Reuse Research: Common Themes and Empirical Results}},
year = {2002}
}
@article{knowles06,
abstract = { This paper concerns multiobjective optimization in scenarios where each solution evaluation is financially and/or temporally expensive. We make use of nine relatively low-dimensional, nonpathological, real-valued functions, such as arise in many applications, and assess the performance of two algorithms after just 100 and 250 (or 260) function evaluations. The results show that NSGA-II, a popular multiobjective evolutionary algorithm, performs well compared with random search, even within the restricted number of evaluations used. A significantly better performance (particularly, in the worst case) is, however, achieved on our test set by an algorithm proposed herein-ParEGO-which is an extension of the single-objective efficient global optimization (EGO) algorithm of Jones et al. ParEGO uses a design-of-experiments inspired initialization procedure and learns a Gaussian processes model of the search landscape, which is updated after every function evaluation. Overall, ParEGO exhibits a promising performance for multiobjective optimization problems where evaluations are expensive or otherwise restricted in number.},
author = {Knowles, Joshua},
doi = {10.1109/TEVC.2005.851274},
isbn = {1089-778X VO - 10},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Design and analysis of computer experiments (DACE),Efficient global optimization (EGO),Expensive black-box functions,Kriging,Landscape approximation,Nondominated sorting genetic algorithm II (NSGA-II,Pareto optima,Performance assessment,Response surfaces,Test suites},
number = {1},
pages = {50--66},
title = {{ParEGO: A hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems}},
volume = {10},
year = {2006}
}
@inproceedings{sayyad13b,
abstract = {Software product lines are hard to configure. Techniques that work for medium sized product lines fail for much larger product lines such as the Linux kernel with 6000+ features. This paper presents simple heuristics that help the Indicator-Based Evolutionary Algorithm (IBEA) in finding sound and optimum configurations of very large variability models in the presence of competing objectives. We employ a combination of static and evolutionary learning of model structure, in addition to utilizing a pre-computed solution used as a âseedâ in the midst of a randomly-generated initial population. The seed solution works like a single straw that is enough to break the camel's back -given that it is a feature-rich seed. We show promising results where we can find 30 sound solutions for configuring upward of 6000 features within 30 minutes.},
author = {Sayyad, Abdel Salam and Ingram, Joseph and Menzies, Tim and Ammar, Hany},
booktitle = {2013 28th IEEE/ACM International Conference on Automated Software Engineering, ASE 2013 - Proceedings},
doi = {10.1109/ASE.2013.6693104},
isbn = {9781479902156},
keywords = {SMT solvers,Variability models,automated configuration,evolutionary algorithms,multiobjective optimization},
pages = {465--474},
title = {{Scalable product line configuration: A straw to break the camel's back}},
year = {2013}
}
@inproceedings{me05b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05sawtooth.pdf\}},
author = {Menzies, Tim},
number = {August},
pages = {1--6},
title = {{Incremental Discretization and Bayes Classifiers Handles Concept Drift and Scales Very Well}},
volume = {X},
year = {2005}
}
@misc{xie09,
author = {Xie, Tao},
title = {{\{NSF\} career award, \{C\}ooperative \{D\}eveloper \{T\}esting with \{T\}est \{I\}ntentions, http://goo.gl/ytw3g}},
year = {2009}
}
@inproceedings{madachy11,
abstract = {General software cost parameters such as size, effort distribution, and productivity are necessarily imprecise due to variations by domain. To improve this situation, empirical software cost analysis using the primary US DoD cost database has been segmented by domain. This analysis supports a software cost estimation metrics manual for improvements in acquisition policies, procedures and tools. We have addressed the challenges of consistent data definitions and taxonomies across diverse stakeholder communities, data integrity, data formats, and others. We highlight example analysis results from an application domain demonstrating cost estimating relationships, benchmarks on reuse parameters and effort distributions for estimators to use.},
author = {Madachy, Raymond and Boehm, Barry and Clark, Brad and Tan, Thomas and Rosa, Wilson},
booktitle = {2011 International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2011.56},
isbn = {978-0-7695-4604-9},
issn = {1938-6451},
keywords = {Department of Defense,software cost estimation,software cost models,software metrics,software productivity},
pages = {392--395},
title = {{US DoD Application Domain Empirical Software Cost Analysis}},
year = {2011}
}
@inproceedings{cora10,
author = {Corazza, a. and Martino, S. and Ferrucci, F. and Gravino, C. and Sarro, F. and Mendes, E.},
booktitle = {Empirical Software Engineering},
doi = {10.1007/s10664-011-9187-3},
isbn = {9781450304047},
issn = {1382-3256},
pages = {4:1----4:10},
series = {PROMISE '10},
title = {{Using tabu search to configure support vector regression for effort estimation}},
year = {2011}
}
@inproceedings{me95za,
author = {Menzies, Tim},
booktitle = {Proceedings of the Melbourne Workshop on Intelligent Decision Support Department of Information Systems Monash University, Caulfield Campus, Melbourne Monday, March 20, 1995},
pages = {1--13},
title = {{Applications of Abduction \# 1 : Intelligent Decision Support Systems 1 Introduction}},
year = {1995}
}
@inproceedings{fea01,
author = {Feather, M and In, H and Kiper, J and Kurtz, J and Menzies, T},
booktitle = {ECE UBC tech report},
title = {{First Contract: Better, Earlier Decisions for Software Projects}},
year = {2001}
}
@inproceedings{me97o,
author = {Menzies, T and Cohen, Rf and Waugh, S},
booktitle = {11th Banff Knowledge Acquisition for \ldots},
title = {{Evaluating conceptual modeling languages}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.28.492\&rep=rep1\&type=pdf},
year = {1998}
}
@article{tosun2010,
author = {Tosun, A and Bener, A and Turhan, B and Menzies, T},
title = {{No Title}}
}
@inproceedings{harman10,
author = {Harman, M},
booktitle = {PROMISE},
doi = {10.1145/1868328.1868330},
isbn = {978-1-4503-0404-7},
pages = {1},
title = {{The relationship between search based software engineering and predictive modeling}},
url = {http://discovery.ucl.ac.uk/1302023/},
year = {2010}
}
@article{Rossum2003a,
abstract = {"Python is a simple, yet powerful programming language that bridges the gap between C and shell programming, and is thus ideally suited for `throw-away programming' and rapid prototyping. Its syntax is put together from constructs borrowed from a variety of other languages; most prominent are influences from ABC, C, Modula-3 and Icon. The Python interpreter is easily extended with new functions and data types implemented in C. Python is also suitable as an extension language for highly customizable C applications such as editors or window managers. Python is available for various operating systems, amongst which several flavors of UNIX, Amoeba, the Apple Macintosh O.S., and MS-DOS. This tutorial introduces the reader informally to the basic concepts and features of the Python language and system. It helps to have a Python interpreter handy for hands-on experience, but as the examples are self-contained, the tutorial can be read off-line as well. For a description of standard objects and modules, see the Python Library Reference manual. The Python Reference Manual gives a more formal definition of the language."},
author = {Rossum, Guido Van and Drake, Fred L},
file = {:Users/timm/svns/doc/pythonVanRossum.pdf:pdf},
journal = {Python},
number = {10},
pages = {1600--1600},
title = {{Python Tutorial}},
volume = {206},
year = {2003}
}
@article{Menzies2006,
abstract = {Effort estimation often requires generalizing from a small number of historical projects. Generalization from such limited experience is an inherently underconstrained problem. Hence, the learned effort models can exhibit large deviations that prevent standard statistical methods (e.g., t-tests) from distinguishing the performance of alternative effort-estimation methods. The COSEEKMO effort-modeling workbench applies a set of heuristic rejection rules to comparatively assess results from alternative models. Using these rules, and despite the presence of large deviations, COSEEKMO can rank alternative methods for generating effort models. Based on our experiments with COSEEKMO, we advise a new view on supposed "best practices" in model-based effort estimation: 1) Each such practice should be viewed as a candidate technique which may or may not be useful in a particular domain, and 2) tools like COSEEKMO should be used to help analysts explore and select the best method for a particular domain},
author = {Menzies, Tim and Chen, Zhihao and Hihn, Jairus and Lum, Karen},
doi = {10.1109/TSE.2006.114},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Menzies et al. - 2006 - Selecting Best Practices for Effort Estimation.pdf:pdf},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {COCOMO,Data mining,Deviation,Model-based effort estimation},
number = {11},
pages = {883--895},
title = {{Selecting best practices for effort estimation}},
volume = {32},
year = {2006}
}
@article{me13a,
abstract = {Background: Do we always need complex methods for software effort estimation (SEE)? Aim: To characterize the essential content of SEE data, i.e., the least number of features and instances required to capture the information within SEE data. If the essential content is very small, then 1) the contained information must be very brief and 2) the value added of complex learning schemes must be minimal. Method: Our QUICK method computes the euclidean distance between rows (instances) and columns (features) of SEE data, then prunes synonyms (similar features) and outliers (distant instances), then assesses the reduced data by comparing predictions from 1) a simple learner using the reduced data and 2) a state-of-the-art learner (CART) using all data. Performance is measured using hold-out experiments and expressed in terms of mean and median MRE, MAR, PRED(25), MBRE, MIBRE, or MMER. Results: For 18 datasets, QUICK pruned 69 to 96 percent of the training data (median = 89 percent). K = 1 nearest neighbor predictions (in the reduced data) performed as well as CART's predictions (using all data). Conclusion: The essential content of some SEE datasets is very small. Complex estimation methods may be overelaborate for such datasets and can be simplified. We offer QUICK as an example of such a simpler SEE method.},
author = {Kocaguneli, Ekrem and Menzies, Tim and Keung, Jacky and Cok, David and Madachy, Ray},
doi = {10.1109/TSE.2012.88},
file = {:Users/timm/svns/doc/cost/13quick.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Software cost estimation,active learning,analogy,k-NN},
number = {8},
pages = {1040--1053},
title = {{Active Learning and effort estimation: Finding the essential content of software effort estimation data}},
volume = {39},
year = {2013}
}
@inproceedings{men87,
author = {Menzies, T J and Worral, C},
booktitle = {Proceedings of AI '87},
title = {{Worlds in Prolog}},
year = {1987}
}
@inproceedings{buse12,
abstract = {Software development is a data rich activity with many sophisticated metrics. Yet engineers often lack the tools and techniques necessary to leverage these potentially powerful information resources toward decision making. In this paper, we present the data and analysis needs of professional software engineers, which we identified among 110 developers and managers in a survey. We asked about their decision making process, their needs for artifacts and indicators, and scenarios in which they would use analytics. The survey responses lead us to propose several guidelines for analytics tools in software development including: Engineers do not necessarily have much expertise in data analysis; thus tools should be easy to use, fast, and produce concise output. Engineers have diverse analysis needs and consider most indicators to be important; thus tools should at the same time support many different types of artifacts and many indicators. In addition, engineers want to drill down into data based on time, organizational structure, and system architecture.},
author = {Buse, Raymond P L and Zimmermann, Thomas},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2012.6227122},
isbn = {9781467310673},
issn = {02705257},
pages = {987--996},
title = {{Information needs for software development analytics}},
year = {2012}
}
@article{Chen2007b,
abstract = {Systematic evolution of ligands by exponential enrichment (SELEX) is an important technology in combinatorial chemistry and molecular biology of developing high affinity target-binding molecules (aptamers) from highly complex nucleic acid ligand libraries. Schematically, the SELEX is a series of iterative rounds of operations where in each operational round ligands are incubated with the target (e.g., a purified protein), and target-binding ligands are extracted and amplified. In the recent development of biological study and drug discovery, by incubating ligand libraries with complex target mixtures (e.g., cell fragments), the SELEX experiments have been explored to simultaneously develop aptamers for targets embedded in target mixtures: the complex SELEX. While holding the considerable advantages of saving experimental resources, practicing the complex SELEX has often accompanied with unstable experimental performances. It is therefore important to understand the behaviors of the new application. In this paper, we develop stochastic computer model, and customized computational algorithm to numerically mimic the complex SELEX. We model the ligand selection through the probability of ligand binding to complex targets at the binding equilibrium, and efficiency of separating target-binders for amplification. The customized computational algorithm allows us to simulate real experiments that operate on huge ligand libraries. We evaluate the ligand evolution, and aptamer enrichment of complex SELEX under various experimental conditions by stochastic simulations, and theorize the simulated results. We argue that the stochastic effects, which were not previously captured in the studies of complex SELEX, may significantly affect the results of experiments. ?? 2007 Elsevier Ireland Ltd. All rights reserved.},
author = {Chen, Chi K.},
doi = {10.1016/j.cmpb.2007.05.008},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Chen07.pdf:pdf},
isbn = {0169-2607},
issn = {01692607},
journal = {Computer Methods and Programs in Biomedicine},
keywords = {Aptamer,Complex SELEX,Simulations,Stochastic computer model},
number = {3},
pages = {189--200},
pmid = {17624471},
title = {{Complex SELEX against target mixture: Stochastic computer model, simulation, and analysis}},
volume = {87},
year = {2007}
}
@article{Oduguwaa,
author = {Oduguwa, Abiola and Tiwari, Ashutosh and Roy, Rajkumar and Bessant, Conrad},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Oduguwa.pdf:pdf},
keywords = {bioinformatics,chemoinformatics,drug discovery,fuzzy,genetic algorithm,logic,neural networks},
title = {{An Overview of Soft Computing Techniques Used in the Drug Discovery Process}}
}
@article{Hqa,
author = {Hq, By Nasa and Analysis, Program and Division, Cost Analysis and Policy, J C L and Level, Joint Confidence},
file = {:Users/timm/svns/doc/cost/JCLFaq.pdf:pdf},
title = {{Joint Confidence Level ( JCL ) FAQ}}
}
@inproceedings{Haiduc2013a,
abstract = {There are more than twenty distinct software engineering tasks addressed with text retrieval (TR) techniques, such as, traceability link recovery, feature location, refactoring, reuse, etc. A common issue with all TR applications is that the results of the retrieval depend largely on the quality of the query. When a query performs poorly, it has to be reformulated and this is a difficult task for someone who had trouble writing a good query in the first place. We propose a recommender (called Refoqus) based on machine learning, which is trained with a sample of queries and relevant results. Then, for a given query, it automatically recommends a reformulation strategy that should improve its performance, based on the properties of the query. We evaluated Refoqus empirically against four baseline approaches that are used in natural language document retrieval. The data used for the evaluation corresponds to changes from five open source systems in Java and C++ and it is used in the context of TR-based concept location in source code. Refoqus outperformed the baselines and its recommendations lead to query performance improvement or preservation in 84\% of the cases (in average).},
address = {San Francisco, USA},
annote = {Laura. Fixed on 10/16/2012 (missing fields - submitted)},
author = {Haiduc, Sonia and Bavota, Gabriele and Marcus, Andrian and Oliveto, Rocco and {De Lucia}, Andrea and Menzies, Tim},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2013.6606630},
isbn = {9781467330763},
issn = {02705257},
keywords = {Query Reformulation,Text Retrieval},
pages = {842--851},
title = {{Automatic query reformulations for text retrieval in software engineering}},
year = {2013}
}
@inproceedings{men92s,
author = {Menzies, Tim and Compton, Paul and Feldman, Bart and Toth, Thomas},
booktitle = {AAAI Techical Report},
title = {{Qualitative Compartmental Modelling}},
volume = {SS-92-02},
year = {1992}
}
@inproceedings{me09j,
abstract = {This paper augments Boehm-Turner's model of agile and plan-based software development augmented with an AI search algorithm. The AI search finds the key factors that predict for the success of agile or traditional plan-based software developments. According to our simulations and AI search algorithm: (1) in no case did agile methods perform worse than plan-based approaches; (2) in some cases, agile performed best. Hence, we recommend that the default development practice for organizations be an agile method. The simplicity of this style of analysis begs the question: why is so much time wasted on evidence-less debates on software process when a simple combination of simulation plus automatic search can mature the dialog much faster?},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09pom2.pdf\}},
author = {Lemon, Bryan and Riesbeck, Aaron and Menzies, Tim and Price, Justin and D\&apos;Alessandro, Joseph and Carlsson, Rikard and Prifiti, Tomi and Peters, Fayola and Lu, Hiuhua and Port, Dan},
booktitle = {ASE2009 - 24th IEEE/ACM International Conference on Automated Software Engineering},
doi = {10.1109/ASE.2009.42},
isbn = {9780769538914},
issn = {1527-1366},
pages = {580--584},
title = {{Applications of simulation and AI search: Assessing the relative merits of agile vs traditional software development}},
year = {2009}
}
@article{me99q,
abstract = {Small-scale software projects usually can't afford to implement
time-consuming and expensive tests. However, the authors show that, in a
surprisingly large number of cases, a small number of randomly selected
tests will adequately probe the software},
author = {Menzies, T. and Gukic, B.},
doi = {10.1109/52.877876},
issn = {0740-7459},
journal = {IEEE Software},
number = {5},
pages = {107--112},
title = {{When to test less [software testing]}},
volume = {17},
year = {2000}
}
@inproceedings{me04d,
author = {Owen, D and Menzies, T},
booktitle = {IEEE Trans. Sofw. Eng. (in preperation)},
title = {{Random Serial World Generation}},
year = {2004}
}
@article{Tarasov2009a,
abstract = {To estimate how sophisticated should an empirical scoring function be to ensure successful docking, scoring and virtual screening a new scoring function NScore (naive score) has been developed and tested. NScore is an extremely simple function and has the minimum possible number of parameters; nevertheless, it allows all the main effects determining the ligand-protein interaction to be taken into account. The fundamental difference of NScore from the currently used empirical functions is that all its parameters are selected on the basis of general physical considerations, without any adjustment or training with the use of experimental data on ligand-protein interaction. The results of docking and scoring with the use of NScore in an independent test sets of proteins and ligands have proved to be as good as those yielded by the ICM, GOLD, and Glide software packages, which use sophisticated empirical scoring functions. With respect to some parameters, the results of docking with the use of NScore are even better than those obtained using other functions. Since no training set is used in the development of NScore, this scoring function is indeed versatile in that it does not depend on the specific goal or target. We have performed virtual screening for ten targets and obtained results almost as good as those yielded by the Glide and better than GOLD and DOCK software.},
author = {Tarasov, Dmitry and Tovbin, Dmitry},
doi = {10.1007/s00894-008-0390-0},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Tarasov2008.pdf:pdf},
isbn = {0948-5023 (Electronic)},
issn = {16102940},
journal = {Journal of Molecular Modeling},
keywords = {Docking,Interaction,Ligand-protein,New scoring function NScore,Scoring,Virtual screening},
number = {3},
pages = {329--341},
pmid = {19066998},
title = {{How sophisticated should a scoring function be to ensure successful docking, scoring and virtual screening?}},
volume = {15},
year = {2009}
}
@article{Hoigaard2011a,
author = {Hoigaard, E},
file = {:Users/timm/svns/doc/coffeescriptSmooth.pdf:pdf},
pages = {214},
title = {{Smooth CoffeeScript}},
year = {2011}
}
@article{jorgensen06,
abstract = {The Standish Group reported in their 1994 CHAOS report that the average cost overrun of software projects was as high as 189\%. This figure for cost overrun is referred to frequently by scientific researchers, software process improvement consultants, and government advisors. In this paper, we review the validity of the Standish Group's 1994 cost overrun results. Our review is based on a comparison of the 189\% cost overrun figure with the cost overrun figures reported in other cost estimation surveys, and an examination of the Standish Group's survey design and analysis methods. We find that the figure reported by the Standish Group is much higher than those reported in similar estimation surveys and that there may be severe problems with the survey design and methods of analysis, e.g. the population sampling method may be strongly biased towards 'failure projects'. We conclude that the figure of 189\% for cost overruns is probably much too high to represent typical software projects in the 1990s and that a continued use of that figure as a reference point for estimation accuracy may lead to poor decision making and hinder progress in estimation practices. Â© 2005 Elsevier Ltd. All rights reserved.},
author = {J\o rgensen, Magne and Mol\o kken-\O stvold, Kjetil},
doi = {10.1016/j.infsof.2005.07.002},
isbn = {0950-5849},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Research method,Software cost estimation,Survey review},
number = {4},
pages = {297--301},
title = {{How large are software cost overruns? A review of the 1994 CHAOS report}},
volume = {48},
year = {2006}
}
@article{Brin1997a,
abstract = {We consider the problem of analyzing market-basket data and present several important contributions. First, we present a new algorithm for nding large itemsets which uses fewer passes over the data than classic algorithms, and yet uses fewer candidate itemsets than methods based on sampling. We investigate the idea of item reordering, which can im- prove the low-level e ciency of the algorithm. Second, we present a new way of generating $\backslash$implication rules," which are normalized based on both the antecedent and the con- sequent and are truly implications (not simply a measure of co-occurrence), and we show how they produce more in- tuitive results than other methods. Finally, we show how di erent characteristics of real data, as opposed to synthetic data, can dramatically a ect the performance of the system and the form of the results.},
author = {Brin, Sergey and Motwani, Rajeev and Ullman, Jeffrey D. and Tsur, Shalom},
doi = {10.1145/253262.253325},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/brin97.pdf:pdf},
isbn = {0897919114},
issn = {01635808},
journal = {ACM SIGMOD Record},
number = {2},
pages = {255--264},
title = {{Dynamic itemset counting and implication rules for market basket data}},
volume = {26},
year = {1997}
}
@article{me12e,
abstract = {The goal of science is conclusion stability, i.e. to discover some effect X that holds in multiple situations. Sadly, there are all too few examples of stable conclusions in software engineering (SE). In fact, the typical result is conclusion instability where what is true for project one, does not hold for project two. We can find numerous studies of the following form: there is as much evidence for as against the argument that some aspect X adds value to a software project. Below are four examples of this type of problem which we believe to be endemic within SE.},
author = {Menzies, Tim and Shepperd, Martin},
doi = {10.1007/s10664-011-9193-5},
issn = {13823256},
journal = {Empirical Software Engineering},
number = {1-2},
pages = {1--17},
title = {{Special issue on repeatable results in software engineering prediction}},
volume = {17},
year = {2012}
}
@inproceedings{me04g,
author = {Menzies, Tim and DiStefano, J and Orrego, Andres S and Chapman, Robert},
booktitle = {Proceedings of the Workshop on Predictive Software Models},
title = {{Assessing predictors of software defects}},
year = {2004}
}
@inproceedings{owen2b,
abstract = { In the development of high-assurance systems, formal modeling, analysis and verification techniques are playing an increasingly important role. In spite of significant advances, formal modeling and verification using model checking, still suffer from limited applicability. The main reason is the exponential runtime space growth exhibited, in the general case, by model checkers. We describe a less rigorous alternative to model checking. We propose an algorithm that automatically translates finite state machine models used by model checkers into a variation of AND-OR graphs. State space verification of AND-OR graphs does not suffer from state space explosion, but its exhaustive search is an NP complete problem. Hence, we demonstrate that random search of AND-OR graphs is a viable alternative to model checking, suitable for system debugging and fast analysis during system development. We support our conclusions through the studies of two models, Dekker's two process mutual exclusion algorithm and the Space Shuttle's liquid hydrogen subsystem.},
author = {Owen, D. and Cukic, B. and Menzies, T.},
booktitle = {7th IEEE International Symposium on High Assurance Systems Engineering, 2002. Proceedings.},
doi = {10.1109/HASE.2002.1173112},
isbn = {0-7695-1769-2},
issn = {1530-2059},
pages = {119},
title = {{An alternative to model checking: verification by random search of AND-OR graphs representing finite-state models}},
volume = {1},
year = {2002}
}
@article{me99m,
author = {Menzies, T and van Harmelen, Frank},
doi = {10.1006/ijhc.1999.0336},
issn = {1071-5819},
journal = {International Journal of HumanComputer Studies special issue on evaluation of Knowledge Engineering Techniques},
month = oct,
number = {4},
pages = {717--727},
title = {{Editorial: Evaluating Knowledge Engineering Techniques}},
volume = {51},
year = {1999}
}
@article{Sweeney02,
abstract = {Consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. Suppose the data holder wants to share a version of the data with researchers. How can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? The solution provided in this paper includes a formal protection model named k -anonymity and a set of accompanying policies for deployment. A release provides k -anonymity protection if the information for each person contained in the release cannot be distinguished from at least k -1 individuals whose information also appears in the release. This paper also examines re-identification attacks that can be realized on releases that adhere to k - anonymity unless accompanying policies are respected. The k -anonymity protection model is important because it forms the basis on which the real-world systems known as Datafly, Âµ-Argus and k -Similar provide guarantees of privacy protection.},
archivePrefix = {arXiv},
arxivId = {10(5),2002;555-570},
author = {Sweeney, Latanya},
doi = {10.1142/S0218488502001648},
eprint = {10(5),2002;555-570},
isbn = {0218-4885},
issn = {0218-4885},
journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
number = {05},
pages = {557--570},
title = {{k-ANONYMITY: A MODEL FOR PROTECTING PRIVACY}},
volume = {10},
year = {2002}
}
@misc{bsc99,
author = {Page, Web},
title = {{No Title}}
}
@inproceedings{macdonell10a,
abstract = {BACKGROUND: In reality project managers are constrained by the incremental nature of data collection. Specifically, project observations are accumulated one project at a time. Likewise within-project data are accumulated one stage or phase at a time. However, empirical researchers have given limited attention to this perspective. PROBLEM: Consequently, our analyses may be biased. On the one hand, our predictions may be optimistic due to the availability of the entire data set, but on the other hand pessimistic due to the failure to capitalize upon the temporal nature of the data. Our goals are (i) to explore the impact of ignoring time when building cost prediction models and (ii) to show the benefits of re-estimating using completed phase data during a project. METHOD: Using a small industrial data set of sixteen software projects from a single organization we compare predictive models developed using a time-aware approach with a more traditional leave-one-out analysis. We then investigate the impact of using requirements, design and implementation phase data on estimating subsequent phase effort. RESULTS: First, we find that failure to take the temporal nature of data into account leads to unreliable estimates of their predictive efficacy. Second, for this organization, prior-phase effort data could be used to improve the management of subsequent process tasks. CONCLUSION: We should collect time-related data and use it in our analyses. Failure to do so may lead to incorrect conclusions being drawn, and may also inhibit industrial take up of our research work.},
author = {MacDonell, Stephen G. and Shepperd, Martin},
booktitle = {Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement - ESEM '10},
doi = {10.1145/1852786.1852828},
isbn = {9781450300391},
keywords = {effort prediction,empirical analysis,phase data,software project management,time series},
pages = {1},
series = {ESEM '10},
title = {{Data accumulation and software effort prediction}},
url = {http://dl.acm.org/citation.cfm?id=1852786.1852828},
year = {2010}
}
@inproceedings{Grechanik10,
abstract = {Database-centric applications (DCAs) are common in enterprise computing, and they use nontrivial databases. Testing of DCAs is increasingly outsourced to test centers in order to achieve lower cost and higher quality. When releasing proprietary DCAs, its databases should also be made available to test engineers, so that they can test using real data. Testing with real data is important, since fake data lacks many of the intricate semantic connections among the original data elements. However, different data privacy laws prevent organizations from sharing these data with test centers because databases contain sensitive information. Currently, testing is performed with fake data that often leads to worse code coverage and fewer uncovered bugs, thereby reducing the quality of DCAs and obliterating benefits of test outsourcing. We show that a popular data anonymization algorithm called k-anonymity seriously degrades test coverage of DCAs. We propose an approach that uses program analysis to guide selective application of k-anonymity. This approach helps protect sensitive data in databases while retaining testing efficacy. Our results show that for small values of k = 7, test coverage drops to less than 30\% from the original coverage of more than 70\%, thus making it difficult to achieve good quality when testing DCAs while applying data privacy.},
author = {Grechanik, Mark and Csallner, Christoph and Fu, Chen and Xie, Qing},
booktitle = {Proceedings - International Symposium on Software Reliability Engineering, ISSRE},
doi = {10.1109/ISSRE.2010.13},
isbn = {9780769542553},
issn = {10719458},
pages = {368--377},
title = {{Is data privacy always good for software testing?}},
year = {2010}
}
@article{Boraso1996a,
author = {Boraso, M and Montangero, C and Sedehi, H},
file = {:Users/timm/svns/doc/cost/96Boraso.pdf:pdf},
title = {{Software cost estimation: An experimental study of model performances}},
year = {1996}
}
@misc{schw02,
author = {Schwaber, Ken},
title = {{No Title}},
year = {2002}
}
@inproceedings{me97o,
author = {Menzies, T and Cohen, Rf and Waugh, S},
booktitle = {11th Banff Knowledge Acquisition for \ldots},
title = {{Evaluating conceptual modeling languages}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.28.492\&rep=rep1\&type=pdf},
year = {1998}
}
@inproceedings{me96f,
author = {Menzies, T J and Goss, S},
booktitle = {Proceedings PKAW '96: Pacific Knowledge Acquisition Workshop and Monash University Department of Software Development Technical Report TR96-15},
title = {{Vague Models and Their Implications for the KBS Design Cycle}},
year = {1996}
}
@inproceedings{meha94,
author = {Menzies, T J and Haynes, P},
booktitle = {Tools Pacific '94},
pages = {83--92},
publisher = {Prentice-Hall},
title = {{The \{M\}ethodologies of \{M\}ethodologies; or, \{E\}valuating \{C\}urrent \{M\}ethodologies: \{W\}hy and \{H\}ow}},
year = {1994}
}
@article{me89za,
author = {Menzies, Tim},
journal = {AI Magazine},
title = {{An \{I\}nvestigation of the \{AI\} and \{E\}xpert \{S\}ystems \{L\}iterature 1980-1984}},
year = {1989}
}
@article{nelson11,
author = {{Adam Nelson Tim Menzies}, Gregory Gay},
journal = {Software- Practice and Experience (to appear)},
title = {{Sharing Experiments Using Open Source Software}},
year = {2011}
}
@inproceedings{me09l,
abstract = {Software fault prediction models play an important role in software quality assurance. They identify software subsystems (modules,components, classes, or files) which are likely to contain faults. These subsystems, in turn, receive additional resources for verification and validation activities. Fault prediction models are binary classifiers typically developed using one of the supervised learning techniques from either a subset of the fault data from the current project or from a similar past project. In practice, it is critical that such models provide a reliable prediction performance on the data not used in training. Variance is an important reliability indicator of software fault prediction models. However, variance is often ignored or barely mentioned in many published studies. In this paper, through the analysis of twelve data sets from a public software engineering repository from the perspective of variance, we explore the following five questions regarding fault prediction models: (1) Do different types ofclassification performance measures exhibit different variance? (2) Does the size of the data set imply a more (or less) accurate prediction performance? (3) Does the size of training subset impact model's stability? (4) Do different classifiers consistently exhibit different performance in terms of model's variance? (5) Are there differences between variance from 1000 runs and 10 runs of 10-fold cross validation experiments? Our results indicate that variance is a very important factor in understanding fault prediction models and we recommend the best practice for reporting variance in empirical software engineering studies.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09irrf.pdf\}},
author = {Jiang, Yue Jiang Yue and Lin, Jie Lin Jie and Cukic, B. and Menzies, T.},
booktitle = {2009 20th International Symposium on Software Reliability Engineering},
doi = {10.1109/ISSRE.2009.13},
isbn = {978-1-4244-5375-7},
issn = {1071-9458},
keywords = {fault prediction models,machine learning,variance},
title = {{Variance Analysis in Software Fault Prediction Models}},
year = {2009}
}
@inproceedings{me03g,
author = {{T. Menzies J. Smith}, D Raffo},
title = {{When is Pair Programming Better?}},
year = {2003}
}
@article{Dai2011a,
abstract = {Word-based models have achieved promising results in sequence comparison. However, as the important statistical properties of words in biological sequence, how to use the overlapping structures and background information of the words to improve sequence comparison is still a problem. This paper proposed a new statistical method that integrates the overlapping structures and the background information of the words in biological sequences. To assess the effectiveness of this integration for sequence comparison, two sets of evaluation experiments were taken to test the proposed model. The first one, performed via receiver operating curve analysis, is the application of proposed method in discrimination between functionally related regulatory sequences and unrelated sequences, intron and exon. The second experiment is to evaluate the performance of the proposed method with f-measure for clustering Hepatitis E virus genotypes. It was demonstrated that the proposed method integrating the overlapping structures and the background information of words significantly improves biological sequence comparison and outperforms the existing models.},
author = {Dai, Qi and Li, Lihua and Liu, Xiaoqing and Yao, Yuhua and Zhao, Fukun and Zhang, Michael},
doi = {10.1371/journal.pone.0026779},
file = {:Users/timm/svns/doc/erin/references/AlgsForDNA/OverlappingStructuresWordsDai2011.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {11},
pmid = {22102867},
title = {{Integrating overlapping structures and background information of words significantly improves biological sequence comparison}},
volume = {6},
year = {2011}
}
@article{Handl2007a,
abstract = {The framework of multiobjective optimization is used to tackle the unsupervised learning problem, data clustering, following a formulation first proposed in the statistics literature. The conceptual advantages of the multiobjective formulation are discussed and an evolutionary approach to the problem is developed. The resulting algorithm, multiobjective clustering with automatic k-determination, is compared with a number of well-established single-objective clustering algorithms, a modern ensemble technique, and two methods of model selection. The experiments demonstrate that the conceptual advantages of multiobjective clustering translate into practical and scalable performance benefits},
author = {Handl, Julia and Knowles, Joshua},
doi = {10.1109/TEVC.2006.877146},
file = {:Users/timm/svns/doc/07handl\_clustering.pdf:pdf},
isbn = {0791836223},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Clustering,Determination of the number of clusters,Evolutionary clustering,Model selection,Multiobjective clustering},
number = {1},
pages = {56--76},
title = {{An evolutionary approach to multiobjective clustering}},
volume = {11},
year = {2007}
}
@article{Erik2010a,
abstract = {The general purpose optimization method known as Particle Swarm Optimization (PSO) has a number of parameters that determine its be- haviour and eï¬cacy in optimizing a given problem. This paper gives a list of good choices of parameters for various optimization scenarios which should help the practitioner achieve better results with little eï¬ort.},
author = {Erik, Magnus and Pedersen, Hvass and Pedersen, Magnus Erik Hvass},
file = {:Users/timm/svns/doc/pso/Off-The-Shelf\_PSO-2010.pdf:pdf},
journal = {Technical Report HL1001, Hvass Laboratories},
keywords = {numerical optimization,parameters,particle swarm},
pages = {1--12},
title = {{Good parameters for particle swarm optimization}},
url = {http://www.hvass-labs.org/people/magnus/publications/pedersen10good-pso.pdf},
volume = {HL1001},
year = {2010}
}
@inproceedings{me97c,
author = {Menzies, T J and Cohen, R E},
booktitle = {European Symposium on the Validation and Verification of Knowledge Based Systems, Leuven, Belgium},
title = {{A Graph-Theoretic Optimisation of Temporal Abductive Validation}},
year = {1997}
}
@inproceedings{platt05,
abstract = {This paper unifies the mathematical foun- dation of three multidimensional scaling al- gorithms: FastMap, MetricMap, and Land- mark MDS (LMDS). All three algorithms are based on the NystrÂ¨ om approximation of the eigenvectors and eigenvalues of a matrix. LMDS is applies the basic NystrÂ¨ om approx- imation, while FastMap and MetricMap use generalizations of NystrÂ¨ om, including defla- tion and using more points to establish an embedding. Empirical experiments on the Reuters and Corel Image Features data sets show that the basic NystrÂ¨ om approximation outperforms these generalizations: LMDS is more accurate than FastMap and MetricMap with roughly the same computation and can become even more accurate if allowed to be slower. 1},
author = {Platt, J C C},
booktitle = {Proceedings of the 10th International Workshop on Artificial Intelligence and Statistics},
isbn = {097273581X},
issn = {02767783},
pages = {261--268},
title = {{Fastmap, MetricMap, and Landmark MDS are all Nystr\{\"{o}\}m algorithms}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:FastMap+,+MetricMap+,+and+Landmark+MDS+are+all+Nystr+?+om+Algorithms\#0},
year = {2005}
}
@book{Laird2006a,
abstract = {An effective, quantitative approach for estimating and managing software projectsHow many people do I need? When will the quality be good enough for commercial sale? Can this really be done in two weeks? Rather than relying on instinct, the authors of Software Measurement and Estimation offer a new, tested approach that includes the quantitative tools, data, and knowledge needed to make sound estimations.The text begins with the foundations of measurement, identifies the appropriate metrics, and then focuses on techniques and tools for estimating the effort needed to reach a given level of quality and performance for a software project. All the factors that impact estimations are thoroughly examined, giving you the tools needed to regularly adjust and improve your estimations to complete a project on time, within budget, and at an expected level of quality.This text includes several features that have proven to be successful in making the material accessible and easy to master:* Simple, straightforward style and logical presentation and organization enables you to build a solid foundation of theory and techniques to tackle complex estimations* Examples, provided throughout the text, illustrate how to use theory to solve real-world problems* Projects, included in each chapter, enable you to apply your newfound knowledge and skills* Techniques for effective communication of quantitative data help you convey your findings and recommendations to peers and managementSoftware Measurement and Estimation: A Practical Approach allows practicing software engineers and managers to better estimate, manage, and effectively communicate the plans and progress of their software projects. With its classroom-tested features, this is an excellent textbook for advanced undergraduate-level and graduate students in computer science and software engineering.An Instructor Support FTP site is available from the Wiley editorial department.},
author = {Laird, Linda M. and Brennan, M. Carol},
file = {:Users/timm/svns/doc/06Software.Measurement.and.Estimation.A.Practical.Approach.Jun.2006.pdf:pdf},
isbn = {0471792527},
pages = {257},
title = {{Software Measurement and Estimation: A Practical Approach}},
url = {http://books.google.com/books?id=3g8wtcpFHZcC\&pgis=1$\backslash$nftp://pedidos.rafalim.com/Software.Measurement.and.Estimation.A.Practical.Approach.Jun.2006.pdf},
year = {2006}
}
@journal{voinea07,
booktitle = {Computers and Graphics},
number = {3},
pages = {410--428},
title = {{S.L. Voinea and A.C. Telea}},
volume = {31},
year = {2007}
}
@article{koc13a,
abstract = {Context: More than half the literature on software effort estimation (SEE) focuses on model comparisons. Each of those requires a sampling method (SM) to generate the train and test sets. Different authors use different SMs such as leave-one-out (LOO), 3Way and 10Way cross-validation. While LOO is a deterministic algorithm, the N-way methods use random selection to build their train and test sets. This introduces the problem of conclusion instability where different authors rank effort estimators in different ways. Objective: To reduce conclusion instability by removing the effects of a sampling method's random test case generation. Method: Calculate bias and variance (B\&V) values following the assumption that a learner trained on the whole dataset is taken as the true model; then demonstrate that the B\&V and runtime values for LOO are similar to N-way by running 90 different algorithms on 20 different SEE datasets. For each algorithm, collect runtimes, B\&V values under LOO, 3Way and 10Way. Results: We observed that: (1) the majority of the algorithms have statistically indistinguishable B\&V values under different SMs and (2) different SMs have similar run times. Conclusion: In terms of their generated B\&V values and runtimes, there is no reason to prefer N-way over LOO. In terms of reproducibility, LOO removes one cause of conclusion instability (the random selection of train and test sets). Therefore, we depreciate N-way and endorse LOO validation for assessing effort models. ?? 2013 Elsevier Inc. All rights reserved.},
author = {Kocaguneli, Ekrem and Menzies, Tim},
doi = {10.1016/j.jss.2013.02.053},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {Bias,Prediction system,Software cost estimation,Variance},
number = {7},
pages = {1879--1890},
title = {{Software effort models should be assessed via leave-one-out validation}},
volume = {86},
year = {2013}
}
@article{Boehm2000c,
author = {Boehm, Barry and Abts, Chris and Chulani, S},
file = {:Users/timm/svns/doc/cost/00Boehm.pdf:pdf},
journal = {Annals of Software Engineering},
pages = {177--205},
title = {{Software development cost estimation approachesâA survey}},
url = {http://www.springerlink.com/index/VV7W63752176772J.pdf},
volume = {10},
year = {2000}
}
@article{ilin10,
abstract = {Principal component analysis (PCA) is a classical data analysis technique that finds linear transformations of data that retain the maximal amount of variance. We study a case where some of the data values are missing, and show that this problem has many features which are usually associated with nonlinear models, such as overfitting and bad locally optimal solutions. A probabilistic formulation of PCA provides a good foundation for handling missing values, and we provide formulas for doing that. In case of high dimensional and very sparse data, overfitting becomes a severe problem and traditional algorithms for PCA are very slow. We introduce a novel fast algorithm and extend it to variational Bayesian learning. Different versions of PCA are compared in artificial experiments, demonstrating the effects of regularization and modeling of posterior variance. The scalability of the proposed algorithm is demonstrated by applying it to the Netflix problem.},
author = {Ilin, Alexander and Raiko, Tapani},
isbn = {9789512294817},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {Theory \& Algorithms},
pages = {1957--2000},
title = {{Practical Approaches to Principal Component Analysis in the Presence of Missing Values}},
url = {http://eprints.pascal-network.org/archive/00007870/},
volume = {11},
year = {2010}
}
@incollection{gordon2001,
abstract = {The increased prevalence of agents raises numerous practical considerations. This paper addresses three of these - adaptability to unforeseen conditions, behavioral assurance, and timeliness of agent responses. Although these requirements appear contradictory, this paper introduces a paradigm in which all three are simultaneously satisfied. Agent strategies are initially verified. Then they are adapted by learning and formally reverified for behavioral assurance. This paper focuses on improving the time efficiency of reverification after learning. A priori proofs are presented that certain learning operators are guaranteed to preserve important classes of properties. In this case, efficiency is maximal because no reverification is needed. For those learning operators with negative a priori results, we present incremental algorithms that can substantially improve the efficiency of reverification.},
author = {Gordon, Diana F.},
booktitle = {Formal Approaches to Agent-Based Systems},
isbn = {978-3-540-42716-2},
pages = {278--293},
publisher = {Springer},
title = {{APT Agents: Agents That Are Adaptive, Predictable and Timely}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.29.5181$\backslash$nhttp://www.springerlink.com/index/Q9TQ8GJ95827M7T7.pdf},
year = {2001}
}
@inproceedings{me03h,
author = {Chiang, E and Menzies, T},
booktitle = {Prosim '03},
title = {{Position Paper: Summary of simulations for Very Early Lifecycle Quality Evaluations}},
year = {2003}
}
@inproceedings{me02g,
author = {Menzies, Tim and Lutz, Robyn},
booktitle = {Seke03},
keywords = {anomaly,artificial intelligence,association,debugging,dent,learning,metrics,nasa mis-,reports on deep space,rule learning,software engineering,surprise,testing and,treatment learning},
pages = {0--5},
title = {{Better analysis of defect data at NASA}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.197.5917\&amp;rep=rep1\&amp;type=pdf},
year = {2003}
}
@inproceedings{me09a,
abstract = {Before performing drastic changes to a project, it is worthwhile to thoroughly explore the available options within the current structure of a project. An alternative to drastic change are internal changes that adjust current options within a software project. In this paper, we show that the effects of numerous internal changes can out-weigh the effects of drastic changes. That is, the benefits of drastic change can often be achieved without disrupting a project. The key to our technique is SEESAW, a novel stochastic stability tool that (a) considers a very large set of minor changes using stochastic sampling; and (b) carefully selects the right combination of effective minor changes. Our results show, using SEESAW, project managers have more project improvement options than they currently realize. This result should be welcome news to managers struggling to maintain control and continuity over their project in the face of multiple demands for drastic change.},
author = {Menzies, T. and Williams, S. and El-Rawas, O. and Boehm, B. and Hihn, J.},
booktitle = {2009 IEEE 31st International Conference on Software Engineering},
doi = {10.1109/ICSE.2009.5070552},
isbn = {978-1-4244-3453-4},
issn = {0270-5257},
title = {{How to avoid drastic software process change (using stochastic stability)}},
year = {2009}
}
@article{me03e,
author = {Menzies, T},
journal = {IEEE Intelligent Systems},
number = {3},
pages = {18--24},
title = {{21\{\^{}\{st\}\} Century $\backslash$uppercase\{AI\}: Proud, Not Smug}},
url = {http://menzies.us/pdf/03aipride.pdf},
volume = {18},
year = {2003}
}
@inproceedings{me06b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06hicss.pdf\}},
author = {Fisher, Marcus S. and Menzies, Tim},
booktitle = {Proceedings of the Annual Hawaii International Conference on System Sciences},
doi = {10.1109/HICSS.2006.251},
isbn = {0769525075},
issn = {15301605},
title = {{Learning IV\&V strategies}},
volume = {9},
year = {2006}
}
@article{Yeung2000a,
author = {Yeung, Ka Yee},
file = {:Users/timm/svns/doc/01yeungPcaClustering.pdf:pdf},
keywords = {be addressed,bioinformatics,clustering,dimension reduction,gene expression analysis,principal component analysis,to appear,to whom correspondence should},
title = {{An empirical study on Principal Component Analysis for clustering gene expression data}},
year = {2000}
}
@book{efron93,
abstract = {Statistics is a subject of many uses and surprisingly few effective practitioners. The traditional road to statistical knowledge is blocked, for most, by a formidable wall of mathematics. The approach in An Introduction to the Bootstrap avoids that wall. It arms scientists and engineers, as well as statisticians, with the computational techniques they need to analyze and understand complicated data sets.},
address = {London},
author = {Efron, B and Tibshirani, R J},
booktitle = {Refrigeration And Air Conditioning},
doi = {10.1111/1467-9639.00050},
isbn = {0412042312},
issn = {04120423},
number = {57},
pages = {436},
pmid = {2049363},
publisher = {Chapman and Hall},
series = {Mono. Stat. Appl. Probab.},
title = {{An Introduction to the Bootstrap}},
url = {http://books.google.com/books?id=gLlpIUxRntoC\&pgis=1},
volume = {57},
year = {1993}
}
@article{mashiko97,
abstract = {In planning software process improvement activities, it is essential to determine the factors that most influence the success of a software project. In this article, we present an investigative and analytical framework for evaluating software process factors based on the Goal/Question/Metric (GQM) paradigm. We built descriptive models of the software process, defects, and cost. These models were used as a common basis of quantitative analysis in the study. We also developed evaluative models that clarify the relationship between the basic metrics, the analysis method, and the goals of the analysis. We confirmed the usefulness of our analytical framework, by applying it in an actual development environment at Matsushita Communication Industrial Company in Japan, where we studied four communications-software projects. This article reports the patterns we noted in the data and suggests process improvement activities based on those findings.},
author = {Mashiko, Yasuhiro and Basili, Victor R.},
doi = {10.1016/0164-1212(95)00194-8},
isbn = {0164-1212},
issn = {01641212},
journal = {Journal of Systems and Software},
number = {1},
pages = {17--32},
title = {{Using the GQM paradigm to investigate influential factors for software process improvement}},
volume = {36},
year = {1997}
}
@inproceedings{me99n,
author = {Menzies, T},
booktitle = {KAW'99: the 12th Workshop on Knowledge Acquisition, Modeling and Management, Voyager Inn, Banff, Alberta, Canada Oct 16-22, 1999},
title = {{h\{Q\}kb- The High Quality Knowledge Base Initiative (Sisyphus V: Learning Design Assessment Knowledge)}},
year = {1999}
}
@article{Krzywicki2009a,
author = {Krzywicki, Alfred and Wobcke, Wayne},
doi = {10.1007/978-3-642-10439-8\_26},
file = {:Users/timm/svns/doc/AI 2009 Advances in Artificial Intelligence\_Krzywicki\_2009.pdf:pdf},
isbn = {364210438X},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {250--259},
title = {{Incremental e-mail classification and rule suggestion using simple term statistics}},
volume = {5866 LNAI},
year = {2009}
}
@article{me09e,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09nodata.pdf\}},
author = {Menzies, T and Williams, S and Elrawas, O and Baker, D and Boehm, B and Hihn, J and Lum, K and Madachy, R},
journal = {Software Process Improvement and Practice},
month = jul,
number = {4},
pages = {213--225},
title = {{Accurate estimates without local data?}},
url = {http://www3.interscience.wiley.com/journal/122364893/abstract},
volume = {14},
year = {2009}
}
@article{Razek1992a,
author = {Razek, Gottfried},
doi = {10.1145/142181.142199},
file = {:Users/timm/svns/doc/ooprolog/p66-razek.pdf:pdf},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
number = {12},
pages = {66--70},
title = {{Combining objects and relations}},
volume = {27},
year = {1992}
}
@inproceedings{me02e,
abstract = { Within NASA, there is an increasing awareness that software is of growing importance to the success of missions. Much data has been collected, and many theories have been advanced on how to reduce or eliminate errors in code. However, learning requires experience. We document a new NASA initiative to build a centralized repository of software defect data; in particular, we document one specific case study on software metrics. Software metrics are used as a basis for prediction of errors in code modules, but there are many different metrics available. McCabe is one of the more popular tools used to produce metrics, but, other metrics can be more significant.},
author = {Menzies, T. and Stefano, J.S. Di and Chapman, M. and McGill, K.},
booktitle = {27th Annual NASA Goddard/IEEE Software Engineering Workshop, 2002. Proceedings.},
doi = {10.1109/SEW.2002.1199449},
isbn = {0-7695-1855-9},
issn = {0021-8499},
title = {{Metrics that matter}},
year = {2002}
}
@article{McFee2011a,
abstract = {Many music information retrieval tasks require ï¬nding the nearest neighbors of a query item in a high-dimensional space. However, the complexity of computing nearest neigh- bors grows linearly with size of the database, making exact re- trieval impractical for large databases. We investigate modern variants of the classical KD-tree algorithm, which efï¬ciently index high-dimensional data by recursive spatial partitioning. Experiments on the Million Song Dataset demonstrate that content-based similarity search can be signiï¬cantly acceler- ated by the use of spatial partitioning structures.},
author = {McFee, B. and Lanckriet, Gert},
file = {:Users/timm/svns/doc/11rptrees.pdf:pdf},
isbn = {9780615548654},
journal = {12th International Society for Music Information Retrieval Conference (ISMIR 2011)},
pages = {55--60},
title = {{Large-Scale Music Similarity Search With Spatial Trees}},
url = {http://cseweb.ucsd.edu/~bmcfee/papers/ismir2011\_sptree.pdf},
year = {2011}
}
@article{Garcia2012a,
abstract = {The nearest neighbor classifier is one of the most used and well-known techniques for performing recognition tasks. It has also demonstrated itself to be one of the most useful algorithms in data mining in spite of its simplicity. However, the nearest neighbor classifier suffers from several drawbacks such as high storage requirements, low efficiency in classification response, and low noise tolerance. These weaknesses have been the subject of study for many researchers and many solutions have been proposed. Among them, one of the most promising solutions consists of reducing the data used for establishing a classification rule (training data) by means of selecting relevant prototypes. Many prototype selection methods exist in the literature and the research in this area is still advancing. Different properties could be observed in the definition of them, but no formal categorization has been established yet. This paper provides a survey of the prototype selection methods proposed in the literature from a theoretical and empirical point of view. Considering a theoretical point of view, we propose a taxonomy based on the main characteristics presented in prototype selection and we analyze their advantages and drawbacks. Empirically, we conduct an experimental study involving different sizes of data sets for measuring their performance in terms of accuracy, reduction capabilities, and runtime. The results obtained by all the methods studied have been verified by nonparametric statistical tests. Several remarks, guidelines, and recommendations are made for the use of prototype selection for nearest neighbor classification.},
author = {Garc\'{\i}a, Salvador and Derrac, Joaqu\'{\i}n and Cano, Jos\'{e} Ram\'{o}n and Herrera, Francisco},
doi = {10.1109/TPAMI.2011.142},
file = {:Users/timm/svns/doc/12prototype.pdf:pdf},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Prototype selection,classification,condensation,edition,nearest neighbor,taxonomy},
number = {3},
pages = {417--435},
pmid = {21768651},
title = {{Prototype selection for nearest neighbor classification: Taxonomy and empirical study}},
volume = {34},
year = {2012}
}
@mastersthesis{papa13,
author = {Papakroni, Vasil},
school = {Lane Department of Computer Science and Electrical Engineering, West Virginia Unviersity},
title = {{Data Carving: Identifying and Removing Irrelevancies in the Data}},
year = {2013}
}
@book{hof81,
author = {Hofstader, D R and Dennett, D C},
title = {{The Mind's I}},
year = {1981}
}
@inproceedings{bird06,
abstract = {Communication \& Co-ordination activities are central to large software projects, but are difficult to observe and study in traditional (closed-source, commercial) settings because of the prevalence of informal, direct communication modes. OSS projects, on the other hand, use the internet as the communication medium, and typically conduct discussions in an open, public manner. As a result, the email archives of OSS projects provide a useful trace of the communica- tion and co-ordination activities of the participants. How- ever, there are various challenges that must be addressed before this data can be effectively mined. Once this is done, we can construct social networks of email correspondents, and begin to address some interesting questions. These in- clude questions relating to participation in the email; the social status of different types of OSS participants; the rela- tionship of email activity and commit activity (in the CVS repositories) and the relationship of social status with com- mit activity. In this paper, we begin with a discussion of our infrastructure and then discuss our approach to mining the email archives; and finally we present some preliminary results from our data analysis.},
author = {Bird, Christian and Gourley, Alex and Devanbu, Prem and Gertz, Michael},
booktitle = {Msr},
doi = {10.1145/1137983.1138016},
isbn = {159593085X},
keywords = {Open Source,Social Networks},
pages = {137--143},
series = {MSR '06},
title = {{Mining Email Social Networks â Categories and Subject Descriptors}},
year = {2006}
}
@inproceedings{me00p,
abstract = {Machine learning is practical for software engineering problems, even in data- starved domains. When data is scarce, knowledge can be farmed from seeds; i.e. minimal and partial descriptions of a domain. These seeds can be grown into large datasets via Monte Carlo simulations. The datasets can then be harvested using machine learning techniques. Examples of this knowledge farming approach, and the associated technique of data-mining, is given from numerous software engineering domains.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/00ml.pdf\}},
author = {Menzies, Tim},
booktitle = {Handbook of Software Engineering and Knowledge Engineering690 (2001).},
isbn = {981-02-4973-X},
month = dec,
number = {690},
pages = {690},
publisher = {World-Scientific},
title = {{Practical Machine Learning for Software Engineering and Knowledge Engineering}},
url = {http://menzies.us/pdf/00ml.pdf},
volume = {1},
year = {2001}
}
@misc{bobntim2,
author = {Cohen, R F and Menzies, T},
number = {TR95-20},
title = {{Reverse Engineering a Software Engineering Curriculum}},
year = {1995}
}
@inproceedings{bobntim1,
author = {Cohen, R F and Menzies, T J},
booktitle = {Software Education Conference (SRIG-ET'94)},
pages = {71--76},
title = {{Providing \{S\}oftware \{E\}ngineering \{S\}tudents with an \{E\}xperience in "\{B\}ig-\{C\}omputing"}},
year = {1995}
}
@article{Iliuk2011a,
abstract = {With over 2,000 publications, including about 250 reviews, resulting from a SciFinder search in just a two year period (2009-2010), the field of aptamer research has continuously generated lots of interest in the scientific community. Aptamers, first reported by three groups independently in 1990, are the artificial single-stranded DNA or RNA sequences (more recently, peptides) that fold into secondary and tertiary structures making them bind to certain targets with extremely high specificity. Owing to the high specific affinity of an aptamer to its target molecule (small molecules, proteins and even entire cells), it is thought to resemble chemical antibodies, with the dissociation constants ranging from nanomolar to picomolar level. Aptamers have a number of unique features which make them a more effective choice than antibodies. First, aptamers can be screened via in vitro process against a synthetic library, making it possible to target any molecules (from small inorganic ions to intact cells), overcoming the limit of having to use cell lines or animals, as is necessary for antibodies. Second, aptamers, once selected, can undergo subsequent amplification through polymerase chain reaction to produce a large quantity with high purity. Third, the simple chemical structure of aptamer makes it easily amendable to further modifications with functional groups according to different purposes. Finally, aptamers are much more stable than antibodies, making them suitable in applications requiring harsh conditions (e.g., high temperature or extreme pH).The applications of aptamers remain very dynamic, with increasing explorations in the fields of biosensing, diagnostics and therapeutics. There have been a numbers of excellent reviews in recent years with different emphases.4-8 Herein, as the first review of aptamers on Analytical Chemistry, we attempt to cover major progresses in bioanalytical applications of aptamers in the past 2 years.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Iliuk, Anton B. and Hu, Lianghai and Tao, W. Andy},
doi = {10.1021/ac201057w},
eprint = {NIHMS150003},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Iliuk11.pdf:pdf},
isbn = {0003-2700$\backslash$n1520-6882},
issn = {00032700},
journal = {Analytical Chemistry},
number = {12},
pages = {4440--4452},
pmid = {21524128},
title = {{Aptamer in bioanalytical applications}},
volume = {83},
year = {2011}
}
@article{me10a,
abstract = {Building quality software is expensive and software quality assurance (QA) budgets are limited. Data miners can learn defect predictors from static code features which can be used to control QA resources; e.g. to focus on the parts of the code predicted to be more defective. Recent results show that better data mining technology is not leading to better defect predictors. We hypothesize that we have reached the limits of the standard learning goal of maximizing area under the curve (AUC) of the probability of false alarms and probability of detection AUC(pd, pf) ; i.e. the area under the curve of a probability of false alarm versus probability of detection. Accordingly, we explore changing the standard goal. Learners that maximize AUC(effort, pd) find the smallest set of modules that contain the most errors. WHICH is a meta-learner framework that can be quickly customized to different goals. When customized to AUC(effort, pd), WHICH out-performs all the data mining methods studied here. More importantly, measured in terms of this new goal, certain widely used learners perform much worse than simple manual methods. Hence, we advise against the indiscriminate use of learners. Learners must be chosen and customized to the goal at hand. With the right architecture (e.g. WHICH), tuning a learner to specific local business goals can be a simple task.},
author = {Menzies, Tim and Milton, Zach and Turhan, Burak and Cukic, Bojan and Jiang, Yue and Bener, AyÅe},
doi = {10.1007/s10515-010-0069-5},
issn = {09288910},
journal = {Automated Software Engineering},
keywords = {Defect prediction,Static code features,Which},
number = {4},
pages = {375--407},
title = {{Defect prediction from static code features: Current results, limitations, new approaches}},
volume = {17},
year = {2010}
}
@article{me96a,
author = {Menzies, T J},
journal = {International Journal of Human Computer Studies},
pages = {305--355},
title = {{Applications of Abduction: Knowledge Level Modeling}},
volume = {45},
year = {1996}
}
@article{Pareek2013a,
abstract = {Humans may be exceptional learners but they have biological limitations and more- over, inductive biases similar to machine learning algorithms. This puts limits on human learning ability and on the kinds of learning tasks humans can easily han- dle. In this paper, we consider the prob- lem of âboostingâ human learners to extend the learning ability of human learners and achieve improved performance on tasks which individual humans find difficult. We consider classification (category learning) tasks, pro- pose a boosting algorithm for human learn- ers and give theoretical justifications. We conduct experiments using Amazonâs Me- chanical Turk on two synthetic datasets â a crosshair task with a nonlinear decision boundary and a gabor patch task with a lin- ear boundary but which is inaccessible to hu- man learners â and one real world dataset â the Opinion Spam detection task introduced in (Ott et al., 2011). Our results show that boosting human learners produces gains in accuracy and can overcome some fundamen- tal limitations of human learners.},
author = {Pareek, Harsh and Ravikumar, Pradeep},
file = {:Users/timm/svns/doc/13humanBoost.pdf:pdf},
journal = {Proceedings of the 30th International Conference on Machine Learning},
pages = {338--346},
title = {{Human Boosting}},
year = {2013}
}
@article{Kitchenham2007a,
abstract = {The objective of this paper is to determine under what circumstances$\backslash$nindividual organisations would be able to rely on cross-company based$\backslash$nestimation models. We performed a systematic review of studies that$\backslash$ncompared predictions from crosscompany models with predictions from$\backslash$nwithin-company models based on analysis of project data. Ten papers$\backslash$ncompared cross-company and within-company estimation models, however,$\backslash$nonly seven of the papers presented independent results. Of those$\backslash$nseven, three found that crosscompany models were as good as within-company$\backslash$nmodels, four found cross-company models were significantly worse$\backslash$nthan within-company models. Experimental procedures used by the studies$\backslash$nd iffered making it impossible to undertake formal meta-analysis$\backslash$nof the results. The main trend distinguishing study results was that$\backslash$nstudies with small single company data sets (i.e. <20 projects) that$\backslash$nused leaveone-out cross-validation all found that the within-company$\backslash$nmodel was significantly more accurate than$\backslash$n$\backslash$nthe cross-company model. The results of this review are inconclusive.$\backslash$nIt is clear that some organisations would be ill-served by cross-company$\backslash$nmodels whereas others would benefit. Further studies are needed,$\backslash$nbut they must be independent (i.e. based on different data bases$\backslash$nor at least different single comp any data sets). In addition, experimenters$\backslash$nneed to standardise their experimental procedures to enable formal$\backslash$nmeta-analysis.},
author = {Kitchenham, B a and Mendes, E and Travassos, G H},
doi = {http://dx.doi.org/10.1109/TSE.2007.1001},
file = {:Users/timm/svns/doc/cost/07Barbara.pdf:pdf},
isbn = {9781450324762},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
number = {5},
pages = {316--329},
title = {{Cross- vs. Within-Company Cost Estimation Studies: A Systematic Review}},
volume = {33},
year = {2007}
}
@article{Wen2012a,
abstract = {Context: Software development effort estimation (SDEE) is the process of predicting the effort required to develop a software system. In order to improve estimation accuracy, many researchers have proposed machine learning (ML) based SDEE models (ML models) since 1990s. However, there has been no attempt to analyze the empirical evidence on ML models in a systematic way. Objective: This research aims to systematically analyze ML models from four aspects: type of ML technique, estimation accuracy, model comparison, and estimation context. Method: We performed a systematic literature review of empirical studies on ML model published in the last two decades (1991-2010). Results: We have identified 84 primary studies relevant to the objective of this research. After investigating these studies, we found that eight types of ML techniques have been employed in SDEE models. Overall speaking, the estimation accuracy of these ML models is close to the acceptable level and is better than that of non-ML models. Furthermore, different ML models have different strengths and weaknesses and thus favor different estimation contexts. Conclusion: ML models are promising in the field of SDEE. However, the application of ML models in industry is still limited, so that more effort and incentives are needed to facilitate the application of ML models. To this end, based on the findings of this review, we provide recommendations for researchers as well as guidelines for practitioners. Â© 2011 Elsevier B.V. All rights reserved.},
author = {Wen, Jianfeng and Li, Shixian and Lin, Zhiyong and Hu, Yong and Huang, Changqin},
doi = {10.1016/j.infsof.2011.09.002},
file = {:Users/timm/svns/doc/12wenEffortEstimationReview.pdf:pdf},
isbn = {0950-5849},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Machine learning,Software effort estimation,Systematic literature review},
number = {1},
pages = {41--59},
title = {{Systematic literature review of machine learning based software development effort estimation models}},
volume = {54},
year = {2012}
}
@article{Tusar2007a,
author = {Tu\v{s}ar, T and Filipi\v{c}, B},
doi = {10.1007/978-3-540-70928-2\_22},
file = {:Users/timm/svns/doc/pso/07deBetterThanOthers.pdf:pdf},
isbn = {978-3-540-70927-5},
issn = {03029743},
journal = {Evolutionary Multi-Criterion Optimization},
pages = {257--271},
title = {{Differential evolution versus genetic algorithms in multiobjective optimization}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-70928-2\_22},
year = {2007}
}
@inproceedings{weimer13,
author = {Weimer, W and Fry, Z P and Forrest, S},
title = {{No Title}}
}
@article{Hein2011a,
abstract = {Spectral clustering is based on the spectral relaxation of the normalized/ratio graph
cut criterion. While the spectral relaxation is known to be loose, it has been shown
recently that a non-linear eigenproblem yields a tight relaxation of the Cheeger
cut. In this paper, we extend this result considerably by providing a characterization
of all balanced graph cuts which allow for a tight relaxation. Although
the resulting optimization problems are non-convex and non-smooth, we provide
an efficient first-order scheme which scales to large graphs. Moreover, our approach
comes with the quality guarantee that given any partition as initialization
the algorithm either outputs a better partition or it stops immediately.},
author = {Hein, Matthias and Setzer, Simon},
file = {:Users/timm/svns/doc/10nipsSpectralClustering.pdf:pdf},
isbn = {9781618395993},
keywords = {Learning/Statistics \& Optimisation},
pages = {1--9},
title = {{Beyond Spectral Clustering - Tight Relaxations of Balanced Graph Cuts}},
url = {http://eprints.pascal-network.org/archive/00008707/},
year = {2011}
}
@inproceedings{rod12,
abstract = {âIn the last decade, a large number of software repositories have been created for different purposes. In this paper we present a survey of the publicly available repositories and classify the most common ones as well as discussing the problems faced by researchers when applying machine learning or statistical techniques to them},
author = {Rodriguez, Daniel and Herraiz, Israel and Harrison, Rachel},
booktitle = {2012 1st International Workshop on Realizing AI Synergies in Software Engineering, RAISE 2012 - Proceedings},
doi = {10.1109/RAISE.2012.6227971},
isbn = {9781467317535},
keywords = {data quality,preprocessing software engineering data,quality,software engineering repositories},
pages = {52--56},
title = {{On software engineering repositories and their open problems}},
year = {2012}
}
@article{Brody2000a,
abstract = {Aptamers are oligonucleotides derived from an in vitro evolution process called SELEX. Aptamers have been evolved to bind proteins which are associated with a number of disease states. Using this method, many powerful antagonists of such proteins have been found. In order for these antagonists to work in animal models of disease and in humans, it is necessary to modify the aptamers. First of all, sugar modifications of nucleoside triphosphates are necessary to render the resulting aptamers resistant to nucleases found in serum. Changing the 2'OH groups of ribose to 2'F or 2'NH2 groups yields aptamers which are long lived in blood. The relatively low molecular weight of aptamers (8000-12000) leads to rapid clearance from the blood. Aptamers can be kept in the circulation from hours to days by conjugating them to higher molecular weight vehicles. When modified, conjugated aptamers are injected into animals, they inhibit physiological functions known to be associated with their target proteins. A new approach to diagnostics is also described. Aptamer arrays on solid surfaces will become available rapidly because the SELEX protocol has been successfully automated. The use of photo-cross-linkable aptamers will allow the covalent attachment of aptamers to their cognate proteins, with very low backgrounds from other proteins in body fluids. Finally, protein staining with any reagent which distinguishes functional groups of amino acids from those of nucleic acids (and the solid support) will give a direct readout of proteins on the solid support.},
author = {Brody, E N and Gold, L},
doi = {10.1016/S1389-0352(99)00004-5},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Brody00.pdf:pdf},
isbn = {1389-0352},
issn = {13890352},
journal = {Journal of biotechnology},
keywords = {brody,clearance,com \v{z} e,compuserve,corresponding author,e-mail address,edwardnbrody,fax,n,oligonucleotide,pharmaceuticals,photo-selex,q 1-303-499-6846,q 1-303-499-8327,selex,tel,universal protein stain},
number = {1},
pages = {5--13},
pmid = {10943568},
title = {{Aptamers as therapeutic and diagnostic agents.}},
volume = {74},
year = {2000}
}
@article{tosun2010,
author = {Tosun, A and Bener, A and Turhan, B and Menzies, T},
title = {{No Title}}
}
@inproceedings{gel03a,
abstract = { Model-based software has become quite popular in recent years, making its way into a broad range of areas, including the aerospace industry. The models provide an easy graphical interface to develop systems, which can generate the sometimes tedious code that follows. While there are many tools available to assess standard procedural code, there are limits to the testing of model-based systems. A major problem with the models are that their internals often contain gray areas of unknown system behavior. These possible behaviors form what is known as a data cloud, which is an overwhelming range of possibilities of a system that can overload analysts (Menzies et al., 2003). With large data clouds, it is hard to demonstrate which particular decision leads to a particular outcome. Even if definite decisions can't be made, it is possible to reduce the variance of and condense the clouds (Menzies et al., 2003). This paper presents two case studies; one with a simple illustrative model and another with a more complex application. The TAR3 treatment learning tool summarizes the particular attribute ranges that selects for particular behaviors of interest, reducing the data clouds.},
author = {Geletko, D. and Menzies, T.},
booktitle = {28th Annual NASA Goddard Software Engineering Workshop, 2003. Proceedings.},
doi = {10.1109/SEW.2003.1270729},
isbn = {0-7695-2064-2},
title = {{Model-based software testing via incremental treatment learning}},
year = {2003}
}
@inproceedings{jiang07,
abstract = {The prediction of fault-prone modules in a software project has been the topic of many studies. In this paper, we investigate whether metrics available early in the development lifecycle can be used to identify fault-prone software modules. More precisely, we build predictive models using the metrics that characterize textual requirements. We compare the performance of requirements-based models against the performance of code-based models and models that combine requirement and code metrics. Using a range of modeling techniques and the data from three NASA projects, our study indicates that the early lifecycle metrics can play an important role in project management, either by pointing to the need for increased quality monitoring during the development or by using the models to assign verification and validation activities.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07issre.pdf\}},
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim},
booktitle = {The 18th IEEE International Symposium on Software Reliability (ISSRE '07)},
doi = {10.1109/ISSRE.2007.24},
isbn = {978-0-7695-3024-6},
issn = {1071-9458},
title = {{Fault Prediction using Early Lifecycle Data}},
year = {2007}
}
@inproceedings{me00a,
author = {Menzies, T and Sinsel, E and Kurtz, T},
booktitle = {Workshop on Intelligent Software Engineering, an ICSE workshop, and NASA/WVU Software Research Lab, Fairmont, WV, Tech report \# NASA-IVV-99-027},
keywords = { Monte-Carlo simulations, decision support systems, effort estimation, risk assessment,COCOMO-II,Keywords: Machine learning},
title = {{Learning to Reduce Risks with COCOMO-II}},
year = {2000}
}
@article{Song2010,
abstract = {BACKGROUND\&\#x02014;Predicting defect-prone software components is an economically important activity and so has received a good deal of attention. However, making sense of the many, and sometimes seemingly inconsistent, results is difficult. OBJECTIVE\&\#x02014;We propose and evaluate a general framework for software defect prediction that supports 1) unbiased and 2) comprehensive comparison between competing prediction systems. METHOD\&\#x02014;The framework is comprised of 1) scheme evaluation and 2) defect prediction components. The scheme evaluation analyzes the prediction performance of competing learning schemes for given historical data sets. The defect predictor builds models according to the evaluated learning scheme and predicts software defects with new data according to the constructed model. In order to demonstrate the performance of the proposed framework, we use both simulation and publicly available software defect data sets. RESULTS\&\#x02014;The results show that we should choose different learning schemes for different data sets (i.e., no scheme dominates), that small details in conducting how evaluations are conducted can completely reverse findings, and last, that our proposed framework is more effective and less prone to bias than previous approaches. CONCLUSIONS\&\#x02014;Failure to properly or fully evaluate a learning scheme can be misleading; however, these problems may be overcome by our proposed framework.},
author = {Song, Qinbao and Jia, Zihan and Shepperd, Martin and Ying, Shi and Liu, Jin},
doi = {10.1109/TSE.2010.90},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework.pdf:pdf;:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Song et al. - 2010 - A General Software Defect-Proneness Prediction Framework(2).pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Machine learning,Scheme evaluation,Software defect prediction,Software defect-proneness prediction},
number = {3},
pages = {356--370},
title = {{A general software defect-proneness prediction framework}},
volume = {37},
year = {2011}
}
@incollection{hallt10,
author = {Hall, Tracy and Bowes, David and Liebchen, Gernot and Wernick, Paul},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-13792-1\_10},
isbn = {3642137911},
issn = {03029743},
keywords = {Software,data,fault,prediction},
pages = {107--115},
publisher = {Springer Berlin Heidelberg},
title = {{Evaluating three approaches to extracting fault data from software change repositories}},
volume = {6156 LNCS},
year = {2010}
}
@inproceedings{me95zb,
author = {Menzies, Tim and Compton, Paul},
booktitle = {Proceedings of the 9th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge Based Systems,},
title = {{The Extensive Implications of Evaluation on the Development of Knowledge-Based System}},
year = {1989}
}
@inproceedings{zuluaga13,
author = {Zuluaga, Marcela and Krause, Andreas and Sergent, Guillaume and P\"{u}schel, Markus},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Active Learning for Multi-Objective Optimization}},
year = {2013}
}
@inproceedings{jiang08,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08compare.pdf\}},
author = {Jiang, Y and Cukic, B and Menzies, T and Bartlow, N},
booktitle = { 4th International Workshop on Predictor Models in Software Engineering, PROMISE 2008},
isbn = {978-1-60558-036-4},
keywords = {Software Quality Measurement},
pages = {11--18},
title = {{Comparing Design and Code Metrics for Software Quality Prediction}},
year = {2008}
}
@book{tufte86,
address = {Cheshire, CT, USA},
author = {Tufte, E},
publisher = {Graphics Press},
title = {{The Visual Display of Quantitative Information}},
year = {2001}
}
@inproceedings{krall14b,
author = {Krall, J and Menzies, T and Davies, M},
booktitle = {Modeling in Human Machine Systems: Challenges for Formal Verification, an AAAI 2014 Spring Symposium},
title = {{Learning the Task Management Space of an Aircraft Approach Model}},
year = {2014}
}
@article{Hall2011a,
abstract = {Background: The accurate prediction of where faults are likely to occur in code can help direct test effort, reduce costs and improve the quality of software. Objective: We investigate how the context of models, the independent variables used and the modelling techniques applied, influence the performance of fault prediction models. Method:We used a systematic literature review to identify 208 fault prediction studies published from January 2000 to December 2010. We synthesise the quantitative and qualitative results of 36 studies which report sufficient contextual and methodological information according to the criteria we develop and apply. Results: The models that perform well tend to be based on simple modelling techniques such as Na\"{\i}ve Bayes or Logistic Regression. Combinations of independent variables have been used by models that perform well. Feature selection has been applied to these combinations when models are performing particularly well. Conclusion: The methodology used to build models seems to be influential to predictive performance. Although there are a set of fault prediction studies in which confidence is possible, more studies are needed that use a reliable methodology and which report their context, methodology and performance comprehensively.},
author = {Hall, Tracy and Beecham, Sarah and Bowes, David and Gray, David and Counsell, Steve},
doi = {10.1109/TSE.2011.103},
file = {:Users/timm/svns/doc/11hall.pdf:pdf},
isbn = {9781612081656},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Systematic literature review,software fault prediction},
number = {6},
pages = {1276--1304},
title = {{A systematic literature review on fault prediction performance in software engineering}},
volume = {38},
year = {2012}
}
@article{harman12dec,
author = {Harman, Mark and Mansouri, S Afshin and Zhang, Yuanyuan},
issn = {0360-0300},
journal = {ACM Comput. Surv.},
month = dec,
number = {1},
pages = {11:1----11:61},
title = {{Search-based Software Engineering: Trends, Techniques and Applications}},
volume = {45},
year = {2012}
}
@article{Proske2005a,
abstract = {Since its discovery in the early 1990s, aptamer technology has progressed tremendously. Automated selection procedures now allow rapid identification of DNA and RNA sequences that can target a broad range of extra- and intracellular proteins with nanomolar affinities and high specificities. The unique binding properties of nucleic acids, which are amenable to various modifications, make aptamers perfectly suitable for different areas of biotechnology. Moreover, the approval of an aptamer for vascular endothelial growth factor by the US Food and Drug Administration highlights the potential of aptamers for therapeutic applications. This review summarizes recent developments and demonstrates that aptamers are valuable tools for diagnostics, purification processes, target validation, drug discovery, and even therapeutic approaches.},
author = {Proske, Daniela and Blank, Michael and Buhmann, Raymund and Resch, Ansgar},
doi = {10.1007/s00253-005-0193-5},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Proske05.pdf:pdf},
issn = {01757598},
journal = {Applied Microbiology and Biotechnology},
number = {4},
pages = {367--374},
pmid = {16283295},
title = {{Aptamers - Basic research, drug development, and clinical applications}},
volume = {69},
year = {2005}
}
@inproceedings{me04e,
author = {Menzies, T and Pecheur, C},
booktitle = {Advances in Computing},
editor = {Zelkowtiz, M},
publisher = {Elsevier},
title = {{Verification and \{V\}alidation and \{A\}rtificial \{I\}ntelligence}},
volume = {65},
year = {2005}
}
@inproceedings{me09l,
abstract = {Software fault prediction models play an important role in software quality assurance. They identify software subsystems (modules,components, classes, or files) which are likely to contain faults. These subsystems, in turn, receive additional resources for verification and validation activities. Fault prediction models are binary classifiers typically developed using one of the supervised learning techniques from either a subset of the fault data from the current project or from a similar past project. In practice, it is critical that such models provide a reliable prediction performance on the data not used in training. Variance is an important reliability indicator of software fault prediction models. However, variance is often ignored or barely mentioned in many published studies. In this paper, through the analysis of twelve data sets from a public software engineering repository from the perspective of variance, we explore the following five questions regarding fault prediction models: (1) Do different types ofclassification performance measures exhibit different variance? (2) Does the size of the data set imply a more (or less) accurate prediction performance? (3) Does the size of training subset impact model's stability? (4) Do different classifiers consistently exhibit different performance in terms of model's variance? (5) Are there differences between variance from 1000 runs and 10 runs of 10-fold cross validation experiments? Our results indicate that variance is a very important factor in understanding fault prediction models and we recommend the best practice for reporting variance in empirical software engineering studies.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09irrf.pdf\}},
author = {Jiang, Yue Jiang Yue and Lin, Jie Lin Jie and Cukic, B. and Menzies, T.},
booktitle = {2009 20th International Symposium on Software Reliability Engineering},
doi = {10.1109/ISSRE.2009.13},
isbn = {978-1-4244-5375-7},
issn = {1071-9458},
keywords = {fault prediction models,machine learning,variance},
title = {{Variance Analysis in Software Fault Prediction Models}},
year = {2009}
}
@incollection{fea03b,
abstract = { Many organizations look to research to yield new and improved products and practices. Connecting practitioners who have the need for research results to the researchers producing those results is important to guiding research and utilizing its results. Likewise, connecting researchers working on related topics to one another, and connecting practitioners with related needs to one another, is important to establishing communities of shared interests. We present an approach that helps identify fruitful such connections.},
author = {Feather, M.S. and Menzies, T. and Connelly, J.R.},
booktitle = {IEMC '03 Proceedings. Managing Technologically Driven Organizations: The Human Side of Innovation and Change},
doi = {10.1109/IEMC.2003.1252313},
isbn = {0-7803-8150-5},
month = nov,
pages = {451--455},
title = {{Identifying fruitful connections between and among researchers and practitioners}},
year = {2003}
}
@article{me03e,
author = {Menzies, T},
journal = {IEEE Intelligent Systems},
number = {3},
pages = {18--24},
title = {{21\{\^{}\{st\}\} Century $\backslash$uppercase\{AI\}: Proud, Not Smug}},
volume = {18},
year = {2003}
}
@book{Simon1969c,
abstract = {Continuing his exploration of the organization of complexity and the science of design, this new edition of Herbert Simon's classic work on artificial intelligence adds a chapter that sorts out the current themes and toolsâchaos, adaptive systems, genetic algorithmsâfor analyzing complexity and complex systems. There are updates throughout the book as well. These take into account important advances in cognitive psychology and the science of design while confirming and extending the book's basic thesis: that a physical symbol system has the necessary and sufficient means for intelligent action. The chapter "Economic Reality" has also been revised to reflect a change in emphasis in Simon's thinking about the respective roles of organizations and markets in economic systems.},
author = {Simon, Ha},
booktitle = {Computers \& Mathematics with Applications},
doi = {10.1016/S0898-1221(97)82941-0},
file = {:Users/timm/svns/doc/96Herbert Simon - Sciences\_of\_the\_Artificial.pdf:pdf},
isbn = {9780262691918},
issn = {08981221},
number = {5},
pages = {130},
pmid = {4470018},
title = {{The sciences of the artificial, (third edition)}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:The+Sciences+of+the+Artificial\#0},
volume = {33},
year = {1997}
}
@inproceedings{me99l,
author = {Menzies, T},
booktitle = {11th Annual International Conference on Software Engineering and Knowledge Engineering, Kaiserslautern, Germany, June 17 - 19, 1999},
title = {{Knowledge Maintenance Heresies: Meta-Knowledge Complicates KM}},
year = {1999}
}
@article{Verykios04,
abstract = {We provide here an overview of the new and rapidly emerging research area of privacy preserving data mining. We also propose a classification hierarchy that sets the basis for analyzing the work which has been performed in this context. A detailed review of the work accomplished in this area is also given, along with the coordinates of each work to the clas- sification hierarchy. A brief evaluation is performed, and some initial conclusions are made.},
author = {Verykios, Vassilios S. and Bertino, Elisa and Fovino, Igor Nai and Provenza, Loredana Parasiliti and Saygin, Yucel and Theodoridis, Yannis},
doi = {10.1145/974121.974131},
isbn = {0163-5808},
issn = {01635808},
journal = {ACM SIGMOD Record},
month = mar,
number = {1},
pages = {50},
title = {{State-of-the-art in privacy preserving data mining}},
volume = {33},
year = {2004}
}
@inproceedings{me98c,
author = {Menzies, T J and Waugh, S},
booktitle = {Proceedings of the Australian AI '98 conference},
publisher = {World-Scientific},
title = {{Lower Limits on the Size of Test Data Sets}},
year = {1998}
}
@article{wang05,
abstract = {In this paper, we present an embedding technique, called MetricMap, which is capable of estimating distances in a pseudometric space. Given a database of objects and a distance function for the objects, which is a pseudometric, we map the objects to vectors in a pseudo-Euclidean space with a reasonably low dimension while preserving the distance between two objects approximately. Such an embedding technique can be used as an approximate oracle to process a broad class of distance-based queries. It is also adaptable to data mining applications such as data clustering and classification. We present the theory underlying MetricMap and conduct experiments to compare MetricMap with other methods including MVP-tree and M-tree in processing the distance-based queries. Experimental results on both protein and RNA data show the good performance and the superiority of MetricMap over the other methods.},
author = {Wang, Jason T L and Wang, Xiong and Shasha, Dennis and Zhang, Kaizhong},
doi = {10.1109/TSMCB.2005.848489},
issn = {10834419},
journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics},
keywords = {Bioinformatics,Data mining,Embedding method,Metric space,Nearest neighbors,Similarity search},
number = {5},
pages = {973--987},
pmid = {16240772},
title = {{MetricMap: An embedding technique for processing distance-based queries in metric spaces}},
volume = {35},
year = {2005}
}
@article{Schutze2009a,
abstract = {We have determined diversities exceeding 10(12) different sequences in an annealing and melting assay using synthetic randomized oligonucleotides as a standard. For such high diversities, the annealing kinetics differ from those observed for low diversities, favouring the remelting curve after annealing as the best indicator of complexity. Direct comparisons of nucleic acid pools obtained from an aptamer selection demonstrate that even highly complex populations can be evaluated by using DiStRO, without the need of complicated calculations.},
author = {Sch\"{u}tze, Tatjana and Arndt, Peter F. and Menger, Marcus and Wochner, Aniela and Vingron, Martin and Erdmann, Volker a. and Lehrach, Hans and Kaps, Christian and Gl\"{o}kler, J\"{o}rn},
doi = {10.1093/nar/gkp1108},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Schutze10.pdf:pdf},
isbn = {1362-4962 (Electronic)$\backslash$n0305-1048 (Linking)},
issn = {03051048},
journal = {Nucleic Acids Research},
number = {4},
pmid = {19965765},
title = {{A calibrated diversity assay for nucleic acid libraries using DiStRO-a Diversity Standard of Random Oligonucleotides}},
volume = {38},
year = {2009}
}
@techrepor{kasunic08,
author = {Zubrow, David},
booktitle = {October},
institution = {Software Engineering Institute, Carnegie Mellon University},
number = {October},
title = {{Can You Trust Your Data ? Measurement and Analysis Infrastructure Diagnosis}},
year = {2008}
}
@article{hand06,
abstract = {Rejoinder: Classifier Technology and the Illusion of Progress [math.ST/0606441]},
archivePrefix = {arXiv},
arxivId = {math/0606461},
author = {Hand, David J.},
doi = {10.1214/088342306000000079},
eprint = {0606461},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Hand - 2006 - Classifier Technology and the Illusion of Progress.pdf:pdf},
isbn = {0883423060000},
issn = {0883-4237},
journal = {Stastical Science},
number = {1},
pages = {1--15},
primaryClass = {math},
title = {{Rejoinder: Classifier Technology and the Illusion of Progress}},
url = {http://arxiv.org/abs/math/0606461},
volume = {21},
year = {2006}
}
@article{Fayyad96,
author = {Fayyad, Usama and Piatetsky-shapiro, Gregory and Smyth, Padhraic},
doi = {10.1145/240455.240463},
isbn = {0-262-56097-6},
issn = {0738-4602},
journal = {American Association for Artificial Intelligence, AI Magazine},
pages = {37--54},
title = {{From Data Mining to Knowledge Discovery in Databases}},
url = {http://www.aaai.org/aitopics/assets/PDF/AIMag17-03-2-article.pdf},
year = {1996}
}
@article{Freund2007a,
author = {Freund, Y. and Dasgupta, S. and Kabra, M. and Verma, N.},
file = {:Users/timm/svns/doc/07rptrees.pdf:pdf},
isbn = {160560352X},
journal = {Neural Information Processing Systems},
pages = {1--8},
title = {{Learning the structure of manifolds using random projections}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Learning+the+structure+of+manifolds+using+random+projections\#0},
year = {2007}
}
@inproceedings{men87,
author = {Menzies, T J and Worral, C},
booktitle = {Proceedings of AI '87},
title = {{Worlds in Prolog}},
year = {1987}
}
@article{nelson11,
author = {{Adam Nelson Tim Menzies}, Gregory Gay},
journal = {Software- Practice and Experience (to appear)},
title = {{Sharing Experiments Using Open Source Software}},
year = {2011}
}
@inproceedings{me95za,
author = {Menzies, Tim},
booktitle = {Proceedings of the Melbourne Workshop on Intelligent Decision Support Department of Information Systems Monash University, Caulfield Campus, Melbourne Monday, March 20, 1995},
pages = {1--13},
title = {{Applications of Abduction \# 1 : Intelligent Decision Support Systems 1 Introduction}},
year = {1995}
}
@misc{me99e,
annote = {in preperation},
author = {Menzies, T and Cukic, B},
howpublished = {NASA/WVU IVV tech report},
month = mar,
title = {{An Average-Case Model of Reachability}},
year = {1999}
}
@article{me98b,
abstract = {Situated cognition is not a mere philosophical concern: it has pragmatic implications for current practice in knowledge acquisition. Tools must move from being design-focused to being maintenance-focused. Reuse-based approaches (e.g. using problem-solving methods) will fail unless the reused descriptions can be extensively modified to suit the new situation. Knowledge engineers must model not only descriptions of expert knowledge, but also the environment in which a knowledge base will perform. Descriptions of knowledge must be constantly re-evaluated. This re-evaluation process has implications for assessing representations},
author = {Menzies, T I M},
doi = {10.1006/ijhc.1998.0230},
isbn = {1071-5819},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
number = {6},
pages = {867--893},
title = {{Towards situated knowledge acquisition}},
url = {http://www.sciencedirect.com/science/article/B6WGR-45J548X-6/2/d7a982a694598b232b8c2e7ec4c0263f},
volume = {49},
year = {1998}
}
@inproceedings{me03a,
abstract = { When it is impractical to rigorously assess all parts of complex systems, test engineers use defect detectors to focus their limited resources. We define some properties of an ideal defect detector and assess different methods of generating one. In the case study presented here, traditional methods of generating such detectors (e.g. reusing detectors from the literature, linear regression, model trees) were found to be inferior to those found via a PACE analysis.},
author = {Menzies, T. and Stefano, J.D. and Ammar, K. and McGill, K. and Callis, P. and Davis, J. and Chapman, R.},
booktitle = {Proceedings. 5th International Workshop on Enterprise Networking and Computing in Healthcare Industry (IEEE Cat. No.03EX717)},
doi = {10.1109/METRIC.2003.1232459},
isbn = {0-7695-1987-3},
issn = {1530-1435},
title = {{When can we test less?}},
year = {2003}
}
@incollection{mockus08,
abstract = {The collection of valid software engineering data involves substantial effort and is not a priority in most software production environments. This often leads to missing or otherwise invalid data. This fact tends to be overlooked by most software engineering researchers and may lead to a biased analysis. This chapter reviews missing data methods and applies them on a software engineering data set to illustrate a variety of practical contexts where such techniques are needed and to highlight the pitfalls of ignoring the missing data problem.},
author = {Mockus, Audris},
booktitle = {Guide to Advanced Empirical Software Engineering},
editor = {Shull, Forrest and Singer, Janice and Sj\o berg, DagI.K.},
pages = {185--200},
publisher = {Springer London},
title = {{Missing Data in Software Engineering}},
url = {http://dx.doi.org/10.1007/978-1-84800-044-5\_7},
year = {2008}
}
@inproceedings{me11e,
abstract = {The practices of industrial and academic data mining are very different. These differences have significant implications for (a) how we manage industrial data mining projects; (b) the direction of academic studies in data mining; and (c) training programs for engineers who seek to use data miners in an industrial setting.},
address = {New York, NY, USA},
author = {Menzies, Tim and Bird, Christian and Zimmermann, Thomas and Schulte, Wolfram and Kocaganeli, Ekrem},
booktitle = {Proceedings of the International Workshop on Machine Learning Technologies in Software Engineering SE - MALETS '11},
doi = {10.1145/2070821.2070824},
isbn = {978-1-4503-1022-2},
keywords = {inductive engineering,industry},
pages = {19--26},
publisher = {ACM},
series = {MALETS '11},
title = {{The inductive software engineering manifesto: principles for industrial data mining}},
url = {citeulike-article-id:10194816$\backslash$nhttp://dx.doi.org/10.1145/2070821.2070824$\backslash$nhttp://portal.acm.org/citation.cfm?id=2070824},
year = {2011}
}
@article{me00o,
author = {Menzies, T and Althoff, K D and Kalfoglou, Y and Motta, E},
journal = {International Journal of Software Engineering and Knowledge Engineering},
month = aug,
number = {4},
title = {{Issues with Meta-Knowledge}},
volume = {10},
year = {2000}
}
@article{me97zg,
author = {Menzies, T},
journal = {The Knowledge Engineering Review},
number = {1},
pages = {1--46},
title = {{Knowledge Maintenance: The State of the Art}},
volume = {14},
year = {1999}
}
@inproceedings{gruska10,
abstract = {Real production code contains lots of knowledge -- on the domain, on the architecture, and on the environment. How can we leverage this knowledge in new projects? Using a novel lightweight souce-code parser, we have mined more than 6,000 open-source Linux projects (totaling 200 million lines of code) to obtain 16 million temporal properties reflecting normal interface usage. New projects can be checked against these rules to detect anomalies -- that is, code that deviates from the wisdom of the crowds. In a sample of 20 projects, \~{}25\% of the top-ranked anomalies uncovered actual code smells or defects.},
author = {Gruska, Natalie and Wasylkowski, Andrzej and Zeller, Andreas},
booktitle = {Proceedings of the 19th international symposium on Software testing and analysis - ISSTA '10},
doi = {10.1145/1831708.1831723},
isbn = {9781605588230},
keywords = {formal concepts analysis,language independent parsing,lightweight parsing,mining specifications,temporal properties},
pages = {119--129},
publisher = {ACM},
series = {ISSTA '10},
title = {{Learning from 6,000 Projects: Lightweight Cross-Project Anomaly Detection}},
url = {http://portal.acm.org/citation.cfm?doid=1831708.1831723},
year = {2010}
}
@article{Leung2009a,
abstract = {BACKGROUND: Recognizing regulatory sequences in genomes is a continuing challenge, despite a wealth of available genomic data and a growing number of experimentally validated examples. METHODOLOGY/PRINCIPAL FINDINGS: We discuss here a simple approach to search for regulatory sequences based on the compositional similarity of genomic regions and known cis-regulatory sequences. This method, which is not limited to searching for predefined motifs, recovers sequences known to be under similar regulatory control. The words shared by the recovered sequences often correspond to known binding sites. Furthermore, we show that although local word profile clustering is predictive for the regulatory sequences involved in blastoderm segmentation, local dissimilarity is a more universal feature of known regulatory sequences in Drosophila. CONCLUSIONS/SIGNIFICANCE: Our method leverages sequence motifs within a known regulatory sequence to identify co-regulated sequences without explicitly defining binding sites. We also show that regulatory sequences can be distinguished from surrounding sequences by local sequence dissimilarity, a novel feature in identifying regulatory sequences across a genome. Source code for WPH-finder is available for download at http://rana.lbl.gov/downloads/wph.tar.gz.},
author = {Leung, Garmay and Eisen, Michael B.},
doi = {10.1371/journal.pone.0006901},
file = {:Users/timm/svns/doc/erin/references/AlgsForDNA/WordProfileSimilarityLeung2009.pdf:pdf},
isbn = {1932-6203 (Electronic)$\backslash$n1932-6203 (Linking)},
issn = {19326203},
journal = {PLoS ONE},
number = {9},
pmid = {19730735},
title = {{Identifying cis-regulatory sequences by word profile similarity}},
volume = {4},
year = {2009}
}
@inproceedings{wilkinson11,
author = {Wilkinson, Leland},
isbn = {9781450308137},
keywords = {random projections,supervised classification},
pages = {6--14},
series = {KDD '11},
title = {{CHIRP : A N ew C lassifier B ased o n Composite Hypercubes on Iterated Random Projections}},
year = {2011}
}
@article{Kriegel2009a,
abstract = {Clustering in high-dimensional spaces is a difficult problem which is recurrent in many domains, for example in image analysis. The difficulty is due to the fact that high-dimensional data usually exist in different low-dimensional subspaces hidden in the original space. A family of Gaussian mixture models designed for high-dimensional data which combine the ideas of subspace clustering and parsimonious modeling are presented. These models give rise to a clustering method based on the expectationmaximization algorithm which is called high-dimensional data clustering (HDDC). In order to correctly fit the data, HDDC estimates the specific subspace and the intrinsic dimension of each group. Experiments on artificial and real data sets show that HDDC outperforms existing methods for clustering high-dimensional data.},
author = {Kriegel, Hans-Peter and Kr\"{o}ger, Peer and Zimek, Arthur},
doi = {10.1145/1497577.1497578},
file = {:Users/timm/svns/doc/09highDimensionalClusteringReview.pdf:pdf},
isbn = {1556-4681},
issn = {15564681},
journal = {ACM Transactions on Knowledge Discovery from Data},
number = {1},
pages = {1--58},
title = {{Clustering high-dimensional data}},
volume = {3},
year = {2009}
}
@article{me11d,
abstract = {Analogy based estimation (ABE) generates an effort estimate for a new software project through adaptation of similar past projects (a.k.a. analogies). Majority of ABE methods follow uniform weighting in adaptation procedure. In this research we investigated non-uniform weighting through kernel density estimation. After an extensive experimentation of 19 datasets, 3 evaluation criteria, 5 kernels, 5 bandwidth values and a total of 2090 ABE variants, we found that: (1) non-uniform weighting through kernel methods cannot outperform uniform weighting ABE and (2) kernel type and bandwidth parameters do not produce a definite effect on estimation performance. In summary simple ABE approaches are able to perform better than much more complex approaches. Hence,âprovided that similar experimental settings are adoptedâwe discourage the use of kernel methods as a weighting strategy in ABE.},
author = {Kocaguneli, Ekrem and Menzies, Tim and Keung, Jacky W.},
doi = {10.1007/s10664-011-9189-1},
issn = {1382-3256},
journal = {Empirical Software Engineering},
pages = {1--24},
publisher = {Springer Netherlands},
title = {{Kernel methods for software effort estimation}},
year = {2011}
}
@inproceedings{lokan09,
abstract = {Models for estimating software development effort are commonly built and evaluated using a set of historical projects. An important question is which projects to use as training data to build the model: should it be all of them, or a subset that seems particularly relevant? One factor to consider is project age: is it best to use the entire history of past projects, or is it more appropriate in a rapidly changing world to use a window of recent projects? We investigate the effect on estimation accuracy of using a moving window, using projects from the ISBSG data set. We find that using a moving window can improve accuracy, and we make some observations about factors that influence the range of possible window sizes and the best window size.},
author = {Lokan, Chris and Mendes, Emilia},
booktitle = {2009 3rd International Symposium on Empirical Software Engineering and Measurement, ESEM 2009},
doi = {10.1109/ESEM.2009.5316019},
file = {:Users/timm/svns/doc/transfer/09lokan.pdf:pdf},
isbn = {9781424448418},
issn = {1938-6451},
pages = {111--122},
title = {{Applying moving windows to software effort estimation}},
year = {2009}
}
@misc{me97s,
author = {Menzies, T J},
title = {{Evaluation Issues for Problem Visual Programming Languages}},
year = {1998}
}
@inproceedings{me09m,
abstract = {The next challenge for the PROMISE community is scaling up and speeding up model generation to meet the size and time constraints of modern software development projects. There will always be a trade-off between completeness and runtime speed. Here we explore that trade-off in the context of using genetic algorithms to learn coverage models; i.e. biases in the control structures for randomized test generators. After applying feature subset selection to logs of the GA output, we find we can generate the coverage model and run the resulting test suite ten times faster while only losing 6\% of the test case coverage.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09fssga.pdf\}},
author = {Andrews, Jh and Menzies, Tim},
booktitle = {5th International Conference on Predictor Models in Software Engineering},
doi = {10.1145/1540438.1540456},
isbn = {9781605586342},
keywords = {feature subset selection,genetic algorithms,software testing},
pages = {13},
title = {{On the value of combining feature subset selection with genetic algorithms: faster learning of coverage models}},
url = {http://dl.acm.org/citation.cfm?id=1540456},
year = {2009}
}
@misc{fea03c,
abstract = { Many organizations look to research to yield new and improved products and practices. Connecting practitioners who have the need for research results to the researchers producing those results is important to guiding research and utilizing its results. Likewise, connecting researchers working on related topics to one another, and connecting practitioners with related needs to one another, is important to establishing communities of shared interests. We demonstrate an approach that helps identify fruitful such connections.},
author = {Feather, M.S. and Menzies, T. and Connelly, J.R.},
booktitle = {Proceedings. 11th IEEE International Requirements Engineering Conference, 2003.},
doi = {10.1109/ICRE.2003.1232783},
isbn = {0-7695-1980-6},
issn = {1090-705X},
month = sep,
title = {{Relating practitioner needs to research activities}},
year = {2003}
}
@inproceedings{me01f,
author = {Menzies, Tim and Hu, Y},
booktitle = {First International Workshop on Model-based Requirements Engineering},
title = {{Reusing models for requirements engineering}},
year = {2001}
}
@inproceedings{me03l,
author = {Menzies, Tim},
booktitle = {Soft Computing in Software Engineering},
editor = {Madravio, M},
publisher = {Springer-Verlag},
title = {{Chapter 99 Maybes Mean ( Mostly ) the Same Thing}},
year = {2003}
}
@inproceedings{me07,
author = {Tar, The and Learner, Treatment},
booktitle = {Review Literature And Arts Of The Americas},
keywords = {contrast set learning,tar3,treatment learning},
title = {{Just Enough Learning ( of Association Rules ):}},
year = {2007}
}
@inproceedings{Haiduc2012a,
address = {Essen, Germany},
author = {Haiduc, Sonia and Bavota, Gabriele and Oliveto, Rocco and {De Lucia}, Andrea and Marcus, Andrian},
booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering - ASE 2012},
doi = {10.1145/2351676.2351690},
isbn = {9781450312042},
pages = {90},
publisher = {ACM},
title = {{Automatic query performance assessment during the retrieval of software artifacts}},
url = {http://dl.acm.org/citation.cfm?doid=2351676.2351690},
year = {2012}
}
@inproceedings{waugh98,
author = {Waugh, S and Blogs, J and Menzies, T},
booktitle = {Proceedings of the Australain AI '98 conference},
title = {{The Temporal Qualitative Compartmental Modeling Language}},
year = {1998}
}
@article{Hann2004a,
abstract = {Lipinski and others, through concepts such as drug-likeness, re-focussed drug discovery back to the principles of medicinal chemistry in the high-throughput era as key to reducing attrition. More recently, the need to go further in defining what makes a good lead has been recognised with the concept of leadlikeness. Leadlikeness implies cut-off values in the physico-chemical profile of chemical libraries such that they have reduced complexity (e.g. MW below <400) and other more restricted properties. We examine these concepts in the context of Virtual (theoretically possible), Tangible (chemically feasible) and Real (physically available) worlds of molecules. In a thought experiment, we take the HTS concept to the extreme: screening an estimated 60 million 'Global Collection' on 5000 targets and realising that perhaps millions of drug candidates might be found that could not possibly be handled in reality. Sampling of the Virtual and Tangible worlds is therefore a necessity. We show that the world of Reals is significantly under-sampled as the MW of compounds increases. This supports the design and screening of 'reduced complexity' (leadlike) compound libraries, preferably with synthetic handles available for rapid chemical iteration and detected as interesting by careful screening or biophysical assays.},
author = {Hann, Mike M. and Oprea, Tudor I.},
doi = {10.1016/j.cbpa.2004.04.003},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Hann\_Oprea\_Leadlike\_COCHBI2004.pdf:pdf},
isbn = {1367-5931 (Print)},
issn = {13675931},
journal = {Current Opinion in Chemical Biology},
keywords = {ACD,Available Chemicals Directory,HAC,HAM,HDO,HTS,MDDR,MDL Drug Data Report,RNG,RO5,RTB,VTR,high-activity molecule,high-throughput screening,hydrogen bond acceptors,hydrogen bond donors,number of rings,rotatable bonds,rule of fives},
number = {3},
pages = {255--263},
pmid = {15183323},
title = {{Pursuing the leadlikeness concept in pharmaceutical research}},
volume = {8},
year = {2004}
}
@article{me13e,
author = {Menzies, Tim},
journal = {Information and Software Technology},
number = {8},
pages = {1477--1478},
title = {{Guest editorial for the Special Section on \{BEST\} \{PAPERS\} from the 2011 conference on Predictive Models in Software Engineering (PROMISE)}},
volume = {55},
year = {2013}
}
@inproceedings{heaven11,
author = {Letier, E},
booktitle = {Requirements Engineering Conference (RE), 2011 19th IEEE International},
isbn = {9781457709241},
pages = {79--88},
title = {{Simulating and Optimizing Design Decisions in Goal-Oriented Requirements Models.}},
url = {http://discovery.ucl.ac.uk/1350008/},
year = {2011}
}
@inproceedings{me05a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05safewhen.pdf\}},
author = {Menzies, Tim and Chen, Zhihao and Port, Dan and Hihn, Jairus},
booktitle = {Proceedings, PROMISE workshop, ICSE},
title = {{Simple software cost estimation: Safe or unsafe}},
volume = {2005},
year = {2005}
}
@article{Chen2007c,
abstract = {Systematic evolution of ligands by exponential enrichment (SELEX) is an in vitro combinatorial engineering approach to enrich aptamers from a library of nucleic acids ligands by iterative extraction and amplification of receptor-bound ligands. Aptamers are the selected nucleic acid ligands with high receptor-binding affinity. Typically, they are obtained in single-receptor SELEX experiments where the ligand library is incubated with receptor molecules of a single identity, e.g., a purified protein. For years, aptamers have been shown to be valuable for biomedical applications and research. To further explore the power of SELEX technology, the idea of complex SELEX was proposed to obtain multiple aptamers by incubating the ligand library with multiple species of receptors. However, the reports on complex SELEX have been few, possible due to the ignorance of the effects of experimental variables. To address this problem, computer simulations should be useful. A major task of simulating complex SELEX is to solve interdependent binding equilibrium equations for binding events among heterogeneous ligands and receptors. Although a detailed subpooling model was developed, that model could be useful to simulate complex SELEX against at most four species of receptors, because the demand of computer memory grew exponentially with the number of receptor species. Here we develop a novel, condensed subpooling model where ligands of similar characteristic affinity are first pooled together regardless of receptor-specificity, and then divided into partial subpools receptor-specifically. With this model, the need of computer memory grows only linearly with receptor number. In the simulation of SELEX against four receptors, our results are the same or very similar to earlier work. We have further simulated SELEX against 100 heterogeneous receptors. We suggest that our computation method can be applied to other research fields where binding events between heterogeneous ligands and receptors are involved. ?? 2006 Elsevier Ltd. All rights reserved.},
author = {Chen, Chi Kan and Kuo, Tai Chih},
doi = {10.1016/j.compchemeng.2006.08.015},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Chen06.pdf:pdf},
issn = {00981354},
journal = {Computers and Chemical Engineering},
keywords = {Aptamers,Computer model,Computer simulation,SELEX},
number = {9},
pages = {1007--1019},
title = {{Simulations of SELEX against complex receptors with a condensed statistical model}},
volume = {31},
year = {2007}
}
@inproceedings{Haiduc2013b,
abstract = {Text retrieval approaches have been used to address many software engineering tasks. In most cases, their use involves issuing a textual query to retrieve a set of relevant software artifacts from the system. The performance of all these approaches depends on the quality of the given query (i.e., its ability to describe the information need in such a way that the relevant software artifacts are retrieved during the search). Currently, the only way to tell that a query failed to lead to the expected software artifacts is by investing time and effort in analyzing the search results. In addition, it is often very difficult to ascertain what part of the query leads to poor results. We propose a novel pre-retrieval metric, which reflects the quality of a query by measuring the specificity of its terms. We exemplify the use of the new specificity metric on the task of concept location in source code. A preliminary empirical study shows that our metric is a good effort predictor for text retrieval-based concept location, outperforming existing techniques from the field of natural language document retrieval.  2012 IEEE.},
address = {Zurich, Switzerland},
annote = {Laura. Fixed on 09/24/2012},
author = {Haiduc, Sonia and Bavota, Gabriele and Oliveto, Rocco and Marcus, Andrian and {De Lucia}, Andrea},
booktitle = {34th IEEE/ACM International Conference on Software Engineering (ICSE'12)},
keywords = {Information retrieval; Software engineering},
pages = {1273--1276},
publisher = {IEEE},
title = {{Evaluating the specificity of text retrieval queries to support software engineering tasks BT  - 34th International Conference on Software Engineering, ICSE 2012, June 2, 2012 - June 9, 2012}},
year = {2012}
}
@article{compton05,
annote = {Available from $\backslash$url\{http://www.cse.unsw.edu.au/\~{}compton/\#Starter\_Papers\}},
author = {Compton, P and Peters, L and Edwards, G and Lavers, T G},
journal = {Knowledge-Based Systems},
month = sep,
number = {5},
pages = {356--362},
title = {{Experience with Ripple-Down Rules}},
volume = {19},
year = {2006}
}
@article{SergioM.Savaresi2000a,
abstract = {This paper deals with the problem of clustering a data-set.$\backslash$nIn particular, the bisecting divisive approach is here$\backslash$nconsidered. This approach can be naturally divided into two$\backslash$nsub-problems: the problem of choosing which cluster must be$\backslash$ndivided, and the problem of splitting the selected cluster.$\backslash$nThe focus here is on the first problem. The contribution of$\backslash$nthis work is to propose a new simple technique for the$\backslash$nselection of the cluster to split. This technique is based$\backslash$nupon the shape of the cluster. This result is presented with$\backslash$nreference to two specific splitting algorithms: the$\backslash$ncelebrated bisecting K-means algorithm, and the recently$\backslash$nproposed Principal Direction Divisive Partitioning (PDDP)$\backslash$nalgorithm. The problem of evaluating the quality of a$\backslash$npartition is also discussed. Keywords. Unsupervised$\backslash$nclustering; cluster selection; quality of clusters; K-means;$\backslash$nPrincipal Direction Divisive Partitioning. 1.},
author = {{Sergio M. Savaresi}, Daniel L. Boley and {Sergio M. Savaresi}, Daniel L. Boley},
file = {:Users/timm/svns/doc/02\_part2\_principalDirectionDivisvePartitioning.pdf:pdf},
keywords = {1,classical problem of unsupervised,cluster selection,clustering of a data-set,divisive partitioning,focuses on is the,in,introduction and problem statement,k-means,principal direction,quality of clusters,the problem this paper,unsupervised clustering},
pages = {1--16},
title = {{Choosing the Cluster to Split in Bisecting Divisive Clustering Algorithms}},
url = {http://citeseer.ist.psu.edu/497394.html$\backslash$nhttp://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.25.3507},
year = {2000}
}
@inproceedings{Freitas98onobjective,
abstract = {Most of the literature argues that surprisingness is an inherently subjective aspect of the discovered knowledge, which cannot be measured in objective terms. This paper departs from this view, and it has a twofold goal: (1) showing that it is indeed possible to define objective (rather than subjective) measures of discovered rule surprisingness; (2) proposing new ideas and methods for defining objective rule surprisingness measures.},
author = {a.a. Freitas},
booktitle = {Proceedings of the Second European Conference on the Principles of Data Mining and Knowledge Discovery (PKDD'98},
doi = {10.1007/BFb0094798},
isbn = {3-540-65068-7},
keywords = {QA 76 Software, computer programming,},
pages = {1--9},
publisher = {Springer-Verlag},
title = {{On Objective Measures of Rule Surprisingness}},
url = {http://dx.doi.org/10.1007/BFb0094798},
year = {1998}
}
@inproceedings{kim11,
abstract = {Many software defect prediction models have been built using historical defect data obtained by mining software repositories (MSR). Recent studies have discovered that data so collected contain noises because current defect collection practices are based on optional bug fix keywords or bug report links in change logs. Automatically collected defect data based on the change logs could include noises. This paper proposes approaches to deal with the noise in defect data. First, we measure the impact of noise on defect prediction models and provide guidelines for acceptable noise level. We measure noise resistant ability of two well-known defect prediction algorithms and find that in general, for large defect datasets, adding FP (false positive) or FN (false negative) noises alone does not lead to substantial performance differences. However, the prediction performance decreases significantly when the dataset contains 20\&\#x025;-35\&\#x025; of both FP and FN noises. Second, we propose a noise detection and elimination algorithm to address this problem. Our empirical study shows that our algorithm can identify noisy instances with reasonable accuracy. In addition, after eliminating the noises using our algorithm, defect prediction accuracy is improved.},
author = {Kim, Sunghun and Zhang, Hongyu and Wu, Rongxin and Gong, Liang},
booktitle = {2011 33rd International Conference on Software Engineering (ICSE)},
doi = {10.1145/1985793.1985859},
isbn = {978-1-4503-0445-0},
issn = {0270-5257},
keywords = {buggy changes,buggy files,data quality,defect prediction,noise resistance},
pages = {481--490},
title = {{Dealing with noise in defect prediction}},
year = {2011}
}
@article{koc11a,
abstract = {Background: Despite decades of research, there is no consensus on which software effort estimation methods produce the most accurate models. Aim: Prior work has reported that, givenM estimation methods, no single method consistently outperforms all others. Perhaps rather than recommending one estimation method as best, it is wiser to generate estimates from ensembles of multiple estimation methods. Method: Nine learners were combined with 10 preprocessing options to generate 9î10 Â¼ 90 solo methods. These were applied to 20 datasets and evaluated using seven error measures. This identified the best n (in our case n Â¼ 13) solo methods that showed stable performance across multiple datasets and error measures. The top 2, 4, 8, and 13 solo methods were then combined to generate 12 multimethods, which were then compared to the solo methods. Results: 1) The top 10 (out of 12) multimethods significantly outperformed all 90 solo methods. 2) The error rates of the multimethods were significantly less than the solo methods. 3) The ranking of the best multimethod was remarkably stable. Conclusion: While there is no best single effort estimation method, there exist best combinations of such effort estimation methods.},
author = {Kocaguneli, Ekrem and Menzies, Tim and Keung, Jacky W.},
doi = {10.1109/TSE.2011.111},
file = {:Users/timm/svns/doc/cost/11comba.pdf:pdf},
isbn = {978-1-4577-2203-5},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Software cost estimation,analogy,ensemble,k-NN,machine learning,neural nets,regression trees,support vector machines},
number = {6},
pages = {1403--1416},
title = {{On the value of ensemble effort estimation}},
volume = {38},
year = {2012}
}
@inproceedings{me02d,
abstract = {Formal analysis of software is a powerful analysis tool, but can be too costly. Random search of formal models can reduce that cost, but is theoretically incomplete. However, random search of finite-state machines exhibits an early saturation effect, i.e., random search quickly yields all that can be found, even after a much longer search. Hence, we avoid the theoretical problem of incompleteness, provided that testing continues until after the saturation point. Such a random search is rapid, consumes little memory, is simple to implement, and can handle very large formal models (in one experiment shown here, over 10<sup>178</sup> states).},
author = {Menzies, T. and Owen, D. and Cukic, B.},
booktitle = {13th International Symposium on Software Reliability Engineering, 2002. Proceedings.},
doi = {10.1109/ISSRE.2002.1173208},
isbn = {0-7695-1763-3},
issn = {1071-9458},
title = {{Saturation effects in testing of formal models}},
year = {2002}
}
@inproceedings{me04a,
author = {Menzies, T and Setamanit, S and Raffo, D},
booktitle = {Prosim 2004},
title = {{Data Mining from Process Models}},
year = {2004}
}
@misc{me97i,
author = {Menzies, T},
howpublished = {Asian-Pacific Workshop on Intelligent Software Engineering},
title = {{Applications of Abduction: A Unified Framework for Software and Knowledge Engineering}},
year = {1998}
}
@inproceedings{me02h,
author = {Menzies, Tim and Owen, David and Cukic, Bojan},
booktitle = {October},
issn = {03029743},
pages = {1--12},
title = {{You seem friendly , but can I trust you ?}},
year = {2002}
}
@article{Stoltenburg2005a,
abstract = {Aptamers are ssDNA or RNA oligonucleotides with very high affinity for their target. They bind to the target with high selectivity and specificity because of their specific three-dimensional shape. They are developed by the so-called Systematic Evolution of Ligands by Exponential Enrichment (SELEX) process. We have modified this method in two steps-use of fluorescent labels for DNA quantification and use of magnetic beads for target immobilization. Thus, radioactive labelling is avoided. Immobilization on magnetic beads enables easy handling, use of very small amounts of target for the aptamer selection, rapid and efficient separation of bound and unbound molecules, and stringent washing steps. We have called this modified SELEX technology FluMag-SELEX. With FluMag-SELEX we have provided a methodological background for our objective of being able to select DNA aptamers for targets with very different properties and size. These aptamers will be applied as new biosensor receptors. In this work selection of streptavidin-specific aptamers by FluMag-SELEX is described. The streptavidin-specific aptamers will be used to check the surface occupancy of streptavidin-coated magnetic beads with biotinylated molecules after immobilization procedures.},
author = {Stoltenburg, R. and Reinemann, C. and Strehlitz, B.},
doi = {10.1007/s00216-005-3388-9},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Stoltenberg05.pdf:pdf},
isbn = {4934123520},
issn = {16182642},
journal = {Analytical and Bioanalytical Chemistry},
keywords = {Aptamer,Magnetic beads,SELEX,Streptavidin},
number = {1},
pages = {83--91},
pmid = {16052344},
title = {{FluMag-SELEX as an advantageous method for DNA aptamer selection}},
volume = {383},
year = {2005}
}
@article{Challenges2005a,
author = {Challenges, Symbol Table and Trees, Binary Search},
file = {:Users/timm/svns/doc/05bst.pdf:pdf},
title = {{4 . 3 Binary Search Trees}},
year = {2005}
}
@inproceedings{me06b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06hicss.pdf\}},
author = {Fisher, Marcus S. and Menzies, Tim},
booktitle = {Proceedings of the Annual Hawaii International Conference on System Sciences},
doi = {10.1109/HICSS.2006.251},
isbn = {0769525075},
issn = {15301605},
title = {{Learning IV\&V strategies}},
volume = {9},
year = {2006}
}
@manual{swiprolog,
author = {Wielemaker, Jan},
title = {{SWI-Prolog}}
}
@inproceedings{me08fh,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08antares.pdf\}},
author = {Gundy-Burlet, K and Schumann, J and Menzies, T and Barrett, T},
booktitle = {9th International Symposium on Artifical Intelligence, Robotics and Automation in Space},
title = {{Parametric Analysis of a Hover Test Vehicle Using Advanced Test Generation and Data Analysis}},
year = {2009}
}
@inproceedings{me11m,
abstract = {AbstractâData miners can infer rules showing how to improve either (a) the effort estimates of a project or (b) the defect predictions of a software module. Such studies often exhibit conclusion instability regarding what is the most effective action for different projects or modules. This instability can be explained by data heterogeneity. We show that effort and defect data contain many local regions with markedly different properties to the global space. In other words, what appears to be useful in a global context is often irrelevant for particular local contexts. This result raises questions about the generality of conclusions from empirical SE. At the very least, SE researchers should test if their supposedly general conclusions are valid within subsets of their data. At the very most, empirical SE should become a search for local regions with similar properties (and conclusions should be constrained to just those regions).},
author = {Menzies, Tim and Butcher, Andrew and Marcus, Andrian and Zimmermann, Thomas and Cok, David},
booktitle = {2011 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011)},
doi = {10.1109/ASE.2011.6100072},
isbn = {978-1-4577-1639-3},
issn = {1938-4300},
keywords = {Data mining,I,defect/effort estimation,empirical SE.,validation},
pages = {343--351},
title = {{Local vs. global models for effort estimation and defect prediction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6100072},
year = {2011}
}
@inproceedings{me95a,
author = {Menzies, T J},
booktitle = {Australian Cognitive Science Society, 3rd Conference},
title = {{Situated \{S\}emantics is a \{S\}ide-\{E\}ffect of the \{C\}omputational \{C\}omplexity of \{A\}bduction}},
year = {1995}
}
@inproceedings{czer11,
author = {Czerwonka, Jacek and Das, Rajiv},
booktitle = {Software Testing, \ldots},
isbn = {1612841740},
month = mar,
pages = {1--10},
title = {{Crane: Failure prediction, change analysis and test prioritization in practice--experiences from windows}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5770625},
year = {2011}
}
@inproceedings{Marcus2010a,
abstract = {Software systems are designed and engineered to process data. However, software is data too. The size and variety of today's software artifacts and the multitude of stakeholder activities result in so much data that individuals can no longer reason about all of it. Software evolution is no longer just about writing code, it is becoming an information management problem.
Analysis and management of the software data are activities that software engineers are not trained to do. We have to look for solutions outside software engineering, adopt them, and make them our own. These solutions can come from data mining, information retrieval, machine learning, statistical analysis, etc. This is not the first time software engineers are looking at such solutions. It has been going on for about two decades, in a form or another. The results so far indicate that software engineering is facing a paradigm shift, where more and more software engineering tasks are reinterpreted as optimization, search, retrieval, or classification problems. Despite this experience, applications of data analysis, data integration, and data mining in software engineering are in their infancy by comparison with other research fields. New research is needed to adapt existing algorithms and tools for software engineering data and processes, and new ones will have to be created. This research has to be supported by integration with software development processes and with education as well. More than that, in order for this type of research to succeed, it should be supported with new approaches to empirical work, where data and results are shared globally among researchers and practitioners.
The talk will focus on arguing for and mapping out (part of) this research agenda, while looking back at (some of) the existing work in the area.},
address = {Antwerp, Belgium},
annote = {Laura. Fixed on 10/01/2012},
author = {Marcus, Andrian},
booktitle = {2010 ERCIM Workshop on Software Evolution (EVOL) and the International Workshop on Principles of Software Evolution (IWPSE)},
keywords = {data\_mining software\_engineering information\_retri},
pages = {1--3},
title = {{Software is data too: how should we deal with it?}},
year = {2010}
}
@incollection{benavides05,
author = {Guizzardi, Giancarlo and Wagner, Gerd and Guarino, Nicola and van Sinderen, Marten},
booktitle = {CAiSE},
doi = {10.1007/b98058},
editor = {Pastor, Oscar and e Cunha, Jo\~{a}o},
isbn = {978-3-540-22151-7},
issn = {0302-9743},
pages = {112--126},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Advanced Information Systems Engineering}},
url = {http://dblp.uni-trier.de/db/conf/caise/caise2004.html\#GuizzardiWGMR04},
volume = {3084},
year = {2004}
}
@inproceedings{ester96,
author = {Ester, Martin and Kriegel, Hans-peter and S, J\"{o}rg and Xu, Xiaowei},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Ester et al. - 1996 - A density-based algorithm for discovering clusters in large spatial databases with noise.pdf:pdf},
pages = {226--231},
publisher = {AAAI Press},
title = {{A density-based algorithm for discovering clusters in large spatial databases with noise}},
year = {1996}
}
@article{me97j,
author = {Menzies, Tim},
doi = {10.1002/(SICI)1097-024X(199712)27:12<1457::AID-SPE140>3.3.CO;2-0},
issn = {00380644},
journal = {Software: Practice and Experience},
keywords = {knowledge-level modelling,oo patterns expert systems},
month = dec,
number = {12},
pages = {1457--1478},
title = {{Objectâoriented patterns: lessons from expert systems}},
url = {http://doi.wiley.com/10.1002/(SICI)1097-024X(199712)27:12<1457::AID-SPE140>3.3.CO;2-0},
volume = {27},
year = {1997}
}
@article{me89za,
author = {Me, Tim},
journal = {AI Magazine},
number = {2},
pages = {53--61},
title = {{An Investigation of AI and Expert Systems Literature : 1 980-l 984}},
volume = {10},
year = {1989}
}
@article{me99r,
abstract = {So, Iâm to be marooned on a desert island with a handful of books relating to software engineering? I have two immediate, conflicting, reactions. One is to complete the punchline to a music-hall joke: "Second prize, marooned with two handfuls of software engineering books". The other is to think, I take a handful of books on a short train journey, because Iâm terrified of being caught without reading material: how will I last on the island? This wins over the joke, and I start to compose my list. ...},
annote = {Available from $\backslash$url\{http://menzies.us/desert.html\}},
author = {Potts, C.},
doi = {10.1023/A:1008684813868},
issn = {09288910},
journal = {Automated Software Engineering},
number = {4},
pages = {463--466},
title = {{Desert island column}},
volume = {4},
year = {1997}
}
@article{me09b,
abstract = {We propose a practical defect prediction approach for companies that do not track defect related data. Specifically, we investigate the applicability of cross-company (CC) data for building localized defect predictors using static code features. Firstly, we analyze the conditions, where CC data can be used as is. These conditions turn out to be quite few. Then we apply principles of analogy-based learning (i.e. nearest neighbor (NN) filtering) to CC data, in order to fine tune these models for localization. We compare the performance of these models with that of defect predictors learned from within-company (WC) data. As expected, we observe that defect predictors learned from WC data outperform the ones learned from CC data. However, our analyses also yield defect predictors learned from NN-filtered CC data, with performance close to, but still not better than, WC data. Therefore, we perform a final analysis for determining the minimum number of local defect reports in order to learn WC defect predictors. We demonstrate in this paper that the minimum number of data samples required to build effective defect predictors can be quite small and can be collected quickly within a few months. Hence, for companies with no local defect data, we recommend a two-phase approach that allows them to employ the defect prediction process instantaneously. In phase one, companies should use NN-filtered CC data to initiate the defect prediction process and simultaneously start collecting WC (local) data. Once enough WC data is collected (i.e. after a few months), organizations should switch to phase two and use predictors learned from WC data.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ccwc.pdf\}},
author = {Turhan, Burak and Menzies, Tim and Bener, AyÅe B. and {Di Stefano}, Justin},
doi = {10.1007/s10664-008-9103-7},
isbn = {1382-3256},
issn = {13823256},
journal = {Empirical Software Engineering},
keywords = {Cross-company,Defect prediction,Learning,Metrics (product metrics),Nearest-neighbor filtering,Within-company},
number = {5},
pages = {540--578},
title = {{On the relative value of cross-company and within-company data for defect prediction}},
volume = {14},
year = {2009}
}
@inproceedings{me96e,
author = {Menzies, T J},
booktitle = {Proceedings of the 10th Knowledge Acquisition Workshop for Knowledge-Based Systems, Banff,Canada},
title = {{Assessing Responses to Situated Congition}},
year = {1996}
}
@inproceedings{me97n,
author = {Menzies, T J},
booktitle = {Banff Knowledge Acquisition workshop, 1998},
title = {{Evaluation Issues for Problem Visual Programming Languages}},
year = {1998}
}
@inproceedings{me00s,
author = {Menzies, T and Cukic, B},
booktitle = {International Workshop on Empirical Studies of Software Maintenance (WESS 2000), October 14, San Jose CA},
title = {{Maintaining Maintainability = Recognizing Reachability}},
year = {2000}
}
@article{kirsopp03,
author = {Kirsopp, Colin and Shepperd, Martin},
journal = {Research and Development in Intelligent Systems XIX},
pages = {61--74},
publisher = {Springer-Verlag New York Inc},
title = {{Case and feature subset selection in case-based software project effort prediction}},
year = {2003}
}
@article{Liu2005c,
abstract = {This paper introduces concepts and algorithms of feature selection, surveys existing feature selection algorithms for classification and clustering, groups and compares different algorithms with a categorizing framework based on search strategies, evaluation criteria, and data mining tasks, reveals unattempted combinations, and provides guidelines in selecting feature selection algorithms. With the categorizing framework, we continue our efforts toward-building an integrated system for intelligent feature selection. A unifying platform is proposed as an intermediate step. An illustrative example is presented to show how existing feature selection algorithms can be integrated into a meta algorithm that can take advantage of individual algorithms. An added advantage of doing so is to help a user employ a suitable algorithm without knowing details of each algorithm. Some real-world applications are included to demonstrate the use of feature selection in data mining. We conclude this work by identifying trends and challenges of feature selection research and development.},
author = {Liu, Huan and Yu, Lei},
doi = {10.1109/TKDE.2005.66},
file = {:Users/timm/svns/doc/04clusteringReview.pdf:pdf},
isbn = {1041-4347},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Categorizing framework,Classification,Clustering,Feature selection,Real-world applications,Unifying platform},
number = {4},
pages = {491--502},
title = {{Toward integrating feature selection algorithms for classification and clustering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1401889},
volume = {17},
year = {2005}
}
@inproceedings{white09,
abstract = {The increasing complexity and cost of software-intensive systems has led developers to seek ways of increasing software reusability. One software reuse approach is to develop a Software Product-line (SPL), which is a reconfigurable software architecture that can be reused across projects. Creating configurations of the SPL that meets arbitrary requirements is hard.},
address = {Pittsburgh, PA, USA},
author = {White, Jules and Dougherty, Brian and Schmidt, Douglas C. and Benavides, David},
booktitle = {Proceedings of the 13th International Software Product Line Conference},
pages = {11--20},
publisher = {Carnegie Mellon University},
series = {SPLC '09},
title = {{Automated reasoning for multi-step feature model configuration problems}},
url = {http://dl.acm.org/citation.cfm?id=1753235.1753238},
year = {2009}
}
@article{basili84,
abstract = {An effective data collection method for evaluating software development methodologies and for studying the software development process is described. The method uses goal-directed data collection to evaluate methodologies with respect to the claims made for them. Such claims are used as a basis for defining the goals of the data collection, establishing a list of questions of interest to be answered by data analysis, defining a set of data categorization schemes, and designing a data collection form. The data to be collected are based on the changes made to the software during development, and are obtained when the changes are made. To ensure accuracy of the data, validation is performed concurrently with software development and data collection. Validation is based on interviews with those people supplying the data. Results from using the methodology show that data validation is a necessary part of change data collection. Without it, as much as 50 percent of the data may be erroneous. Feasibility of the data collection methodology was demonstrated by applying it to five different projects in two different environments. The application showed that the methodology was both feasible and useful.},
author = {Basili, Victor R. and Weiss, David M.},
doi = {10.1109/TSE.1984.5010301},
isbn = {0098-5589 VO - SE-10},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Data collection,data collection methodology,error analysis,error classification,software engineering experimentation},
month = nov,
number = {6},
pages = {728--738},
title = {{A Methodology for Collecting Valid Software Engineering Data}},
volume = {SE-10},
year = {1984}
}
@inproceedings{Gupta2004,
abstract = {In this paper we introduce a new single pass clustering algorithm called GenIc designed with the objective of having low overall cost. We examine some of the properties of GenIc and compare it to windowed k-means. We also study its performance using experimental data sets obtained from network monitoring.},
author = {Gupta, Chetan and Grossman, Robert},
booktitle = {Proceedings of the SIAM International Conference on Data Mining},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Gupta, Grossman - 2004 - Genic A single pass generalized incremental algorithm for clustering.pdf:pdf},
keywords = {O(n) clustering},
pages = {147--153},
title = {{Genic: A single pass generalized incremental algorithm for clustering}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=gcJVK9a9RR0C\&amp;oi=fnd\&amp;pg=PA147\&amp;dq=GenIc+:+A+Single+Pass+Generalized+Incremental+Algorithm+for+Clustering\&amp;ots=mOra4Ryn2o\&amp;sig=Wvri4I0679nq1\_D\_8BogxvuyU7g},
year = {2004}
}
@article{deb00a,
author = {Deb, Kalyanmoy and Pratap, Amrit and Agarwal, Sameer and Meyarivan, T},
journal = {IEEE Transactions on Evolutionary Computation},
pages = {182--197},
title = {{.\_A FAST ELITIST MULTIOBJECTIVE GENETIC ALGORITHM- NSGA-II.pdf}},
volume = {6},
year = {2002}
}
@article{me11p,
author = {Brady, Adam},
journal = {Software Quality Professional},
keywords = {article,case-based reasoning,data quality,is available on the,note,planning,sqp website,supplemental material for this},
number = {4},
title = {{What is â Enough â Quality for Data Repositories ?}},
volume = {13},
year = {2011}
}
@inproceedings{andrews07,
abstract = {Randomized testing has been shown to be an effective method fortesting software units. However, the thoroughness of randomized unit testing varies widely according to the settings of certain parameters, such as the relative frequencies with which methods are called. In this paper, we describe a system which uses agenetic algorithm to find parameters for randomized unit testing that optimize test coverage. We compare our coverage results to previous work, and report on case studies and experiments on system options. Copyright 2007 ACM.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07ase-nighthawk.pdf\}},
author = {Andrews, J.H. and Li, F.C.H. and Menzies, Tim},
booktitle = {Proceedings of the twenty-second IEEE/ACM international conference on Automated software engineering},
doi = {10.1145/1321631.1321654},
isbn = {9781595938824},
keywords = {genetic algorithms,randomized testing,test coverage},
pages = {144--153},
title = {{Nighthawk: A two-level genetic-random unit test data generator}},
url = {http://dl.acm.org/citation.cfm?id=1321654},
year = {2007}
}
@article{me03f,
author = {Menzies, T},
journal = {Requirements Engineering},
title = {{Editorial, Requirements Engineering Journal, Special Issue on Model-based Requirements Engineering}},
year = {2003}
}
@article{kocaguneli2014transfer,
author = {Kocaguneli, Ekrem and Menzies, Tim and Mendes, Emilia},
journal = {Empirical Software Engineering},
pages = {1--31},
publisher = {Springer US},
title = {{Transfer learning in effort estimation}},
year = {2014}
}
@inproceedings{andrews07,
abstract = {Randomized testing has been shown to be an effective method fortesting software units. However, the thoroughness of randomized unit testing varies widely according to the settings of certain parameters, such as the relative frequencies with which methods are called. In this paper, we describe a system which uses agenetic algorithm to find parameters for randomized unit testing that optimize test coverage. We compare our coverage results to previous work, and report on case studies and experiments on system options. Copyright 2007 ACM.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07ase-nighthawk.pdf\}},
author = {Andrews, J.H. and Li, F.C.H. and Menzies, Tim},
booktitle = {Proceedings of the twenty-second IEEE/ACM international conference on Automated software engineering},
doi = {10.1145/1321631.1321654},
isbn = {9781595938824},
keywords = {genetic algorithms,randomized testing,test coverage},
pages = {144--153},
title = {{Nighthawk: A two-level genetic-random unit test data generator}},
url = {http://dl.acm.org/citation.cfm?id=1321654},
year = {2007}
}
@article{krall12,
author = {Krall, Joseph},
doi = {10.4236/jsea.2012.57052},
issn = {1945-3116},
journal = {Journal of Software Engineering and Applications},
number = {07},
pages = {459--466},
title = {{Aspects of Replayability and Software Engineering: Towards a Methodology of Developing Games}},
volume = {05},
year = {2012}
}
@inproceedings{lum06,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06ispa.pdf\}},
author = {Lum, Karen and Menzies, Tim and Hihn, Jairus},
booktitle = {ISPA Conference Proceedings},
title = {{Studies in Software Cost Model Behavior: Do We Really Understand Cost Model Performance?}},
url = {http://trs-new.jpl.nasa.gov/dspace/handle/2014/41450},
year = {2006}
}
@inproceedings{me12b,
abstract = {Gaming companies now routinely apply data mining to their user data in order to plan the next release of their software. We predict that such software development analytics will become commonplace, in the near future. For example, as large software systems migrate to the cloud, they are divided and sold as dozens of smaller apps; when shopping inside the cloud, users are free to mix and match their apps from multiple vendors (e.g. Google Docs' word processor with Zoho's slide manager); to extend, or even retain, market share cloud vendors must mine their user data in order to understand what features best attract their clients. This panel will address the open issues with analytics. Issues addressed will include the following. What is the potential for software development analytics? What are the strengths and weaknesses of the current generation of analytics tools? How best can we mature those tools?},
author = {Menzies, Tim and Zimmermann, Thomas},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2012.6227117},
isbn = {9781467310673},
issn = {02705257},
keywords = {analytics,empirical software engineering,industry,mining software repositories},
pages = {1032--1033},
title = {{Goldfish bowl panel: Software development analytics}},
year = {2012}
}
@article{Lecture2010a,
author = {Lecture, Stochastics and Prof, Notes and Schmidt, Volker},
file = {:Users/timm/svns/doc/12markovChainsMonteCarlo.pdf:pdf},
number = {July},
title = {{Markov Chains and Monte â Carlo Simulation}},
year = {2010}
}
@inproceedings{me03b,
author = {Liu, Y and Menzies, T and Cukic, B},
title = {{Detecting Novelties by Mining Association Rules}},
year = {2003}
}
@article{basili99z,
author = {Basili, Victor R and Others},
journal = {ACM SIGSOFT Software Engineering Notes},
month = may,
number = {3},
pages = {37--44},
title = {{Final Report \{NSF\} Workshop on a Software Research Program For the 21st Century, Greenbelt, Maryland}},
volume = {24},
year = {1999}
}
@article{wu08,
abstract = {This paper presents the top 10 data mining algorithms identified by the IEEE International Conference on Data Mining (ICDM) inDecember 2006: C4.5, k-Means, SVM, Apriori, EM, PageRank, AdaBoost, kNN, Naive Bayes, and CART. These top 10 algorithms are among themost influential datamining algorithms in the research community.With each algorithm, we provide a description of the algorithm, discuss the impact of the algorithm, and reviewcurrent and further research on the algorithm. These 10 algorithms cover classification clustering, statistical learning, association analysis, and linkmining, which are all among the most important topics in data mining research and development.},
author = {Wu, Xindong and Kumar, Vipin and {Ross Quinlan}, J. and Ghosh, Joydeep and Yang, Qiang and Motoda, Hiroshi and McLachlan, Geoffrey J. and Ng, Angus and Liu, Bing and Yu, Philip S. and Zhou, Zhi-Hua and Steinbach, Michael and Hand, David J. and Steinberg, Dan},
doi = {10.1007/s10115-007-0114-2},
file = {:Users/timm/svns/doc/07top10dataMiners.pdf:pdf},
isbn = {1011500701},
issn = {0219-1377},
journal = {Knowledge and Information Systems},
number = {1},
pages = {1--37},
title = {{Top 10 algorithms in data mining}},
volume = {14},
year = {2008}
}
@article{Bennett2006a,
abstract = {We consider a dynamical system in R driven by a vector field -U', where U is a multi-well potential satisfying some regularity conditions. We perturb this dynamical system by a Levy noise of small intensity and such that the heaviest tail of its Levy measure is regularly varying. We show that the perturbed dynamical system exhibits metastable behaviour i.e. on a proper time scale it reminds of a Markov jump process taking values in the local minima of the potential U. Due to the heavy-tail nature of the random perturbation, the results differ strongly from the well studied purely Gaussian case.},
archivePrefix = {arXiv},
arxivId = {math/0601771},
author = {Imkeller, Peter and Pavlyukevich, Ilya},
doi = {10.1051/ps},
eprint = {0601771},
file = {:Users/timm/svns/doc/optimalML/06overview.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {convex optimization,machine learning,mathematical programming},
pages = {33},
primaryClass = {math},
title = {{Metastable Behaviour of Small Noise Levy-Driven Diffusions}},
url = {http://arxiv.org/abs/math/0601771},
volume = {7},
year = {2006}
}
@techreport{turhan11,
author = {Turhan, Burak},
institution = {Department of Information Processing Science, University of Oulu},
title = {{Technical Report: Conclusion Stability and OO Defect Predictors}},
year = {2011}
}
@misc{spear00,
title = {{No Title}}
}
@inproceedings{koc12m,
author = {Kocaguneli, Ekrem and Menzies, T and Hihn, Jairus and Kang, Bh},
booktitle = {\ldots Models in Software \ldots},
doi = {10.1145/2365324.2365336},
isbn = {9781450312417},
keywords = {all or part of,analogy-,based estimation,function points,instance selection,k-nn,lines of code,or hard copies of,permission to make digital,popularity,this work for},
pages = {89--98},
title = {{Size Doesn â t Matter ? On the Value of Software Size Features for Effort Estimation}},
url = {http://dl.acm.org/citation.cfm?id=2365336},
year = {2012}
}
@inproceedings{orrego09,
abstract = {Using process simulation and AI search methods, we compare software reuse against other possible changes to a project. such as reducing functionality or improving the skills of the programmer population. In one case, two generations of reuse were as good or better than any other project change (but a third and fourth generation of reuse was not useful). In another case, applying reuse to a project was demonstrable worse than several other possible changes to a project. Our conclusion is that the general claims regarding the benefits of software reuse do not hold for specific projects. We argue that the merits of software reuse need to be evaluated in a project by project basis. AI search over process models is useful for such an assessment, particularly when there is not sufficient data for precisely tuning a simulation model.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09reuse.pdf\}},
author = {{Andres Orrego, Tim Menzies}, Oussama El-Rawas},
booktitle = {Icsp2009},
pages = {186--197},
title = {{On the Relative Merits of Software Reuse}},
year = {2009}
}
@article{me99p,
abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article. ACM has opted to expose the complete List rather than only correct and linked references.},
author = {Menzies, Tim},
doi = {10.1145/318964.318969},
isbn = {1523-8822},
issn = {15238822},
journal = {Intelligence},
number = {3},
pages = {26--32},
title = {{Cost benefits of ontologies}},
volume = {10},
year = {1999}
}
@article{tosun2010,
author = {Tosun, A and Bener, A and Turhan, B and Menzies, T},
title = {{No Title}}
}
@inproceedings{harman12,
abstract = {This paper introduces app store mining and analysis as a form of software repository mining. Unlike other software repositories traditionally used in MSR work, app stores usually do not provide source code. However, they do provide a wealth of other information in the form of pricing and customer reviews. Therefore, we use data mining to extract feature information, which we then combine with more readily available information to analyse apps' technical, customer and business aspects. We applied our approach to the 32,108 non-zero priced apps available in the Blackberry app store in September 2011. Our results show that there is a strong correlation between customer rating and the rank of app downloads, though perhaps surprisingly, there is no correlation between price and downloads, nor between price and rating. More importantly, we show that these correlation findings carry over to (and are even occasionally enhanced within) the space of data mined app features, providing evidence that our `App store MSR' approach can be valuable to app developers. View full abstract},
author = {Harman, Mark and Jia, Yue and Zhang, Yuanyuan},
booktitle = {IEEE International Working Conference on Mining Software Repositories},
doi = {10.1109/MSR.2012.6224306},
isbn = {9781467317610},
issn = {21601852},
pages = {108--111},
title = {{App store mining and analysis: MSR for app stores}},
year = {2012}
}
@inproceedings{me00b,
abstract = {The behavior of nondeterminate systems can be hard to predict,
since similar inputs at different times can generate different outputs.
In other words, the behavior seen during the testing process may not be
seen at runtime. Due to the uncertainties associated with
nondeterminism, the standard view is that we should avoid such
nondeterminate systems, especially for systems requiring high
reliability. While this is a valid guideline, at least in two
application areas such nondeterminacy is unavoidable. Early life-cycle
requirements and AI software are becoming widely used, yet both are
imprecise and may exhibit nondeterminate behaviour if explored
rigorously by a test device. Based on a literature review and some
theoretical studies, we argue that many stable properties exist within
the space of all possible nondeterminate behaviors. However, we also
show that seemingly trivial changes to a nondeterministic system can
turn an easily testable system into an impossibly hard system to test.
Finally, we stress that this analysis does not imply a correlation
between stable zones of nondeterminate testability and the ultimate
maintainability of nondeterminate systems. That is, while we are
optimistic about testing nondeterminate systems, we remain cautious
about the maintenance of such systems},
author = {Menzies, T. and Cukic, B. and Singh, H. and Powell, J.},
booktitle = {Proceedings 11th International Symposium on Software Reliability Engineering. ISSRE 2000},
doi = {10.1109/ISSRE.2000.885874},
isbn = {0-7695-0807-3},
issn = {1071-9458},
title = {{Testing nondeterminate systems}},
year = {2000}
}
@article{Bavota2013,
author = {{Bavota Gabriele}, De Lucia Andrea Marcus Andrian and Oliveto, Rocco},
journal = {Empirical Software Engineering},
pages = {1--48},
title = {{Automating extract class refactoring: an improved method and its evaluation}},
year = {2013}
}
@book{paul13,
author = {Paul, L A and Hall, N},
publisher = {Oxford University Press},
title = {{Causation : A Userâs Guide}},
year = {2013}
}
@article{Spears1990a,
author = {Spears, W.M. and {De Jong}, K.a.},
file = {:Users/timm/svns/doc/92ga\_rules.pdf:pdf},
pages = {335--341},
title = {{Using genetic algorithms for supervised concept learning}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=130359},
year = {1990}
}
@inproceedings{nam13,
author = {Pan, Sinno Jialin},
booktitle = {the 2013 International Conference on Software Engineering},
isbn = {9781467330763},
organization = {IEEE Press Piscataway, NJ, USA},
pages = {802--811},
title = {{Transfer Defect * Learning 2013. 05. 22}},
year = {2013}
}
@article{jmlr12,
abstract = {DEAP is a novel evolutionary computation framework for rapid prototyping and testing of ideas. Its design departs from most other existing frameworks in that it seeks to make algorithms explicit and data structures transparent, as opposed to the more common black-box frameworks. Freely avail- able with extensive documentation at http://deap.gel.ulaval.ca, DEAP is an open source project under an LGPL license.},
author = {Gagn, Christian},
doi = {10.1.1.413.6512},
isbn = {1532-4435},
issn = {1533-7928},
journal = {Journal of Machine Learning Research},
month = jul,
pages = {2171--2175},
title = {{DEAP : Evolutionary Algorithms Made Easy}},
url = {http://jmlr.csail.mit.edu/papers/volume13/fortin12a/fortin12a.pdf},
volume = {13},
year = {2012}
}
@inproceedings{me03g,
author = {{T. Menzies J. Smith}, D Raffo},
title = {{When is Pair Programming Better?}},
year = {2003}
}
@article{Zaki2007a,
abstract = {We present a novel algorithm called Clicks, that finds clusters in categorical datasets based on a search for k-partite maximal cliques. Unlike previous methods, Clicks mines subspace clusters. It uses a selective vertical method to guarantee complete search. Clicks outperforms previous approaches by over an order of magnitude and scales better than any of the existing method for high-dimensional datasets. These results are demonstrated in a comprehensive performance study on real and synthetic datasets. Â© 2006 Elsevier B.V. All rights reserved.},
author = {Zaki, Mohammed J. and Peters, Markus and Assent, Ira and Seidl, Thomas},
doi = {10.1016/j.datak.2006.01.005},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/zaki06.pdf:pdf},
isbn = {159593135X},
issn = {0169023X},
journal = {Data and Knowledge Engineering},
keywords = {Categorical data,Clustering,Maximal cliques,k-Partite graph},
number = {1},
pages = {51--70},
title = {{Clicks: An effective algorithm for mining subspace clusters in categorical datasets}},
volume = {60},
year = {2007}
}
@inproceedings{me09k,
abstract = {Concept location is a critical activity during software evolution as it produces the location where a change is to start in response to a modification request, such as, a bug report or a new feature request. Lexical-based concept location techniques rely on matching the text embedded in the source code to queries formulated by the developers. The efficiency of such techniques is strongly dependent on the ability of the developer to write good queries. We propose an approach to augment information retrieval (IR) based concept location via an explicit relevance feedback (RF) mechanism. RF is a two-part process in which the developer judges existing results returned by a search and the IR system uses this information to perform a new search, returning more relevant information to the user. A set of case studies performed on open source software systems reveals the impact of RF on IR based concept location.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09irrf.pdf\}},
author = {Gay, Gregory and Haiduc, Sonia and Marcus, Andrian and Menzies, Tim},
booktitle = {IEEE International Conference on Software Maintenance, ICSM},
doi = {10.1109/ICSM.2009.5306315},
isbn = {9781424448289},
issn = {1063-6773},
pages = {351--360},
title = {{On the use of relevance feedback in IR-based concept location}},
year = {2009}
}
@article{Takahashi2006a,
abstract = {Models for numerical simulations should be described in a coherent style. They are expected to have consistencies at the causal dependency level. However, System Dynamics causal loop diagrams can have inconsistencies. This diagram styleâs arrows, concerning flow and stock relationships, can have the opposite direction of stock flow diagrams which can numerically simulate models. These inconsistencies can cause inappropriate qualitative simulations so that it is sometimes recommended to use stock flow diagrams instead of causal loop diagrams even for qualitative simulations. However, causal loop diagrams have merits in their use. Causal loop diagrams are intuitively easy to draw and read. If causal loop diagrams are given information about each variableâs dynamic property, they can be changed to stock flow diagrams and simulation models can be generated. This paper suggests how to use causal loop diagrams as a starting point in numerical simulation research.},
author = {Takahashi, Yutaka},
file = {:Users/timm/svns/doc/optimalML/06takModelingWithIncomplete.pdf:pdf},
journal = {Proceedings of the 24th International Conference of the System Dynamics Society},
keywords = {automatic modelling,natural language,stock flow diagram},
pages = {122},
title = {{Stock Flow Diagram Making with Incomplete Information about Time Properties of Variables}},
year = {2006}
}
@inproceedings{me96f,
author = {Menzies, T J and Goss, S},
booktitle = {Proceedings PKAW '96: Pacific Knowledge Acquisition Workshop and Monash University Department of Software Development Technical Report TR96-15},
title = {{Vague Models and Their Implications for the KBS Design Cycle}},
year = {1996}
}
@inproceedings{me97b,
author = {Menzies, T J and Mahidadia, a},
booktitle = {Workshop on Problem-Solving Methods for Knowledge-based Systems, IJCAI '97, August 23.},
title = {{Ripple-Down Rationality: A Framework for Maintaining PSMs}},
year = {1997}
}
@misc{me07c,
annote = {$\backslash$url\{http://promisedata.org/repository\}},
author = {Boetticher, G and Menzies, T and Ostrand, T},
institution = {West Virginia University, Lane Department of Computer Science and Electrical Engineering},
title = {{The \{PROMISE\} \{R\}epository of \{E\}mpirical \{S\}oftware \{E\}ngineering \{D\}ata}},
year = {2007}
}
@misc{me00c,
author = {Menzies, Tim and Cukic, Bojan and Coiera, Enrico},
month = apr,
number = {April},
pages = {7--10},
title = {{Agents Talking Faster Â¤Â£}},
year = {2000}
}
@inproceedings{burk04,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/04lean.pdf\}},
author = {Burkleaux, T and Menzies, T and Owen, D},
booktitle = {Proceedings of WITSE 2005},
title = {{LEAN = (LURCH+TAR3) = Reusable Modeling Tools}},
year = {2004}
}
@article{Boots2011a,
abstract = {Recently, a number of researchers have proposed spectral algorithms for learning models of dynam- ical systemsâfor example, Hidden Markov Models (HMMs), Partially Observable Markov Decision Pro- cesses (POMDPs), and Transformed Predictive State Representations (TPSRs). These algorithms are attrac- tive since they are statistically consistent and not sub- ject to local optima. However, they are batch methods: they need to store their entire training data set in mem- ory at once and operate on it as a large matrix, and so they cannot scale to extremely large data sets (ei- ther many examples or many features per example). In turn, this restriction limits their ability to learn accurate models of complex systems. To overcome these lim- itations, we propose a new online spectral algorithm, which uses tricks such as incremental Singular Value Decomposition (SVD) and random projections to scale to much larger data sets and more complex systems than previous methods. We demonstrate the new method on an inertial measurement prediction task and a high- bandwidth video mapping task and we illustrate desir- able behaviors such as âclosing the loop,â where the la- tent state representation changes suddenly as the learner recognizes that it has returned to a previously known place. Introduction},
author = {Boots, Byron and Gordon, Geoffrey J.},
file = {:Users/timm/svns/doc/11onlineSpectralLearning.pdf:pdf},
isbn = {9781577355083},
journal = {Proceedings of the 25th National Conference on Artificial Intelligence},
title = {{An Online Spectral Learning Algorithm for Partially Observable Nonlinear Dynamical Systems}},
year = {2011}
}
@inproceedings{me00u,
author = {Menzies, T and Singh, H},
booktitle = {Advances in Artificial Intelligence, 14th Biennial Conference of the Canadian Society for Computational Studies of Intelligence, AI 2001, Ottawa, Canada, June 7-9, 2001, Proceedings},
pages = {100--110},
title = {{How AI Can Help SE; or: Randomized Search Not Considered Harmful}},
year = {2001}
}
@misc{Sayyad-Shirabad+Menzies:2005,
author = {{Sayyad Shirabad, J., Menzies}, T.J.},
booktitle = {University of Ottawa, Canada .},
howpublished = {School of Information Technology and Engineering, University of Ottawa, Canada},
title = {{The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering}},
url = {http://promise.site.uottawa.ca/SERepository},
year = {2005}
}
@article{Dasgupta2005,
abstract = {We abstract out the core search problem of active learning schemes, to better understand the extent to which adaptive labeling can improve sample complexity. We give various upper and lower bounds on the number of labels which need to be queried, and we prove that a popular greedy active learning rule is approximately as good as any other strategy for minimizing this number of labels. 1},
author = {Dasgupta, Sanjoy},
journal = {Advances in Neural Information Processing Systems 17},
number = {x},
pages = {337--344},
title = {{Analysis of a greedy active learning strategy}},
url = {http://media.nips.cc/nipsbooks/nipspapers/paper\_files/nips17/NIPS2004\_0514.pdf},
volume = {1},
year = {2004}
}
@misc{bobntim2,
author = {Cohen, R F and Menzies, T},
number = {TR95-20},
title = {{Reverse Engineering a Software Engineering Curriculum}},
year = {1995}
}
@article{turhan12,
abstract = {A core assumption of any prediction model is that test data distribution does not differ from training data distribution. Prediction models used in software engineering are no exception. In reality, this assumption can be violated in many ways resulting in inconsistent and non-transferrable observations across different cases. The goal of this paper is to explain the phenomena of conclusion instability through the dataset shift concept from software effort and fault prediction perspective. Different types of dataset shift are explained with examples from software engineering, and techniques for addressing associated problems are discussed. While dataset shifts in the form of sample selection bias and imbalanced data are well-known in software engineering research, understanding other types is relevant for possible interpretations of the non-transferable results across different sites and studies. Software engineering community should be aware of and account for the dataset shift related issues when evaluating the validity of research outcomes. \&copy; 2011 Springer Science+Business Media, LLC.},
author = {Turhan, Burak},
doi = {10.1007/s10664-011-9182-8},
issn = {13823256},
journal = {Empirical Software Engineering},
keywords = {Dataset shift,Defect prediction,Effort estimation,Prediction models},
number = {1-2},
pages = {62--74},
publisher = {Springer Netherlands},
title = {{On the dataset shift problem in software engineering prediction models}},
volume = {17},
year = {2012}
}
@article{me99r,
abstract = {So, Iâm to be marooned on a desert island with a handful of books relating to software engineering? I have two immediate, conflicting, reactions. One is to complete the punchline to a music-hall joke: "Second prize, marooned with two handfuls of software engineering books". The other is to think, I take a handful of books on a short train journey, because Iâm terrified of being caught without reading material: how will I last on the island? This wins over the joke, and I start to compose my list. ...},
annote = {Available from $\backslash$url\{http://menzies.us/desert.html\}},
author = {Potts, C.},
doi = {10.1023/A:1008684813868},
issn = {09288910},
journal = {Automated Software Engineering},
number = {4},
pages = {463--466},
title = {{Desert island column}},
volume = {4},
year = {1997}
}
@phdthesis{hall99,
abstract = {A central problem in machine learning is identifying a representative set of features from which to construct a classification model for a particular task. This thesis addresses the problem of feature selection for machine learning through a correlation based approach. The central hypothesis is that good feature sets contain features that are highly correlated with the class, yet uncorrelated with each other. A feature evaluation formula, based on ideas from test theory, provides an operational ...},
author = {Hall, Mark a},
booktitle = {Methodology},
pages = {1--5},
school = {Department of Computer Science, University of Waikato},
title = {{Correlation-based Feature Selection for Machine Learning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.62.9584\&amp;rep=rep1\&amp;type=pdf},
volume = {21i195-i20},
year = {1999}
}
@inproceedings{cruz09,
abstract = {In this paper, we discuss the challenge of making logistic regression models able to predict fault-prone object-oriented classes across software projects. Several studies have obtained successful results in using design-complexity metrics for such a purpose. However, our data exploration indicates that the distribution of these metrics varies from project to project, making the task of predicting across projects difficult to achieve. As a first attempt to solve this problem, we employed simple log transformations for making design-complexity measures more comparable among projects. We found these transformations useful in projects which data is not as spread as the data used for building the prediction model.},
author = {Cruz, a. and Ochimizu, K.},
booktitle = {2009 3rd International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2009.5316002},
isbn = {978-1-4244-4842-5},
issn = {1938-6451},
pages = {460--463},
title = {{Towards logistic regression models for predicting fault-prone code across software projects}},
year = {2009}
}
@inproceedings{me12c,
annote = {Available from http://menzies.us/pdf/12idea.pdf},
author = {Borges, Raymond and Menzies, Tim},
booktitle = {Proceedings of the 8th International Conference on Predictive Models in Software Engineering - PROMISE '12},
doi = {10.1145/2365324.2365328},
isbn = {9781450312417},
keywords = {effort estimation,optimization},
pages = {11--18},
title = {{Learning to change projects}},
url = {http://dl.acm.org/citation.cfm?doid=2365324.2365328},
year = {2012}
}
@article{me89za,
author = {Menzies, Tim},
journal = {AI Magazine},
title = {{An \{I\}nvestigation of the \{AI\} and \{E\}xpert \{S\}ystems \{L\}iterature 1980-1984}},
year = {1989}
}
@inproceedings{me03i,
author = {Comford, Steven L. and Feather, Martin S. and Dunphy, Julia R. and Salcedo, Jose and Menzies, Tim},
booktitle = {IEEE Aerospace Conference Proceedings},
doi = {10.1109/AERO.2003.1235551},
isbn = {078037651X},
issn = {1095323X},
pages = {3681--3690},
title = {{Optimizing spacecraft design optimization engine development: Progress and plans}},
volume = {8},
year = {2003}
}
@misc{Boetticher:Menzies:Ostrand:2007,
author = {Menzies, T and Caglayan, B and Kocaguneli, E and Krall, J and Peters, F and Turhan, B},
booktitle = {Available: promisedata. googlecode. com},
institution = {West Virginia University, Department of Computer Science},
title = {{The promise repository of empirical software engineering data}},
url = {http://promisedata.org/repository},
year = {2012}
}
@inproceedings{me92n,
author = {Menzies, T J and Compton, P and Mahidadia, a},
booktitle = {Communicating Scientific and Technical Knowledge, an AAAI '92 workshop},
title = {{Communicating Research Models of Human Physiology using Qualitative Compartmental Modeling}},
year = {1992}
}
@article{koc11a,
abstract = {Background: Despite decades of research, there is no consensus on which software effort estimation methods produce the most accurate models. Aim: Prior work has reported that, givenM estimation methods, no single method consistently outperforms all others. Perhaps rather than recommending one estimation method as best, it is wiser to generate estimates from ensembles of multiple estimation methods. Method: Nine learners were combined with 10 preprocessing options to generate 9î10 Â¼ 90 solo methods. These were applied to 20 datasets and evaluated using seven error measures. This identified the best n (in our case n Â¼ 13) solo methods that showed stable performance across multiple datasets and error measures. The top 2, 4, 8, and 13 solo methods were then combined to generate 12 multimethods, which were then compared to the solo methods. Results: 1) The top 10 (out of 12) multimethods significantly outperformed all 90 solo methods. 2) The error rates of the multimethods were significantly less than the solo methods. 3) The ranking of the best multimethod was remarkably stable. Conclusion: While there is no best single effort estimation method, there exist best combinations of such effort estimation methods.},
author = {Kocaguneli, Ekrem and Menzies, Tim and Keung, Jacky W.},
doi = {10.1109/TSE.2011.111},
file = {:Users/timm/svns/doc/cost/11comba.pdf:pdf},
isbn = {978-1-4577-2203-5},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Software cost estimation,analogy,ensemble,k-NN,machine learning,neural nets,regression trees,support vector machines},
number = {6},
pages = {1403--1416},
title = {{On the value of ensemble effort estimation}},
volume = {38},
year = {2012}
}
@inproceedings{minku12b,
author = {Minku, Ll and Yao, Xin},
booktitle = {\ldots Conference on Predictive Models in Software \ldots},
file = {:Users/timm/svns/doc/transfer/12minku.pdf:pdf},
isbn = {9781450312417},
keywords = {bles of learning machines,chronological split,concept drift,cross-company estimation mod-,els,ensem-,online learning,software effort estimation},
pages = {69--78},
series = {PROMISE '12},
title = {{Can cross-company data improve performance in software effort estimation?}},
url = {http://dl.acm.org/citation.cfm?id=2365334},
year = {2012}
}
@inproceedings{waugh97,
annote = {$\backslash$url\{http://www.cse.unsw.edu.au/\~{}timm/pub/docs\}},
author = {Waugh, S and Menzies, T J and Goss, S},
booktitle = {Advanced Topics in Artificial Intelligence: 10th Australian Joint Conference on AI},
editor = {Sattar, Abdul},
isbn = {3-540-63797-4},
publisher = {Springer-Verlag},
title = {{Evaluating a Qualitative Reasoner}},
year = {1997}
}
@article{Gray2012a,
abstract = {Background: The NASA metrics data program (MDP) data sets have been heavily used in software defect prediction research. Aim: To highlight the data quality issues present in these data sets, and the problems that can arise when they are used in a binary classification context. Method: A thorough exploration of all 13 original NASA data sets, followed by various experiments demonstrating the potential impact of duplicate data points when data mining. Conclusions: Firstly researchers need to analyse the data that forms the basis of their findings in the context of how it will be used. Secondly, the bulk of defect prediction experiments based on the NASA MDP data sets may have led to erroneous findings. This is mainly because of repeated/duplicate data points potentially causing substantial amounts of training and testing data to be identical.},
author = {Gray, D. and Bowes, D. and Davey, N. and Sun, Y. and Christianson, B.},
doi = {10.1049/iet-sen.2011.0132},
file = {:Users/timm/svns/doc/12grayNoise.pdf:pdf},
issn = {17518806},
journal = {IET Software},
number = {6},
pages = {549},
title = {{Reflections on the NASA MDP data sets}},
volume = {6},
year = {2012}
}
@inproceedings{krall14aaai,
author = {Krall, Joseph and Menzies, Tim and Davies, Misty},
booktitle = {2014 AAAI Spring Symposium Series},
title = {{Learning the Task Management Space of an Aircraft Approach Model}},
year = {2014}
}
@inproceedings{me95zb,
author = {Menzies, Tim and Compton, Paul},
booktitle = {Proceedings of the 9th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge Based Systems,},
title = {{The Extensive Implications of Evaluation on the Development of Knowledge-Based System}},
year = {1989}
}
@inproceedings{nag06,
abstract = {What is it that makes software fail? In an empirical study of the post-release defect history of five Microsoft software systems, we found that failure-prone software entities are statistically correlated with code complexity measures. However, there is no single set of complexity metrics that could act as a universally best defect predictor. Using principal component analysis on the code metrics, we built regression models that accurately predict the likelihood of post-release defects for new entities. The approach can easily be generalized to arbitrary projects; in particular, predictors obtained from one project can also be significant for new, similar projects.},
author = {Nagappan, Nachiappan and Ball, Thomas and Zeller, Andreas},
booktitle = {Proceedings of the 28th international conference on Software engineering},
doi = {10.1145/1134285.1134349},
isbn = {1-59593-375-1},
issn = {02705257},
keywords = {bug database,complexity metrics,empirical study,principal component analysis,regression model},
pages = {452--461},
series = {ICSE '06},
title = {{Mining metrics to predict component failures}},
url = {http://doi.acm.org/10.1145/1134285.1134349},
year = {2006}
}
@inproceedings{goa06,
abstract = {Model-checking techniques are successfully used in the verification of both hardware and software systems of industrial relevance. Unfortunately, the capability of current techniques is still limited and the effort required for verification can be prohibitive (if verification is possible at all). As a complement, fast, but incomplete, search tools may provide practical benefits not attainable with full verification tools, for example, reduced need for manual abstraction and fast detection of property violations during model development. In this report we investigate the performance of a simple random search technique. We conducted an experiment on a production-sized formal model of the mode-logic of a flight guidance system. Our results indicate that random search quickly finds the vast majority of property violations in our case-example. In addition, the times to detect various property violations follow an acutely right-skewed distribution and are highly biased toward the easy side. We hypothesize that the observations reported here are related to the phase transition phenomenon seen in Boolean satisfiability and other NP-complete problems. If so, these observations could be revealing some of the fundamental aspects of software (model) faults and have implications on how software engineering activities, such as analysis, testing, and reliability modeling, should be performed},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06compsac.pdf\}},
author = {Gao, Jimin and Heimdahl, Mats and Owen, David and Menzies, Tim},
booktitle = {Proceedings - International Computer Software and Applications Conference},
doi = {10.1109/COMPSAC.2006.64},
isbn = {0769526551},
issn = {07303157},
pages = {150--157},
title = {{On the distribution of property violations in formal models: An initial study}},
volume = {1},
year = {2006}
}
@misc{Zhou2007a,
author = {., Hongfang Zhou and ., Boqin Feng and ., Lintao Lv and ., Yue Hui},
booktitle = {Information Technology Journal},
doi = {10.3923/itj.2007.255.258},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/zhou07.pdf:pdf},
issn = {18125638},
number = {2},
pages = {255--258},
title = {{A Robust Algorithm for Subspace Clustering of High-Dimensional Data*}},
url = {http://www.scialert.net/abstract/?doi=itj.2007.255.258},
volume = {6},
year = {2007}
}
@article{Settles2010a,
abstract = {The key idea behind active learning is that a machine learning algorithm can achieve greater accuracy with fewer training labels if it is allowed to choose the data from which it learns. An active learner may pose queries, usually in the form of unlabeled data instances to be labeled by an oracle (e.g., a human annotator). Active learning is well-motivated in many modern machine learning problems, where unlabeled data may be abundant or easily obtained, but labels are difficult, time-consuming, or expensive to obtain. This report provides a general introduction to active learning and a survey of the literature. This includes a discussion of the scenarios in which queries can be formulated, and an overview of the query strategy frameworks proposed in the literature to date. An analysis of the empirical and theoretical evidence for successful active learning, a summary of problem setting variants and practical issues, and a discussion of related topics in machine learning research are also presented.},
author = {Settles, Burr},
doi = {10.1.1.167.4245},
file = {:Users/timm/svns/doc/10bsettlesActiveLearning.pdf:pdf},
issn = {00483931},
journal = {Machine Learning},
number = {2},
pages = {201--221},
title = {{Active Learning Literature Survey}},
volume = {15},
year = {2010}
}
@inproceedings{chen12,
abstract = {Recently, many automatic test generation techniques have been proposed, such as Randoop, Pex and jCUTE. However, usually test coverage of these techniques has been around 50-60\% only, due to several challenges, such as 1) the object mutation problem, where test generators cannot create and/or modify test inputs to desired object states; and 2) the constraint solving problem, where test generators fail to solve path conditions to cover certain branches. By analyzing branches not covered by state-of-the-art techniques, we noticed that these challenges might not be so difficult for humans. To verify this hypothesis, we propose a Puzzle-based Automatic Testing environment (PAT) which decomposes object mutation and complex constraint solving problems into small puzzles for humans to solve. We generated PAT puzzles for two open source projects and asked different groups of people to solve these puzzles. It was shown that they could be effectively solved by humans: 231 out of 400 puzzles were solved by humans at an average speed of one minute per puzzle. The 231 puzzle solutions helped cover 534 and 308 additional branches (7.0\% and 5.8\% coverage improvement) in the two open source projects, on top of the saturated branch coverages achieved by the two state-of-the-art test generation techniques.},
author = {Chen, Ning and Kim, Sunghun},
booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering - ASE 2012},
doi = {10.1145/2351676.2351697},
isbn = {9781450312042},
keywords = {1,are applied to,are largely due to,ating test inputs,challenges of gener-,code coverage,especially when the approaches,human computation,insuffi-,object-oriented programs,testing,the low test coverages,the major challenges include},
pages = {140},
title = {{Puzzle-based automatic testing: bringing humans into the loop by solving puzzles}},
url = {http://dl.acm.org/citation.cfm?doid=2351676.2351697},
year = {2012}
}
@article{Zhou2011a,
abstract = {A multiobjective optimization problem involves several conflicting objectives and has a set of Pareto optimal solutions. By evolving a population of solutions, multiobjective evolutionary algorithms (MOEAs) are able to approximate the Pareto optimal set in a single run. MOEAs have attracted a lot of research effort during the last 20 years, and they are still one of the hottest research areas in the field of evolutionary computation. This paper surveys the development of MOEAs primarily during the last eight years. It covers algorithmic frameworks such as decomposition-based MOEAs (MOEA/Ds), memetic MOEAs, coevolutionary MOEAs, selection and offspring reproduction operators, MOEAs with specific search methods, MOEAs for multimodal problems, constraint handling and MOEAs, computationally expensive multiobjective optimization problems (MOPs), dynamic MOPs, noisy MOPs, combinatorial and discrete MOPs, benchmark problems, performance indicators, and applications. In addition, some future research issues are also presented. Â© 2011 Elsevier B.V. All rights reserved.},
author = {Zhou, Aimin and Qu, Bo-Yang and Li, Hui and Zhao, Shi-Zheng and Suganthan, Ponnuthurai Nagaratnam and Zhang, Qingfu},
doi = {10.1016/j.swevo.2011.03.001},
file = {:Users/timm/svns/doc/11deSurvey.pdf:pdf},
isbn = {2210-6502},
issn = {22106502},
journal = {Swarm and Evolutionary Computation},
keywords = {evolutionary multiobjective optimization,multiobjective evolutionary algorithms,multiobjective optimization},
number = {1},
pages = {32--49},
publisher = {Elsevier B.V.},
title = {{Multiobjective evolutionary algorithms: A survey of the state of the art}},
url = {http://dx.doi.org/10.1016/j.swevo.2011.03.001},
volume = {1},
year = {2011}
}
@inproceedings{betta12,
abstract = {Much research energy in software engineering is focused on the creation of effort and defect prediction models. Such models are important means for practitioners to judge their current project situation, optimize the allocation of their resources, and make informed future decisions. However, software engineering data contains a large amount of variability. Recent research demonstrates that such variability leads to poor fits of machine learning models to the underlying data, and suggests splitting datasets into more fine-grained subsets with similar properties. In this paper, we present a comparison of three different approaches for creating statistical regression models to model and predict software defects and development effort. Global models are trained on the whole dataset. In contrast, local models are trained on subsets of the dataset. Last, we build a global model that takes into account local characteristics of the data. We evaluate the performance of these three approaches in a case study on two defect and two effort datasets. We find that for both types of data, local models show a significantly increased fit to the data compared to global models. The substantial improvements in both relative and absolute prediction errors demonstrate that this increased goodness of fit is valuable in practice. Finally, our experiments suggest that trends obtained from global models are too general for practical recommendations. At the same time, local models provide a multitude of trends which are only valid for specific subsets of the data. Instead, we advocate the use of trends obtained from global models that take into account local characteristics, as they combine the best of both worlds.},
author = {Bettenburg, Nicolas and Nagappan, Meiyappan and Hassan, Ahmed E.},
booktitle = {IEEE International Working Conference on Mining Software Repositories},
doi = {10.1109/MSR.2012.6224300},
file = {:Users/timm/svns/doc/12betternburg.pdf:pdf},
isbn = {9781467317610},
issn = {21601852},
keywords = {models,software metrics,techniques},
pages = {60--69},
title = {{Think locally, act globally: Improving defect and effort prediction models}},
year = {2012}
}
@article{Lopez-Herrejon2015a,
author = {Lopez-Herrejon, Roberto E. and Linsbauer, Lukas and Egyed, Alexander},
doi = {10.1016/j.infsof.2015.01.008},
file = {:Users/timm/svns/doc/sbse/15sbseMappingStudy.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {search based software engineering,software product line,systematic mapping study},
pages = {33--51},
publisher = {Elsevier B.V.},
title = {{A systematic mapping study of search-based software engineering for software product lines}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950584915000166},
volume = {61},
year = {2015}
}
@book{white09,
author = {White, Tom},
publisher = {O'Reilly Media},
title = {{Hadoop: The Definitive Guide}},
year = {2009}
}
@inproceedings{me00v,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/00vp.pdf\}},
author = {Menzies, T J},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{Evaluation Issues for Problem Visual Programming Languages}},
year = {1998}
}
@inproceedings{me03q,
abstract = { Assessing software costs money and better assessment costs exponentially more money. Given finite budgets, assessment resources are typically skewed towards areas that are believed to be mission critical. This leaves blind spots: portions of the system that may contain defects which may be missed. Therefore, in addition to rigorously assessing mission critical areas, a parallel activity should sample the blind spots. This paper assesses defect detectors based on static code measures as a blind spot sampling method. In contrast to previous results, we find that such defect detectors yield results that are stable across many applications. Further, these detectors are inexpensive to use and can be tuned to the specifics of the current business situations.},
author = {Menzies, T. and Stefano, J.S. Di},
booktitle = {Eighth IEEE International Symposium on High Assurance Systems Engineering, 2004. Proceedings.},
doi = {10.1109/HASE.2004.1281737},
isbn = {0-7695-2094-4},
issn = {1530-2059},
title = {{How good is your blind spot sampling policy}},
year = {2004}
}
@inproceedings{me97p,
author = {Menzies, T J},
booktitle = {The Second Australian Workshop on Requirements Engineering (AWRE'97)},
title = {{Qualitative Causal Diagrams for Requirements Engineering}},
year = {1997}
}
@inproceedings{me99f,
author = {Menzies, T and Cukic, B},
booktitle = {Proceedings, AAAI '99 workshop on Intelligent Software Engineering, Orlando, Florida},
month = jul,
title = {{Intelligent Testing can be Very Lazy}},
year = {1999}
}
@article{gay10,
abstract = {Testing large-scale systems is expensive in terms of both time and money. Running simulations early in the process is a proven method of finding the design faults likely to lead to critical system failures, but determining the exact cause of those errors is still time-consuming and requires access to a limited number of domain experts. It is desirable to find an automated method that explores the large number of combinations and is able to isolate likely fault points.   Treatment learning is a subset of minimal contrast-set learning that, rather than classifying data into distinct categories, focuses on finding the unique factors that lead to a particular classification. That is, they find the smallest change to the data that causes the largest change in the class distribution. These treatments, when imposed, are able to identify the factors most likely to cause a mission-critical failure. The goal of this research is to comparatively assess treatment learning against state-of-the-art numerical optimization techniques. To achieve this, this paper benchmarks the TAR3 and TAR4.1 treatment learners against optimization techniques across three complex systems, including two projects from the Robust Software Engineering (RSE) group within the National Aeronautics and Space Administration (NASA) Ames Research Center. The results clearly show that treatment learning is both faster and more accurate than traditional optimization methods.},
author = {Gay, Gregory and Menzies, Tim and Davies, Misty and Gundy-Burlet, Karen},
doi = {10.1007/s10515-010-0072-x},
issn = {09288910},
journal = {Automated Software Engineering},
keywords = {Contrast-set learning,Monte carlo filtering,Optimization,Search-based software engineering,Simulation},
month = dec,
number = {4},
pages = {439--468},
title = {{Automatically finding the control variables for complex system behavior}},
volume = {17},
year = {2010}
}
@misc{me01b,
author = {Menzies, T},
booktitle = {ASERC workshop on Quantiative Software Engineering},
title = {{Applictions of Computational Intelligence to Quantitative Software Engineering}},
year = {2001}
}
@article{tosun10a,
abstract = {CONTEXT$\backslash$nBuilding defect prediction models in large organizations has many challenges due to limited resources and tight schedules in the software development lifecycle. It is not easy to collect data, utilize any type of algorithm and build a permanent model at once. We have conducted a study in a large telecommunications company in Turkey to employ a software measurement program and to predict pre-release defects. Based on our prior publication, we have shared our experience in terms of the project steps (i.e. challenges and opportunities). We have further introduced new techniques that improve our earlier results. $\backslash$n$\backslash$nOBJECTIVE$\backslash$nIn our previous work, we have built similar predictors using data representative for US software development. Our task here was to check if those predictors were specific solely to US organizations or to a broader class of software. $\backslash$n$\backslash$nMETHOD$\backslash$nWe have presented our approach and results in the form of an experience report. Specifically, we have made use of different techniques for improving the information content of the software data and the performance of a Na\"{\i}ve Bayes classifier in the prediction model that is locally tuned for the company. We have increased the information content of the software data by using module dependency data and improved the performance by adjusting the hyper-parameter (decision threshold) of the Na\"{\i}ve Bayes classifier. We have reported and discussed our results in terms of defect detection rates and false alarms. We also carried out a costâbenefit analysis to show that our approach can be efficiently put into practice. $\backslash$n$\backslash$nRESULTS$\backslash$nOur general result is that general defect predictors, which exist across a wide range of software (in both US and Turkish organizations), are present. Our specific results indicate that concerning the organization subject to this study, the use of version history information along with code metrics decreased false alarms by 22\%, the use of dependencies between modules further reduced false alarms by 8\%, and the decision threshold optimization for the Na\"{\i}ve Bayes classifier using code metrics and version history information further improved false alarms by 30\% in comparison to a prediction using only code metrics and a default decision threshold. $\backslash$n$\backslash$nCONCLUSION$\backslash$nImplementing statistical techniques and machine learning on a real life scenario is a difficult yet possible task. Using simple statistical and algorithmic techniques produces an average detection rate of 88\%. Although using dependency data improves our results, it is difficult to collect and analyze such data in general. Therefore, we would recommend optimizing the hyper-parameter of the proposed technique, Na\"{\i}ve Bayes, to calibrate the defect prediction model rather than employing more complex classifiers. We also recommend that researchers who explore statistical and algorithmic methods for defect prediction should spend less time on their algorithms and more time on studying the pragmatic considerations of large organizations.},
author = {Boetticher, Gary D. and Ruhe, Guenther and Tosun, AyÅe and Bener, AyÅe and Turhan, Burak and Menzies, Tim},
doi = {10.1016/j.infsof.2010.06.006},
isbn = {978-1-60558-634-2},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Experience report,Na\"{\i}ve Bayes,Software defect prediction,Static code attributes},
number = {11},
pages = {1242--1257},
title = {{Practical considerations in deploying statistical methods for defect prediction: A case study within the Turkish telecommunications industry}},
url = {http://www.sciencedirect.com/science/article/pii/S0950584910001163},
volume = {52},
year = {2010}
}
@inproceedings{feather06a,
abstract = {For several years we have been employing a riskbased decision process to guide development and application of advanced technologies, and for research and technology portfolio planning. The process is supported by custom software, in which visualization plays an important role. During requirements gathering, visualization is used to help scrutinize the status (completeness, extent) of the information. During decision making based on the gathered information, visualization is used to help decisionmakers understand the space of options and their consequences. In this paper we summarize the visualization capabilities that we have employed, indicating when and how they have proven useful.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06rev.pdf\}},
author = {Feather, Martin S. and Cornford, Steven L. and Kiper, James D. and Menzies, Tim},
booktitle = {First International Workshop on Visualization in Requirements Engineering, REV 2006},
doi = {10.1109/REV.2006.2},
isbn = {0769527116},
title = {{Experiences using visualization techniques to present requirements, risks to them, and options for risk mitigation}},
year = {2007}
}
@article{briand02,
abstract = { A number of papers have investigated the relationships between design metrics and the detection of faults in object-oriented software. Several of these studies have shown that such models can be accurate in predicting faulty classes within one particular software product. In practice, however, prediction models are built on certain products to be used on subsequent software development projects. How accurate can these models be, considering the inevitable differences that may exist across projects and systems? Organizations typically learn and change. From a more general standpoint, can we obtain any evidence that such models are economically viable tools to focus validation and verification effort? This paper attempts to answer these questions by devising a general but tailorable cost-benefit model and by using fault and design data collected on two mid-size Java systems developed in the same environment. Another contribution of the paper is the use of a novel exploratory analysis technique - MARS (multivariate adaptive regression splines) to build such fault-proneness models, whose functional form is a-priori unknown. The results indicate that a model built on one system can be accurately used to rank classes within another system according to their fault proneness. The downside, however, is that, because of system differences, the predicted fault probabilities are not representative of the system predicted. However, our cost-benefit model demonstrates that the MARS fault-proneness model is potentially viable, from an economical standpoint. The linear model is not nearly as good, thus suggesting a more complex model is required.},
author = {Briand, Lionel C. and Melo, Walcelio L. and W\"{u}st, J\"{u}rgen},
doi = {10.1109/TSE.2002.1019484},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Cross-validation,Empirical validation,Measures,Metrics,Object-oriented},
number = {7},
pages = {706--720},
title = {{Assessing the applicability of fault-proneness models across object-oriented software projects}},
volume = {28},
year = {2002}
}
@inproceedings{me97n,
author = {Menzies, T J},
booktitle = {Banff Knowledge Acquisition workshop, 1998},
title = {{Evaluation Issues for Problem Visual Programming Languages}},
year = {1998}
}
@inproceedings{RamMe1996,
author = {Ramakrishnan, S and Menzies, T and Hasslinger, M and Bok, P and Mccarthy, H and Devakadadcham, B and Moulder, D},
booktitle = {Proceedings of Tools-Pacific, Melbourne},
title = {{On Building an Effective Measurement System for OO Software Process}},
year = {1996}
}
@article{Japkowicz2000a,
author = {Provost, Foster},
file = {:Users/timm/svns/doc/09imbalanced.pdf:pdf},
journal = {AAAI 2000 Workshop on Imbalanced Data Sets},
keywords = {Imbalanced datasets},
number = {9},
pages = {10--15},
title = {{Machine Learning from Imbalanced Data Sets}},
url = {http://www.aaai.org/Papers/Workshops/2000/WS-00-05/WS00-05-003.pdf},
volume = {21},
year = {2000}
}
@article{K.Beck2005a,
abstract = {JUnit is a simple Java testing framework to write tests for you Java application. This tutorial gives you an overview of the features of JUnit and shows a little example how you can write tests for your Java application.},
archivePrefix = {arXiv},
arxivId = {0201616416},
author = {K.Beck, C.Andres},
eprint = {0201616416},
file = {:Users/timm/svns/doc/00beck.pdf:pdf},
isbn = {0201616416},
issn = {20161641},
journal = {Writing},
pages = {85--110},
pmid = {17337672},
title = {{Extreme Programming Explained}},
url = {http://www.laliluna.de/assets/tutorials/junit-testing-en.pdf},
year = {2005}
}
@article{Lum2006a,
author = {Lum, Karen and Menzies, Tim and Hihn, Jairus},
file = {:Users/timm/svns/doc/cost/06Lum.pdf:pdf},
title = {{Studies in Software Cost Model Behavior: Do We Really Understand Cost Model Performance?}},
url = {http://trs-new.jpl.nasa.gov/dspace/handle/2014/41450},
year = {2006}
}
@article{Takahashi2005a,
abstract = {Mental models are bases to recognise phenomena and make plans to improve situations. They can be expressed in model builders' natural language. It is also necessary to examine mental models using a computer simulation. The Computer simulation requires expressions, which can be translated into computer codes. Therefore, model builders need to translate their model from their own natural language to simulation-friendly language, i.e. stock flow diagrams in System Dynamics. It is widely recognised that this translation is sometimes difficult not only for people who are beginners of System Dynamics but also for people who are experienced in the field. This paper discusses a possible translation procedure and shows an application of it. The proposed procedure is designed to use a subset of a natural language as an intermediate language. This idea is applicable regardless of variety of natural language.},
author = {Takahashi, Yutaka},
file = {:Users/timm/svns/doc/optimalML/05nl2compartments.pdf:pdf},
journal = {Proceedings of the 23rd International Conference of the System Dynamics Society},
pages = {141},
title = {{Translation from Natural Language to Stock Flow Diagrams}},
year = {2005}
}
@inproceedings{me10e,
abstract = {Insufficient risk analysis often leads to software system design defects and system failures. Assurance of software risk documents aims to increase the confidence that identified risks are complete, specific, and correct. Yet assurance methods rely heavily on manual analysis that requires significant knowledge of historical projects and subjective, perhaps biased judgment from domain experts. To address the issue, we have developed RARGen, a text mining-based approach based on well-established methods aiming to automatically create and maintain risk repositories to identify usable risk association rules (RARs) from a corpus of risk analysis documents. RARs are risks that have frequently occurred in historical projects. We evaluate RARGen on 20 publicly available e-service projects. Our evaluation results show that RARGen can effectively reason about RARs, increase confidence and cost-effectiveness of risk assurance, and support difficult-to-perform activities such as assuring complete-risk identification.},
author = {Huang, Lg and Port, D and Wang, L},
booktitle = {\ldots on Automated software \ldots},
doi = {10.1145/1858996.1859027},
isbn = {9781450301169},
keywords = {association rule,enables economical generation and,latent semantic analysis,maintenance of risk assurance,mining,mitigations into a repository,project risks and their,risk assurance,risk reduction,software repositories,text mining,that},
pages = {163--166},
title = {{Text mining in supporting software systems risk assurance}},
url = {http://dl.acm.org/citation.cfm?id=1859027},
year = {2010}
}
@inproceedings{Ramakrishnan1995,
author = {Ramakrishnan, S and Menzies, T},
booktitle = {Proceedings SEEP'96, New Zealand},
title = {{An Ongoing Experiment in O-O Software Process and Product Measurements}},
year = {1996}
}
@article{feather08,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ddp.pdf\}},
author = {Feather, M and Cornford, S and Hicks, K and Kiper, J and Menzies, T},
journal = {IEEE Software},
title = {{Application of a broad-spectrum quantitative requirements model to early-lifecycle decision making}},
year = {2008}
}
@inproceedings{owen03c,
abstract = { We have been exploring LURCH, an approximate (not necessarily complete) alternative to traditional model checking based on a randomized search algorithm. Randomized algorithms like LURCH have been known to outperform their deterministic counterparts for search problems representing a wide range of applications. The cost of an approximate strategy is the potential for inaccuracy. If complete algorithms terminate, they find all the features they are searching for. On the other hand, by its very nature, randomized search can miss important features. Our experiments suggest that this inaccuracy problem is not too serious. In the case studies presented here and elsewhere, LURCHS random search usually found the correct results. Also, these case studies strongly suggest that LURCH can scale to much larger models than standard model checkers like NuSMV and SPIN. The two case studies presented in this paper are selected for their simplicity and their complexity. The simple problem of the dining philosophers has been widely studied. By making the dinner more crowded, we can compare the memory and runtimes of standard methods (SPIN) and LURCH. When hundreds of philosophers sit down to eat, both LURCH and SPIN can find the deadlock case. However, SPINS memory and runtime requirements can grow exponentially while LURCHS requirements stay quite low. Success with highly symmetric, automatically generated problems says little about the generality of a technique. Hence, our second example is far more complex: a real-world flight guidance system from Rockwell Collins. Compared to NuSMV, LURCH performed very well on this model. Our random search finds the vast majority of faults (close to 90\%); runs much faster (seconds and minutes as opposed to hours); and uses very little memory (single digits to 10s of megabytes as opposed to 10s to 100s of megabytes). The rest of this paper is structured as follows. We begin with a theoretical rationale for why random search methods like LURCH can be incomplete, yet still successful. Next, we note that for a class of problems, the complete search of standard model checkers can be overkill. LURCH is then briefly introduced and our two case studies are presented.},
author = {Owen, D. and Menzies, T. and Heimdahl, M. and Gao, Jimin Gao Jimin},
booktitle = {28th Annual NASA Goddard Software Engineering Workshop, 2003. Proceedings.},
doi = {10.1109/SEW.2003.1270728},
isbn = {0-7695-2064-2},
title = {{On the advantages of approximate vs. complete verification: bigger models, faster, less memory, usually accurate}},
year = {2003}
}
@inproceedings{me98f,
author = {Menzies, T J and Waugh, S},
booktitle = {Proceedings, Pacific Rim Conference on Artificial Intelligence, Singapore},
publisher = {Springer-Verlag},
title = {{On the Practicality of Viewpoint-based Requirements Engineering}},
year = {1998}
}
@book{sed88,
author = {Sedgewick, R},
publisher = {Addison-Wesley},
title = {{Algorithms}},
year = {1988}
}
@misc{me01c,
author = {Bonnett, Alastair},
isbn = {0130193240, 9780130193247},
pages = {116},
title = {{How to argue}},
year = {2001}
}
@article{Tritchler2005a,
abstract = {This paper considers a clustering method motivated by a multivariate analysis of variance model and computationally based on eigenanalysis (thus the term âspectralâ in the title). Our focus is on large problems, and we present the method in the context of clustering genes using microarray expression data. We provide an efficient computational algorithm and discuss its properties and interpretation in statistical and geometric terms. Leukemia and Melanoma data sets are analyzed to demonstrate the use of the method, and simulations are carried out to compare our method with two other clustering algorithms. We extend the method to enable supervision by either gene or array characteristics.},
author = {Tritchler, David and Fallah, Shafagh and Beyene, Joseph},
doi = {10.1016/j.csda.2004.04.010},
file = {:Users/timm/svns/doc/05spectralDivisvePartitioning.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics \& Data Analysis},
keywords = {clustering,eigenanalysis,microarray,spectral,supervised learning},
number = {1},
pages = {63--76},
title = {{A spectral clustering method for microarray data}},
volume = {49},
year = {2005}
}
@article{Djordjevic2006b,
abstract = {SELEX (systematic evolution of ligands by exponential enrichment) is an experimental procedure that allows the extraction, from an initially random pool of DNA, of those oligomers with high affinity for a given DNA-binding protein. We address what is a suitable experimental and computational procedure to infer parameters of transcription factor-DNA interaction from SELEX experiments. To answer this, we use a biophysical model of transcription factor-DNA interactions to quantitatively model SELEX. We show that a standard procedure is unsuitable for obtaining accurate interaction parameters. However, we theoretically show that a modified experiment in which chemical potential is fixed through different rounds of the experiment allows robust generation of an appropriate dataset. Based on our quantitative model, we propose a novel bioinformatic method of data analysis for such a modified experiment and apply it to extract the interaction parameters for a mammalian transcription factor CTF/NFI. From a practical point of view, our method results in a significantly improved false positive/false negative trade-off, as compared to both the standard information theory based method and a widely used empirically formulated procedure.},
archivePrefix = {arXiv},
arxivId = {arXiv:q-bio/0512001v1},
author = {Djordjevic, Marko and Sengupta, Anirvan M},
doi = {10.1088/1478-3975/3/1/002},
eprint = {0512001v1},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Djordjevic05n2.pdf:pdf},
issn = {1478-3975},
journal = {Physical biology},
number = {1},
pages = {13--28},
pmid = {16582458},
primaryClass = {arXiv:q-bio},
title = {{Quantitative modeling and data analysis of SELEX experiments.}},
volume = {3},
year = {2006}
}
@article{Jong1994a,
abstract = {In this article, we explore the use of genetic algorithms (GAs) as$\backslash$na key element in the design and implementation of robust concept$\backslash$nlearning systems. We describe and evaluate a GA-based system called$\backslash$nGABIL that continually learns and refines concept classification$\backslash$nrules from its interaction with the environment. The use of GAs is$\backslash$nmotivated by recent studies showing the effects of various forms$\backslash$nof bias built into different concept learning systems, resulting$\backslash$nin systems that perform well on certain concept classes (generally,$\backslash$nthose well matched to the biases) and poorly on others. By incorporating$\backslash$na GA as the underlying adaptive search mechanism, we are able to$\backslash$nconstruct a concept learning system that has a simple, unified architecture$\backslash$nwith several important features. First, the system is surprisingly$\backslash$nrobust even with minimal bias. Second, the system can be easily extended$\backslash$nto incorporate traditional forms of bias found in other concept learning$\backslash$nsystems. Finally, the architecture of the system encourages explicit$\backslash$nrepresentation of such biases and, as a result, provides for an important$\backslash$nadditional feature: the ability to dynamically adjust system bias.$\backslash$nThe viability of this approach is illustrated by comparing the performance$\backslash$nof GABIL with that of four other more traditional concept learners$\backslash$n(AQ14, C4.5, ID5R, and IACL) on a variety of target concepts. We$\backslash$nconclude with some observations about the merits of this approach$\backslash$nand about possible extensions.},
author = {{De Jong}, Kenneth a. and Spears, William M. and Gordon, Diana F.},
doi = {10.1007/BF00993042},
file = {:Users/timm/svns/doc/92ga\_rules\_long.pdf:pdf},
issn = {08856125},
journal = {Machine Learning},
keywords = {Concept learning,bias adjustment,genetic algorithms},
number = {2-3},
pages = {161--188},
title = {{Using genetic algorithms for concept learning}},
volume = {13},
year = {1993}
}
@inproceedings{rich98zb,
author = {Richards, D and Menzies, T J},
booktitle = {Banff Workshop on Knowledge Acquisition},
title = {{Extending the SISYPHUS III Experiment from a Knowledge Engineering Task to a Requirements Engineering Task}},
year = {1998}
}
@inproceedings{me08fh,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08antares.pdf\}},
author = {Gundy-Burlet, K and Schumann, J and Menzies, T and Barrett, T},
booktitle = {9th International Symposium on Artifical Intelligence, Robotics and Automation in Space},
title = {{Parametric Analysis of a Hover Test Vehicle Using Advanced Test Generation and Data Analysis}},
year = {2009}
}
@article{Kocaguneli2012a,
abstract = {Background: There are too many design options for software effort estimators. How can we best explore them all? Aim: We seek aspects on general principles of effort estimation that can guide the design of effort estimators. Method: We identified the essential assumption of analogy-based effort estimation, i.e., the immediate neighbors of a project offer stable conclusions about that project. We test that assumption by generating a binary tree of clusters of effort data and comparing the variance of supertrees versus smaller subtrees. Results: For 10 data sets (from Coc81, Nasa93, Desharnais, Albrecht, ISBSG, and data from Turkish companies), we found: 1) The estimation variance of cluster subtrees is usually larger than that of cluster supertrees; 2) if analogy is restricted to the cluster trees with lower variance, then effort estimates have a significantly lower error (measured using MRE, AR, and Pred(25) with a Wilcoxon test, 95 percent confidence, compared to nearest neighbor methods that use neighborhoods of a fixed size). Conclusion: Estimation by analogy can be significantly improved by a dynamic selection of nearest neighbors, using only the project data from regions with small variance.},
author = {Kocaguneli, Ekrem and Menzies, Tim and Bener, Ayse Basar and Keung, Jacky W.},
doi = {10.1109/TSE.2011.27},
file = {:Users/timm/svns/doc/cost/11teak.pdf:pdf},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Software cost estimation,analogy,k-NN},
number = {2},
pages = {425--438},
title = {{Exploiting the essential assumptions of analogy-based effort estimation}},
volume = {38},
year = {2012}
}
@book{hayes83,
author = {Biles, J.a.},
booktitle = {Proceedings of the IEEE},
doi = {10.1109/PROC.1985.13159},
isbn = {0201106868},
issn = {0018-9219},
number = {2},
pages = {383--383},
pmid = {837},
publisher = {Addison-Wesley},
title = {{Building expert systems}},
volume = {73},
year = {1985}
}
@article{Martens2011a,
abstract = {This paper proposes a complete framework to assess the overall performance of classification models from a user perspective in terms of accuracy, comprehensibility, and justifiability. A review is provided of accuracy and comprehensibility measures, and a novel metric is introduced that allows one to measure the justifiability of classification models. Furthermore, taxonomy of domain constraints is introduced, and an overview of the existing approaches to impose constraints and include domain knowledge in data mining techniques is presented. Finally, justifiability metric is applied to a credit scoring and customer churn prediction case. ?? 2011 Elsevier B.V. All rights reserved.},
author = {Martens, David and Vanthienen, Jan and Verbeke, Wouter and Baesens, Bart},
doi = {10.1016/j.dss.2011.01.013},
file = {:Users/timm/svns/doc/xplain/11Martens.pdf:pdf},
isbn = {0167-9236},
issn = {01679236},
journal = {Decision Support Systems},
keywords = {Classification,Comprehensibility,Data mining,Justifiability,Metrics},
number = {4},
pages = {782--793},
publisher = {Elsevier B.V.},
title = {{Performance of classification models from a user perspective}},
url = {http://dx.doi.org/10.1016/j.dss.2011.01.013},
volume = {51},
year = {2011}
}
@incollection{bosch10,
abstract = {Product line engineering allows for the rapid development of variants of a domain specific application by using a common set of reusable assets often known as core assets. Variability modeling is a critical issue in product line engineering, where the use of feature modeling is one of most commonly used formalisms. To support an effective and automated derivation of concrete products for a product family, staged configuration has been proposed in the research literature. In this paper, we propose the integration of well-known requirements engineering principles into stage configuration. Being inspired by the well-established Preview requirements engineering framework, we initially propose an extension of feature models with capabilities for capturing business oriented requirements. This representation enables a more effective capturing of stakeholders' preferences over the business requirements and objectives (e.g.,. implementation costs or security) in the form of fuzzy linguistic variables (e.g., high, medium, and low). On top of this extension, we propose a novel method, the Stratified Analytic Hierarchy process, which first helps to rank and select the most relevant high level business objectives for the target stakeholders (e.g., security over implementation costs), and then helps to rank and select the most relevant features from the feature model to be used as the starting point in the staged configuration process. Besides a complete formalization of the process, we define the place of our proposal in existing software product line lifecycles as well as demonstrate the use of our proposal on the widely-used e-Shop case study. Finally, we report on the results of our user study, which indicates a high appreciation of the proposed method by the participating industrial software developers. The tool support for S-\{AHP\} is also introduced.},
author = {Bagheri, Ebrahim and Asadi, Mohsen and Gasevic, Dragan and Soltani, Samaneh},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-15579-6\_21},
editor = {Bosch, Jan and Lee, Jaejoon},
isbn = {3642155782},
issn = {03029743},
pages = {300--315},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Stratified analytic hierarchy process: Prioritization and selection of software features}},
url = {http://dx.doi.org/10.1007/978-3-642-15579-6\_21},
volume = {6287 LNCS},
year = {2010}
}
@inproceedings{mccallum00,
abstract = {Many important problems involve clustering large datasets. Although naive implementations of clustering are computa- tionally expensive, there are established efficient techniques for clustering when the dataset has either (1) a limited num- ber of clusters, (2) a low feature dimensionality, or (3) a small number of data points. However, there has been much less work on methods of efficiently clustering datasets that are large in all three ways at onceâfor example, having millions of data points that exist in many thousands of di- mensions representing many thousands of clusters. We present a new technique for clustering these large, high- dimensional datasets. The key idea involves using a cheap, approximate distance measure to efficiently divide the data into overlapping subsets we call canopies.Then cluster- ing is performed by measuring exact distances only between points that occur in a common canopy. Using canopies, large clustering problems that were formerly impossible become practical. Under reasonable assumptions about the cheap distance metric, this reduction in computational cost comes without any loss in clustering accuracy. Canopies can be applied to many domains and used with a variety of cluster- ing approaches, including Greedy Agglomerative Clustering, K-means and Expectation-Maximization. We present ex- perimental results on grouping bibliographic citations from the reference sections of research papers. Here the canopy approach reduces computation time over a traditional clus- tering approach by more than an order of magnitude and decreases error in comparison to a previously used algorithm by 25\%. Categories},
author = {McCallum, Andrew and Nigam, Kamal and Ungar, Lyle H.},
booktitle = {Proceedings of the Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/347090.347123},
isbn = {1581132336},
pages = {169--178},
series = {KDD '00},
title = {{Efficient clustering of high-dimensional data sets with application to reference matching}},
url = {http://portal.acm.org/citation.cfm?doid=347090.347123},
year = {2000}
}
@article{yang13,
abstract = {Context Parametric cost estimation models need to be continuously calibrated and improved to assure more accurate software estimates and reflect changing software development contexts. Local calibration by tuning a subset of model parameters is a frequent practice when software organizations adopt parametric estimation models to increase model usability and accuracy. However, there is a lack of understanding about the cumulative effects of such local calibration practices on the evolution of general parametric models over time. Objective This study aims at quantitatively analyzing and effectively handling local bias associated with historical cross-company data, thus improves the usability of cross-company datasets for calibrating and maintaining parametric estimation models. Method We design and conduct three empirical studies to measure, analyze and address local bias in cross-company dataset, including: (1) defining a method for measuring the local bias associated with individual organization data subset in the overall dataset; (2) analyzing the impacts of local bias on the performance of an estimation model; (3) proposing a weighted sampling approach to handle local bias. The studies are conducted on the latest COCOMO II calibration dataset. Results Our results show that the local bias largely exists in cross company dataset, and the local bias negatively impacts the performance of parametric model. The local bias based weighted sampling technique helps reduce negative impacts of local bias on model performance. Conclusion Local bias in cross-company data does harm model calibration and adds noisy factors to model maintenance. The proposed local bias measure offers a means to quantify degree of local bias associated with a cross-company dataset, and assess its influence on parametric model performance. The local bias based weighted sampling technique can be applied to trade-off and mitigate potential risk of significant local bias, which limits the usability of cross-company data for general parametric model calibration and maintenance. ?? 2013 Elsevier B.V. All rights reserved.},
author = {Yang, Ye and He, Zhimin and Mao, Ke and Li, Qi and Nguyen, Vu and Boehm, Barry and Valerdi, Ricardo},
doi = {10.1016/j.infsof.2013.03.002},
file = {:Users/timm/svns/doc/13ye.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {COCOMO II,Effort estimation,Local bias,Model maintenance,Parametric model,Weighted sampling},
number = {8},
pages = {1496--1511},
title = {{Analyzing and handling local bias for calibrating parametric cost estimation models}},
volume = {55},
year = {2013}
}
@inproceedings{me01e,
abstract = { Software management oracles often contain numerous subjective features. At each subjective point, a range of behaviors is possible. Stochastic simulation samples a subset of the possible behaviors. After many such stochastic simulations, the TAR2 treatment learner can find control actions that have (usually) the same impact despite the subjectivity of the oracle.},
author = {Menzies, T. and Kiper, J.D.},
booktitle = {Proceedings 16th Annual International Conference on Automated Software Engineering (ASE 2001)},
doi = {10.1109/ASE.2001.989836},
isbn = {0-7695-1426-X},
issn = {1527-1366},
title = {{Better reasoning about software engineering activities}},
year = {2001}
}
@inproceedings{me02d,
abstract = {Formal analysis of software is a powerful analysis tool, but can be too costly. Random search of formal models can reduce that cost, but is theoretically incomplete. However, random search of finite-state machines exhibits an early saturation effect, i.e., random search quickly yields all that can be found, even after a much longer search. Hence, we avoid the theoretical problem of incompleteness, provided that testing continues until after the saturation point. Such a random search is rapid, consumes little memory, is simple to implement, and can handle very large formal models (in one experiment shown here, over 10<sup>178</sup> states).},
author = {Menzies, T. and Owen, D. and Cukic, B.},
booktitle = {13th International Symposium on Software Reliability Engineering, 2002. Proceedings.},
doi = {10.1109/ISSRE.2002.1173208},
isbn = {0-7695-1763-3},
issn = {1071-9458},
title = {{Saturation effects in testing of formal models}},
year = {2002}
}
@article{me13za,
author = {Menzies, Tim},
file = {:Users/timm/svns/doc/13beyond.pdf:pdf},
journal = {Software, IEEE},
month = jul,
number = {3},
pages = {90--91},
title = {{Beyond Data Mining}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6504887},
volume = {30},
year = {2013}
}
@inproceedings{hame94,
author = {Haynes, P and Menzies, T J},
booktitle = {Tools '94},
pages = {121--129},
publisher = {Prentice Hall},
title = {{The \{E\}ffects of \{C\}lass \{C\}oupling on \{C\}lass \{S\}ize in \{S\}malltalk \{S\}ystems}},
year = {1994}
}
@inproceedings{me09i,
abstract = {When AI search methods are applied to software process models, then appropriate technologies can be discovered for a software project. We show that those recommendations are greatly affected by the business context of its use. For example, the automatic defect reduction tools explored by the ASE community are only relevant to a subset of software projects, and only according to certain value criteria. Therefore, when arguing for the value of a particular technology, that argument should include a description of the value function of the target user community.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09value.pdf\}},
author = {Green, Phillip and Menzies, Tim and Williams, Steven and El-Rawas, Oussama},
booktitle = {ASE2009 - 24th IEEE/ACM International Conference on Automated Software Engineering},
doi = {10.1109/ASE.2009.93},
isbn = {9780769538914},
issn = {1527-1366},
keywords = {Artificial intelligence,Software economics},
pages = {52--61},
title = {{Understanding the value of software engineering technologies}},
year = {2009}
}
@article{me89za,
author = {Me, Tim},
journal = {AI Magazine},
number = {2},
pages = {53--61},
title = {{An Investigation of AI and Expert Systems Literature : 1 980-l 984}},
volume = {10},
year = {1989}
}
@misc{me01d,
author = {Menzies, T and Kiper, J D},
title = {{Machine Learning for Requirements Engineering}},
year = {2001}
}
@article{simons99,
abstract = {With each eye fixation, we experience a richly detailed visual world. Yet recent work on visual integration and change direction reveals that we are surprisingly unaware of the details of our environment from one view to the next: we often do not detect large changes to objects and scenes ('change blindness'). Furthermore, without attention, we may not even perceive objects ('inattentional blindness'). Taken together, these findings suggest that we perceive and remember only those objects and details that receive focused attention. In this paper, we briefly review and discuss evidence for these cognitive forms of 'blindness'. We then present a new study that builds on classic studies of divided visual attention to examine inattentional blindness for complex objects and events in dynamic scenes. Our results suggest that the likelihood of noticing an unexpected object depends on the similarity of that object to other objects in the display and on how difficult the priming monitoring task is. Interestingly, spatial proximity of the critical unattended object to attended locations does not appear to affect detection, suggesting that observers attend to objects and events, not spatial positions. We discuss the implications of these results for visual representations and awareness of our visual environment.},
author = {Simons, Daniel J. and Chabris, Christopher F.},
doi = {10.1068/p2952},
isbn = {0301-0066 (Print); 1468-4233 (Electronic)},
issn = {03010066},
journal = {Perception},
number = {9},
pages = {1059--1074},
pmid = {10694957},
title = {{Gorillas in our midst: Sustained inattentional blindness for dynamic events}},
volume = {28},
year = {1999}
}
@article{durillo11,
abstract = {One important issue addressed by software companies is to determine which features should be included in the next release of their products, in such a way that the highest possible number of customers get satisfied while entailing the minimum cost for the company. This problem is known as the Next Release Problem (NRP). Since minimizing the total cost of including new features into a software package and maximizing the total satisfaction of customers are contradictory objectives, the problem has a multi-objective nature. In this work, we apply three state-of-the-art multi-objective metaheuristics (two genetic algorithms, NSGA-II and MOCell, and one evolutionary strategy, PAES) for solving NRP. Our goal is twofold: on the one hand, we are interested in analyzing the results obtained by these metaheuristics over a benchmark composed of six academic problems plus a real world data set provided by Motorola; on the other hand, we want to provide insight about the solution to the problem. The obtained results show three different kinds of conclusions: NSGA-II is the technique computing the highest number of optimal solutions, MOCell provides the product manager with the widest range of different solutions, and PAES is the fastest technique (but with the least accurate results). Furthermore, we have observed that the best solutions found so far are composed of a high percentage of low-cost requirements and of those requirements that produce the largest satisfaction on the customers as well.},
author = {Durillo, Juan J. and Zhang, Yuanyuan and Alba, Enrique and Harman, Mark and Nebro, Antonio J.},
doi = {10.1007/s10664-010-9147-3},
isbn = {1066401091473},
issn = {13823256},
journal = {Empirical Software Engineering},
keywords = {Multi-objective optimization,Next release,Requirements engineering,Search based software engineering},
month = feb,
number = {1},
pages = {29--60},
publisher = {Kluwer Academic Publishers},
title = {{A study of the bi-objective next release problem}},
volume = {16},
year = {2011}
}
@inproceedings{brady10b,
author = {Brady, Adam and Menzies, Tim},
booktitle = {The 6th International Conference on Predictive Models in Software Engineering (PROMISE '10)},
doi = {http://dx.doi.org/10.1145/1868328.1868333},
title = {{Case-Based Reasoning vs Parametric Models for Software Quality Optimization}},
year = {2010}
}
@inproceedings{me97q,
author = {Menzies, T J},
booktitle = {Banff KA '98 workshop.},
title = {{Evaluation Issues with Critical Success Metrics}},
year = {1998}
}
@article{me12a,
abstract = {The goal of science is conclusion stability, i.e. to discover some effect X that holds in multiple situations. Sadly, there are all too few examples of stable conclusions in software engineering (SE). In fact, the typical result is conclusion instability where what is true for project one, does not hold for project two. We can find numerous studies of the following form: there is as much evidence for as against the argument that some aspect X adds value to a software project. Below are four examples of this type of problem which we believe to be endemic within SE.},
author = {Menzies, Tim and Shepperd, Martin},
doi = {10.1007/s10664-011-9193-5},
issn = {13823256},
journal = {Empirical Software Engineering},
number = {1-2},
pages = {1--17},
title = {{Special issue on repeatable results in software engineering prediction}},
volume = {17},
year = {2012}
}
@article{Li2000a,
abstract = {While principal component analysis (PCA) has found wide application in process monitoring, slow and normal process changes often occur in real processes, which lead to false alarms for a fixed-model monitoring approach. In this paper, we propose two recursive PCA algorithms for adaptive process monitoring. The paper starts with an efficient approach to updating the correlation matrix recursively. The algorithms, using rank-one modification and Lanczos tridiagonalization, are then proposed and their computational complexity is compared. The number of principal components and the confidence limits for process monitoring are also determined recursively. A complete adaptive monitoring algorithm that addresses the issues of missing values and outlines is presented. Finally, the proposed algorithms are applied to a rapid thermal annealing process in semiconductor processing for adaptive monitoring.},
author = {Li, Weihua and Yue, H. Henry and Valle-Cervantes, Sergio and Qin, S. Joe},
doi = {10.1016/S0959-1524(00)00022-6},
file = {:Users/timm/svns/doc/00RecursivePCA.pdf:pdf},
issn = {09591524},
journal = {Journal of Process Control},
keywords = {adaptive process monitoring,cation,lanczos tridiagonalization,rank-one modi,recursive principal component analysis},
number = {5},
pages = {471--486},
title = {{Recursive PCA for adaptive process monitoring}},
volume = {10},
year = {2000}
}
@article{Zimmermann2010a,
abstract = {Genomic SELEX is a discovery tool for genomic aptamers, which are genomically encoded functional domains in nucleic acid molecules that recognize and bind specific ligands. When combined with genomic libraries and using RNA-binding proteins as baits, Genomic SELEX used with high-throughput sequencing enables the discovery of genomic RNA aptamers and the identification of RNA-protein interaction networks. Here we describe how to construct and analyze genomic libraries, how to choose baits for selections, how to perform the selection procedure and finally how to analyze the enriched sequences derived from deep sequencing. As a control procedure, we recommend performing a " Neutral" SELEX experiment in parallel to the selection, omitting the selection step. This control experiment provides a background signal for comparison with the positively selected pool. We also recommend deep sequencing the initial library in order to facilitate the final in silico analysis of enrichment with respect to the initial levels. Counter selection procedures, using modified or inactive baits, allow strengthening the binding specificity of the winning selected sequences. Â© 2010.},
author = {Zimmermann, Bob and Bilusic, Ivana and Lorenz, Christina and Schroeder, Ren\'{e}e},
doi = {10.1016/j.ymeth.2010.06.004},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Zimmermann10.pdf:pdf},
isbn = {1095-9130 (Electronic)$\backslash$r1046-2023 (Linking)},
issn = {10462023},
journal = {Methods},
number = {2},
pages = {125--132},
pmid = {20541015},
publisher = {Elsevier Inc.},
title = {{Genomic SELEX: A discovery tool for genomic aptamers}},
url = {http://dx.doi.org/10.1016/j.ymeth.2010.06.004},
volume = {52},
year = {2010}
}
@article{Potok2005a,
abstract = { Fast and high-quality document clustering algorithms play an important role in effectively navigating, summarizing, and organizing information. Recent studies have shown that partitional clustering algorithms are more suitable for clustering large datasets. However, the K-means algorithm, the most commonly used partitional clustering algorithm, can only generate a local optimal solution. In this paper, we present a particle swarm optimization (PSO) document clustering algorithm. Contrary to the localized searching of the K-means algorithm, the PSO clustering algorithm performs a globalized search in the entire solution space. In the experiments we conducted, we applied the PSO, K-means and hybrid PSO clustering algorithm on four different text document datasets. The number of documents in the datasets ranges from 204 to over 800, and the number of terms ranges from over 5000 to over 7000. The results illustrate that the hybrid PSO algorithm can generate more compact clustering results than the K-means algorithm.},
author = {Cui, X. and Potok, T.E. and Palathingal, P.},
doi = {10.1109/SIS.2005.1501621},
file = {:Users/timm/svns/doc/pso/01psoDocumentCluster.pdf:pdf},
isbn = {0-7803-8916-6},
journal = {Proceedings 2005 IEEE Swarm Intelligence Symposium, 2005. SIS 2005.},
pages = {185--191},
title = {{Document clustering using particle swarm optimization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1501621},
year = {2005}
}
@misc{john96,
annote = {(personal communication)},
author = {Johnson, R},
title = {{No Title}}
}
@inproceedings{me00w,
author = {Menzies, T J},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
publisher = {World-Scientific},
title = {{Knowledge Elicitation: the State of the Art}},
year = {2002}
}
@inproceedings{barr10,
abstract = {This paper discusses the history of IEEE since the formation of American Institute of Electrical Engineers (AIEE) in 1884 to the formation of Institute of Radio Engineers (IRE). There are always new frontiers opening up to be explored, and IEEE, with a wealth of resources in its volunteers and staff and its international membership, will be there to promote technology and support its advancement.},
archivePrefix = {arXiv},
arxivId = {arXiv:0810.3192v3},
author = {Pickering, Alan D. and Cooper, Andrew J. and Smillie, Luke D. and Corr, Philip J.},
booktitle = {Psychologist},
doi = {10.1044/leader.FMP.19082014.10},
eprint = {arXiv:0810.3192v3},
isbn = {0309537045},
issn = {09528229},
month = nov,
number = {1},
pages = {22--25},
pmid = {7818268},
title = {{On the shoulders of giants}},
volume = {26},
year = {2013}
}
@inproceedings{me00t,
author = {Menzies, Tim and Singh, Harhsinder},
booktitle = {2nd International Workshop on Soft Computing applied to Software Engineering (Netherlands), February},
pages = {1--24},
title = {{Many Maybes Mean ( Mostly ) the Same Thing}},
year = {2001}
}
@inproceedings{me92n,
author = {Menzies, T J and Compton, P and Mahidadia, a},
booktitle = {Communicating Scientific and Technical Knowledge, an AAAI '92 workshop},
title = {{Communicating Research Models of Human Physiology using Qualitative Compartmental Modeling}},
year = {1992}
}
@article{pan10,
abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research.},
author = {Pan, Sinno Jialin and Yang, Qiang},
doi = {10.1109/TKDE.2009.191},
file = {:Users/timm/svns/doc/10transfer.pdf:pdf},
isbn = {1041-4347 VO - 22},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Transfer learning,data mining.,machine learning,survey},
number = {10},
pages = {1345--1359},
title = {{A survey on transfer learning}},
volume = {22},
year = {2010}
}
@inproceedings{mega94,
author = {Menzies, T J and Gambetta, W},
booktitle = {ECAI '94 Workshop on Validation of Knowledge-Based Systems},
title = {{Exhaustive \{A\}bduction: A \{P\}ractical \{M\}odel \{V\}alidation \{T\}ool}},
year = {1994}
}
@article{me11o,
abstract = {Learning predictors for student retention is very difficult. After reviewing the literature, it is evident that there is considerable room for improvement in the current state of the art. As shown in this paper, improvements are possible if we (a) explore a wide range of learning methods; (b) take care when selecting attributes; (c) assess the efficacy of the learned theory not just by its median performance, but also by the variance in that performance; (d) study the delta of student factors between those who stay and those who are retained. Using these techniques, for the goal of predicting if students will remain for the first three years of an undergraduate degree, the following factors were found to be informative: family background and family's social-economic status, high school GPA and test scores. (C) 2011 Elsevier Ltd. All rights reserved.},
author = {Nandeshwar, a and Menzies, T and Nelson, a},
doi = {10.1016/j.eswa.2011.05.048},
isbn = {0957-4174},
journal = {Expert Systems with Applications},
keywords = {Data mining,Financial aid,Predictive modeling,Student retention,attrition,dropout,higher education,model},
number = {12},
pages = {14984--14996},
title = {{Learning patterns of university student retention}},
url = {<Go to ISI>://WOS:000295193400066},
volume = {38},
year = {2011}
}
@article{me97m,
abstract = { We can test a theory of "X" by checking if that theory can reproduce known behavior of "'X." In the general case, this check for time-based simulations is only practical for short simulation runs. We show that, given certain reasonable language restrictions, the complexity of this check reduces to the granularity of the measurements. That is, provided a very long simulation run is only measured infrequently, this check is feasible.},
author = {Menzies, Tim and Cohen, Robert F. and Waugh, Sam and Goss, Simon},
doi = {10.1109/TKDE.2002.1047773},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Abduction,Complexity,Qualitative reasoning,Validation},
number = {6},
pages = {1362--1375},
title = {{Applications of abduction: Testing very long qualitative simulations}},
volume = {14},
year = {2002}
}
@article{Ofa,
author = {Of, Transmission and Thick, Through and Targets, Silicon},
file = {:Users/timm/svns/doc/cost/02Nasahandbook.pdf:pdf},
title = {{N a s a}}
}
@inproceedings{fea01,
author = {Feather, M and In, H and Kiper, J and Kurtz, J and Menzies, T},
booktitle = {ECE UBC tech report},
title = {{First Contract: Better, Earlier Decisions for Software Projects}},
year = {2001}
}
@inproceedings{me91b,
author = {Menzies, T J},
booktitle = {IJCAI '91 Knowledge Acquisition Workshop},
title = {{Concerning the User of Procedural Construct as a Knowledge Acquisition Technique}},
year = {1991}
}
@article{deb12a,
abstract = {A predictive model is required to be accurate and comprehensible in order to inspire confidence in a business setting. Both aspects have been assessed in a software effort estimation setting by previous studies. However, no univocal conclusion as to which technique is the most suited has been reached. This study addresses this issue by reporting on the results of a large scale benchmarking study. Different types of techniques are under consideration, including techniques inducing tree/rule based models like M5 and CART, linear models such as various types of linear regression, nonlinear models (MARS, multilayered perceptron neural networks, radial basis function networks, and least squares support vector machines), and estimation techniques that do not explicitly induce a model (e.g., a case-based reasoning approach). Furthermore, the aspect of feature subset selection by using a generic backward input selection wrapper is investigated. The results are subjected to rigorous statistical testing and indicate that ordinary least squares regression in combination with a logarithmic transformation performs best. Another key finding is that by selecting a subset of highly predictive attributes such as project size, development, and environment related attributes, typically a significant increase in estimation accuracy can be obtained.},
address = {Los Alamitos, CA, USA},
author = {Dejaeger, Karel and Verbeke, Wouter and Martens, David and Baesens, Bart},
doi = {http://doi.ieeecomputersociety.org/10.1109/TSE.2011.55},
file = {:Users/timm/svns/doc/11dejaeger.pdf:pdf},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {HF Commerce,QA76 Computer software},
pages = {375--397},
publisher = {IEEE Computer Society},
title = {{Data mining techniques for software effort estimation: a comparative study}},
url = {http://eprints.soton.ac.uk/336472/},
volume = {38},
year = {2012}
}
@book{Segaran2007a,
abstract = {We consider advective-reactive solute transport in porous media whose hydraulic and transport properties are uncertain. These properties are treated as random fields, which renders nonlinear advection-reaction transport equations stochastic. We derive a deterministic equation for the probability density function (PDF) of the concentration of a solute that undergoes heterogeneous reactions, e.g., precipitation or dissolution. The derivation treats exactly (without linearization) a reactive term in the transport equation which accounts for uncertainty (randomness) in both flow velocity and kinetic rate constants but requires a closure, such as a Large-Eddy-Diffusivity (LED) approximation used in the present analysis. No closure is required when reaction rates are the only source of uncertainty. We use exact concentration PDFs obtained for this setting to analyze the accuracy of our general, LED-based PDF equations. ?? 2010 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {1109.3454},
author = {Tartakovsky, Daniel M. and Broyda, Svetlana},
booktitle = {Journal of Contaminant Hydrology},
doi = {10.1016/j.jconhyd.2010.08.009},
eprint = {1109.3454},
file = {:Users/timm/svns/doc/collectiveInt.pdf:pdf},
isbn = {0780375424},
issn = {01697722},
keywords = {Geochemistry,Heterogeneous reaction,Random,Reactive transport,Stochastic modeling,Uncertainty quantification},
number = {C},
pages = {129--140},
pmid = {20926156},
title = {{PDF equations for advective-reactive transport in heterogeneous porous media with uncertain properties}},
url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0596529325},
volume = {120-121},
year = {2011}
}
@inproceedings{he13,
abstract = {The fundamental issue in cross project defect prediction is selecting the most appropriate training data for creating quality defect predictors. Another concern is whether historical data of open-source projects can be used to create quality predictors for proprietary projects from a practical point-of-view. Current studies have proposed statistical approaches to finding these training data, however, thus far no apparent effort has been made to study their success on proprietary data. Also these methods apply brute force techniques which are computationally expensive. In this work we introduce a novel data selection procedure which takes into account the similarities between the distribution of the test and potential training data. Additionally we use feature subset selection to increase the similarity between the test and training sets. Our procedure provides a comparable and scalable means of solving the cross project defect prediction problem for creating quality defect predictors. To evaluate our procedure we conducted empirical studies with comparisons to the within company defect prediction and a relevancy filtering method. We found that our proposed method performs relatively better than the filtering method in terms of both computation cost and prediction performance.},
author = {He, Zhimin and Peters, Fayola and Menzies, Tim and Yang, Ye},
booktitle = {International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2013.20},
isbn = {978-0-7695-5056-5},
issn = {19493770},
keywords = {cross-project,data similarity,feature subset selection,instance selection,software defect prediction},
pages = {45--54},
title = {{Learning from open-source projects: An empirical study on defect prediction}},
year = {2013}
}
@inproceedings{rod11,
abstract = {Traditionally, simulation has been used by project managers in optimising decision making. However, current simulation packages only include simulation optimisation which considers a single objective (or multiple objectives combined into a single fitness function). This paper aims to describe an approach that consists of using multiobjective optimisation techniques via simulation in order to help software project managers find the best values for initial team size and schedule estimates for a given project so that cost, time and productivity are optimised. Using a System Dynamics (SD) simulation model of a software project, the sensitivity of the output variables regarding productivity, cost and schedule using different initial team size and schedule estimations is determined. The generated data is combined with a well-known multiobjective optimisation algorithm, NSGA-II, to find optimal solutions for the output variables. The NSGA-II algorithm was able to quickly converge to a set of optimal solutions composed of multiple and conflicting variables from a medium size software project simulation model. Multiobjective optimisation and SD simulation modeling are complementary techniques that can generate the Pareto front needed by project managers for decision making. Furthermore, visual representations of such solutions are intuitive and can help project managers in their decision making process. Copyright 2011 ACM.},
author = {Rodr\'{\i}guez, D and Ruiz, M and Riquelme, J C and Harrison, R},
booktitle = {Genetic and Evolutionary Computation Conference, GECCO'11},
doi = {10.1145/2001576.2001829},
isbn = {9781450305570 (ISBN)},
keywords = {Best value,Computer simulation,Computer software,Cost and schedule,Cost benefit analysis,Current simulation,Decision making,Decision making process,Fitness functions,Genetic algorithms,Managers,Medium size,Multi objective,Multi-objective genetic algorithm,Multiobjective genetic algorithms,Multiobjective optimization,Multiple objectives,NSGA-II,NSGA-II algorithm,Optimal solutions,Optimal systems,Output variables,Pareto front,Productivity,Project management,Project managers,Simulation model,Simulation optimisation,Single objective,Software project,Software project management,Software project simulation,System dynamics,Team size,Visual representations},
pages = {1883--1890},
title = {{Multiobjective simulation optimisation in software project management}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84860409205\&partnerID=40\&md5=57795412cf78aa1990315978a336e186},
year = {2011}
}
@article{Schellhammer2007a,
abstract = {Structure-based virtual screening today is basically organized as a sequential process where the molecules of a screening library are evaluated for instance with respect to their fit with a biological target. In this paper, we present a novel structure-based screening paradigm avoiding sequential searching and therefore enabling sublinear runtime behavior. We implemented the novel paradigm in the virtual screening tool TrixX and successfully applied it in screening experiments on four targets from relevant therapeutic areas. With the screening paradigm implemented in TrixX, we propose some important extensions and modifications to traditional virtual screening approaches: Instead of processing all compounds in the screening library sequentially, TrixX first analyzes the geometric and physicochemical binding site characteristics and then draws compounds with matching features from a compound catalog. The catalog organizes the compounds by their physicochemical and geometric features making use of relational database technology with indexed tables in order to support efficient queries for compounds with specific features. A key element of the compound catalog is a highly selective geometric descriptor that carries information on the type of functional groups of the compound, their Euclidian distance, the preferred interaction direction of each functional group, and the location of steric bulk around the triangle. In a re-docking experiment with 200 protein-ligand complexes, we could show that TrixX is able to correctly predict the location of ligand functional groups in co-crystallized complexes. In a retrospective virtual screening experiment for four different targets, the enrichment factors of TrixX are comparable to the enrichment factors of FlexX and FlexX-Scan. With computing times clearly below one second per compound, TrixX counts among the fastest virtual screening tools currently available and is nearly two orders of magnitude faster than standard FlexX.},
author = {Schellhammer, Ingo and Rarey, Matthias},
doi = {10.1007/s10822-007-9103-5},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Schellhammer2007.pdf:pdf},
issn = {0920654X},
journal = {Journal of Computer-Aided Molecular Design},
keywords = {FlexX,Geometric hashing,Molecular descriptor,Molecular docking,Relational database,Structure-based virtual screening,TrixX},
number = {5},
pages = {223--238},
pmid = {17294247},
title = {{TrixX: Structure-based molecule indexing for large-scale virtual screening in sublinear time}},
volume = {21},
year = {2007}
}
@article{shepperd12,
abstract = {Background--Self-evidently empirical analyses rely upon the quality of their data. Likewise, replications rely upon accurate reporting and using the same rather than similar versions of datasets. In recent years, there has been much interest in using machine learners to classify software modules into defect-prone and not defect-prone categories. The publicly available NASA datasets have been extensively used as part of this research. Objective--This short note investigates the extent to which published analyses based on the NASA defect datasets are meaningful and comparable. Method--We analyze the five studies published in the IEEE Transactions on Software Engineering since 2007 that have utilized these datasets and compare the two versions of the datasets currently in use. Results--We find important differences between the two versions of the datasets, implausible values in one dataset and generally insufficient detail documented on dataset preprocessing. Conclusions--It is recommended that researchers 1) indicate the provenance of the datasets they use, 2) report any preprocessing in sufficient detail to enable meaningful replication, and 3) invest effort in understanding the data prior to applying machine learners.},
author = {Shepperd, Martin and Song, Qinbao and Sun, Zhongbin and Mair, Carolyn},
doi = {10.1109/TSE.2013.11},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Empirical software engineering,data quality,defect prediction,machine learning},
number = {9},
pages = {1208--1215},
title = {{Data quality: Some comments on the NASA software defect datasets}},
volume = {39},
year = {2013}
}
@inproceedings{me03r,
abstract = { Model-based software has become quite popular in recent years, making its way into a broad range of areas, including the aerospace industry. The models provide an easy graphical interface to develop systems, which can generate the sometimes tedious code that follows. While there are many tools available to assess standard procedural code, there are limits to the testing of model-based systems. A major problem with the models are that their internals often contain gray areas of unknown system behavior. These possible behaviors form what is known as a data cloud, which is an overwhelming range of possibilities of a system that can overload analysts (Menzies et al., 2003). With large data clouds, it is hard to demonstrate which particular decision leads to a particular outcome. Even if definite decisions can't be made, it is possible to reduce the variance of and condense the clouds (Menzies et al., 2003). This paper presents two case studies; one with a simple illustrative model and another with a more complex application. The TAR3 treatment learning tool summarizes the particular attribute ranges that selects for particular behaviors of interest, reducing the data clouds.},
author = {Geletko, D. and Menzies, T.},
booktitle = {28th Annual NASA Goddard Software Engineering Workshop, 2003. Proceedings.},
doi = {10.1109/SEW.2003.1270729},
isbn = {0-7695-2064-2},
month = dec,
title = {{Model-based software testing via incremental treatment learning}},
year = {2003}
}
@inproceedings{feather06a,
abstract = {For several years we have been employing a riskbased decision process to guide development and application of advanced technologies, and for research and technology portfolio planning. The process is supported by custom software, in which visualization plays an important role. During requirements gathering, visualization is used to help scrutinize the status (completeness, extent) of the information. During decision making based on the gathered information, visualization is used to help decisionmakers understand the space of options and their consequences. In this paper we summarize the visualization capabilities that we have employed, indicating when and how they have proven useful.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06rev.pdf\}},
author = {Feather, Martin S. and Cornford, Steven L. and Kiper, James D. and Menzies, Tim},
booktitle = {First International Workshop on Visualization in Requirements Engineering, REV 2006},
doi = {10.1109/REV.2006.2},
isbn = {0769527116},
title = {{Experiences using visualization techniques to present requirements, risks to them, and options for risk mitigation}},
year = {2007}
}
@article{me08b,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ddp.pdf\}},
author = {Feather, M and Cornford, S and Hicks, K and Kiper, J and Menzies, T},
journal = {IEEE Software},
month = may,
title = {{Application of a broad-spectrum quantitative requirements model to early-lifecycle decision making}},
year = {2008}
}
@inproceedings{burk04,
author = {Burkleaux, T and Menzies, T and Owen, D},
booktitle = {Proceedings of WITSE 2005},
title = {{LEAN = (LURCH+TAR3) = Reusable Modeling Tools}},
year = {2004}
}
@article{Tanaka2009a,
abstract = {By generating a large diversity of molecules, the immune system selects antibodies that bind antigens. Sharing the same approach, combinatorial biotechnologies use a large library of compounds to screen for molecules of high affinity to a given target. Understanding the properties of the best binders in the pool aids the design of the library. In particular, how does the maximum affinity increase with the size of the library or repertoire? We consider two alternative models to examine the properties of extreme affinities. In the first model, affinities are distributed lognormally, while in the second, affinities are determined by the number of matches to a target sequence. The second model more explicitly models nucleic acids (DNA or RNA) and proteins such as antibodies. Using extreme value theory we show that the logarithm of the mean of the highest affinity in a combinatorial library grows linearly with the square root of the log of the library size. When there is an upper bound to affinity, this "absolute maximum" is also approached approximately linearly with root log library size, reaching the upper limit abruptly. The design of libraries may benefit from considering how this plateau is reached as the library size is increased. Â© 2009 Elsevier Ltd. All rights reserved.},
author = {Tanaka, Mark M. and Sisson, Scott a. and King, Garry C.},
doi = {10.1016/j.jtbi.2009.07.041},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Tanaka09.pdf:pdf},
issn = {00225193},
journal = {Journal of Theoretical Biology},
keywords = {Affinity distribution,Combinatorial chemistry,Extreme value theory,Immune repertoire,Library size},
number = {2},
pages = {260--265},
pmid = {19665466},
publisher = {Elsevier},
title = {{High affinity extremes in combinatorial libraries and repertoires}},
url = {http://dx.doi.org/10.1016/j.jtbi.2009.07.041},
volume = {261},
year = {2009}
}
@article{Djordjevic2007a,
abstract = {Systematic Evolution of Ligands by EXponential enrichment (SELEX) is an experimental procedure that allows extraction, from an initially random pool of oligonucleotides, of the oligomers with a desired binding affinity for a given molecular target. The procedure can be used to infer the strongest binders for a given DNA or RNA binding protein, and the highest affinity binding sequences isolated through SELEX can have numerous research, diagnostic and therapeutic applications. Recently, important new modifications of the SELEX protocol have been proposed. In particular, a modification of the standard SELEX procedure allows generating a dataset from which protein-DNA interaction parameters can be determined with unprecedented accuracy. Another variant of SELEX allows investigating interactions of a protein with nucleic-acid fragments derived from the entire genome of an organism. We review here different SELEX-based methods, with particular emphasis on the experimental design and on the applications aimed at inferring protein-DNA interactions. In addition to the experimental issues, we also review relevant methods of data analysis, as well as theoretical modeling of SELEX. ?? 2007 Elsevier B.V. All rights reserved.},
author = {Djordjevic, Marko},
doi = {10.1016/j.bioeng.2007.03.001},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Djordjevic07.pdf:pdf},
isbn = {1389-0344},
issn = {13890344},
journal = {Biomolecular Engineering},
keywords = {Genomic SELEX,High-throughput SELEX,In vitro selection,Protein-nucleic acid interactions,SELEX modeling,SELEX-SAGE},
number = {2},
pages = {179--189},
pmid = {17428731},
title = {{SELEX experiments: New prospects, applications and data analysis in inferring regulatory pathways}},
volume = {24},
year = {2007}
}
@inproceedings{me01f,
author = {Menzies, Tim and Hu, Y},
booktitle = {First International Workshop on Model-based Requirements Engineering},
title = {{Reusing models for requirements engineering}},
year = {2001}
}
@misc{fea03c,
abstract = { Many organizations look to research to yield new and improved products and practices. Connecting practitioners who have the need for research results to the researchers producing those results is important to guiding research and utilizing its results. Likewise, connecting researchers working on related topics to one another, and connecting practitioners with related needs to one another, is important to establishing communities of shared interests. We demonstrate an approach that helps identify fruitful such connections.},
author = {Feather, M.S. and Menzies, T. and Connelly, J.R.},
booktitle = {Proceedings. 11th IEEE International Requirements Engineering Conference, 2003.},
doi = {10.1109/ICRE.2003.1232783},
isbn = {0-7695-1980-6},
issn = {1090-705X},
month = sep,
title = {{Relating practitioner needs to research activities}},
year = {2003}
}
@inproceedings{me91c,
author = {Menzies, T J},
booktitle = {Tools 3: Proceedings of the third International Technology of Object-Oriented Languages and; Systems conference},
publisher = {Prentice-Hall},
title = {{Beyond the MVC Triad: Quality Assurance via Interactive Specification Editors}},
year = {1991}
}
@inproceedings{yang11,
abstract = {Background: Continuously calibrated and validated parametric models are necessary for realistic software estimates. However, in practice, variations in model adoption and usage patterns introduce a great deal of local bias in the resultant historical data. Such local bias should be carefully examined and addressed before the historical data can be used for calibrating new versions of parametric models. Aims: In this study, we aim at investigating the degree of such local bias in a cross-company historical dataset, and assessing its impacts on parametric estimation model's performance. Method: Our study consists of three parts: 1) defining a method for measuring and analyzing the local bias associated with individual organization data subset in the overall dataset; 2) assessing the impacts of local bias on the estimation performance of COCOMO II 2000 model; 3) performing a correlation analysis to verify that local bias can be harmful to the performance of a parametric estimation model. Results: Our results show that the local bias negatively impacts the performance of parametric model. Our measure of local bias has a positive correlation with the performance by statistical importance. Conclusion: Local calibration by using the whole multi-company data would get worse performance. The influence of multi-company data could be defined by local bias and be measured by our method.},
author = {Yang, Ye and Xie, Lang and He, Zhimin and Li, Qi and Nguyen, Vu and Boehm, Barry and Valerdi, Ricardo},
booktitle = {Proceedings of the 7th International Conference on Predictive Models in Software Engineering - Promise '11},
doi = {10.1145/2020390.2020404},
isbn = {9781450307093},
keywords = {accuracy indicator,all or part of,effort estimation,local bias,or hard copies of,parametric model,permission to make digital,this work for},
pages = {1--10},
title = {{Local bias and its impacts on the performance of parametric estimation models}},
url = {http://dl.acm.org/citation.cfm?doid=2020390.2020404},
year = {2011}
}
@article{Hamula2006a,
abstract = {Advances in systematic evolution of ligands by exponential enrichment (SELEX), a selection protocol for aptamers, have resulted in increased applications of DNA and RNA aptamers in developing analytical techniques. We review recent developments in SELEX techniques as well as new aptamer-based bioanalytical applications. Â© 2006 Elsevier Ltd. All rights reserved.},
author = {Hamula, Camille L a and Guthrie, Jeffrey W. and Zhang, Hongquan and Li, Xing Fang and Le, X. Chris},
doi = {10.1016/j.trac.2006.05.007},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Hamula06.pdf:pdf},
isbn = {0165-9936},
issn = {01659936},
journal = {TrAC - Trends in Analytical Chemistry},
keywords = {Affinity binding,Aptamer,Bioanalytical assay,Biosensor,Chiral separation,In vitro selection,Protein,SELEX},
number = {7},
pages = {681--691},
title = {{Selection and analytical applications of aptamers}},
volume = {25},
year = {2006}
}
@article{Rodriguez-Baena2011a,
abstract = {Binary datasets represent a compact and simple way to store data about the relationships between a group of objects and their possible properties. In the last few years, different biclustering algorithms have been specially developed to be applied to binary datasets. Several approaches based on matrix factorization, suffix trees or divide-and-conquer techniques have been proposed to extract useful biclusters from binary data, and these approaches provide information about the distribution of patterns and intrinsic correlations.},
author = {Rodriguez-Baena, Domingo S. and Perez-Pulido, Antonio J. and Aguilar-Ruiz, Jesus S.},
doi = {10.1093/bioinformatics/btr464},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/rodriguez-Baena11.pdf:pdf},
isbn = {1367-4811 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
number = {19},
pages = {2738--2745},
pmid = {21824973},
title = {{A biclustering algorithm for extracting bit-patterns from binary datasets}},
volume = {27},
year = {2011}
}
@inproceedings{passos11,
abstract = {Folklore and beliefs are strong in the software practitioners' community. Software engineering is a communication intensive activity. Software engineers are innovation driven and regularly use automated resources to share ideas, new paradigms and approaches to support and improve their practices. This information flow generates technical folklore and beliefs (that do not have a formal trial basis). Software engineers applying practices are influenced by these and they are inevitably taken on board in the adoption of a particular technology or practice. This paper presents an industrial case study, using a qualitative approach, to investigate the origins and impacts of beliefs on software development team practices. Its main contribution is on the understanding of creation and evolution of technical beliefs, and in studying its use for team practices improvement in the software engineering industry.},
author = {Passos, Carol and Braun, Ana Paula and Cruzes, Daniela S. and Mendonca, Manoel},
booktitle = {2011 International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2011.63},
isbn = {978-0-7695-4604-9},
issn = {1938-6451},
keywords = {belief,business culture and values,industry case study,software practices,technical folklore and beliefs},
pages = {444--452},
title = {{Analyzing the Impact of Beliefs in Software Project Practices}},
year = {2011}
}
@inproceedings{me09a,
abstract = {Before performing drastic changes to a project, it is worthwhile to thoroughly explore the available options within the current structure of a project. An alternative to drastic change are internal changes that adjust current options within a software project. In this paper, we show that the effects of numerous internal changes can out-weigh the effects of drastic changes. That is, the benefits of drastic change can often be achieved without disrupting a project. The key to our technique is SEESAW, a novel stochastic stability tool that (a) considers a very large set of minor changes using stochastic sampling; and (b) carefully selects the right combination of effective minor changes. Our results show, using SEESAW, project managers have more project improvement options than they currently realize. This result should be welcome news to managers struggling to maintain control and continuity over their project in the face of multiple demands for drastic change.},
author = {Menzies, T. and Williams, S. and El-Rawas, O. and Boehm, B. and Hihn, J.},
booktitle = {2009 IEEE 31st International Conference on Software Engineering},
doi = {10.1109/ICSE.2009.5070552},
isbn = {978-1-4244-3453-4},
issn = {0270-5257},
title = {{How to avoid drastic software process change (using stochastic stability)}},
year = {2009}
}
@inproceedings{zimmermann09,
author = {Zimmermann, T and Nagappan, N and Gall, H and Giger, E and Murphy, B},
booktitle = {ESEC/FSE'09},
month = aug,
title = {{Cross-Project Defect Prediction}},
year = {2009}
}
@misc{gay07,
author = {Gay, G and Menzies, T},
institution = {Lane Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{Under- vs Over- Sampling for C4.5 and Naive Bayes Defect Predictors}},
year = {2007}
}
@article{me06a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06qrre.pdf\}},
author = {Menzies, T and Richardson, J},
journal = {IEEE Computer},
month = oct,
title = {{Making Sense of Requirements, Sooner}},
year = {2006}
}
@inproceedings{me96i,
author = {Menzies, T J},
booktitle = {Proceedings of the Eighth International Conference on Software Engineering and Knowledge Engineering},
isbn = {0-9641699-3-2},
publisher = {Knowledge Systems Institute, Skokie, Illinois, USA},
title = {{Visual Programming, Knowledge Engineering, and Visual Programming}},
year = {1996}
}
@misc{me98a,
author = {Menzies, T and Waugh, S and Goss, S},
howpublished = {Submitted to ECAI '98},
title = {{Taming Chatter with Relevant Envisionments}},
year = {1998}
}
@inproceedings{me11m,
abstract = {AbstractâData miners can infer rules showing how to improve either (a) the effort estimates of a project or (b) the defect predictions of a software module. Such studies often exhibit conclusion instability regarding what is the most effective action for different projects or modules. This instability can be explained by data heterogeneity. We show that effort and defect data contain many local regions with markedly different properties to the global space. In other words, what appears to be useful in a global context is often irrelevant for particular local contexts. This result raises questions about the generality of conclusions from empirical SE. At the very least, SE researchers should test if their supposedly general conclusions are valid within subsets of their data. At the very most, empirical SE should become a search for local regions with similar properties (and conclusions should be constrained to just those regions).},
author = {Menzies, Tim and Butcher, Andrew and Marcus, Andrian and Zimmermann, Thomas and Cok, David},
booktitle = {2011 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011)},
doi = {10.1109/ASE.2011.6100072},
isbn = {978-1-4577-1639-3},
issn = {1938-4300},
keywords = {Data mining,I,defect/effort estimation,empirical SE.,validation},
pages = {343--351},
title = {{Local vs. global models for effort estimation and defect prediction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6100072},
year = {2011}
}
@misc{me95i,
author = {Menzies, T J and Taylor, a},
institution = {Department of Software Development, Monash University},
number = {TR95-36},
title = {{Abduction and Memoing}},
year = {1995}
}
@book{seni10,
author = {Elder, Jhon F. and Seni, Giobanni},
publisher = {Morgan Claypool},
title = {{Ensemble Methods in Data Mining: Improving Accuracy Through Combining Predictions}},
url = {http://www.amazon.com/Ensemble-Methods-Data-Mining-Predictions-ebook/dp/B0093QMDT8/ref=sr\_1\_2?ie=UTF8\&qid=1398840878\&sr=8-2\&keywords=ensemble+methods},
year = {2010}
}
@article{Book2008a,
abstract = {It is well known that a programâs cost is related to its schedule, yet when a programâs schedule estimate is updated, it is not often that the cost estimate is updated in parallel to reflect consistency with the new schedule estimate. One reason for this deficiency in estimating is probably the unfortunate wall of separation that seems to divide those analysts who do cost estimating from those analysts who do schedule estimating. Another appears to be a lack of understanding of the extent of the impact of schedule growth on cost growth.},
author = {Book, Stephen a. and Book, Stephen a.},
file = {:Users/timm/svns/doc/cost/07Quantify.pdf:pdf},
journal = {The Measurable News},
number = {1},
pages = {11--15},
title = {{Quantifying the Relationship between Schedule and Cost}},
year = {2008}
}
@inproceedings{me92k,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/ai92.pdf\}},
author = {Menzies, T J},
booktitle = {Proceedings of AI '92, Australia},
title = {{Maintaining Procedural Knowledge: Ripple-Down-Functions}},
year = {1992}
}
@article{Debnath2005a,
abstract = {A rapid development in diverse areas of molecular biology and genetic engineering resulted in emergence of variety of tools. These tools are not only applicable to basic researches being carried out world over, but also exploited for precise detection of abnormal conditions in plants, animals and human body. Although a basic researcher is well versed with few techniques used by him/her in the laboratory, they may not be well acquainted with methodologies, which can be used to work out some of their own research problems.The picture is more blurred when the molecular diagnostic tools are to be used by physicians, scientists and technicians working in diagnostic laboratories in hospitals, industry and academic institutions. Since many of them are not trained in basics of these methods, they come across several gray areas in understanding of these tools. The accurate application of molecular diagnostic tools demands in depth understanding of the methodology for precise detection of the abnormal condition of living body.To meet the requirements of a good book on molecular diagnostics of students, physicians, scientists working in agricultural, veterinary, medical and pharmaceutical sciences, it needs to expose the reader lucidly to:Give basic science behind commonly used tools in diagnosticsExpose the readers to detailed applications of these tools andMake them aware the availability of such diagnostic toolsThe book will attract additional audience of pathologists, medical microbiologists, pharmaceutical sciences, agricultural scientists and veterinary doctors if the following topics are incorporated at appropriate places in Unit II or separately as a part of Unit-III in the book.Molecular diagnosis of diseases in agricultural cropsMolecular diagnosis of veterinary diseases.Molecular epidemiology, which helps to differentiate various epidemic strains and sources of disease outbreaks. Even in different units of the same hospital, the infections could be by different strains of the same species and the information becomes valuable for infection control strategies.Drug resistance is a growing problem for bacterial, fungal and parasitic microbes and the molecular biology tools can help to detect the drug resistance genes without the cultivation and in vitro sensitivity testing. Molecular diagnostics offers faster help in the selection of the proper antibiotic for the treatment of tuberculosis, which is a major problem of the in the developing world. The conventional culture and drug sensitivity testing of tuberculosis bacilli is laborious and time consuming, whereas molecular diagnosis offers rapid drug resistant gene detection even from direct clinical samples. The same approach for HIV, malaria and many more diseases needs to be considered.Molecular diagnostics in the detection of diseases during foetal life is an upcoming area in the foetal medicine in case of genetic abnormalities and infectious like TORCH complex etc.The book will be equally useful to students, scientists and professionals working in the field of molecular diagnostics.},
author = {Debnath, Mousumi and Prasad, Godavarthi B K S and Bisen, Prakash S.},
doi = {10.1007/978-90-481-3261-4},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Debnath10.pdf:pdf},
isbn = {9781588293565},
journal = {Molecular Diagnostics: Promises and Possibilities},
keywords = {amplification,aptamers,combinatorial library,dna aptamers,dna selection,monolex,oligomers,oligonucleotide library,pathogens,rna aptamers,selex,therapeutics},
pages = {1--520},
title = {{Molecular diagnostics: Promises and possibilities}},
year = {2005}
}
@article{Koyuturk2004a,
abstract = { Biclustering is an important problem that arises in diverse applications, including analysis of gene expression and drug interaction data. The problem can be formalized in various ways through different interpretation of data and associated optimization functions. We focus on the problem of finding unusually dense patterns in binary (0-1) matrices. This formulation is appropriate for analyzing experimental datasets that come from not only binary quantization of gene expression data, but also more comprehensive datasets such as gene-feature matrices that include functions of coded proteins and motifs in the coding sequence. We formalize the notion of an "unusually" dense submatrix to evaluate the interestingness of a pattern in terms of statistical significance based on the assumption of a uniform memoryless source. We then simplify it to assess statistical significance of discovered patterns. Using statistical significance as an objective function, we formulate the problem as one of finding significant dense submatrices of a large sparse matrix. Adopting a simple iterative heuristic along with randomized initialization techniques, we derive fast algorithms for discovering binary biclusters. We conduct experiments on a binary gene-feature matrix and a quantized breast tumor gene expression matrix. Our experimental results show that the proposed method quickly discovers all interesting patterns in these datasets.},
author = {Koyuturk, M. and Szpankowski, W. and Grama, a.},
doi = {10.1109/CSB.2004.1332467},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/Koyurturk04.pdf:pdf},
isbn = {0-7695-2194-0},
journal = {Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference, 2004. CSB 2004.},
title = {{Biclustering gene-feature matrices for statistically significant dense patterns}},
year = {2004}
}
@misc{bsc99,
author = {Page, Web},
title = {{No Title}}
}
@article{Batal2009a,
author = {Batal, Iyad},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/iyadAR.pdf:pdf},
title = {{Association Rule Mining Overview}},
year = {2009}
}
@article{box51,
abstract = {The general problem is considered of finding experimentally the levels of a number of quantitative variables at which some, dependent response has a maximum value. Ideally this could be done by covering the whole of the region of possible values of the variables with a network and carrying out an experiment to determine the response at each point of the network. It is obviously more economical to begin at some point in the region, carry out some preliminary experiments in its neighbourhood and to determine what seems to be the best direction in which to continue experimentation. If the experimental error is small this will often lead to the maximum value of the response. The authors discuss possible designs when the errors are appreciable, but not too large, and consider the accuracy with which the optimum point is determined.},
author = {Box, G. E. P. and Wilson, K. B.},
doi = {10.1007/978-1-4612-4380-9\_23},
isbn = {EE000175 00359246 DI993125 99P0202F},
issn = {00359246},
journal = {Journal of the Royal Statistical Society},
number = {1},
pages = {1--45},
title = {{On the Experimental Attainment of Optimum Conditions}},
volume = {13},
year = {1951}
}
@article{me98d,
author = {Menzies, T J and Clancey, B},
journal = {International Journal of Human-Computer Studies},
title = {{Editorial, Special Issue on Situated Cognition}},
volume = {49},
year = {1998}
}
@article{vasil13,
author = {Papakroni, Vasil and Menzies, Tim and Peters, Fayola and Partington, Susan and Marcus, Andrian and State, Wayne},
isbn = {2011680013004},
journal = {Submitted to the International Conference on Automated Software Engineering (ASE'13)},
keywords = {-data mining,clas-,clustering,defect prediction,feature selection,instance based,planning,sification},
title = {{Peeking at Data Considered Harmful ?}},
year = {2012}
}
@inproceedings{me00b,
abstract = {The behavior of nondeterminate systems can be hard to predict,
since similar inputs at different times can generate different outputs.
In other words, the behavior seen during the testing process may not be
seen at runtime. Due to the uncertainties associated with
nondeterminism, the standard view is that we should avoid such
nondeterminate systems, especially for systems requiring high
reliability. While this is a valid guideline, at least in two
application areas such nondeterminacy is unavoidable. Early life-cycle
requirements and AI software are becoming widely used, yet both are
imprecise and may exhibit nondeterminate behaviour if explored
rigorously by a test device. Based on a literature review and some
theoretical studies, we argue that many stable properties exist within
the space of all possible nondeterminate behaviors. However, we also
show that seemingly trivial changes to a nondeterministic system can
turn an easily testable system into an impossibly hard system to test.
Finally, we stress that this analysis does not imply a correlation
between stable zones of nondeterminate testability and the ultimate
maintainability of nondeterminate systems. That is, while we are
optimistic about testing nondeterminate systems, we remain cautious
about the maintenance of such systems},
author = {Menzies, T. and Cukic, B. and Singh, H. and Powell, J.},
booktitle = {Proceedings 11th International Symposium on Software Reliability Engineering. ISSRE 2000},
doi = {10.1109/ISSRE.2000.885874},
isbn = {0-7695-0807-3},
issn = {1071-9458},
title = {{Testing nondeterminate systems}},
year = {2000}
}
@inproceedings{me09i,
abstract = {When AI search methods are applied to software process models, then appropriate technologies can be discovered for a software project. We show that those recommendations are greatly affected by the business context of its use. For example, the automatic defect reduction tools explored by the ASE community are only relevant to a subset of software projects, and only according to certain value criteria. Therefore, when arguing for the value of a particular technology, that argument should include a description of the value function of the target user community.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09value.pdf\}},
author = {Green, Phillip and Menzies, Tim and Williams, Steven and El-Rawas, Oussama},
booktitle = {ASE2009 - 24th IEEE/ACM International Conference on Automated Software Engineering},
doi = {10.1109/ASE.2009.93},
isbn = {9780769538914},
issn = {1527-1366},
keywords = {Artificial intelligence,Software economics},
pages = {52--61},
title = {{Understanding the value of software engineering technologies}},
year = {2009}
}
@article{olvera10,
abstract = {In supervised learning, a training set providing previously known information is used to classify new instances. Commonly, several instances are stored in the training set but some of them are not useful for classifying therefore it is possible to get acceptable classification rates ignoring non useful cases; this process is known as instance selection. Through instance selection the training set is reduced which allows reducing runtimes in the classification and/or training stages of classifiers. This work is focused on presenting a survey of the main instance selection methods reported in the literature.},
author = {Olvera-L\'{o}pez, J. Arturo and Carrasco-Ochoa, J. Ariel and Mart\'{\i}nez-Trinidad, J. Francisco and Kittler, Josef},
doi = {10.1007/s10462-010-9165-y},
issn = {02692821},
journal = {Artificial Intelligence Review},
keywords = {Data reduction,Instance selection,Pre-processing,Supervised learning},
month = aug,
number = {2},
pages = {133--143},
publisher = {Kluwer Academic Publishers},
title = {{A review of instance selection methods}},
volume = {34},
year = {2010}
}
@inproceedings{clancey96a,
abstract = {A continuing problem in business today is the design of humanÃcomputer systems that$\backslash$nrespect how work actually gets done. The overarching context of work consists of$\backslash$nactivities, which people conceive as ways of organizing their daily life and especially their$\backslash$ninteractions with each other. Activities include reading mail, going to workshops,$\backslash$nmeeting with colleagues over lunch, answering phone calls, and so on. Brahms is$\backslash$na multiagent simulation tool for modeling the activities of groups in diÂ¤erent locations$\backslash$nand the physical environment consisting of objects and documents, including especially$\backslash$ncomputer systems. A Brahms model of work practice reveals circumstantial, interactional$\backslash$nin\ss uences on how work actually gets done, especially how people involve each other in$\backslash$ntheir work. In particular, a model of practice reveals how people accomplish a collaboration$\backslash$nthrough multiple and alternative means of communication, such as meetings,$\backslash$ncomputer tools, and written documents. Choices of what and how to communicate are$\backslash$ndependent upon social beliefs and behaviorsÃwhat people know about each other\~{O}s$\backslash$nactivities, intentions, and capabilities and their understanding of the norms of the group.$\backslash$nAs a result, Brahms models can help humanÃcomputer system designers to understand$\backslash$nhow tasks and information actually \ss ow between people and machines, what work is$\backslash$nrequired to synchronize individual contributions, and how tools hinder or help this$\backslash$nprocess. In particular, work\ss ow diagrams generated by Brahms are the emergent product$\backslash$nof local interactions between agents and representational artifacts, not pre-ordained,$\backslash$nend-to-end paths built in by a modeler. We developed Brahms as a tool to support the$\backslash$ndesign of work by illuminating how formal \ss ow descriptions relate to the social systems$\backslash$nof work; we accomplish this by incorporating multiple viewsÃrelating people, information,$\backslash$nsystems, and geographyÃin one tool. Applications of Brahms could also include$\backslash$nsystem requirements analysis, instruction, implementing software agents, and a workbench$\backslash$nfor relating cognitive and social theories of human behavior.},
author = {Clancey, Wj and Sachs, P},
booktitle = {Int. J. HumanâComputer Studies},
doi = {10.1006/ijhc.1998.0229},
editor = {Compton, P and Mizoguchi, R and Motoda, H and Menzies, Tim},
isbn = {1071-5819},
issn = {10715819},
pages = {831--865},
publisher = {Department of Artificial Intelligence},
title = {{Brahms: Simulating practice for work systems design}},
url = {http://www.sciencedirect.com/science/article/pii/S1071581998902294},
volume = {49},
year = {1998}
}
@inproceedings{meesad02,
abstract = {Using optimization tools such as genetic algorithms to construct a
fuzzy expert system (FES), focusing only on its accuracy without
considering comprehensibility may result in a system that is not easy to
understand or the so called a black box model. To exploit the
transparency features of FESs for explanation in higher-level knowledge
representation, a FES should provide high comprehensibility while
preserving its accuracy. The completeness of fuzzy sets and rule
structures should also be considered to guarantee that every data point
has a response output. This paper proposes some quantitative measures to
determine the degree of the accuracy, comprehensibility, and
completeness of FESs. These quantitative measures are then used as a
fitness function for a genetic algorithm in an optimally built FES},
author = {Meesad, Phayung Meesad Phayung and Yen, G.G.},
booktitle = {2002 IEEE World Congress on Computational Intelligence. 2002 IEEE International Conference on Fuzzy Systems. FUZZ-IEEE'02. Proceedings (Cat. No.02CH37291)},
doi = {10.1109/FUZZ.2002.1005001},
file = {:Users/timm/svns/doc/xplain/02meesad.pdf:pdf},
isbn = {0-7803-7280-8},
issn = {10987584},
pages = {284--289},
title = {{Quantitative measures of the accuracy, comprehensibility, and
completeness of a fuzzy expert system}},
volume = {1},
year = {2002}
}
@article{zave93,
abstract = {The feature-interaction problem found in complex software systems
that support telecommunications is reviewed. The relationship between
feature interactions and formal specifications is examined. Several
important ways telecommunications has evolved beyond plain old telephone
service (POTS) are described. It is shown how many feature interactions
can be eliminated by applying known techniques of formal specification.
A glossary that explains telecommunications terms not defined in the
text and acronyms used throughout the article is included},
address = {Los Alamitos, CA, USA},
author = {Zave, P.},
doi = {10.1109/2.223539},
issn = {0018-9162},
journal = {Computer},
month = aug,
number = {8},
pages = {20--29},
publisher = {IEEE Computer Society Press},
title = {{Feature interactions and formal specifications in
telecommunications}},
url = {http://dx.doi.org/10.1109/2.223539},
volume = {26},
year = {1993}
}
@article{VanUitert2008c,
abstract = {Genomic datasets often consist of large, binary, sparse data matrices. In such a dataset, one is often interested in finding contiguous blocks that (mostly) contain ones. This is a biclustering problem, and while many algorithms have been proposed to deal with gene expression data, only two algorithms have been proposed that specifically deal with binary matrices. None of the gene expression biclustering algorithms can handle the large number of zeros in sparse binary matrices. The two proposed binary algorithms failed to produce meaningful results. In this article, we present a new algorithm that is able to extract biclusters from sparse, binary datasets. A powerful feature is that biclusters with different numbers of rows and columns can be detected, varying from many rows to few columns and few rows to many columns. It allows the user to guide the search towards biclusters of specific dimensions. When applying our algorithm to an input matrix derived from TRANSFAC, we find transcription factors with distinctly dissimilar binding motifs, but a clear set of common targets that are significantly enriched for GO categories.},
author = {van Uitert, Miranda and Meuleman, Wouter and Wessels, Lodewyk},
doi = {10.1089/cmb.2008.0066},
file = {:Users/timm/svns/doc/erin/references/BinarySparseClustering/Uitert08.pdf:pdf},
issn = {1066-5277},
journal = {Journal of computational biology : a journal of computational molecular cell biology},
keywords = {biclustering,binary data,transcription factor binding},
number = {10},
pages = {1329--1345},
pmid = {19040367},
title = {{Biclustering sparse binary genomic data.}},
volume = {15},
year = {2008}
}
@inproceedings{me90,
author = {Menzies, T J},
booktitle = {Proceedings \{AI\} '90},
title = {{Isa Object Part-of Knowledge Representation?}},
year = {1990}
}
@inproceedings{kim12,
author = {Kim, Yang Sok and Kang, Byeong Ho and Ryu, Seung Hwan and Compton, Paul and Han, Soyeon Caren and Menzies, Tim},
booktitle = {Knowledge Management and Acquisition for Intelligent Systems Lecture Notes in Computer Science},
pages = {258--271},
title = {{Crowd-Sourced Knowledge Bases}},
volume = {7457},
year = {2012}
}
@article{jorgensen04a,
abstract = {This paper provides an extensive review of studies related to expert$\backslash$nestimation of software development effort. The main goal and contribution$\backslash$nof the review is to support the research on expert estimation, e.g.,$\backslash$nto ease other researcher's search for relevant expert estimation$\backslash$nstudies. In addition, we provide software practitioners with useful$\backslash$nestimation guidelines, based on the research-based knowledge of expert$\backslash$nestimation processes. The review results suggest that expert estimation$\backslash$nis the most frequently applied estimation strategy for software projects,$\backslash$nthat there is no substantial evidence in favour of use of estimation$\backslash$nmodels, and that there are situations where we can expect expert$\backslash$nestimates to be more accurate than formal estimation models. The$\backslash$nfollowing 12 expert estimation "best practice" guidelines are evaluated$\backslash$nthrough the review: (1) evaluate estimation accuracy, but avoid high$\backslash$nevaluation pressure; (2) avoid conflicting estimation goals; (3)$\backslash$nask the estimators to justify and criticize their estimates; (4)$\backslash$navoid irrelevant and unreliable estimation information; (5) use documented$\backslash$ndata from previous development tasks; (6) find estimation experts$\backslash$nwith relevant domain background and good estimation records; (7)$\backslash$nEstimate top-down and bottom-up, independently of each other; (8)$\backslash$nuse estimation checklists; (9) combine estimates from different experts$\backslash$nand estimation strategies; (10) assess the uncertainty of the estimate;$\backslash$n(11) provide feedback on estimation accuracy and development task$\backslash$nrelations; and, (12) provide estimation training opportunities. We$\backslash$nfound supporting evidence for all 12 estimation principles, and provide$\backslash$nsuggestions on how to implement them in software organizations.},
author = {Jorgensen, M},
journal = {Journal of Systems and Software},
number = {1-2},
title = {{A review of studies on expert estimation of software development effort}},
volume = {70},
year = {2004}
}
@article{Shirai2014a,
abstract = {To meet critical business challenges, software development teams need data to effectively manage product quality, cost, and schedule. The Team Software ProcessSM (TSPSM) provides a framework that teams use to collect software process data in real time, using a defined disciplined process. This data holds promise for use in software engineering research. We combined data from 109 industrial projects into a database to support performance benchmarking and model development. But is the data of sufficient quality to draw conclusions? We applied various tests and techniques to identify data anomalies that affect the quality of the data in several dimensions. In this paper, we report some initial results of our analysis, describing the amount and the rates of identified anomalies and suspect data, including incorrectness, inconsistency, and credibility. To illustrate the types of data available for analysis, we provide three examples. The preliminary results of this empirical study suggest that some aspects of the data quality are good and the data are generally credible, but size data are often missing},
author = {Shirai, Yasutaka and Nichols, William and Kasunic, Mark},
doi = {10.1145/2600821.2600841},
file = {:Users/timm/svns/doc/14tsp.pdf:pdf},
isbn = {9781450327541},
journal = {ICSSP 2014 Proceedings of the 2014 International Conference on Software and System Process},
keywords = {data quality,database,team software process,tsp},
pages = {25--29},
title = {{Initial Evaluation of Data Quality in a TSP Software Engineering Project Data Repository}},
year = {2014}
}
@article{Kaariainen2006,
author = {K\"{a}\"{a}ri\"{a}inen, M},
journal = {Algorithmic Learning Theory},
title = {{Active learning in the non-realizable case}},
url = {http://www.springerlink.com/index/PKU3430515658M85.pdf},
year = {2006}
}
@inproceedings{hassan10,
abstract = {Software engineering data (such as code bases, exe- cution traces, historical code changes, mailing lists, and bug databases) contains a wealth of information about a projectÂ¿s status, progress, and evolution. Using well- established data mining techniques, practitioners and re- searchers can explore the potential of this valuable data in order to better manage their projects and to produce higher-quality software systems that are delivered on time and within budget. This tutorial presents the latest research in mining Soft- ware Engineering (SE) data, discusses challenges associ- ated with mining SE data, highlights SE data mining suc- cess stories, and outlines future research directions. Partic- ipants will acquire knowledge and skills needed to perform research or conduct practice in the field and to integrate data mining techniques in their own research or practice.},
author = {Xie, Tao and Pei, Jian and Hassan, Ahmed E.},
booktitle = {29th International Conference on Software Engineering (ICSE'07 Companion)},
doi = {10.1109/ICSECOMPANION.2007.50},
isbn = {0-7695-2892-9},
issn = {1088467X (ISSN)},
publisher = {ACM},
series = {ICSE '10},
title = {{Mining Software Engineering Data}},
year = {2007}
}
@inproceedings{allahyari:user-oriented,
abstract = {This paper reviews methods for evaluating and analyzing the understandability of classification models in the context of data mining. The motivation for this study is the fact that the majority of previous work on evaluation and optimization of classification models has focused on assessing or increasing the accuracy of the models and thus user-oriented properties such as comprehensibility and understandability have been largely overlooked. We conduct a quantitative survey to examine the concept of understandability from the user's point of view. The survey results are analyzed using the analytic hierarchy process (AHP) to rank models according to their understandability. The results indicate that decision tree models are perceived as more understandable than rule-based models. Using the survey results regarding understandability of a number of models in conjunction with quantitative measurements of the complexity of the models, we are able to establish a negative correlation between the complexity and understandability of the classification models, at least for one of the two studied data sets. Â© 2011 The authors and IOS Press. All rights reserved.},
author = {Allahyari, Hiva and Lavesson, Niklas},
booktitle = {Frontiers in Artificial Intelligence and Applications},
doi = {10.3233/978-1-60750-754-3-11},
isbn = {9781607507536},
issn = {09226389},
keywords = {Classification,evaluation,understandability},
pages = {11--19},
title = {{User-oriented assessment of classification model understandability}},
volume = {227},
year = {2011}
}
@inproceedings{lum06,
author = {Lum, Karen and Menzies, Tim and Hihn, Jairus},
booktitle = {ISPA Conference Proceedings},
title = {{Studies in Software Cost Model Behavior: Do We Really Understand Cost Model Performance?}},
url = {http://trs-new.jpl.nasa.gov/dspace/handle/2014/41450},
year = {2006}
}
@inproceedings{me99h,
author = {Menzies, T and Cukic, B and Coiera, E},
booktitle = {AAAI'99 workshop on Conflicts and Identifying Opportunities.},
title = {{Smaller, Faster Dialogues via Conversational Probing}},
year = {1999}
}
@article{me05c,
abstract = { Good software cost models can significantly help software project managers. With good models, project stakeholders can make informed decisions about how to manage resources, how to control and plan the project, or how to deliver the project on time, on schedule, and on budget. Real-world data sets, such as those coming from software engineering projects, often contain noisy, irrelevant, or redundant variables. We propose that cost modelers should perform data-pruning experiments after data collection and before model building. Such pruning experiments are simple and fast.},
author = {Chen, Z. and Menzies, T. and Port, D. and Boehm, D.},
doi = {10.1109/MS.2005.151},
issn = {0740-7459},
journal = {IEEE Software},
keywords = {COCOMO,cost modeling,feature subset selection,software engineering,time estimation,wrapper},
month = nov,
number = {6},
pmid = {21609814},
title = {{Finding the right data for software cost modeling}},
volume = {22},
year = {2005}
}
@article{Menzies2010,
author = {El-Rawas, Oussama and Menzies, Tim},
doi = {10.1007/s11334-010-0137-9},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Menzies - 2010 - A second look at Faster , Better , Cheaper.pdf:pdf},
issn = {16145046},
journal = {Innovations in Systems and Software Engineering},
keywords = {COCOMO,Faster Better Cheaper,Predictor models,Simulated annealing,Software engineering,Software processes},
number = {4},
pages = {319--335},
title = {{A second look at Faster, Better, Cheaper}},
volume = {6},
year = {2010}
}
@inproceedings{me02o,
author = {Menzies, Tim and Mason, Lindsay},
booktitle = {Proceedings of the 2002 ACM SIGPLAN workshop on Rule-based programming - RULE '02},
doi = {10.1145/570186.570194},
isbn = {1581136064},
keywords = {history,prolog,rule-based programming},
pages = {79--92},
title = {{Some prolog macros for rule-based programming}},
url = {http://portal.acm.org/citation.cfm?doid=570186.570194},
year = {2002}
}
@article{Guo11az,
abstract = {Software product line (SPL) engineering is a software engineering approach to building configurable software systems. SPLs commonly use a feature model to capture and document the commonalities and variabilities of the underlying software system. A key challenge when using a feature model to derive a new SPL configuration is determining how to find an optimized feature selection that minimizes or maximizes an objective function, such as total cost, subject to resource constraints. To help address the challenges of optimizing feature selection in the face of resource constraints, this paper presents an approach that uses G enetic A lgorithms for optimized FE ature S election (GAFES) in SPLs. Our empirical results show that GAFES can produce solutions with 86-97\% of the optimality of other automated feature selection algorithms and in 45-99\% less time than existing exact and heuristic feature selection techniques. ?? 2011 Elsevier Inc. All rights reserved.},
address = {New York, NY, USA},
author = {Guo, Jianmei and White, Jules and Wang, Guangxin and Li, Jian and Wang, Yinglin},
doi = {10.1016/j.jss.2011.06.026},
isbn = {0164-1212},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {Configuration,Feature models,Genetic algorithm,Optimization,Product derivation,Software product lines},
month = dec,
number = {12},
pages = {2208--2221},
publisher = {Elsevier Science Inc.},
title = {{A genetic algorithm for optimized feature selection with resource constraints in software product lines}},
url = {http://dx.doi.org/10.1016/j.jss.2011.06.026},
volume = {84},
year = {2011}
}
@book{BERGE89,
author = {Berge, Claude},
publisher = {North-Holland},
title = {{Hypergraphs}},
year = {1989}
}
@article{shepperd12z,
abstract = {Context: Software engineering has a problem in that when we empirically evaluate competing prediction systems we obtain conflicting results. Objective: To reduce the inconsistency amongst validation study results and provide a more formal foundation to interpret results with a particular focus on continuous prediction systems. Method: A new framework is proposed for evaluating competing prediction systems based upon (1) an unbiased statistic, Standardised Accuracy, (2) testing the result likelihood relative to the baseline technique of random 'predictions', that is guessing, and (3) calculation of effect sizes. Results: Previously published empirical evaluations of prediction systems are re-examined and the original conclusions shown to be unsafe. Additionally, even the strongest results are shown to have no more than a medium effect size relative to random guessing. Conclusions: Biased accuracy statistics such as MMRE are deprecated. By contrast this new empirical validation framework leads to meaningful results. Such steps will assist in performing future meta-analyses and in providing more robust and usable recommendations to practitioners. ?? 2012 Elsevier B.V. All rights reserved.},
author = {Shepperd, Martin and MacDonell, Steve},
doi = {10.1016/j.infsof.2011.12.008},
isbn = {09505849},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Empirical validation,Prediction system,Randomisation techniques,Software engineering},
number = {8},
pages = {820--827},
title = {{Evaluating prediction systems in software project estimation}},
volume = {54},
year = {2012}
}
@inproceedings{dekhtyar04,
abstract = {Software compiles and therefore is characterized by a parseable grammar. Natural language text rarely conforms to prescriptive grammars and therefore is much harder to parse. Mining parseable structures is easier than mining less structured entities. Therefore, most work on mining repositories focuses on software, not natural language text. Here, we report experiments with mining natural language text (requirements documents) suggesting that: (a) mining natural language is not too difficult, so (b) software repositories should routinely be augmented with all the natural language text used to develop that software.},
author = {Dekhtyar, a.},
booktitle = {"International Workshop on Mining Software Repositories (MSR 2004)" W17S Workshop - 26th International Conference on Software Engineering},
doi = {10.1049/ic:20040470},
isbn = {0 86341 432 X},
number = {917},
pages = {22--26},
title = {{Text is software tool}},
url = {http://www.mendeley.com/research/text-is-software-too/},
volume = {2004},
year = {2004}
}
@inproceedings{me99n,
author = {Menzies, T},
booktitle = {KAW'99: the 12th Workshop on Knowledge Acquisition, Modeling and Management, Voyager Inn, Banff, Alberta, Canada Oct 16-22, 1999},
title = {{h\{Q\}kb- The High Quality Knowledge Base Initiative (Sisyphus V: Learning Design Assessment Knowledge)}},
year = {1999}
}
@inproceedings{posnet11,
abstract = {Software systems are decomposed hierarchically, for example, into modules, packages and files. This hierarchical decomposition has a profound influence on evolvability, maintainability and work assignment. Hierarchical decomposition is thus clearly of central concern for empirical software engineering researchers; but it also poses a quandary. At what level do we study phenomena, such as quality, distribution, collaboration and productivity? At the level of files? packages? or modules? How does the level of study affect the truth, meaning, and relevance of the findings? In other fields it has been found that choosing the wrong level might lead to misleading or fallacious results. Choosing a proper level, for study, is thus vitally important for empirical software engineering research; but this issue hasn't thus far been explicitly investigated. We describe the related idea of ecological inference and ecological fallacy from sociology and epidemiology, and explore its relevance to empirical software engineering; we also present some case studies, using defect and process data from 18 open source projects to illustrate the risks of modeling at an aggregation level in the context of defect prediction, as well as in hypothesis testing.},
author = {Posnett, Daryl and Filkov, Vladimir and Devanbu, Premkumar},
booktitle = {2011 26th IEEE/ACM International Conference on Automated Software Engineering, ASE 2011, Proceedings},
doi = {10.1109/ASE.2011.6100074},
isbn = {9781457716393},
issn = {1938-4300},
pages = {362--371},
title = {{Ecological inference in empirical software engineering}},
year = {2011}
}
@article{Lisurek2010a,
abstract = {Success in small molecule screening relies heavily on the preselection of compounds. Here, we present a strategy for the enrichment of chemical libraries with potentially bioactive compounds integrating the collected knowledge of medicinal chemistry. Employing a genetic algorithm, substructures typically occurring in bioactive compounds were identified using the World Drug Index. Availability of compounds containing the selected substructures was analysed in vendor libraries, and the substructure-specific sublibraries were assembled. Compounds containing reactive, undesired functional groups were omitted. Using a diversity filter for both physico-chemical properties and the substructure composition, the compounds of all the sublibraries were ranked. Accordingly, a screening collection of 16,671 compounds was selected. Diversity and chemical space coverage of the collection indicate that it is highly diverse and well-placed in the chemical space spanned by bioactive compounds. Furthermore, secondary assay-validated hits presented in this study show the practical relevance of our library design strategy.},
author = {Lisurek, Michael and Rupp, Bernd and Wichard, J\"{o}rg and Neuenschwander, Martin and {Von Kries}, J. P. and Frank, Ronald and Rademann, J\"{o}rg and K\"{u}hne, Ronald},
doi = {10.1007/s11030-009-9187-z},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Lisurek2009.pdf:pdf},
isbn = {1381-1991},
issn = {13811991},
journal = {Molecular Diversity},
keywords = {Bio informatics,Drug design,High throughput screening,Library design,Molecular diversity},
number = {2},
pages = {401--408},
pmid = {19685275},
title = {{Design of chemical libraries with potentially bioactive molecules applying a maximum common substructure concept}},
volume = {14},
year = {2010}
}
@misc{simon78,
author = {Simon, H},
title = {{Rational Decision-Making in Business Organiations- a Nobel Memorial Lecture, December 8}},
url = {http://goo.gl/E80Nyy},
year = {1978}
}
@inproceedings{lokan13,
abstract = {Software development effort estimation is an essential aspect of software project management. An effort estimation model expresses relationships between effort and factors such as organizational and project features (e.g. software functional size, and the programming language used in a project). However, software development practices and tools change over time, to environmental changes. This can affect some relationships assumed in an effort estimation model. A moving windows method (a method for treating the timing information of projects), has thus been proposed for estimation models. The moving windows method uses data from a fixed number of the most recent projects data for model construction. However, it is not clear that moving windows is the best way to handle the timing information in an estimation model. The goal of our research is to determine how best to treat timing information in constructing effort estimation models. To achieve the goal, we compared six different methods (moving windows, dummy variable of moving windows, dummy variables of equal bins, dummy variables of year, year predictor, and serial number) for treating timing data, in terms of estimation accuracy. In the experiment, we use three software development project datasets. We found that moving windows is best when the number of projects included in the dataset is not small, and dummy variable of moving windows is the best when the number is small. Copyright 2013 ACM.},
author = {Tsunoda, M.a and Amasaki, S.b and Lokan, C.c},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/2486046.2486051},
file = {:Users/timm/svns/doc/transfer/13lokan.pdf:pdf},
isbn = {9781450320627},
pages = {10--19},
series = {ICSSP 2013},
title = {{How to treat timing information for software effort estimation?}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84878471195\&partnerID=40\&md5=c0cc3f1f1c01d25a817579d77230a0c1},
year = {2013}
}
@article{Menzies2013b,
author = {Menzies, Tim and Butcher, Andrew and Cok, David},
doi = {http://dx.doi.org/10.1109/TSE.2012.83},
file = {:Users/timm/svns/doc/cost/12gense.pdf:pdf},
journal = {Software Engineering, IEEE Transactions on},
number = {6},
pages = {822 -- 834},
title = {{Local versus Global Lessons for Defect Prediction and Effort Estimation}},
volume = {39},
year = {2013}
}
@inproceedings{ag98,
abstract = {Knowledge discovery in databases (KDD) and machine learning
researchers recognize that comprehensibility is an important condition
for the use, and therefore usefulness, of knowledge discovery methods.
An investigation of the comprehensibility of the discovered patterns may
benefit IS research as well. This paper identifies some of the issues
that such inquiry may face. Related findings and conclusions of four
case studies focusing on applications of decision tree induction
methods, are described. A discussion based on these studies suggests,
among the rest, that the problem of comprehensibility is complicated by
a complex context due to a diversity of problem domain attributes, user
and task characteristics, algorithmic methods, and concurrency of user
goals. Solutions to problems of discovered patterns that are not easy to
interpret and validate may involve integration of available information
technologies, and utilization of multiple information types and sources.
An investigation of comprehensibility issues may benefit from the
adoption of multiple definitions in relation to this concept},
author = {Askira-Gelman, I.},
booktitle = {Proceedings of the Thirty-First Hawaii International Conference on System Sciences},
doi = {10.1109/HICSS.1998.648319},
isbn = {0-8186-8255-8},
issn = {10603425},
title = {{Knowledge discovery: comprehensibility of the results}},
volume = {5},
year = {1998}
}
@article{nelson11,
author = {{Adam Nelson Tim Menzies}, Gregory Gay},
journal = {Software- Practice and Experience (to appear)},
month = mar,
number = {3},
pages = {283--305},
title = {{Sharing Experiments Using Open Source Software}},
volume = {41},
year = {2011}
}
@article{Arif2009c,
abstract = {Binary fingerprints encoding the presence of 2D fragment substructures in molecules are extensively used for similarity-based virtual screening in the agrochemical and pharmaceutical industries. This paper describes two techniques for enhancing the effectiveness of screening: the use of a second-level search based on the nearest neighbours of the initial reference structure; and the use of weighted fingerprints encoding the frequency of occurrence, rather than just the mere presence, of substructures. Experiments using several databases for which both structural and bioactivity data are available demonstrate the effectiveness of these two approaches.},
author = {Arif, Shereena M. and Hert, J\'{e}r\^{o}me and Holliday, John D. and Malim, Nurul and Willett, Peter},
doi = {10.1007/978-3-642-04031-3\_35},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Arif22009.pdf:pdf},
isbn = {3642040306},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Chemoinformatics,Fingerprint,Fragment substructure,Similarity measure,Similarity searching,Turbo similarity searching,Virtual screening,Weighting scheme},
pages = {404--414},
title = {{Enhancing the effectiveness of fingerprint-based virtual screening: Use of turbo similarity searching and of fragment frequencies of occurrence}},
volume = {5780 LNBI},
year = {2009}
}
@online{promise12,
author = {Menzies, T. and Caglayan, B. and Kocaguneli, E. and Krall, J. and Peters, F. and {B. Turhan}},
month = jun,
title = {{The PROMISE Repository of empirical software engineering data}},
url = {http://promisedata.googlecode.com},
year = {2012}
}
@article{krall14,
author = {Krall, J and Menzies, T},
file = {:Users/timm/svns/doc/optimalML/galeTse.pdf:pdf},
journal = {IEEE Transactions on Software Engineering (submitted)},
title = {{GALE: Geometric Active Learning for Search-based Software Engineering}},
year = {2014}
}
@misc{me97r,
author = {Menzies, T and Waugh, S and Goss, S and Cohen, Robert F},
howpublished = {Submitted to FOIS '97},
title = {{Evaluating a Temporal Causal Ontology}},
year = {1997}
}
@inproceedings{me10c,
author = {Kocaguneli, Ekrem and Gay, Gregory and Menzies, Tim and Yang, Ye and Keung, Jacky W.},
booktitle = {Proceedings of the IEEE/ACM international conference on Automated software engineering - ASE '10},
doi = {10.1145/1858996.1859061},
isbn = {9781450301169},
pages = {321},
title = {{When to use data from other projects for effort estimation}},
url = {http://portal.acm.org/citation.cfm?doid=1858996.1859061},
year = {2010}
}
@inproceedings{JALALI2007,
address = {Washington, DC, USA},
author = {Jalali, Omid and Jalali, Omid and Menzies, Tim and Menzies, Tim and Baker, Dan and Baker, Dan},
booktitle = {Jet Propulsion},
doi = {http://dx.doi.org/10.1109/PROMISE.2007.3},
isbn = {0-7695-2954-2},
pages = {1--9},
publisher = {IEEE Computer Society},
title = {{Column Pruning Beats Strati cation in Effort Estimation}},
year = {2007}
}
@article{shn08,
author = {Shneiderman, B},
journal = {Science},
month = mar,
number = {7},
pages = {1349--1350},
title = {{Science 2.0}},
volume = {319},
year = {2008}
}
@article{Ibm1993a,
author = {Ibm, Agrawal and Road, Tomasz Almaden},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/agrawal93.pdf:pdf},
journal = {IBM Almaden Research Center},
pages = {207--216},
title = {{Mining Association in Large Databases}},
year = {1993}
}
@inproceedings{me02c,
author = {Menzies, Tim and Chiang, Eliza and Feather, Martin and Hu, Ying and Kiper, James D},
booktitle = {Jet Propulsion},
editor = {Khoshgoftaar, Taghi M},
isbn = {1-4020-7427-1},
publisher = {Kluwer},
title = {{Condensing Uncertainty via Incremental Treatment Learning}},
year = {2002}
}
@inproceedings{deMoura08,
author = {Bjorner, N. and de Moura, L.},
booktitle = {[cited 2010 July]; Available from:http://research.microsoft.com/projects/Z3},
series = {TACAS'08/ETAPS'08},
title = {{Z3: An efficient SMT solver}},
year = {2007}
}
@article{me11p,
author = {Brady, Adam},
journal = {Software Quality Professional},
keywords = {article,case-based reasoning,data quality,is available on the,note,planning,sqp website,supplemental material for this},
number = {4},
title = {{What is â Enough â Quality for Data Repositories ?}},
volume = {13},
year = {2011}
}
@article{Sedighizadeh2009a,
abstract = {The Particle Swarm Optimization (PSO) algorithm, as one of the latest algorithms inspired from the nature, was introduced in the mid 1990s and since then, it has been utilized as an optimization tool in various applications, ranging from biological and medical applications to computer graphics and music composition. In this paper, following a brief introduction to the PSO algorithm, the chronology of its evolution is presented and all major PSO-based methods are comprehensively surveyed. Next, these methods are studied separately and their important factors and parameters are summarized in a comparative table. In addition, a new taxonomy of PSO-based methods is presented. It is the purpose of this paper is to present an overview of previous and present conditions of the PSO algorithm as well as its opportunities and challenges. Accordingly, the history, various methods, and taxonomy of this algorithm are discussed and its different applications together with an analysis of these applications are evaluated.},
author = {Sedighizadeh, Davoud and Masehian, Ellips},
doi = {10.7763/IJCTE.2009.V1.80},
file = {:Users/timm/svns/doc/pso/09reviewPSO.pdf:pdf},
isbn = {9821828841},
issn = {17938201},
journal = {International Journal of Computer Theory and Engineering},
keywords = {Applications.,Heuristic Optimization,Optimization (PSO),Particles Swarm,Taxonomy},
number = {5},
pages = {486--502},
title = {{Particle Swarm Optimization Methods , Taxonomy and Applications}},
volume = {1},
year = {2009}
}
@incollection{maimon05,
title = {{No Title}}
}
@misc{Siekmanna,
author = {Siekmann, J},
file = {:Users/timm/svns/doc/Engineering Knowledge in the Age of the Semantic Web 14th \ldots\_Suryanto\_2004.pdf:pdf},
isbn = {3540233407},
title = {{Engineering Knowledge in the Age of the Semantic Web}}
}
@article{me10d,
abstract = {There exists a large and growing number of proposed estimation methods but little conclusive evidence ranking one method over another. Prior effort estimation studies suffered from  conclusion instability , where the rankings offered to different methods were not stable across (a)Â different evaluation criteria; (b)Â different data sources; or (c)Â different random selections of that data. This paper reports a study of 158 effort estimation methods on data sets based on COCOMO features. Four  best  methods were detected that were consistently better than the  rest  of the other 154 methods. These rankings of  best  and  rest  methods were stable across (a)Â three different evaluation criteria applied to (b)Â multiple data sets from two different sources that were (c)Â divided into hundreds of randomly selected subsets using four different random seeds. Hence, while there exists no single universal  best  effort estimation method, there appears to exist a small number (four) of most useful methods. This result both complicates and simplifies effort estimation research. The complication is that any future effort estimation analysis should be preceded by a  selection study  that finds the best local estimator. However, the simplification is that such a study need not be labor intensive, at least for COCOMO style data sets.},
author = {Menzies, Tim and Jalali, Omid and Hihn, Jairus and Baker, Dan and Lum, Karen},
doi = {10.1007/s10515-010-0070-z},
issn = {09288910},
journal = {Automated Software Engineering},
keywords = {COCOMO,Data mining,Effort estimation,Evaluation},
month = dec,
number = {4},
pages = {409--437},
title = {{Stable rankings for different effort models}},
volume = {17},
year = {2010}
}
@article{me99c,
author = {Menzies, T},
journal = {Submitted to AAAI-99},
title = {{Simpler, Faster Abductive Validation}},
year = {1999}
}
@inproceedings{jalali08,
abstract = {Recent work with NASA's Jet Propulsion Laboratory has allowed for external access to five of JPL's real-world requirements models, anonymized to conceal proprietary information, but retaining their computational nature. Experimentation with these models, reported herein, demonstrates a dramatic speedup in the computations performed on them. These models have a well defined goal: select mitigations that retire risks which, in turn, increases the number of attainable requirements. Such a non-linear optimization is a well-studied problem. However identification of not only (a) the optimal solution(s) but also (b) the key factors leading to them is less well studied. Our technique, called KEYS, shows a rapid way of simultaneously identifying the solutions and their key factors. KEYS improves on prior work by several orders of magnitude. Prior experiments with simulated annealing or treatment learning took tens of minutes to hours to terminate. KEYS runs much faster than that; e.g for one model, KEYS ran 13,000 times faster than treatment learning (40 minutes versus 0.18 seconds). Processing these JPL models is a non-linear optimization problem: the fewest mitigations must be selected while achieving the most requirements. Non-linear optimization is a well studied problem. With this paper, we challenge other members of the PROMISE community to improve on our results with other techniques.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08keys.pdf\}},
author = {Jalali, Omid and Menzies, Tim and Feather, Martin},
booktitle = {Proceedings of the PROMISE 2008 Workshop (ICSE)},
doi = {10.1145/1370788.1370807},
isbn = {9781605580364},
issn = {02705257},
title = {{Optimizing Requirements Decisions with KEYS}},
year = {2008}
}
@misc{me09h,
author = {Menzies, Tim},
booktitle = {Journal of Software Engineering and Applications},
doi = {10.4236/jsea.2009.24030},
issn = {1945-3116},
month = nov,
number = {04},
pages = {221--236},
title = {{Explanation vs Performance in Data Mining: A Case Study with Predicting Runaway Projects}},
volume = {02},
year = {2009}
}
@article{me08a,
abstract = {Abstract  After data mining National Aeronautics and Space Administration (NASA) independent verification and validation (IV\&V) data,$\backslash$n  we offer (a) an early life cycle predictor for project issue frequency and severity; (b) an IV\&V task selector (that used$\backslash$n  the predictor to find the appropriate IV\&V tasks); and (c) pruning heuristics describing what tasks to ignore, if the budget$\backslash$n  cannot accommodate all selected tasks. In ten-way cross-validation experiments, the predictor performs very well indeed: the$\backslash$n  average f-measure for predicting four classes of issue severity was over 0.9. This predictor is built using public-domain data and$\backslash$n  software. To the best of our knowledge, this is the first reproducible report of a predictor for issue frequency and severity$\backslash$n  that can be applied early in the life cycle.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07ivv.pdf\}},
author = {Menzies, Tim and Benson, Markland and Costello, Ken and Moats, Christina and Northey, Melissa and Richardson, Julian},
doi = {10.1007/s11334-008-0046-3},
issn = {16145046},
journal = {Innovations in Systems and Software Engineering},
keywords = {Data mining,Early life cycle defect prediction,IV\&V,NASA},
month = mar,
number = {2},
pages = {169--183},
title = {{Learning better IV\&V practices}},
volume = {4},
year = {2008}
}
@inproceedings{me92l,
author = {Menzies, T and Mahidadia, a and Compton, P},
booktitle = {Proceedings of the 7th \{AAAI\}-Sponsored \{B\}anff Knowledge Acquisition for Knowledge-Based Systems Workshop \{B\}anff, \{C\}anada, October 11-16},
title = {{Using \{C\}ausality as a \{G\}eneric \{K\}nowledge \{R\}epresentation, or \{W\}hy and \{H\}ow \{C\}entralised \{K\}nowledge \{S\}ervers \{C\}an \{U\}se \{C\}ausality}},
year = {1992}
}
@article{budgen08,
abstract = {When conducting a systematic literature review, researchers usually determine the relevance of primary studies on the basis of the title and abstract. However, experience indicates that the abstracts for many software engineering papers are of too poor a quality to be used for this purpose. A solution adopted in other domains is to employ structured abstracts to improve the quality of information provided. This study consists of a formal experiment to investigate whether structured abstracts are more complete and easier to understand than non-structured abstracts for papers that describe software engineering experiments. We constructed structured versions of the abstracts for a random selection of 25 papers describing software engineering experiments. The 64 participants were each presented with one abstract in its original unstructured form and one in a structured form, and for each one were asked to assess its clarity (measured on a scale of 1 to 10) and completeness (measured with a questionnaire that used 18 items). Based on a regression analysis that adjusted for participant, abstract, type of abstract seen first, knowledge of structured abstracts, software engineering role, and preference for conventional or structured abstracts, the use of structured abstracts increased the completeness score by 6.65 (SE 0.37, p < 0.001) and the clarity score by 2.98 (SE 0.23, p  < 0.001). 57 participants reported their preferences regarding structured abstracts: 13 (23\%) had no preference; 40 (70\%) preferred structured abstracts; four preferred conventional abstracts. Many conventional software engineering abstracts omit important information. Our study is consistent with studies from other disciplines and confirms that structured abstracts can improve both information content and readability. Although care must be taken to develop appropriate structures for different types of article, we recommend that Software Engineering journals and conferences adopt structured abstracts.},
author = {Budgen, David and Kitchenham, Barbara a. and Charters, Stuart M. and Turner, Mark and Brereton, Pearl and Linkman, Stephen G.},
doi = {10.1007/s10664-008-9075-7},
issn = {13823256},
journal = {Empirical Software Engineering},
keywords = {Randomised controlled laboratory experiment,Structured abstract},
number = {4},
pages = {435--468},
title = {{Presenting software engineering results using structured abstracts: A randomised experiment}},
volume = {13},
year = {2008}
}
@inproceedings{me04b,
author = {Menzies, T and Di\~{}Stefano, Justin S and Cunanan, Chris and Chapman, Robert (Mike)},
booktitle = {IEEE Transactions Software Engineering (in preperation)},
title = {{The Business Case for Defect Logging}},
year = {2004}
}
@article{aha91,
author = {Aha, David W and Kibler, Dennis and Albert, Marc K},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Aha, Kibler, Albert - 1991 - Instance-based learning algorithms.pdf:pdf},
journal = {Mach. Learn.},
month = jan,
number = {1},
pages = {37--66},
title = {{Instance-Based Learning Algorithms}},
volume = {6},
year = {1991}
}
@inproceedings{me91a,
abstract = {A major problem with building expert systems is that experts always communicate knowledge in a specific context. A knowledge acquisition methodology has been developed which restricts the use of knowledge to the context in which it was provided. This method, "ripple down rules" allows for extremely rapid and simple knowledge acquisition without the help of a knowledge engineer. An expert system based on this approach and built by experts is now in routine use. This paper reviews what has been achieved using the approach, its problems and potential.},
author = {Compton, Pea and Edwards, G and Kang, B and Lazarus, L and Malor, R and Menzies, T and Preston, P and Srinivasan, a and Sammut, C},
booktitle = {Proceedings of the Sixth AAAI Knowledge Acquisition for Knowledge-Based Systems Workshop, Calgary, Canada, University of Calgary},
pages = {1--6},
title = {{Ripple down rules: possibilities and limitations}},
year = {1991}
}
@inproceedings{memaco92,
author = {Menzies, T and Mahidadia, A and Compton, P},
booktitle = {Proceedings of the 7th \{AAAI\}-Sponsored \{B\}anff Knowledge Acquisition for Knowledge-Based Systems Workshop \{B\}anff, \{C\}anada, October 11-16},
title = {{Using \{C\}ausality as a \{G\}eneric \{K\}nowledge \{R\}epresentation, or \{W\}hy and \{H\}ow \{C\}entralised \{K\}nowledge \{S\}ervers \{C\}an \{U\}se \{C\}ausality}},
year = {1992}
}
@article{murphy12,
abstract = {The Software Engineering research community have spent considerable effort in developing models to predict the behaviour of software. A number of these models have been derived based on the pre and post behaviour of the development of software products, but when these models are applied to other products, the results are often disappointing. This appears to differentiate Software from other engineering disciplines that often depend on generic predictive models to verify the correctness of their products. This short paper discusses why other engineering disciplines have managed to create generalized models, the challenges faced by the Software industry to build these models, and the change we have made to our process in Microsoft to address some of these challenges.},
author = {Murphy, Brendan},
doi = {10.1007/s10664-011-9184-6},
issn = {13823256},
journal = {Empirical Software Engineering},
keywords = {Development,Models,Reliability,Risk,Software Engineering},
number = {1-2},
pages = {18--22},
title = {{The difficulties of building generic reliability models for software}},
volume = {17},
year = {2012}
}
@article{Koch2015a,
author = {Koch, Patrick and Wagner, Tobias and Emmerich, Michael T.M. and B\"{a}ck, Thomas and Konen, Wolfgang},
doi = {10.1016/j.asoc.2015.01.005},
file = {:Users/timm/svns/doc/sbse/15tunings.pdf:pdf},
issn = {15684946},
journal = {Applied Soft Computing},
pages = {357--370},
publisher = {Elsevier B.V.},
title = {{Efficient multi-criteria optimization on noisy machine learning problems}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S156849461500006X},
volume = {29},
year = {2015}
}
@article{Harper2006a,
abstract = {Data mining is a fast-growing field that is finding application across a wide range of industries. HTS is a crucial part of the drug discovery process at most large pharmaceutical companies. Accurate analysis of HTS data is, therefore, vital to drug discovery. Given the large quantity of data generated during an HTS, and the importance of analyzing those data effectively, it is unsurprising that data-mining techniques are now increasingly applied to HTS data analysis. Taking a broad view of both the HTS process and the data-mining process, we review recent literature that describes the application of data-mining techniques to HTS data. ?? 2006 Elsevier Ltd. All rights reserved.},
author = {Harper, Gavin and Pickett, Stephen D.},
doi = {10.1016/j.drudis.2006.06.006},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/HarperPickett06.pdf:pdf},
isbn = {1359-6446 (Print)},
issn = {13596446},
journal = {Drug Discovery Today},
number = {15-16},
pages = {694--699},
pmid = {16846796},
title = {{Methods for mining HTS data}},
volume = {11},
year = {2006}
}
@inproceedings{kocharm13,
abstract = {We offer a case study illustrating three rules for reporting$\backslash$nresearch to industrial practitioners. Firstly, report ârelevantâ$\backslash$nresults; e.g. this paper explores the effects of distributed development$\backslash$non software products. Second: ârecheckâ old results if new results call$\backslash$nthem into question. Many papers say distributed development can be$\backslash$nharmful to software quality. Previous work by Bird et al. allayed that$\backslash$nconcern but a recent paper by Posnett et al. suggests that the Bird$\backslash$nresult was biased by the kinds of files it explored. Hence, this paper$\backslash$nrechecks that result and finds significant differences in Microsoft$\backslash$nproducts (Office 2010) between software built by distributed or$\backslash$ncollocated teams. At first glance, this recheck calls into question the$\backslash$nwidespread practice of distributed development. Our third rule is to$\backslash$nâreflectâ on results to avoid confusing practitioners with an arcane$\backslash$nmathematical analysis. For example, on reflection, we found that the$\backslash$neffect size of the differences seen in the collocated and distributed$\backslash$nsoftware was so small that it need not concern industrial practitioners.$\backslash$nOur conclusion is that at least for Microsoft products, distributed$\backslash$ndevelopment is not considered harmful.},
author = {Kocaguneli, Ekrem and Zimmermann, Thomas and Bird, Christian and Nagappan, Nachiappan and Menzies, Tim},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2013.6606637},
file = {:Users/timm/svns/doc/13distributed.pdf:pdf},
isbn = {9781467330763},
issn = {02705257},
pages = {882--890},
title = {{Distributed development considered harmful?}},
year = {2013}
}
@inproceedings{Scanniello2013,
author = {Scanniello, Giuseppe and Gravino, Carmine and Marcus, Andrian and Menzies, Tim},
booktitle = {2013 28th IEEE/ACM International Conference on Automated Software Engineering, ASE 2013 - Proceedings},
doi = {10.1109/ASE.2013.6693126},
isbn = {9781479902156},
keywords = {Empirical Study,Fault Prediction,Software Clustering},
organization = {IEEE},
pages = {640--645},
title = {{Class level fault prediction using software clustering}},
year = {2013}
}
@inproceedings{me00e,
abstract = {When a lack of data inhibits decision-making, large-scale what-if
queries can be conducted over the uncertain parameter ranges. Such
queries can generate an overwhelming amount of data. We describe a
general method for understanding that data. Large-scale what-if queries
can guide Monte Carlo simulations of a model. Machine learning can then
be used to summarize the output. The summarization is an ensemble of
decision trees. The TARZAN system [so-called because it swings through
(or searches) the decision trees] can poll the ensemble looking for
majority conclusions regarding what factors change the classifications
of the data. TARZAN can succinctly present the results from very large
what-if queries. For example, in one of the studies presented, we can
view the significant features from 10<sup>9</sup> what-if queries on
half a page},
author = {Menzies, T. and Sinsel, E.},
booktitle = {Proceedings ASE 2000. Fifteenth IEEE International Conference on Automated Software Engineering},
doi = {10.1109/ASE.2000.873661},
isbn = {0-7695-0710-7},
issn = {1527-1366},
title = {{Practical large scale what-if queries: case studies with software
risk assessment}},
year = {2000}
}
@article{emse12,
abstract = {The goal of science is conclusion stability, i.e. to discover some effect X that holds in multiple situations. Sadly, there are all too few examples of stable conclusions in software engineering (SE). In fact, the typical result is conclusion instability where what is true for project one, does not hold for project two. We can find numerous studies of the following form: there is as much evidence for as against the argument that some aspect X adds value to a software project. Below are four examples of this type of problem which we believe to be endemic within SE.},
author = {Menzies, Tim and Shepperd, Martin},
doi = {10.1007/s10664-011-9193-5},
issn = {13823256},
journal = {Empirical Software Engineering},
number = {1-2},
pages = {1--17},
title = {{Special issue on repeatable results in software engineering prediction}},
volume = {17},
year = {2012}
}
@inproceedings{me06c,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06bad.pdf\}},
author = {Orrego, Andres},
booktitle = {Citeseer},
title = {{Bayesian Anomaly Detection (BAD v0. 1)}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.74.3186\&amp;rep=rep1\&amp;type=pdf},
year = {2003}
}
@inproceedings{owen03d,
author = {Owen, David and Menzies, Tim and Heimdahl, Mats and Gao, Jimin},
title = {{Finding \{F\}aults \{Q\}uickly in \{F\}ormal \{M\}odels \{U\}sing \{R\}andom \{S\}earch}},
year = {2004}
}
@article{Menzies2006,
abstract = {Effort estimation often requires generalizing from a small number of historical projects. Generalization from such limited experience is an inherently underconstrained problem. Hence, the learned effort models can exhibit large deviations that prevent standard statistical methods (e.g., t-tests) from distinguishing the performance of alternative effort-estimation methods. The COSEEKMO effort-modeling workbench applies a set of heuristic rejection rules to comparatively assess results from alternative models. Using these rules, and despite the presence of large deviations, COSEEKMO can rank alternative methods for generating effort models. Based on our experiments with COSEEKMO, we advise a new view on supposed "best practices" in model-based effort estimation: 1) Each such practice should be viewed as a candidate technique which may or may not be useful in a particular domain, and 2) tools like COSEEKMO should be used to help analysts explore and select the best method for a particular domain},
author = {Menzies, Tim and Chen, Zhihao and Hihn, Jairus and Lum, Karen},
doi = {10.1109/TSE.2006.114},
file = {:Users/timm/Library/Application Support/Mendeley Desktop/Downloaded/Menzies et al. - 2006 - Selecting Best Practices for Effort Estimation.pdf:pdf},
isbn = {0098-5589},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {COCOMO,Data mining,Deviation,Model-based effort estimation},
number = {11},
pages = {883--895},
title = {{Selecting best practices for effort estimation}},
volume = {32},
year = {2006}
}
@inproceedings{me08h,
abstract = {Prediction of fault prone software components is one of the most researched$\backslash$nproblems in software engineering. Many statistical techniques have$\backslash$nbeen proposed but there is no consensus on the methodology to select$\backslash$nthe ``best model" for the specific project. In this paper, we introduce$\backslash$nand discuss the merits of cost curve analysis of fault prediction$\backslash$nmodels. Cost curves allow software quality engineers to introduce$\backslash$nproject-specific cost of module misclassification into model evaluation.$\backslash$nClassifying a software module as fault-prone implies the application$\backslash$nof some verification activities, thus adding to the development cost.$\backslash$nMisclassifying a module as fault free carries the risk of system$\backslash$nfailure, also associated with cost implications. Through the analysis$\backslash$nof sixteen projects from public repositories, we observe that software$\backslash$nquality does not necessarily benefit from the prediction of fault$\backslash$nprone components. The inclusion of misclassification cost in model$\backslash$nevaluation may indicate that even the ``best" models achieve performance$\backslash$nno better than trivial classification. Our results support a recommendation$\backslash$nfavoring the use of cost curves in practice with the hope they will$\backslash$nbecome a standard tool for software quality model performance evaluation.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08costcurves.pdf\}},
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim},
booktitle = {ISSRE'08: Proceedings of the 19th International Symposium on Software Reliability Engineering},
pages = {197--206},
title = {{Costs Curve Evaluation of Fault Prediction Models}},
year = {2008}
}
@inproceedings{delucia06,
abstract = {The presence of traceability links between software artefacts is very important to achieve high comprehensibility and maintainability. This is confirmed by several researches and tools aiming at support traceability link maintenance and recovery. We propose to use traceability information combined with Information Retrieval techniques within an Eclipse plug-in to show the software engineer the similarity between source code components being developed and the high level artefacts they should be traced on. Such a similarity suggests actions aiming at improving the correct usage of identifiers and comments in source code and, as a consequence, the traceability and the comprehensibility level. The approach and tool have been assessed with a controlled experiment performed with master students},
author = {{De Lucia}, Andrea and {Di Penta}, Massimiliano and Oliveto, Rocco and Zurolo, Francesco},
booktitle = {IEEE International Conference on Program Comprehension},
doi = {10.1109/ICPC.2006.28},
isbn = {0769526012},
issn = {1092-8138},
keywords = {Empirical studies,Traceability recovery},
pages = {317--326},
title = {{Improving comprehensibility of source code via traceability information: A controlled experiment}},
volume = {2006},
year = {2006}
}
@article{he12,
abstract = {Software defect prediction helps to optimize testing resources allocation by identifying defect-prone modules prior to testing. Most existing models build their prediction capability based on a set of historical data, presumably from the same or similar project settings as those under prediction. However, such historical data is not always available in practice. One potential way of predicting defects in projects without historical data is to learn predictors from data of other projects. This paper investigates defect predictions in the cross-project context focusing on the selection of training data. We conduct three large-scale experiments on 34 data sets obtained from 10 open source projects. Major conclusions from our experiments include: (1) in the best cases, training data from other projects can provide better prediction results than training data from the same project; (2) the prediction results obtained using training data from other projects meet our criteria for acceptance on the average level, defects in 18 out of 34 cases were predicted at a Recall greater than 70\% and a Precision greater than 50\%; (3) results of cross-project defect predictions are related with the distributional characteristics of data sets which are valuable for training data selection. We further propose an approach to automatically select suitable training data for projects without historical data. Prediction results provided by the training data selected by using our approach are comparable with those provided by training data from the same project.},
author = {He, Zhimin and Shu, Fengdi and Yang, Ye and Li, Mingshu and Wang, Qing},
doi = {10.1007/s10515-011-0090-3},
file = {:Users/timm/svns/doc/transfer/12he.pdf:pdf},
isbn = {1051501100903},
issn = {09288910},
journal = {Automated Software Engineering},
keywords = {Cross-project,Data characteristics,Defect prediction,Machine learning,Training data},
number = {2},
pages = {167--199},
title = {{An investigation on the feasibility of cross-project defect prediction}},
volume = {19},
year = {2012}
}
@misc{briand06,
author = {Briand, Lionel},
title = {{Keynote address, PROMISE'06}},
year = {2006}
}
@inproceedings{menzies12,
abstract = {Gaming companies now routinely apply data mining to their user data in order to plan the next release of their software. We predict that such software development analytics will become commonplace, in the near future. For example, as large software systems migrate to the cloud, they are divided and sold as dozens of smaller apps; when shopping inside the cloud, users are free to mix and match their apps from multiple vendors (e.g. Google Docs' word processor with Zoho's slide manager); to extend, or even retain, market share cloud vendors must mine their user data in order to understand what features best attract their clients. This panel will address the open issues with analytics. Issues addressed will include the following. What is the potential for software development analytics? What are the strengths and weaknesses of the current generation of analytics tools? How best can we mature those tools?},
author = {Menzies, Tim and Zimmermann, Thomas},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2012.6227117},
isbn = {9781467310673},
issn = {02705257},
keywords = {analytics,empirical software engineering,industry,mining software repositories},
pages = {1032--1033},
title = {{Goldfish bowl panel: Software development analytics}},
year = {2012}
}
@article{Maldonado2006a,
abstract = {This review is dedicated to a survey on molecular similarity and diversity. Key findings reported in recent investigations are selectively highlighted and summarized. Even if this overview is mainly centered in chemoinformatics, applications in other areas (pharmaceutical and medical chemistry, combinatorial chemistry, chemical databases management, etc.) are also introduced. The approaches used to define and describe the concepts of molecular similarity and diversity in the context of chemoinformatics are discussed in the first part of this review. We introduce, in the second and third parts, the descriptions and analyses of different methods and techniques. Finally, current applications and problems are enumerated and discussed in the last part.},
author = {Maldonado, Ana G. and Doucet, J. P. and Petitjean, Michel and Fan, Bo T.},
doi = {10.1007/s11030-006-8697-1},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Maldonado2004.pdf:pdf},
isbn = {1381-1991},
issn = {13811991},
journal = {Molecular Diversity},
keywords = {Chemoinformatics,Classification methods,Clustering methods,Combinatorial chemistry,Compound selection,Descriptors,Drug design,High throughput screening,Library design,Molecular diversity,Molecular similarity,Partitioning,Selection methods},
number = {1},
pages = {39--79},
pmid = {16404528},
title = {{Molecular similarity and diversity in chemoinformatics: From theory to applications}},
volume = {10},
year = {2006}
}
@article{boehm00m,
abstract = {Not Available},
author = {Boehm, Barry and Basili, Victor R.},
doi = {10.1109/MC.2000.841781},
isbn = {0018-9162 VO - 33},
issn = {00189162},
journal = {Computer},
month = may,
number = {5},
pages = {27--33},
title = {{Gaining intellectual control of software development}},
volume = {33},
year = {2000}
}
@book{schank77,
abstract = {Published in 1977, Scripts, Plans, Goals and Understanding is a valuable contribution to the field of Cognitive Psychology.},
author = {Welin, Carl Wilhelm},
booktitle = {Journal of Pragmatics},
doi = {10.1016/0378-2166(79)90031-6},
isbn = {978-0898591385},
issn = {03782166},
number = {2},
pages = {211--217},
pmid = {3929},
publisher = {Psychology Press},
title = {{Scripts, plans, goals and understanding, an inquiry into human knowledge structures}},
volume = {3},
year = {1979}
}
@article{Han2000a,
abstract = {Mining frequent patterns in transaction databases? time? series databases? and man y other kinds of databases has been studied popularly in data mining researc h? Most of the previous studies adopt an Ap rio ri ?lik e candidate set generation?and?test approac h? Ho ev w er? candidate set generation is still costly ? especially when there exist proli?c patterns and?or long patterns? In this study ?w e propose a no el frequent pattern v tree ?FP?tree ? structure? whic h is an extended pre?x? tree structure for storing compressed? crucial information about frequen t patterns? and dev elop an e?cien t FP?tree? based mining method? FP?gro wth? for mining the c omplete set of fr quent p e atterns b y pattern fragmen t gro wth? E?ciency of mining is ac hiev ed with three tec hniques? ??? a large database is compressed in to a highly condensed? m h smaller data structure? whic uc ha oids costly v ? repeated database scans? ??? our FP?tree ?based mining adopts a pattern fragmen t gro wth method to a oid the costly v generation of a large n um ber of candidate sets? and ??? a partitioning?based? divide?and?conquer method is used to decompose the mining task in to a set of smaller tasks for mining con?ned patterns in conditional databases? whic h dramatically reduces the searc h space? Our performance study sho ws that the FP?gro wth method is e?cien t and scalable for mining both long and short frequen t patterns? and is about an order of magnitude faster than the Ap rio ri algorithm and also faster than some recen tly reported new frequen t pattern mining methods?},
author = {Han, Jiawei and Pei, Jian and Yin, Yiwen},
doi = {10.1145/335191.335372},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/han04.pdf:pdf},
isbn = {1581132182},
issn = {01635808},
journal = {ACM SIGMOD Record},
keywords = {algorithm,and it was supported,association mining,at simon fraser university,canada,data structure,frequent pattern mining,in part by the,natural sciences,performance improvements,the work was done},
number = {2},
pages = {1--12},
pmid = {24075448},
title = {{Mining frequent patterns without candidate generation}},
volume = {29},
year = {2000}
}
@inproceedings{CHEN2005,
address = {New York, NY, USA},
author = {Chen, Zhihao and Menzies, Tim and Port, Dan and Boehm, Barry},
booktitle = {ACM SIGSOFT Software Engineering Notes},
doi = {10.1145/1082983.1083171},
isbn = {-159593-125-2},
issn = {01635948},
number = {4},
pages = {1},
publisher = {ACM},
title = {{Feature subset selection can improve software cost estimation accuracy}},
volume = {30},
year = {2005}
}
@misc{me02j,
author = {T.Menzies},
institution = {Department of Computer Science and Electrical Engineering, West Virginia University},
title = {{V and V of adaptive systems}},
year = {2002}
}
@inproceedings{me88,
annote = {Adelaide, Australia},
author = {Menzies, T J and Dean, M and Black, J and Fleming, J},
booktitle = {Ai '88},
title = {{Combining Heuristics with Simulation Models: An Expert System for the Optimal Management of Pig}},
year = {1988}
}
@inproceedings{me11b,
abstract = {Background: Building effort estimators requires the training data. How can we find that data? It is tempting to cross the boundaries of development type, location, language, application and hardware to use existing datasets of other organizations. However, prior results caution that using such cross data may not be useful. Aim: We test two conjectures: (1) instance selection can automatically prune irrelevant instances and (2) retrieval from the remaining examples is useful for effort estimation, regardless of their source. Method: We selected 8 cross-within divisions (21 pairs of within-cross subsets) out of 19 datasets and evaluated these divisions under different analogy-based estimation (ABE) methods. Results: Between the within \&\#x0026; cross experiments, there were few statistically significant differences in (i) the performance of effort estimators, or (ii) the amount of instances retrieved for estimation. Conclusion: For the purposes of effort estimation, there is little practical difference between cross and within data. After applying instance selection, the remaining examples (be they from within or from cross source divisions) can be used for effort estimation.},
author = {Kocaguneli, Ekrem and Menzies, Tim},
booktitle = {2011 International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1109/ESEM.2011.34},
isbn = {978-0-7695-4604-9},
issn = {1938-6451},
keywords = {cross resource,k-NN,software cost estimation,within resource},
pages = {255--264},
title = {{How to Find Relevant Data for Effort Estimation?}},
year = {2011}
}
@misc{me99i,
annote = {NASA IVV Facility Technical Report},
author = {Menzies, T and Houle, M E and Powell, J},
title = {{RAPTURE/SP2: Efficient Testing of Temporal Properties Without Search Space Explosion}},
year = {1999}
}
@inproceedings{me93k,
author = {Menzies, T J},
booktitle = {DX-93: The International Workshop on Principles on Model-Based Diagnosis},
title = {{The Complexity of Model Review}},
year = {1993}
}
@article{Uiterta,
author = {Uitert, Miranda Van and Meuleman, Wouter and Wessels, Lodewyk},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/BicBin\_code/BicBinStringResults.pdf:pdf},
pages = {1--14},
title = {{Additional STRING results for BicBin}}
}
@inproceedings{jiang08,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08compare.pdf\}},
author = {Jiang, Y and Cukic, B and Menzies, T and Bartlow, N},
booktitle = { 4th International Workshop on Predictor Models in Software Engineering, PROMISE 2008},
isbn = {978-1-60558-036-4},
keywords = {Software Quality Measurement},
pages = {11--18},
title = {{Comparing Design and Code Metrics for Software Quality Prediction}},
year = {2008}
}
@inproceedings{veerappa11,
abstract = {Multi-objective decisions problems are ubiquitous in requirements engineering. A common approach to solve them is to apply search-based techniques to generate a set of non-dominated solutions, formally known as the Pareto front, that characterizes all solutions for which no other solution performs better on all objectives simultaneously. Analysing the shape of the Pareto front helps decision makers understand the solution space and possible tradeoffs among the conflicting objectives. Interpreting the optimal solutions, however, remains a significant challenge. It is in particular difficult to identify whether solutions that have similar levels of goals attainment correspond to minor variants within a same design or to very different designs involving completely different sets of decisions. Our goal is to help decision makers identify groups of strongly related solutions in a Pareto front so that they can understand more easily the range of design choices, identify areas where strongly different solutions achieve similar levels of objectives, and decide first between major groups of solutions before deciding for a particular variant within the chosen group. The benefits of the approach are illustrated on a small example and validated on a larger independently-produced example representative of industrial problems.},
address = {Washington, DC, USA},
author = {Veerappa, Varsha and Letier, Emmanuel},
booktitle = {Proceedings of the 2011 IEEE 19th International Requirements Engineering Conference, RE 2011},
doi = {10.1109/RE.2011.6051654},
file = {:Users/timm/svns/doc/11veerappa\_clustering.pdf:pdf},
isbn = {9781457709234},
issn = {1090-705X},
keywords = {Cost-value based requirements selection,hierarchical clustering,multi-objective decision making,search-based software engineering},
pages = {89--98},
publisher = {IEEE Computer Society},
series = {RE '11},
title = {{Understanding clusters of optimal solutions in multi-objective decision problems}},
url = {http://dx.doi.org/10.1109/RE.2011.6051654},
year = {2011}
}
@inproceedings{me02l,
abstract = { There are many machine learning algorithms currently available. In the 21st century, the problem no longer lies in writing the learner but in choosing which learners to run on a given data set. We argue that the final choice of learners should not be exclusive; in fact, there are distinct advantages in running data sets through multiple learners. To illustrate our point, we perform a case study on a reuse data set using three different styles of learners: association rule, decision tree induction, and treatment. Software reuse is a topic of avid debate in the professional and academic arena; it has proven that it can be both a blessing and a curse. Although there is much debate over where and when reuse should be instituted into a project, our learners found some procedures which should significantly improve the odds of a reuse program succeeding.},
author = {Stefano, J.S. Di and Menzies, T.},
booktitle = {14th IEEE International Conference on Tools with Artificial Intelligence, 2002. (ICTAI 2002). Proceedings.},
doi = {10.1109/TAI.2002.1180811},
isbn = {0-7695-1849-4},
issn = {1082-3409},
title = {{Machine learning for software engineering: case studies in software reuse}},
year = {2002}
}
@inproceedings{zannier06,
author = {Zannier, Carmen and Zannier, Carmen and Melnik, Grigori and Melnik, Grigori and Maurer, Frank and Maurer, Frank},
booktitle = {ICSE'06},
doi = {10.1145/1134285.1134333},
isbn = {1595933751},
pages = {341--350},
title = {{On the success of empirical studies in the international conference on software engineering}},
url = {http://portal.acm.org/citation.cfm?id=1134285.1134333},
year = {2006}
}
@inproceedings{me07f,
abstract = {Adoption of advanced automated SE (ASE) tools would be favored if a business case could be made that these tools are more valuable than alternate methods. In theory, software prediction models can be used to make that case. In practice, this is complicated by the "local tuning" problem. Normally, predictors for software effort and defects and threat use local data to tune their predictions. Such local tuning data is often unavailable. This paper shows that assessing the relative merits of different SE methods need not require precise local tunings. STAR1 is a simulated annealer plus a Bayesian post-processor that explores the space of possible local tunings within software prediction models. STAR1 ranks project decisions by their effects on effort and defects and threats. In experiments with two NASA systems, STAR1 found that ASE tools were necessary to minimize effort/ defect/ threats.},
address = {New York, NY, USA},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07casease-v0.pdf\}},
author = {Menzies, Tim and Feather, Martin S and Madachy, Ray and Boehm, Barry W.},
booktitle = {Proc. ASE},
doi = {http://doi.acm.org/10.1145/1321631.1321676},
isbn = {978-1-59593-882-4},
pages = {303--312},
publisher = {ACM},
title = {{The Business Case for Automated Software Engineering}},
url = {http://portal.acm.org/citation.cfm?id=1321631.1321676},
year = {2007}
}
@article{chandola09,
author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
journal = {ACM Comput. Surv.},
month = jul,
number = {3},
pages = {15:1----15:58},
title = {{Anomaly detection: A survey}},
volume = {41},
year = {2009}
}
@book{Madachy2008a,
abstract = {This book is designed for professionals and students in software engineering or information technology who are interested in understanding the dynamics of software development in order to assess and optimize their own process strategies. It explains how simulation of interrelated technical and social factors can provide a means for organizations to vastly improve their processes. It is structured for readers to approach the subject from different perspectives, and includes descriptive summaries of the best research and applications.},
author = {Madachy, Raymond J.},
doi = {10.1002/9780470192719},
file = {:Users/timm/svns/doc/optimalML/madachyBook.pdf:pdf},
isbn = {9780470192719},
pages = {30},
title = {{Software Process Dynamics}},
url = {http://doi.wiley.com/10.1002/9780470192719},
year = {2008}
}
@article{Kirsopp2003,
author = {Kirsopp, Colin and Shepperd, Martin},
journal = {Research and Development in Intelligent Systems XIX},
pages = {61--74},
publisher = {Springer-Verlag New York Inc},
title = {{Case and feature subset selection in case-based software project effort prediction}},
year = {2003}
}
@misc{purify,
author = {$\backslash$urlhttp://www.pureatria.com/products, Pure Atria},
title = {{Purify}}
}
@article{me11o,
abstract = {Learning predictors for student retention is very difficult. After reviewing the literature, it is evident that there is considerable room for improvement in the current state of the art. As shown in this paper, improvements are possible if we (a) explore a wide range of learning methods; (b) take care when selecting attributes; (c) assess the efficacy of the learned theory not just by its median performance, but also by the variance in that performance; (d) study the delta of student factors between those who stay and those who are retained. Using these techniques, for the goal of predicting if students will remain for the first three years of an undergraduate degree, the following factors were found to be informative: family background and family's social-economic status, high school GPA and test scores. (C) 2011 Elsevier Ltd. All rights reserved.},
author = {Nandeshwar, a and Menzies, T and Nelson, a},
doi = {10.1016/j.eswa.2011.05.048},
isbn = {0957-4174},
journal = {Expert Systems with Applications},
keywords = {Data mining,Financial aid,Predictive modeling,Student retention,attrition,dropout,higher education,model},
number = {12},
pages = {14984--14996},
title = {{Learning patterns of university student retention}},
url = {<Go to ISI>://WOS:000295193400066},
volume = {38},
year = {2011}
}
@misc{me95l,
author = {Menzies, Tim},
booktitle = {TR95-40, Software Development, Monash University},
institution = {Department of Software Development, Monash University},
number = {TR95-35},
title = {{Frameworks for assessing visual languages}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.1555\&rep=rep1\&type=pdf},
year = {1995}
}
@inproceedings{me94z,
annote = {$\backslash$url\{http://menzies.us/pdf/banff94.pdf\}},
author = {Menzies, T J and Compton, P},
booktitle = {Proceedings of the 8th AAAI-Sponsored Banff Knowledge Acquisition for Knowledge-Based Systems Workshop, Banff, Canada},
title = {{Knowledge Acquisition for Performance Systems; or: When can "tests" replace "tasks"?}},
year = {1994}
}
@inproceedings{menz91,
author = {Menzies, T J},
booktitle = {Tools Pacific 4},
editor = {Meyer, B},
title = {{\{ISA\} \{O\}bject \{PARTOF\} \{K\}nowledge \{R\}epresentation (Part Two)?}},
year = {1991}
}
@inproceedings{kocharm13,
abstract = {We offer a case study illustrating three rules for reporting$\backslash$nresearch to industrial practitioners. Firstly, report ârelevantâ$\backslash$nresults; e.g. this paper explores the effects of distributed development$\backslash$non software products. Second: ârecheckâ old results if new results call$\backslash$nthem into question. Many papers say distributed development can be$\backslash$nharmful to software quality. Previous work by Bird et al. allayed that$\backslash$nconcern but a recent paper by Posnett et al. suggests that the Bird$\backslash$nresult was biased by the kinds of files it explored. Hence, this paper$\backslash$nrechecks that result and finds significant differences in Microsoft$\backslash$nproducts (Office 2010) between software built by distributed or$\backslash$ncollocated teams. At first glance, this recheck calls into question the$\backslash$nwidespread practice of distributed development. Our third rule is to$\backslash$nâreflectâ on results to avoid confusing practitioners with an arcane$\backslash$nmathematical analysis. For example, on reflection, we found that the$\backslash$neffect size of the differences seen in the collocated and distributed$\backslash$nsoftware was so small that it need not concern industrial practitioners.$\backslash$nOur conclusion is that at least for Microsoft products, distributed$\backslash$ndevelopment is not considered harmful.},
author = {Kocaguneli, Ekrem and Zimmermann, Thomas and Bird, Christian and Nagappan, Nachiappan and Menzies, Tim},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2013.6606637},
file = {:Users/timm/svns/doc/13distributed.pdf:pdf},
isbn = {9781467330763},
issn = {02705257},
pages = {882--890},
title = {{Distributed development considered harmful?}},
year = {2013}
}
@article{sen12,
abstract = {Even though data warehousing (DW) requires huge investments, the data warehouse market is experiencing incredible growth. However, a large number of DW initiatives end up as failures. In this paper, we argue that the maturity of a data warehousing process (DWP) could significantly mitigate such large-scale failures and ensure the delivery of consistent, high quality, âsingle-version of truthâ data in a timely manner. However, unlike software development, the assessment of DWP maturity has not yet been tackled in a systematic way. In light of the critical importance of data as a corporate resource, we believe that the need for a maturity model for DWP could not be greater. In this paper, we describe the design and development of a five-level DWP maturity model (DWP-M) over a period of three years. A unique aspect of this model is that it covers processes in both data warehouse development and operations. Over 20 key DW executives from 13 different corporations were involved in the model development process. The final model was evaluated by a panel of experts; the results strongly validate the functionality, productivity, and usability of the model. We present the initial and final DWP-M model versions, along with illustrations of several key process areas at different levels of maturity.},
author = {Sen, a. and Ramamurthy, K. and Sinha, a. P.},
doi = {10.1109/TSE.2011.2},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
number = {2},
pages = {336--353},
title = {{A Model of Data Warehousing Process Maturity}},
volume = {38},
year = {2012}
}
@article{Moreno-MontesdeOca2014a,
abstract = {Context: Business process modeling is an essential part of understanding and redesigning the activities that a typical enterprise uses to achieve its business goals. The quality of a business process model has a significant impact on the development of any enterprise and IT support for that process. Objective: Since the insights on what constitutes modeling quality are constantly evolving, it is unclear whether research on business process modeling quality already covers all major aspects of modeling quality. Therefore, the objective of this research is to determine the state of the art on business process modeling quality: What aspects of process modeling quality have been addressed until now and which gaps remain to be covered? Method: We performed a systematic literature review of peer reviewed articles as published between 2000 and August 2013 on business process modeling quality. To analyze the contributions of the papers we use the Formal Concept Analysis technique. Results: We found 72 studies addressing quality aspects of business process models. These studies were classified into different dimensions: addressed model quality type, research goal, research method, and type of research result. Our findings suggest that there is no generally accepted framework of model quality types. Most research focuses on empirical and pragmatic quality aspects, specifically with respect to improving the understandability or readability of models. Among the various research methods, experimentation is the most popular one. The results from published research most often take the form of intangible knowledge. Conclusion: We believe there is a lack of an encompassing and generally accepted definition of business process modeling quality. This evidences the need for the development of a broader quality framework capable of dealing with the different aspects of business process modeling quality. Different dimensions of business process quality and of the process of modeling still require further research. Â© 2014 Elsevier B.V. All rights reserved.},
author = {{Moreno-Montes de Oca}, Isel and Snoeck, Monique and Reijers, Hajo a. and Rodr\'{\i}guez-Morffi, Abel},
doi = {10.1016/j.infsof.2014.07.011},
file = {:Users/timm/svns/doc/sbse/15businessModels.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Business process modeling,Modeling quality,Systematic literature review},
pages = {187--205},
publisher = {Elsevier B.V.},
title = {{A systematic literature review of studies on business process modeling quality}},
url = {http://dx.doi.org/10.1016/j.infsof.2014.07.011},
volume = {58},
year = {2014}
}
@article{me08e,
author = {Menzies, Tim and Milton, Z and Bener, a and Cukic, Bojan and Gay, G and Jiang, Y and Turhan, B},
journal = {Submitted to IEEE TSE},
title = {{Overcoming Ceiling Effects in Defect Prediction}},
year = {2008}
}
@incollection{argy08,
abstract = {Learning the common structure shared by a set of supervised tasks is an important
practical and theoretical problem. Knowledge of this structure may lead to better
generalization performance on the tasks and may also facilitate learning new
tasks. We propose a framework for solving this problem, which is based on regularization
with spectral functions of matrices. This class of regularization problems
exhibits appealing computational properties and can be optimized efciently
by an alternating minimization algorithm. In addition, we provide a necessary
and sufcient condition for convexity of the regularizer. We analyze concrete examples
of the framework, which are equivalent to regularization with Lp matrix
norms. Experiments on two real data sets indicate that the algorithm scales well
with the number of tasks and improves on state of the art statistical performance.},
author = {Argyriou, Andreas and Micchelli, Charles and Pontil, Massimiliano and Ying, Yiming},
booktitle = {Conf. Neural Information Processing Systems},
file = {:Users/timm/svns/doc/04BlankertzTransfer.pdf:pdf},
isbn = {160560352X},
keywords = {Learning/Statistics \& Optimisation,Theory \& Algorithms},
pages = {25--32},
title = {{A Spectral Regularization Framework for Multi-Task Structure Learning}},
url = {http://eprints.pascal-network.org/archive/00003779/},
year = {2008}
}
@article{Chen2008c,
abstract = {Clustering high dimensional data has become a challenge in data mining due to the curse of dimensionality. To solve this problem, subspace clustering has been defined as an extension of traditional clustering that seeks to find clusters in subspaces spanned by different combinations of dimensions within a dataset. This paper presents a new subspace clustering algorithm that calculates the local feature weights automatically in an EM-based clustering process. In the algorithm, the features are locally weighted by using a new unsupervised weighting method, as a means to minimize a proposed clustering criterion that takes into account both the average intra-clusters compactness and the average inter-clusters separation for subspace clustering. For the purposes of capturing accurate subspace information, an additional outlier detection process is presented to identify the possible local outliers of subspace clusters, and is embedded between the E-step and M-step of the algorithm. The method has been evaluated in clustering real-world gene expression data and high dimensional artificial data with outliers, and the experimental results have shown its effectiveness.},
author = {Chen, Lifei and Jiang, Qingshan},
doi = {10.1007/s11704-008-0007-x},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/chen08.pdf:pdf},
issn = {16737350},
journal = {Frontiers of Computer Science in China},
keywords = {Clustering criterion,EM algorithm,High dimensional clustering,Outlier detection,Subspace clustering},
number = {1},
pages = {81--86},
title = {{An extended EM algorithm for subspace clustering}},
volume = {2},
year = {2008}
}
@inproceedings{peters12,
abstract = {Ideally, we can learn lessons from software projects across$\backslash$nmultiple organizations. However, a major impediment to such knowledge$\backslash$nsharing are the privacy concerns of software development organizations.$\backslash$nThis paper aims to provide defect data-set owners with an effective$\backslash$nmeans of privatizing their data prior to release. We explore MORPH which$\backslash$nunderstands how to maintain class boundaries in a data-set. MORPH is a$\backslash$ndata mutator that moves the data a random distance, taking care not to$\backslash$ncross class boundaries. The value of training on this MORPHed data is$\backslash$ntested via a 10-way within learning study and a cross learning study$\backslash$nusing Random Forests, Naive Bayes, and Logistic Regression for ten$\backslash$nobject-oriented defect datasets from the PROMISE data repository.$\backslash$nMeasured in terms of exposure of sensitive attributes, the MORPHed data$\backslash$nwas four times more private than the unMORPHed data. Also, in terms of$\backslash$nthe f-measures, there was little difference between the MORPHed and$\backslash$nunMORPHed data (original data and data privatized by data-swapping) for$\backslash$nboth the cross and within study. We conclude that at least for the kinds$\backslash$nof OO defect data studied in this project, data can be privatized$\backslash$nwithout concerns for inference efficacy.},
annote = {$\backslash$url\{http://menzies.us/pdf/12privacy.pdf\}},
author = {Peters, Fayola and Menzies, Tim},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2012.6227194},
isbn = {9781467310673},
issn = {02705257},
keywords = {data mining,defect prediction,privacy},
pages = {189--199},
title = {{Privacy and utility for defect prediction: Experiments with MORPH}},
year = {2012}
}
@misc{briand11,
author = {Briand, L},
title = {{Personnel communication}},
year = {2011}
}
@article{yann00,
abstract = {In this study we present a review of the emerging field of meta-knowledge components as practised over the past decade among a variety of practitioners. We use the artificially-defined term `meta-knowledge' to encompass all those different but overlapping notions used by the Artificial Intelligence and Software Engineering communities to represent reusable modelling frameworks: ontologies, problem-solving methods, experience factories and experience bases, patterns, to name a few. We then elaborate on how meta-knowledge is deployed in the context of system's design to improve its reliability by consistency checking, enhance its reuse potential, and manage its knowledge sharing. We speculate on its usefulness and explore technologies for supporting deployment of meta-knowledge. We argue that, despite the different approaches being followed in systems design by divergent communities, meta-knowledge is present in all cases, in a tacit or explicit form, and its utilisation depends on pragmatic aspects which we try to identify and critically review on criteria of effectiveness.},
author = {Kalfoglou, Yannis and Menzies, Tim and Althoff, Klaus-Dieter and Motta, Enrico},
doi = {10.1017/S0269888900004033},
issn = {0269-8889},
journal = {The Knowledge Engineering Review},
month = dec,
number = {4},
title = {{Meta-Knowledge in systems design: panacea ...or undelivered promise?}},
url = {http://eprints.soton.ac.uk/260533/},
volume = {15},
year = {2000}
}
@inproceedings{keogh05,
abstract = { In this work, we introduce the new problem of finding time series discords. Time series discords are subsequences of a longer time series that are maximally different to all the rest of the time series subsequences. They thus capture the sense of the most unusual subsequence within a time series. Time series discords have many uses for data mining, including improving the quality of clustering, data cleaning, summarization, and anomaly detection. Discords are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length of the subsequence) unlike most anomaly detection algorithms that typically require many parameters. We evaluate our work with a comprehensive set of experiments. In particular, we demonstrate the utility of discords with objective experiments on domains as diverse as Space Shuttle telemetry monitoring, medicine, surveillance, and industry, and we demonstrate the effectiveness of our discord discovery algorithm with more than one million experiments, on 82 different datasets from diverse domains.},
address = {Washington, DC, USA},
author = {Keogh, Eamonn and Lin, Jessica and Fu, Ada},
booktitle = {Proceedings - IEEE International Conference on Data Mining, ICDM},
doi = {10.1109/ICDM.2005.79},
isbn = {0769522785},
issn = {15504786},
keywords = {Anomaly detection,Clustering,Time series data mining},
pages = {226--233},
publisher = {IEEE Computer Society},
series = {ICDM '05},
title = {{HOT SAX: Efficiently finding the most unusual time series subsequence}},
url = {http://dx.doi.org/10.1109/ICDM.2005.79},
year = {2005}
}
@article{ostr05,
author = {Ostrouchov, George and Samatova, Nagiza F},
issn = {0162-8828},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
month = aug,
number = {8},
pages = {1340--1343},
title = {{[2005][8] On FastMap and the convex hull of multivariate data toward fast and robust dimension reduction.pdf}},
volume = {27},
year = {2005}
}
@article{blei03,
author = {Blei, D M and Ng, a Y and Jordan, M I},
issn = {1532-4435},
journal = {Jmlr},
month = mar,
pages = {993--1022},
title = {{Latent \{Dirichlet\} Allocation}},
volume = {3},
year = {2003}
}
@inproceedings{holmes10,
abstract = {The goal of this one-day workshop is to bring together researchers and practitioners with interest and experience in the theory, elaboration, and evaluation of concepts, techniques, and tools for providing recommendations to developers, managers, and other stakeholders involved in software engineering tasks.},
author = {Holmes, Reid and Robillard, Martin P. and Walker, Robert J. and Zimmermann, Thomas},
booktitle = {2010 ACM/IEEE 32nd International Conference on Software Engineering},
doi = {10.1145/1810295.1810426},
isbn = {978-1-60558-719-6},
issn = {0270-5257},
keywords = {data mining,development tasks,feedback,inference,infrastructure,recommendation systems for software engineering,usability},
pages = {455--456},
publisher = {ACM},
series = {ICSE '10},
title = {{RSSE 2010: Second International Workshop on Recommendation Systems for Software Engineering}},
volume = {2},
year = {2010}
}
@article{krall14,
author = {Krall, J and Menzies, T},
file = {:Users/timm/svns/doc/optimalML/galeTse.pdf:pdf},
journal = {IEEE Transactions on Software Engineering (submitted)},
title = {{GALE: Geometric Active Learning for Search-based Software Engineering}},
year = {2014}
}
@incollection{fea03a,
abstract = { We present an approach to matching software practitioners' needs to software researchers' activities. It uses an accepted taxonomical software classification scheme as intermediary, in terms of which practitioners express needs, and researchers express activities. A decision support tool is used to combine these expressions of needs/activities, and to assist in studying the implications of that combined knowledge. This enables identification of fruitful connections between researchers and practitioners, of areas of common interest among researchers, and practitioners, and of "gaps": areas of unfulfilled needs or unmotivated research. We discuss the software engineering underpinning this approach, illustrating its utility by reporting on experiments with a real-world dataset gathered from researchers and practitioners. We also suggest that this same approach would be applicable to understanding the distribution of interests represented by presenters and attendees of a conference such as APSEC.},
author = {Feather, M.S. and Menzies, T. and Connelly, J.R.},
booktitle = {Tenth Asia-Pacific Software Engineering Conference, 2003.},
doi = {10.1109/APSEC.2003.1254353},
isbn = {0-7695-2011-1},
month = dec,
title = {{Matching software practitioner needs to researcher activities}},
year = {2003}
}
@article{me99j,
author = {Menzies, Tim},
doi = {10.1006/ijhc.1999.0329},
issn = {10715819},
journal = {International journal of human-computer studies},
month = oct,
number = {4},
pages = {783--799},
title = {{Critical success metrics: evaluation at the business level}},
url = {http://www.sciencedirect.com/science/article/pii/S1071581999903294},
volume = {51},
year = {1999}
}
@inproceedings{me03i,
author = {Comford, Steven L. and Feather, Martin S. and Dunphy, Julia R. and Salcedo, Jose and Menzies, Tim},
booktitle = {IEEE Aerospace Conference Proceedings},
doi = {10.1109/AERO.2003.1235551},
isbn = {078037651X},
issn = {1095323X},
pages = {3681--3690},
title = {{Optimizing spacecraft design optimization engine development: Progress and plans}},
volume = {8},
year = {2003}
}
@article{Cui2005a,
abstract = { Fast and high-quality document clustering algorithms play an important role in effectively navigating, summarizing, and organizing information. Recent studies have shown that partitional clustering algorithms are more suitable for clustering large datasets. However, the K-means algorithm, the most commonly used partitional clustering algorithm, can only generate a local optimal solution. In this paper, we present a particle swarm optimization (PSO) document clustering algorithm. Contrary to the localized searching of the K-means algorithm, the PSO clustering algorithm performs a globalized search in the entire solution space. In the experiments we conducted, we applied the PSO, K-means and hybrid PSO clustering algorithm on four different text document datasets. The number of documents in the datasets ranges from 204 to over 800, and the number of terms ranges from over 5000 to over 7000. The results illustrate that the hybrid PSO algorithm can generate more compact clustering results than the K-means algorithm.},
author = {Cui, X. and Potok, T.E. and Palathingal, P.},
doi = {10.1109/SIS.2005.1501621},
file = {:Users/timm/svns/doc/pso/05clusterPSO.pdf:pdf},
isbn = {0-7803-8916-6},
journal = {Proceedings 2005 IEEE Swarm Intelligence Symposium, 2005. SIS 2005.},
title = {{Document clustering using particle swarm optimization}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1501621},
year = {2005}
}
@inproceedings{me00e,
abstract = {When a lack of data inhibits decision-making, large-scale what-if
queries can be conducted over the uncertain parameter ranges. Such
queries can generate an overwhelming amount of data. We describe a
general method for understanding that data. Large-scale what-if queries
can guide Monte Carlo simulations of a model. Machine learning can then
be used to summarize the output. The summarization is an ensemble of
decision trees. The TARZAN system [so-called because it swings through
(or searches) the decision trees] can poll the ensemble looking for
majority conclusions regarding what factors change the classifications
of the data. TARZAN can succinctly present the results from very large
what-if queries. For example, in one of the studies presented, we can
view the significant features from 10<sup>9</sup> what-if queries on
half a page},
author = {Menzies, T. and Sinsel, E.},
booktitle = {Proceedings ASE 2000. Fifteenth IEEE International Conference on Automated Software Engineering},
doi = {10.1109/ASE.2000.873661},
isbn = {0-7695-0710-7},
issn = {1527-1366},
title = {{Practical large scale what-if queries: case studies with software
risk assessment}},
year = {2000}
}
@article{deerwester90,
abstract = {A new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents ("semantic structure") in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. Initial tests find this completely automatic method for retrieval to be promising.},
archivePrefix = {arXiv},
arxivId = {arXiv:1403.2923v1},
author = {Deerwester, S and Dumais, S T and Furnas, G W and Landauer, T K and Harshman, R},
doi = {10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9},
eprint = {arXiv:1403.2923v1},
isbn = {9781450300322},
issn = {00028231},
journal = {Journal of the American Society for Information Science},
number = {6},
pages = {391--407},
pmid = {470195},
title = {{Indexing by Latent Semantic Analysis}},
volume = {41},
year = {1990}
}
@article{me06a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06qrre.pdf\}},
author = {Menzies, T and Richardson, J},
journal = {IEEE Computer},
month = oct,
title = {{Making Sense of Requirements, Sooner}},
year = {2006}
}
@article{Campos-nanez2012a,
author = {Campos-n\'{a}\~{n}ez, Enrique},
file = {:Users/timm/svns/doc/optimalML/introSystemDynamics.pdf:pdf},
title = {{Introduction to System Dynamics Causal-loop Diagrams}},
year = {2012}
}
@inproceedings{me08h,
abstract = {Prediction of fault prone software components is one of the most researched$\backslash$nproblems in software engineering. Many statistical techniques have$\backslash$nbeen proposed but there is no consensus on the methodology to select$\backslash$nthe ``best model" for the specific project. In this paper, we introduce$\backslash$nand discuss the merits of cost curve analysis of fault prediction$\backslash$nmodels. Cost curves allow software quality engineers to introduce$\backslash$nproject-specific cost of module misclassification into model evaluation.$\backslash$nClassifying a software module as fault-prone implies the application$\backslash$nof some verification activities, thus adding to the development cost.$\backslash$nMisclassifying a module as fault free carries the risk of system$\backslash$nfailure, also associated with cost implications. Through the analysis$\backslash$nof sixteen projects from public repositories, we observe that software$\backslash$nquality does not necessarily benefit from the prediction of fault$\backslash$nprone components. The inclusion of misclassification cost in model$\backslash$nevaluation may indicate that even the ``best" models achieve performance$\backslash$nno better than trivial classification. Our results support a recommendation$\backslash$nfavoring the use of cost curves in practice with the hope they will$\backslash$nbecome a standard tool for software quality model performance evaluation.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08costcurves.pdf\}},
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim},
booktitle = {ISSRE'08: Proceedings of the 19th International Symposium on Software Reliability Engineering},
pages = {197--206},
title = {{Costs Curve Evaluation of Fault Prediction Models}},
year = {2008}
}
@misc{clancey96,
annote = {Personal communcaition},
author = {Clancey, W},
title = {{No Title}},
year = {1996}
}
@inproceedings{Haiduc2010a,
abstract = {One of the main challenges faced by today's developers is keeping up with the staggering amount of source code that needs to be read and understood. In order to help developers with this problem and reduce the costs associated with it, one solution is to use simple textual descriptions of source code entities that developers can grasp easily, while capturing the code semantics precisely. We propose an approach to automatically determine such descriptions, based on automated text summarization technology.},
address = {Cape Town, South Africa},
annote = {Laura. Fixed on 10/04/2012},
author = {Haiduc, Sonia and Aponte, Jairo and Marcus, Andrian},
booktitle = {2010 ACM/IEEE 32nd International Conference on Software Engineering},
doi = {10.1145/1810295.1810335},
isbn = {978-1-60558-719-6},
issn = {0270-5257},
keywords = {program comprehension,summary,text summarization},
pages = {223--226},
title = {{Supporting program comprehension with source code summarization}},
volume = {2},
year = {2010}
}
@article{Noman2008a,
author = {Noman, Nasimul and Iba, Hitoshi},
file = {:Users/timm/svns/doc/08-de-localSearch.pdf:pdf},
number = {1},
pages = {107--125},
title = {{Using an Adaptive Local Search}},
volume = {12},
year = {2008}
}
@inproceedings{shi10,
abstract = {Labeled examples are often expensive and time-consuming to obtain. One practically important problem is: can the labeled data from other related sources help predict the target task, even if they have (a) different feature spaces (e.g., image vs. text data), (b) different data distributions, and (c) different output spaces? This paper proposes a solution and discusses the conditions where this is possible and highly likely to produce better results. It works by first using spectral embedding to unify the different feature spaces of the target and source data sets, even when they have completely different feature spaces. The principle is to cast into an optimization objective that preserves the original structure of the data, while at the same time, maximizes the similarity between the two. Second, a judicious sample selection strategy is applied to select only those related source examples. At last, a Bayesian-based approach is applied to model the relationship between different output spaces. The three steps can bridge related heterogeneous sources in order to learn the target task. Among the 12 experiment data sets, for example, the images with wavelet-transformed-based features are used to predict another set of images whose features are constructed from color-histogram space. By using these extracted examples from heterogeneous sources, the models can reduce the error rate by as much as\~{}50$\backslash$\&\#x025;, compared with the methods using only the examples from the target task.},
author = {Shi, Xiaoxiao and Liu, Qi and Fan, Wei and Yu, Philip S. and Zhu, Ruixin},
booktitle = {Proceedings - IEEE International Conference on Data Mining, ICDM},
doi = {10.1109/ICDM.2010.65},
file = {:Users/timm/svns/doc/10ShiTransfer.pdf:pdf},
isbn = {9780769542560},
issn = {15504786},
pages = {1049--1054},
title = {{Transfer learning on heterogenous feature spaces via spectral transformation}},
year = {2010}
}
@book{Burnham2011c,
abstract = {CoffeeScript: Accelerated JavaScript Development offers a thorough introduction to this new language, starting from the basics. Youll learn to use time-saving features like list comprehensions and splats, organize your code into modules with extensible classes, and see how to deploy your work to multiple environments. Each chapter is example-driven and includes challenging exercises to push your CoffeeScript know-how further. Through the course of the book, youll build a fast-paced multiplayer word game writing both the client (with jQuery) and server (with Node.js) in CoffeeScript. And because the two languages are so deeply intertwined, youll deepen your understanding of JavaScript along the way. CoffeeScript makes it easier than ever to write powerful, standards-compliant JavaScript code. This book lets you start doing it today.},
author = {Burnham, Trevor},
booktitle = {Managing},
file = {:Users/timm/svns/doc/coffeescript-landscape.pdf:pdf},
isbn = {9781934356784},
pages = {136},
title = {{CoffeeScript : Accelerated JavaScript Development}},
url = {http://pragprog.com/book/tbcoffee/coffeescript},
year = {2011}
}
@article{Liu2000a,
author = {Liu, Bing and Ma, Yiming and Wong, C.},
doi = {10.1007/3-540-45372-5\_58},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/liu00.pdf:pdf},
journal = {Principles of Data Mining and Knowledge Discovery},
pages = {293--317},
title = {{Improving an association rule based classifier}},
url = {http://www.springerlink.com/index/cdldmeqbbj8qruey.pdf},
year = {2000}
}
@article{Hu2001a,
author = {Hu, Qing and Plant, Robert T and Hertz, David B},
file = {:Users/timm/svns/doc/cost/98Qing.pdf:pdf},
number = {I},
pages = {143--163},
title = {{Software Cost Estimation Using Economic Production Models}},
volume = {1},
year = {2001}
}
@inproceedings{jiang08a,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08transform.pdf\}},
author = {Jiang, Y and Cukic, B and Menzies, T},
booktitle = {Defects 2008},
title = {{Does Transformation Help?}},
year = {2008}
}
@inproceedings{Guo2010,
abstract = {We performed an empirical study to characterize factors that affect which bugs get fixed in Windows Vista and Windows 7, focusing on factors related to bug report edits and relationships between people involved in handling the bug. We found that bugs reported by people with better reputations were more likely to get fixed, as were bugs handled by people on the same team and working in geographical proximity. We reinforce these quantitative results with survey feedback from 358 Microsoft employees who were involved in Windows bugs. Survey respondents also mentioned additional qualitative influences on bug fixing, such as the importance of seniority and interpersonal skills of the bug reporter. Informed by these findings, we built a statistical model to predict the probability that a new bug will be fixed (the first known one, to the best of our knowledge). We trained it on Windows Vista bugs and got a precision of 68\&\#x025; and recall of 64\&\#x025; when predicting Windows 7 bug fixes. Engineers could use such a model to prioritize bugs during triage, to estimate developer workloads, and to decide which bugs should be closed or migrated to future product versions.},
annote = {Social metrics stuff.},
author = {Guo, Philip J. and Zimmermann, Thomas and Nagappan, Nachiappan and Murphy, Brendan},
booktitle = {2010 ACM/IEEE 32nd International Conference on Software Engineering},
doi = {10.1145/1806799.1806871},
file = {:Users/timm/svns/doc/guo10.pdf:pdf},
isbn = {978-1-60558-719-6},
issn = {0270-5257},
pages = {495--504},
title = {{Characterizing and predicting which bugs get fixed: an empirical study of Microsoft Windows}},
url = {http://portal.acm.org/citation.cfm?id=1806871},
volume = {1},
year = {2010}
}
@inproceedings{sayyad13a,
author = {Sayyad, Abdel Salam and Menzies, Tim and Ammar, Hany},
booktitle = {Proceedings of the 2013 International Conference on Software Engineering (ICSE '13)},
doi = {http://dx.doi.org/10.1109/ICSE.2013.6606595},
file = {:Users/timm/svns/doc/13ibea.pdf:pdf},
isbn = {9781467330749},
pages = {492--501},
series = {ICSE '13},
title = {{On the Value of User Preferences in Search-Based Software Engineering: A Case Study in Software Product Lines}},
year = {2013}
}
@inproceedings{me08g,
abstract = {In mission critical systems, such as those developed by NASA, it is very important that the test engineers properly recognize the severity of each issue they identify during testing. Proper severity assessment is essential for appropriate resource allocation and planning for fixing activities and additional testing. Severity assessment is strongly influenced by the experience of the test engineers and by the time they spend on each issue. The paper presents a new and automated method named SEVERIS (severity issue assessment), which assists the test engineer in assigning severity levels to defect reports. SEVERIS is based on standard text mining and machine learning techniques applied to existing sets of defect reports. A case study on using SEVERIS with data from NASApsilas Project and Issue Tracking System (PITS) is presented in the paper. The case study results indicate that SEVERIS is a good predictor for issue severity levels, while it is easy to use and efficient.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08severis.pdf\}},
author = {Menzies, Tim and Marcus, Andrian},
booktitle = {IEEE International Conference on Software Maintenance, ICSM},
doi = {10.1109/ICSM.2008.4658083},
isbn = {9781424426140},
issn = {1063-6773},
pages = {346--355},
title = {{Automated severity assessment of software defect reports}},
year = {2008}
}
@book{Simon1969b,
abstract = {Continuing his exploration of the organization of complexity and the science of design, this new edition of Herbert Simon's classic work on artificial intelligence adds a chapter that sorts out the current themes and toolsâchaos, adaptive systems, genetic algorithmsâfor analyzing complexity and complex systems. There are updates throughout the book as well. These take into account important advances in cognitive psychology and the science of design while confirming and extending the book's basic thesis: that a physical symbol system has the necessary and sufficient means for intelligent action. The chapter "Economic Reality" has also been revised to reflect a change in emphasis in Simon's thinking about the respective roles of organizations and markets in economic systems.},
author = {Simon, Ha},
booktitle = {Computers \& Mathematics with Applications},
doi = {10.1016/S0898-1221(97)82941-0},
file = {:Users/timm/svns/doc/96Herbert Simon - Sciences\_of\_the\_Artificial.pdf:pdf},
isbn = {9780262691918},
issn = {08981221},
number = {5},
pages = {130},
pmid = {4470018},
title = {{The sciences of the artificial, (third edition)}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:The+Sciences+of+the+Artificial\#0},
volume = {33},
year = {1997}
}
@inproceedings{me00m,
author = {Menzies, T J and Debenham, J},
booktitle = {Encyclopedia of Computer Science and Technology},
editor = {Kent, A and Williams, J G},
number = {27},
pages = {35--54},
publisher = {Marcell Dekker Inc.},
title = {{Expert Systems Maintenance}},
volume = {47},
year = {2000}
}
@article{Wang2012a,
abstract = {During the past decade, solving constrained opti- mization problems with evolutionary algorithms has received considerable attention among researchers and practitioners. Cai and Wangâs method (abbreviated as CW method) is a recent constrained optimization evolutionary algorithm proposed by the authors. However, its main shortcoming is that a trial-and- error process has to be used to choose suitable parameters. To overcome the above shortcoming, this paper proposes an improved version of the CW method, called CMODE, which combines multiobjective optimization with differential evolu- tion to deal with constrained optimization problems. Like its predecessor CW, the comparison of individuals in CMODE is also based on multiobjective optimization. In CMODE, however, differential evolution serves as the search engine. In addition, a novel infeasible solution replacement mechanism based on multiobjective optimization is proposed, with the purpose of guiding the population toward promising solutions and the feasible region simultaneously. The performance of CMODE is evaluated on 24 benchmark test functions. It is shown empirically that CMODE is capable of producing highly competitive results compared with some other state-of-the-art approaches in the community of constrained evolutionary optimization},
author = {Wang, Yong and Cai, Zixing},
doi = {10.1109/TEVC.2010.2093582},
file = {:Users/timm/svns/doc/12de.pdf:pdf},
isbn = {1089-778X},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Constrained optimization problems,constraint-handling technique,differential evolution,multiobjective optimization},
number = {1},
pages = {117--134},
title = {{Combining multiobjective optimization with differential evolution to solve constrained optimization problems}},
volume = {16},
year = {2012}
}
@inproceedings{me08f,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ispa.pdf\}},
author = {Hihn, J and Menzies, T and Lum, K and Baker, D and Jalali, O},
booktitle = {ISPA'08: International Society of Parametric Analysis},
title = {{\{2CEE\}, A \{T\}WENTY \{F\}IRST \{C\}ENTURY \{E\}FFORT \{E\}STIMATION \{M\}ETHODOLOGY}},
year = {2008}
}
@book{Webb2002a,
abstract = {Statistical pattern recognition relates to the use of statistical techniques for analysing data measurements in order to extract information and make justified decisions. It is a very active area of study and research, which has seen many advances in recent years. Applications such as data mining, web searching, multimedia data retrieval, face recognition, and cursive handwriting recognition, all require robust and efficient pattern recognition techniques. This third edition provides an introduction to statistical pattern theory and techniques, with material drawn from a wide range of fields, including the areas of engineering, statistics, computer science and the social sciences. The book has been updated to cover new methods and applications, and includes a wide range of techniques such as Bayesian methods, neural networks, support vector machines, feature selection and feature reduction techniques.Technical descriptions and motivations are provided, and the techniques are illustrated using real examples.},
author = {Webb, Andrew and Copsey, Keith},
booktitle = {Books.Google.Com},
doi = {10.1002/0470854774},
file = {:Users/timm/svns/doc/02webb.pdf:pdf},
isbn = {9780470682272},
issn = {0036-1445},
pages = {666},
title = {{Statistical Pattern Recognition}},
url = {http://books.google.com/books?hl=en\&lr=\&id=ivMBWCe\_f0gC\&oi=fnd\&pg=PR7\&dq=Statistical+Pattern+Recognition\&ots=HF4pvbtd4w\&sig=QEehQ-v53issKsZC84gN7noV05M},
volume = {9},
year = {2011}
}
@article{Kralj2009a,
abstract = {This paper gives a survey of contrast set mining (CSM), emerging pattern mining (EPM), and subgroup
discovery (SD) in a unifying framework named supervised descriptive rule discovery. While
all these research areas aim at discovering patterns in the form of rules induced from labeled data,
they use different terminology and task definitions, claim to have different goals, claim to use different
rule learning heuristics, and use different means for selecting subsets of induced patterns.
This paper contributes a novel understanding of these subareas of data mining by presenting a unified
terminology, by explaining the apparent differences between the learning tasks as variants of
a unique supervised descriptive rule discovery task and by exploring the apparent differences between
the approaches. It also shows that various rule learning heuristics used in CSM, EPMand SD
algorithms all aim at optimizing a trade off between rule coverage and precision. The commonalities
(and differences) between the approaches are showcased on a selection of best known variants
of CSM, EPM and SD algorithms. The paper also provides a critical survey of existing supervised
descriptive rule discovery visualization methods.},
author = {Kralj, Petra and Lavrac, Nada and Webb, Geoff},
doi = {10.1145/1577069.1577083},
file = {:Users/timm/svns/doc/kralj-novak09a.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
keywords = {Theory \& Algorithms},
pages = {377--403},
title = {{Supervised Descriptive Rule Discovery: A Unifying Survey of Contrast Set, Emerging Pattern and Subgroup Mining}},
url = {http://eprints.pascal-network.org/archive/00005127/},
volume = {10},
year = {2009}
}
@article{molina05,
author = {Molina, Julian and Laguna, Manuel and Marto, Rafael and Caballero, Rafael and Metaheuristics, Keywords Multiobjective and Optimization, Non-linear Multiobjective},
journal = {INFORMS Journal on Computing},
keywords = {evolutionary multiobjective optimization,multiobjective metaheuristics,non-linear multiobjective optimization},
pages = {1--27},
title = {{SSPMO: A Scatter Tabu Search Procedure for Non- Linear Multiobjective Optimization}},
year = {2005}
}
@article{Jiang2003a,
author = {Jiang, Lei and Yang, Wenhui},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/pi06.pdf:pdf},
number = {02},
pages = {10--12},
title = {{A Modified Fuzzy C-Means Algorithm for}},
year = {2003}
}
@article{Hamerly2010a,
author = {Hamerly, Greg},
file = {:Users/timm/svns/doc/10hameryKmeans.pdf:pdf},
journal = {2010 SIAM international conference on data mining (SDM 2010)},
pages = {130--140},
title = {{Making k -means even faster}},
url = {http://www.siam.org/proceedings/datamining/2010/dm10\_012\_hamerlyg.pdf$\backslash$nhttp://cs.baylor.edu/~hamerly/papers/sdm\_2010.pdf},
year = {2010}
}
@article{Shepperd2000a,
author = {Shepperd, Martin},
file = {:Users/timm/svns/doc/cost/07shepperd.pdf:pdf},
isbn = {0769528295},
keywords = {challenge,cost models,effort prediction,empirical soft-,i believe this is,nonetheless,remains a largely unsolved,software project management,still an important topic,ware engineering},
title = {{Software project economics : a roadmap Software project economics : a roadmap}},
year = {2000}
}
@article{ouni13,
abstract = {Software defects often lead to bugs, runtime errors and software$\backslash$nmaintenance difficulties. They should be systematically prevented,$\backslash$nfound, removed or fixed all along the software lifecycle. However,$\backslash$ndetecting and fixing these defects is still, to some extent, a$\backslash$ndifficult, time-consuming and manual process. In this paper, we propose$\backslash$na two-step automated approach to detect and then to correct various$\backslash$ntypes of maintainability defects in source code. Using Genetic$\backslash$nProgramming, our approach allows automatic generation of rules to detect$\backslash$ndefects, thus relieving the designer from a fastidious manual rule$\backslash$ndefinition task. Then, we correct the detected defects while minimizing$\backslash$nthe correction effort. A correction solution is defined as the$\backslash$ncombination of refactoring operations that should maximize as much as$\backslash$npossible the number of corrected defects with minimal code modification$\backslash$neffort. We use the Non-dominated Sorting Genetic Algorithm (NSGA-II) to$\backslash$nfind the best compromise. For six open source projects, we succeeded in$\backslash$ndetecting the majority of known defects, and the proposed corrections$\backslash$nfixed most of them with minimal effort.},
author = {Ouni, Ali and Kessentini, Marouane and Sahraoui, Houari and Boukadoum, Mounir},
doi = {10.1007/s10515-011-0098-8},
isbn = {0928-8910},
issn = {09288910},
journal = {Automated Software Engineering},
keywords = {By example,Effort,Maintainability defects,Multi-objective optimization,Search-based software engineering,Software maintenance},
number = {1},
pages = {47--79},
publisher = {Springer US},
title = {{Maintainability defects detection and correction: A multi-objective approach}},
url = {http://dx.doi.org/10.1007/s10515-011-0098-8},
volume = {20},
year = {2013}
}
@inproceedings{me03d,
author = {Gunnalan, Rajesh and Us, T I M Menzies and Appukutty, Kalaivani},
title = {{Feature Subset Selection with TAR2less}},
year = {2003}
}
@inproceedings{burk04,
author = {Burkleaux, T and Menzies, T and Owen, D},
booktitle = {Proceedings of WITSE 2005},
title = {{LEAN = (LURCH+TAR3) = Reusable Modeling Tools}},
year = {2004}
}
@inproceedings{turhan08,
abstract = {Several research in defect prediction focus on building models with available local data (i.e. within company predictors). To employ these models, a company should have a data repository, where project metrics and defect information from past projects are stored. However, few companies apply this practice. In a recent work, we have shown that cross company data can be used for building predictors with the cost of increased false alarms. Thus, we argued that the practical application of cross-company predictors is limited to mission critical projects and companies should starve for local data. In this paper, we show that nearest neighbor (NN) sampling of cross-company data removes the increased false alarm rates. We conclude that cross company defect predictors can be practical tools with NN sampling, yet local predictors are still the best and companies should keep starving for local data. Copyright 2008 ACM.},
annote = {hW},
author = {Turhan, B and Bener, a and Menzies, T},
booktitle = {DEFECTS'08: 2008 International Symposium on Software Testing and Analysis - Proceedings of the 2008 Workshop on Defects in Large Software Systems 2008, DEFECTS'08},
doi = {10.1145/1390817.1390824},
isbn = {9781605580517 (ISBN)},
keywords = {Alarm systems,Building models,Computer software,Computer software selection and evaluation,Data repositories,Defect predictions,Defects,Errors,False Alarm rates,False alarms,Local datums,Mission critical,Nearest neighbors,Project metrics,Software testing,Technical presentations},
pages = {26},
title = {{Nearest neighbor sampling for cross company defect predictors (Abstract only)}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-57349150689\&partnerID=40\&md5=49e517a851134cb3ea7c5addee82d5e6},
year = {2008}
}
@inproceedings{dekhtyar04,
abstract = {Software compiles and therefore is characterized by a parseable grammar. Natural language text rarely conforms to prescriptive grammars and therefore is much harder to parse. Mining parseable structures is easier than mining less structured entities. Therefore, most work on mining repositories focuses on software, not natural language text. Here, we report experiments with mining natural language text (requirements documents) suggesting that: (a) mining natural language is not too difficult, so (b) software repositories should routinely be augmented with all the natural language text used to develop that software.},
author = {Dekhtyar, a.},
booktitle = {"International Workshop on Mining Software Repositories (MSR 2004)" W17S Workshop - 26th International Conference on Software Engineering},
doi = {10.1049/ic:20040470},
isbn = {0 86341 432 X},
number = {917},
pages = {22--26},
title = {{Text is software tool}},
url = {http://www.mendeley.com/research/text-is-software-too/},
volume = {2004},
year = {2004}
}
@article{Poli2007a,
abstract = {Particle swarm optimization (PSO) has undergone many changes since its introduction in 1995. As researchers have learned about the technique, they have derived new versions, developed new applications, and published theoretical studies of the effects of the various parameters and aspects of the algorithm. This paper comprises a snapshot of particle swarming from the authorsâ perspective, including variations in the algorithm, current and ongoing research, applications and open problems.},
author = {Poli, Riccardo and Kennedy, James and Blackwell, Tim},
doi = {10.1007/s11721-007-0002-0},
file = {:Users/timm/svns/doc/pso/07psoReview.pdf:pdf},
isbn = {9781612840529},
issn = {1935-3812},
journal = {Swarm Intelligence},
keywords = {particle swarm optimization,particle swarms,pso,real world applications,social networks,swarm,swarm dynamics,theory},
number = {1},
pages = {33--57},
pmid = {21738602},
title = {{Particle swarm optimization}},
volume = {1},
year = {2007}
}
@article{raffo05b,
abstract = {In this paper, we present a 'forward-looking' decision support framework that integrates up-to-date metrics data with simulation models of the software development process in order to support the software project management control function. This forward-looking approach (called the PROMPT method) provides predictions of project performance and the impact of various management decisions. Tradeoffs among performance measures are accomplished using outcome based control limits (OBCLs) and are augmented using multi-criteria utility functions and financial measures of performance to evaluate various process alternatives. The decision support framework enables the program manager to plan, manage and track current software development activities in the short term and to take corrective action as necessary to bring the project back on track. The model provides insight on potential performance impacts of the proposed corrective actions. A real world example utilizing a software process simulation model is presented. ?? 2005 Elsevier B.V. All rights reserved.},
author = {Raffo, David M.},
doi = {10.1016/j.infsof.2005.09.004},
isbn = {0950-5849},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Control limits,Multi-criteria decision making,Project management,Simulation,Software measurement repositories,Software process modeling},
month = dec,
number = {15},
pages = {1009--1017},
title = {{Software project management using PROMPT: A hybrid metrics, modeling and utility framework}},
volume = {47},
year = {2005}
}
@article{Wilkinson2011a,
author = {Wilkinson, Leland},
file = {:Users/timm/svns/doc/11clusterHyperCube.pdf:pdf},
isbn = {9781450308137},
keywords = {random projections,supervised classification},
pages = {6--14},
title = {{CHIRP : A 1ew \& lassifier \% ased Rn Composite Hypercubes on Iterated Random Projections}},
year = {2011}
}
@misc{bobntim2,
author = {Cohen, R F and Menzies, T},
number = {TR95-20},
title = {{Reverse Engineering a Software Engineering Curriculum}},
year = {1995}
}
@article{Taouji2012a,
abstract = {Aptamers represent an important class of synthetic protein binders useful for proteome-wide applications. The identification and characterisation of such molecules have been greatly facilitated by the development of Systematic Evolution of Ligands by Exponential Amplification (SELEX). Since then numerous advances and alternatives to improve efficient aptamer discovery have been reported. In the present manuscript we discuss the recent advances performed around the SELEX approach that may help to expand the availability of new aptamers and the subsequent applications that may be developed. Â© 2011 Elsevier B.V.},
author = {Taouji, Sa\"{\i}d and Dausse, Eric and Evad\'{e}, Laetitia and {Di Primo}, Carmelo and Toulm\'{e}, Jean Jacques and Chevet, Eric},
doi = {10.1016/j.nbt.2011.11.017},
file = {:Users/timm/svns/doc/erin/references/Aptamer/Taouji2012.pdf:pdf},
isbn = {1871-6784},
issn = {18716784},
journal = {New Biotechnology},
number = {5},
pages = {550--554},
pmid = {22178698},
title = {{Advances in binder identification and characterisation: The case of oligonucleotide aptamers}},
volume = {29},
year = {2012}
}
@misc{me01d,
author = {Menzies, T and Kiper, J D},
title = {{Machine Learning for Requirements Engineering}},
year = {2001}
}
@inproceedings{me06c,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/06bad.pdf\}},
author = {Orrego, Andres},
booktitle = {Citeseer},
title = {{Bayesian Anomaly Detection (BAD v0. 1)}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.74.3186\&amp;rep=rep1\&amp;type=pdf},
year = {2003}
}
@inproceedings{me13f,
author = {Menzies, Tim},
booktitle = {PROMISE '13},
title = {{Beyond Data Mining; Towards "Idea Engineering"}},
year = {2013}
}
@article{scott99,
abstract = {In this article, we discuss the need to evaluate the performance of data mining procedures and argue that tests done with real data sets cannot provide all the information needed for a thorough assessment of their performance characteristics. We argue that artificial data sets are therefore essential. After a discussion of the desirable characteristics of such artificial data, we describe two pseudo-random generators. The first is based on the multi-variate normal distribution and gives the investigator full control of the degree of correlation between the variables in the artificial data sets. The second is inspired by fractal techniques for synthesizing artificial landscapes and can produce data whose classification complexity can be controlled by a single parameter. We conclude with a discussion of the additional work necessary to achieve the ultimate goal of a method of matching data sets to the most appropriate data mining technique.},
author = {Scott, P. D. and Wilkins, E.},
doi = {10.1016/S0950-5849(99)00021-X},
issn = {09505849},
journal = {Information and Software Technology},
number = {9},
pages = {579--587},
title = {{Evaluating data mining procedures: Techniques for generating artificial data sets}},
volume = {41},
year = {1999}
}
@inproceedings{keung08z,
author = {Keung, Jacky},
booktitle = {Proceedings of the Second International Symposium on Empirical Software Engineering and Measurement, \{ESEM\} 2008, October 9-10, 2008, Kaiserslautern, Germany},
isbn = {978-1-59593-971-5},
pages = {294--296},
series = {ESEM '08},
title = {{Empirical evaluation of analogy-x for software cost estimation}},
url = {http://doi.acm.org/10.1145/1414004.1414057},
year = {2008}
}
@mastersthesis{province15,
author = {Province, B},
school = {CSEE, WVU},
title = {{Explorataions of the Low Dimensionality of SE data (in preperation)}},
year = {2015}
}
@inproceedings{aranda09,
abstract = {Every bug has a story behind it. The people that discover and resolve it need to coordinate, to get information from documents, tools, or other people, and to navigate through issues of accountability, ownership, and organizational structure. This paper reports on a field study of coordination activities around bug fixing that used a combination of case study research and a survey of software professionals. Results show that the histories of even simple bugs are strongly dependent on social, organizational, and technical knowledge that cannot be solely extracted through automation of electronic repositories, and that such automation provides incomplete and often erroneous accounts of coordination. The paper uses rich bug histories and survey results to identify common bug fixing coordination patterns and to provide implications for tool designers and researchers of coordination in software development.},
author = {Aranda, Jorge and Venolia, Gina},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2009.5070530},
isbn = {9781424434527},
issn = {02705257},
pages = {298--308},
series = {ICSE '09},
title = {{The secret life of bugs: Going past the errors and omissions in software repositories}},
year = {2009}
}
@inproceedings{me09j,
abstract = {This paper augments Boehm-Turner's model of agile and plan-based software development augmented with an AI search algorithm. The AI search finds the key factors that predict for the success of agile or traditional plan-based software developments. According to our simulations and AI search algorithm: (1) in no case did agile methods perform worse than plan-based approaches; (2) in some cases, agile performed best. Hence, we recommend that the default development practice for organizations be an agile method. The simplicity of this style of analysis begs the question: why is so much time wasted on evidence-less debates on software process when a simple combination of simulation plus automatic search can mature the dialog much faster?},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/09pom2.pdf\}},
author = {Lemon, Bryan and Riesbeck, Aaron and Menzies, Tim and Price, Justin and D\&apos;Alessandro, Joseph and Carlsson, Rikard and Prifiti, Tomi and Peters, Fayola and Lu, Hiuhua and Port, Dan},
booktitle = {ASE2009 - 24th IEEE/ACM International Conference on Automated Software Engineering},
doi = {10.1109/ASE.2009.42},
isbn = {9780769538914},
issn = {1527-1366},
pages = {580--584},
title = {{Applications of simulation and AI search: Assessing the relative merits of agile vs traditional software development}},
year = {2009}
}
@misc{me96o,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/96ie.pdf\}},
author = {Menzies, T and Tucker, S},
title = {{Subject Handbook SFT3500/SYS3030: Industrial Experience Project}},
year = {1996}
}
@inproceedings{JIANG20082,
abstract = {Data preprocessing (transformation) plays an important role in data$\backslash$nmining and machine learning. In this study, we investigate the effect$\backslash$nof four different preprocessing methods to fault-proneness prediction$\backslash$nusing nine datasets from NASA Metrics Data Programs (MDP) and ten$\backslash$nclassification algorithms. Our experiments indicate that log transformation$\backslash$nrarely improves classification performance, but discretization affects$\backslash$nthe performance of many different algorithms. The impact of different$\backslash$ntransformations differs. Random forest algorithm, for example, performs$\backslash$nbetter with original and log transformed data set. Boosting and Naive$\backslash$nBayes perform significantly better with discretized data. We conclude$\backslash$nthat no general benefit can be expected from data transformations.$\backslash$nInstead, selected transformation techniques are recommended to boost$\backslash$nthe performance of specific classification algorithms.},
address = {New York, NY, USA},
author = {Jiang, Yue and Cukic, Bojan and Menzies, Tim},
booktitle = {Proceedings of the 2008 workshop on Defects in large software systems - DEFECTS '08},
doi = {10.1145/1390817.1390822},
isbn = {9781605580517},
pages = {16},
publisher = {ACM},
title = {{Can data transformation help in the detection of fault-prone modules?}},
url = {http://portal.acm.org/citation.cfm?doid=1390817.1390822},
year = {2008}
}
@inproceedings{me08d,
abstract = {Context: There are many methods that input static code features and output a predictor for faulty code modules. These data mining methods have hit a "performance ceiling"; i.e., some inherent upper bound on the amount of information offered by, say, static code features when identifying modules which contain faults. Objective: We seek an explanation for this ceiling effect. Perhaps static code features have "limited information content"; i.e. their information can be quickly and completely discovered by even simple learners. Method: An initial literature review documents the ceiling effect in other work. Next, using three sub-sampling techniques (under-, over-, and micro-sampling), we look for the lower useful bound on the number of training instances. Results: Using micro-sampling, we find that as few as 50 instances yield as much information as larger training sets. Conclusions: We have found much evidence for the limited information hypothesis. Further progress in learning defect predictors may not come from better algorithms. Rather, we need to be improving the information content of the training data, perhaps with case-based reasoning methods. Copyright 2008 ACM.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ceiling.pdf\}},
author = {Menzies, Tim and Turhan, Burak and Bener, Ayse and Gay, Gregory and Cukic, Bojan and Jiang, Yue},
booktitle = {Proceedings of the 4th international workshop on Predictor models in software engineering - PROMISE '08},
doi = {10.1145/1370788.1370801},
isbn = {9781605580364},
issn = {02705257},
keywords = {Defect prediction,Naive bayes,Over-sampling,Under-sampling},
pages = {47},
title = {{Implications of ceiling effects in defect predictors}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-57049155106\&partnerID=tZOtx3y1},
year = {2008}
}
@article{me03j,
abstract = {Chung et al. have proposed a graphical model that captures the interdependencies between design alternatives in terms of synergy and trade-offs. This model can assist in identifying quality/risk trade-offs early in the lifecycle of software development, such as architectural design and testing process choices. The Chung et al. method is an analysis framework only: their technique does not include an execution or analysis module. This paper presents a simulation tool developed to analyze such a model, and techniques to facilitate decision making by reducing the space of options worth considering. Our techniques combine Monte Carlo simulations to generate options with a machine learner to determine which option yields the most/least favorable outcome. Experiments based on the above methodology were performed on two case studies, and the results showed that treatment learning successfully pinpointed the key attributes among uncertainties in our test domains. Copyright Â© 2003 John Wiley \& Sons, Ltd.},
author = {Chiang, Eliza and Menzies, Tim},
doi = {10.1002/spip.161},
issn = {1099-1670},
journal = {Software Process: Improvement and Practice},
number = {3â4},
pages = {141--159},
title = {{Simulations for very early lifecycle quality evaluations}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/spip.161/abstract},
volume = {7},
year = {2002}
}
@article{Zheng2010a,
author = {Zheng, Zhao and Lei, Wang and Huan, Liu},
file = {:Users/timm/svns/doc/10SpectralFss.pdf:pdf},
isbn = {9781577354642},
journal = {Twenty-Fourth AAAI Conference on Artificial Intelligence},
keywords = {Technical Papers -- Machine Learning},
pages = {1----6},
title = {{Efficient Spectral Feature Selection with Minimum Redundancy}},
year = {2010}
}
@misc{bobntim2,
author = {Cohen, R F and Menzies, T},
number = {TR95-20},
title = {{Reverse Engineering a Software Engineering Curriculum}},
year = {1995}
}
@article{me97a,
abstract = {It is difficult to assess hypothetical models in poorly measured domains such as neuroendocrinology. Without a large library of observations to constrain inference, the execution of such incomplete models implies making assumptions. Mutually exclusive assumptions must be kept in separate worlds. We define a general abductive multiple-worlds engine that assesses such models by (i) generating the worlds and (ii) tests if these worlds contain known behaviour. World generation is constrained via the use of relevant envisionment. We describe QCM, a modeling language for compartmental models that can be processed by this inference engine. This tool has been used to find faults in theories published in international refereed journals; i.e. QCM can detect faults which are invisible to other methods. The generality and computational limits of this approach are discussed. In short, this approach is applicable to any representation that can be compiled into an and-or graph, provided the graphs are not too big or too intricate (fanout < 7).},
author = {Menzies, Tim and Compton, Paul},
doi = {10.1016/S0933-3657(97)00391-6},
issn = {09333657},
journal = {Artificial Intelligence in Medicine},
keywords = {Abduction,Hypothesis testing,Neuroendocrinology,Qualitative reasoning},
number = {2},
pages = {145--175},
pmid = {9201384},
title = {{Applications of abduction: Hypothesis testing of neuroendocrinological qualitative compartmental models}},
volume = {10},
year = {1997}
}
@inproceedings{valerdi04,
author = {Valerdi, R and Miller, C and Thomas, G},
booktitle = {\ldots Conference on Systems Engineering, Las \ldots},
month = sep,
title = {{Systems engineering cost estimation by consensus}},
url = {http://web.mit.edu/rvalerdi/www/SE cost estimation by consensus - paper.pdf},
year = {2004}
}
@article{jorg04,
abstract = {This paper provides an extensive review of studies related to expert$\backslash$nestimation of software development effort. The main goal and contribution$\backslash$nof the review is to support the research on expert estimation, e.g.,$\backslash$nto ease other researcher's search for relevant expert estimation$\backslash$nstudies. In addition, we provide software practitioners with useful$\backslash$nestimation guidelines, based on the research-based knowledge of expert$\backslash$nestimation processes. The review results suggest that expert estimation$\backslash$nis the most frequently applied estimation strategy for software projects,$\backslash$nthat there is no substantial evidence in favour of use of estimation$\backslash$nmodels, and that there are situations where we can expect expert$\backslash$nestimates to be more accurate than formal estimation models. The$\backslash$nfollowing 12 expert estimation "best practice" guidelines are evaluated$\backslash$nthrough the review: (1) evaluate estimation accuracy, but avoid high$\backslash$nevaluation pressure; (2) avoid conflicting estimation goals; (3)$\backslash$nask the estimators to justify and criticize their estimates; (4)$\backslash$navoid irrelevant and unreliable estimation information; (5) use documented$\backslash$ndata from previous development tasks; (6) find estimation experts$\backslash$nwith relevant domain background and good estimation records; (7)$\backslash$nEstimate top-down and bottom-up, independently of each other; (8)$\backslash$nuse estimation checklists; (9) combine estimates from different experts$\backslash$nand estimation strategies; (10) assess the uncertainty of the estimate;$\backslash$n(11) provide feedback on estimation accuracy and development task$\backslash$nrelations; and, (12) provide estimation training opportunities. We$\backslash$nfound supporting evidence for all 12 estimation principles, and provide$\backslash$nsuggestions on how to implement them in software organizations.},
author = {Jorgensen, M},
journal = {Journal of Systems and Software},
number = {1-2},
pages = {37--60},
title = {{A review of studies on expert estimation of software development effort}},
volume = {70},
year = {2004}
}
@inproceedings{nohrer12,
abstract = {Tolerating inconsistencies is well accepted in design modeling because it is often neither obvious how to fix an inconsistency nor important to do so right away. However, there are technical reasons why inconsistencies are not tolerated in many areas of software engineering. The most obvious being that common reasoning engines are rendered (partially) useless in the presence of inconsistencies. This paper investigates automated strategies for tolerating inconsistencies during decision-making in product line engineering, based on isolating parts from reasoning that cause inconsistencies. We compare trade offs concerning incorrect and incomplete reasoning and demonstrate that it is even possible to fully eliminate incorrect reasoning in the presence of inconsistencies at the expense of marginally less complete reasoning. Our evaluation is based on seven medium-to-large size software product line case studies. It is important to note that our mechanism for tolerating inconsistencies can be applied to arbitrary SAT problems and thus the basic principles of this approach are applicable to other domains also. Copyright Â© 2012 ACM.},
author = {N\"{o}hrer, Alexander and Biere, Armin and Egyed, Alexander},
booktitle = {Proceedings of the 16th International Software Product Line Conference on - SPLC '12 -volume 1},
doi = {10.1145/2362536.2362543},
isbn = {9781450310949},
keywords = {Formal reasoning,Inconsistencies,User guidance},
pages = {11},
series = {SPLC '12},
title = {{A comparison of strategies for tolerating inconsistencies during decision-making}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867484663\&partnerID=tZOtx3y1},
volume = {1},
year = {2012}
}
@inproceedings{me08g,
abstract = {In mission critical systems, such as those developed by NASA, it is very important that the test engineers properly recognize the severity of each issue they identify during testing. Proper severity assessment is essential for appropriate resource allocation and planning for fixing activities and additional testing. Severity assessment is strongly influenced by the experience of the test engineers and by the time they spend on each issue. The paper presents a new and automated method named SEVERIS (severity issue assessment), which assists the test engineer in assigning severity levels to defect reports. SEVERIS is based on standard text mining and machine learning techniques applied to existing sets of defect reports. A case study on using SEVERIS with data from NASApsilas Project and Issue Tracking System (PITS) is presented in the paper. The case study results indicate that SEVERIS is a good predictor for issue severity levels, while it is easy to use and efficient.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08severis.pdf\}},
author = {Menzies, Tim and Marcus, Andrian},
booktitle = {IEEE International Conference on Software Maintenance, ICSM},
doi = {10.1109/ICSM.2008.4658083},
isbn = {9781424426140},
issn = {1063-6773},
pages = {346--355},
title = {{Automated severity assessment of software defect reports}},
year = {2008}
}
@inproceedings{xie12,
abstract = {Tool automation to reduce manual effort has been an active research area in various sub fields of software engineering such as software testing and analysis. To maximize the value of software testing and analysis, effective support for cooperation between engineers and tools is greatly needed and yet lacking in state-of-the-art research and practice. In particular, testing and analysis are in a great need of (1) effective ways for engineers to communicate their testing or analysis goals and guidance to tools and (2) tools with strong enough capabilities to accomplish the given testing or analysis goals and with effective ways to communicate challenges faced by them to engineers -- enabling a feedback loop between engineers and tools to refine and accomplish the testing or analysis goals. In addition, different tools have their respective strengths and weaknesses, and there is also a great need of allowing these tools to cooperate with each other. Similarly, there is a great need of allowing engineers (or even users) to cooperate to help tools such as in the form of crowd sourcing. A new research frontier on synergistic co operations between humans and tools, tools and tools, and humans and humans is yet to be explored. This paper presents recent example advances on cooperative testing and analysis.},
author = {Xie, Tao},
booktitle = {Proceedings - 2012 IEEE 12th International Working Conference on Source Code Analysis and Manipulation, SCAM 2012},
doi = {10.1109/SCAM.2012.31},
isbn = {9780769547831},
keywords = {cooperative testing and analysis,crowdsourcing,human-assisted computing,human-centric computing,tool integration},
month = sep,
pages = {1--3},
title = {{Cooperative testing and analysis: Human-tool, tool-tool and human-human cooperations to get work done}},
url = {http://www.csc.ncsu.edu/faculty/xie/publications/scam12-keynote.pdf},
year = {2012}
}
@article{Song2014a,
abstract = {Modern software systems are increasingly configurable. While this has many benefits, it also makes some software engineering tasks,such as software testing, much harder. This is because, in theory,unique errors could be hiding in any configuration, and, therefore,every configuration may need to undergo expensive testing. As this is generally infeasible, developers need cost-effective technique for selecting which specific configurations they will test. One popular selection approach is combinatorial interaction testing (CIT), where the developer selects a strength t and then computes a covering array (a set of configurations) in which all t-way combinations of configuration option settings appear at least once. In prior work, we demonstrated several limitations of the CIT approach. In particular, we found that a given system's effective configuration space - the minimal set of configurations needed to achieve a specific goal - could comprise only a tiny subset of the system's full configuration space. We also found that effective configuration space may not be well approximated by t-way covering arrays. Based on these insights we have developed an algorithm called interaction tree discovery (iTree). iTree is an iterative learning algorithm that efficiently searches for a small set of configurations that closely approximates a system's effective configuration space. On each iteration iTree tests the system on a small sample of carefully chosen configurations, monitors the system's behaviors, and then applies machine learning techniques to discover which combinations of option settings are potentially responsible for any newly observed behaviors. This information is used in the next iteration to pick a new sample of configurations that are likely to reveal further new behaviors. In prior work, we presented an initial version of iTree and performed an initial evaluation with promising results. This paper presents an improved iTree algorithm in greater detail. The - ey improvements are based on our use of composite proto-interactions - a construct that improves iTree's ability to correctly learn key configuration option combinations, which in turn significantly improves iTree's running time, without sacrificing effectiveness. Finally, the paper presents a detailed evaluation of the improved iTree algorithm by comparing the coverage it achieves versus that of covering arrays and randomly generated configuration sets, including a significantly expanded scalability evaluation with the \~{} 1M-LOC MySQL. Our results strongly suggest that the improved iTree algorithm is highly scalable and can identify a high-coverage test set of configurations more effectively than existing methods.},
author = {Song, Charles and Porter, Adam and Foster, Jeffrey S.},
doi = {10.1109/TSE.2013.55},
file = {:Users/timm/svns/doc/14itree.pdf:pdf},
isbn = {9781467310673},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Empirical software engineering,software configurations,software testing and analysis},
number = {3},
pages = {251--265},
title = {{ITree: Efficiently discovering high-coverage configurations using interaction trees}},
volume = {40},
year = {2014}
}
@article{Levine2007a,
abstract = {Systematic evolution of ligands by exponential enrichment (SELEX) is a procedure by which a mixture of nucleic acids that vary in sequence can be separated into pure components with the goal of isolating those with specific biochemical activities. The basic idea is to combine the mixture with a specific target molecule and then separate the target-NA complex from the resulting reaction. The target-NA complex is then separated by mechanical means (for example by filtration), the NA is then eluted from the complex, amplified by polymerase chain reaction (PCR) and the process repeated. After several rounds, one should be left with a pool of [NA] that consists mostly of the species in the original pool that best binds to the target. In Irvine et al. [Irvine, D., Tuerk, C., Gold, L., 1991. SELEXION, systematic evolution of nucleic acids by exponential enrichment with integrated optimization by non-linear analysis. J. Mol. Biol. 222, 739-761] a mathematical analysis of this process was given. In this paper we revisit Irvine et al. [Ibid]. By rewriting the equations for the SELEX process, we considerably reduce the labor of computing the round to round distribution of nucleic acid fractions. We also establish necessary and sufficient conditions for the SELEX process to converge to a pool consisting solely of the best binding nucleic acid to a fixed target in a manner that maximizes the percentage of bound target. The assumption is that there is a single nucleic acid binding site on the target that permits occupation by not more than one nucleic acid. We analyze the case for which there is no background loss (no support losses and no free [NA] left on the support). We then examine the case in which such there are such losses. The significance of the analysis is that it suggests an experimental approach for the SELEX process as defined in Irvine et al. [Ibid] to converge to a pool consisting of a single best binding nucleic acid without recourse to any a priori information about the nature of the binding constants or the distribution of the individual nucleic acid fragments. ?? 2006 Elsevier Ltd. All rights reserved.},
author = {Levine, Howard a. and Nilsen-Hamilton, Marit},
doi = {10.1016/j.compbiolchem.2006.10.002},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Levine07.pdf:pdf},
isbn = {1476-9271},
issn = {14769271},
journal = {Computational Biology and Chemistry},
keywords = {Aptamer,Mathematical analysis,SELEX},
number = {1},
pages = {11--35},
pmid = {17218151},
title = {{A mathematical analysis of SELEX}},
volume = {31},
year = {2007}
}
@article{Lee2009b,
abstract = {Landmark multidimensional scaling (LMDS) uses a subset of data (landmark points) to solve classical multidimensional scaling (MDS), where the scalability is increased but the approximation is noise-sensitive. In this paper we present an LMDS ensemble where we use a portion of the input in a piecewise manner to solve classical MDS, combining individual LMDS solutions which operate on different partitions of the input. Ground control points (GCPs) that are shared by partitions considered in the ensemble, allow us to align individual LMDS solutions in a common coordinate system through affine transformations. We incorporate priors into combining multiple LMDS solutions such that the weighted averaging by priors improves the noise-robustness of our method. Our LMDS ensemble is much less noise-sensitive while maintaining the scalability and the speed of LMDS. Experiments on synthetic data (noisy grid) and real-world data (similar image retrieval) confirm the high performance of the proposed LMDS ensemble. ?? 2009 Elsevier Ltd. All rights reserved.},
author = {Lee, Seunghak and Choi, Seungjin},
doi = {10.1016/j.patcog.2008.11.039},
file = {:Users/timm/svns/doc/09landmark\_MBS\_ensembles.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Dimensionality reduction,Embedding,Multidimensional scaling (MDS),Unsupervised learning},
number = {9},
pages = {2045--2053},
title = {{Landmark MDS ensemble}},
volume = {42},
year = {2009}
}
@inproceedings{men92s,
author = {Menzies, Tim and Compton, Paul and Feldman, Bart and Toth, Thomas},
booktitle = {AAAI Techical Report},
title = {{Qualitative Compartmental Modelling}},
volume = {SS-92-02},
year = {1992}
}
@inproceedings{me00y,
author = {Menzies, Tim and Cukic, Bojan},
booktitle = {Handbook of Software Engineering and Knowledge Engineering, Volume II},
editor = {Chang, S K},
isbn = {981-02-4974-8},
pages = {1--22},
title = {{How Many Tests are Enough ?}},
volume = {2},
year = {2000}
}
@inproceedings{me05d,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/05learncost.pdf\}},
author = {Menzies, Tim and Port, D and Chen, Z and Hihn, J and Stukes, S},
booktitle = {Ieee Ase},
title = {{Specialization and extrapolation of induced domain models: Case studies in software effort estimation}},
volume = {2005},
year = {2005}
}
@article{me99c,
author = {Menzies, T},
journal = {Submitted to AAAI-99},
title = {{Simpler, Faster Abductive Validation}},
year = {1999}
}
@article{me13e,
author = {Menzies, Tim},
journal = {Information and Software Technology},
number = {8},
pages = {1477--1478},
title = {{Guest editorial for the Special Section on \{BEST\} \{PAPERS\} from the 2011 conference on Predictive Models in Software Engineering (PROMISE)}},
volume = {55},
year = {2013}
}
@article{feather08,
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08ddp.pdf\}},
author = {Feather, M and Cornford, S and Hicks, K and Kiper, J and Menzies, T},
journal = {IEEE Software},
title = {{Application of a broad-spectrum quantitative requirements model to early-lifecycle decision making}},
year = {2008}
}
@article{cortes95,
author = {Cortes, Corinna and Vapnik, Vladimir},
issn = {0885-6125},
journal = {Machine Learning},
number = {3},
pages = {273--297},
title = {{Support-vector networks}},
volume = {20},
year = {1995}
}
@article{Levy-Nissenbaum2008a,
abstract = {Nucleic acid ligands, also known as aptamers, are a class of macromolecules that are being used in several novel nanobiomedical applications. Aptamers are characterized by high affinity and specificity for their target, a versatile selection process, ease of chemical synthesis and a small physical size, which collectively make them attractive molecules for targeting diseases or as therapeutics. These properties will enable aptamers to facilitate innovative new nanotechnologies with applications in medicine. In this review, we will highlight recent developments in using aptamers in nanotechnology solutions for treating and diagnosing disease. Â© 2008 Elsevier Ltd. All rights reserved.},
author = {Levy-Nissenbaum, Etgar and Radovic-Moreno, Aleksandar F. and Wang, Andrew Z. and Langer, Robert and Farokhzad, Omid C.},
doi = {10.1016/j.tibtech.2008.04.006},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Levy08.pdf:pdf},
isbn = {0167-7799},
issn = {01677799},
journal = {Trends in Biotechnology},
number = {8},
pages = {442--449},
pmid = {18571753},
title = {{Nanotechnology and aptamers: applications in drug delivery}},
volume = {26},
year = {2008}
}
@article{me07d,
abstract = {Although there are times when random search is dangerous and should be avoided, software analysis should start with random methods because they are so cheap, moving to the more complex methods only when random methods fail},
annote = {$\backslash$url\{http://menzies.us/pdf/07strange.pdf\}},
author = {Menzies, Tim and Owen, David and Richardson, Julian},
doi = {10.1109/MC.2007.37},
issn = {00189162},
journal = {Computer},
keywords = {Artificial intelligence,Data mining,LURCH,Software engineering,TAR3},
number = {1},
pages = {54--60},
title = {{The strangest thing about software}},
volume = {40},
year = {2007}
}
@article{Voinea2007a,
abstract = {In this article we describe an ongoing effort to integrate information visualization techniques into the process of configuration management for software systems. Our focus is to help software engineers manage the evolution of large and complex software systems by offering them effective and efficient ways to query and assess system properties using visual techniques. To this end, we combine several techniques from different domains, as follows. First, we construct an infrastructure that allows generic querying and data mining of different types of software repositories such as CVS and Subversion. Using this infrastructure, we construct several models of the software source code evolution at different levels of detail, ranging from project and package up to function and code line. Second, we describe a set of views that allow examining the code evolution models at different levels of detail and from different perspectives. We detail three views: the file view shows changes at line level across many versions of a single, or a few, files. The project view shows changes at file level across entire software projects. The decomposition view shows changes at subsystem level across entire projects. We illustrate how the proposed techniques, which we implemented in a fully operational toolset, have been used to answer non-trivial questions on several real-world, industry-size software projects. Our work is at the crossroads of applied software engineering (SE) and information visualization, as our toolset aims to tightly integrate the methods promoted by the InfoVis field into the SE practice.},
author = {Voinea, Lucian and Telea, Alexandru},
doi = {10.1016/j.cag.2007.01.031},
file = {:Users/timm/svns/doc/xplain/07Voinea.pdf:pdf},
isbn = {0097-8493},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {data mining,maintenance,software engineering,software evolution,software visualization},
number = {3},
pages = {410--428},
title = {{Visual data mining and analysis of software repositories}},
volume = {31},
year = {2007}
}
@inproceedings{Scanniello2013,
author = {Scanniello, Giuseppe and Gravino, Carmine and Marcus, Andrian and Menzies, Tim},
booktitle = {2013 28th IEEE/ACM International Conference on Automated Software Engineering, ASE 2013 - Proceedings},
doi = {10.1109/ASE.2013.6693126},
isbn = {9781479902156},
keywords = {Empirical Study,Fault Prediction,Software Clustering},
organization = {IEEE},
pages = {640--645},
title = {{Class level fault prediction using software clustering}},
year = {2013}
}
@article{neto08,
abstract = {A rich body of experiences hasn't yet been published on all the software development techniques researchers have proposed. In fact, by some estimates, the techniques for which we do have substantial experience are few and far between. When we started looking at the evidence on model-based testing (MBT), we thought we'd come across some strong studies that showed this approach's capabilities compared to conventional testing techniques-this wasn't the case. However, we can still extract some useful knowledge and also discuss some issues that are relevant to other software technologies with similar types of evidence.},
author = {Neto, Arilo Dias and Subramanyan, Rajesh and Vieira, Marlon and Travassos, Guilherme Horta and Shull, Forrest},
doi = {10.1109/MS.2008.64},
isbn = {0740-7459},
issn = {07407459},
journal = {IEEE Software},
keywords = {Book reviews,Empirical study,Model-based testing,Object oriented modeling,Programming,Reliability,Software,Systematic review,Testing,Unified modeling language},
number = {3},
pages = {10--13},
title = {{Improving evidence about software technologies: A look at model-based testing}},
volume = {25},
year = {2008}
}
@article{Reidys2002a,
abstract = {Fitness landscapes have proven to be a valuable concept in evolutionary biology, combinatorial optimization, and the physics of disordered systems. A fitness landscape is a mapping from a configuration space into the real numbers. The configuration space is equipped with some notion of adjacency, nearness, distance or accessibility. Landscape theory has emerged as an attempt to devise suitable mathematical structures for describing the âstaticâ properties of landscapes as well as their influence on the dynamics of adaptation. In this review we focus on the connections of landscape theory with algebraic combinatorics and random graph theory, where exact results are available.},
author = {Reidys, Christian M. and Stadler, Peter F.},
doi = {10.1137/S0036144501395952},
file = {:Users/timm/svns/doc/erin/references/AlgsForDNA/CombinatorialLandscapesReidys.pdf:pdf},
isbn = {0036-1445},
issn = {0036-1445},
journal = {SIAM Review},
keywords = {05c90,1,15-02,ams subject classifications,coherent algebras,combinatorial optimization,correlation functions,fitness landscape,fitness landscape originated in,genotype phenotype map,introduction,neutrality,random graphs,sequential dynamical systems,the 1930s in,the concept of a},
number = {1},
pages = {3--54},
pmid = {1054},
title = {{Combinatorial Landscapes}},
volume = {44},
year = {2002}
}
@article{Hale2010a,
abstract = {Information systems portfolio management assumes that software will evolve to maintain alignment with operational needs, a goal that must be met through effective ongoing maintenance. Thus, a primary goal of software maintainers is to ensure that production code is updated without the introduction of defects. However, there is a dearth of research that examines the work product defects that occur as these applications evolve. The goal of this study is to characterize software evolution lifecycle work product defects and factors that may increase or reduce their occurrence. The study takes place within a global consulting organization conducting ongoing software maintenance for a Fortune 100 telecommunications firm by a project team assessed at Capability Maturity Model Integration (CMMI) Level 3. This study reports on 961 work product reviews conducted across the evolution activities of the ISO/IEC 12207 Software Development Life Cycle Processes. After controlling for team and expertise differences, the study's major finding is that corrective evolution projects inject a greater number of work product defects than enhancive evolution projects. This result does not arise from the schedule compression often associated with corrective evolution. Rather, it is concluded that the increase in work product defects is associated with the increased complexity of analysis-stage problem diagnosis found in corrective evolution projects. The analysis is augmented by additional covariates including the number of work product reviewers, preparation time of reviewers, and size of the project.},
author = {Hale, David P. and Hale, Joanne E. and Smith, Randy K.},
doi = {10.1145/1952712.1952716},
file = {:Users/timm/svns/doc/11hale.pdf:pdf},
isbn = {0095-0033},
issn = {00950033},
journal = {ACM SIGMIS Database},
keywords = {development,documentation,inspections,maintenance,management,measurement,problem diagnosis,reliability,reviews,software engineering,verification,walkthrough},
number = {1},
pages = {59},
title = {{Evaluation of work product defects during corrective \& enhancive software evolution}},
volume = {42},
year = {2010}
}
@inproceedings{tosun09,
abstract = {CONTEXT$\backslash$nBuilding defect prediction models in large organizations has many challenges due to limited resources and tight schedules in the software development lifecycle. It is not easy to collect data, utilize any type of algorithm and build a permanent model at once. We have conducted a study in a large telecommunications company in Turkey to employ a software measurement program and to predict pre-release defects. Based on our prior publication, we have shared our experience in terms of the project steps (i.e. challenges and opportunities). We have further introduced new techniques that improve our earlier results. $\backslash$n$\backslash$nOBJECTIVE$\backslash$nIn our previous work, we have built similar predictors using data representative for US software development. Our task here was to check if those predictors were specific solely to US organizations or to a broader class of software. $\backslash$n$\backslash$nMETHOD$\backslash$nWe have presented our approach and results in the form of an experience report. Specifically, we have made use of different techniques for improving the information content of the software data and the performance of a Na\"{\i}ve Bayes classifier in the prediction model that is locally tuned for the company. We have increased the information content of the software data by using module dependency data and improved the performance by adjusting the hyper-parameter (decision threshold) of the Na\"{\i}ve Bayes classifier. We have reported and discussed our results in terms of defect detection rates and false alarms. We also carried out a costâbenefit analysis to show that our approach can be efficiently put into practice. $\backslash$n$\backslash$nRESULTS$\backslash$nOur general result is that general defect predictors, which exist across a wide range of software (in both US and Turkish organizations), are present. Our specific results indicate that concerning the organization subject to this study, the use of version history information along with code metrics decreased false alarms by 22\%, the use of dependencies between modules further reduced false alarms by 8\%, and the decision threshold optimization for the Na\"{\i}ve Bayes classifier using code metrics and version history information further improved false alarms by 30\% in comparison to a prediction using only code metrics and a default decision threshold. $\backslash$n$\backslash$nCONCLUSION$\backslash$nImplementing statistical techniques and machine learning on a real life scenario is a difficult yet possible task. Using simple statistical and algorithmic techniques produces an average detection rate of 88\%. Although using dependency data improves our results, it is difficult to collect and analyze such data in general. Therefore, we would recommend optimizing the hyper-parameter of the proposed technique, Na\"{\i}ve Bayes, to calibrate the defect prediction model rather than employing more complex classifiers. We also recommend that researchers who explore statistical and algorithmic methods for defect prediction should spend less time on their algorithms and more time on studying the pragmatic considerations of large organizations.},
author = {Boetticher, Gary D. and Ruhe, Guenther and Tosun, AyÅe and Bener, AyÅe and Turhan, Burak and Menzies, Tim},
booktitle = {Information and Software Technology},
doi = {10.1016/j.infsof.2010.06.006},
isbn = {978-1-60558-634-2},
issn = {09505849},
keywords = {Experience report,Na\"{\i}ve Bayes,Software defect prediction,Static code attributes},
number = {11},
pages = {1242--1257},
title = {{Practical considerations in deploying statistical methods for defect prediction: A case study within the Turkish telecommunications industry}},
url = {http://www.sciencedirect.com/science/article/pii/S0950584910001163},
volume = {52},
year = {2010}
}
@misc{shepperd11,
annote = {Available on-line at http://goo.gl/JbXcL},
author = {Shepperd, Martin},
booktitle = {CREST Open Workshop, University College, October 24-25},
title = {{It doesn't matter what you do but does matter who does it!}},
year = {2011}
}
@article{me13za,
author = {Menzies, Tim},
file = {:Users/timm/svns/doc/13beyond.pdf:pdf},
journal = {Software, IEEE},
month = jul,
number = {3},
pages = {90--91},
title = {{Beyond Data Mining}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6504887},
volume = {30},
year = {2013}
}
@inproceedings{me03a,
abstract = { When it is impractical to rigorously assess all parts of complex systems, test engineers use defect detectors to focus their limited resources. We define some properties of an ideal defect detector and assess different methods of generating one. In the case study presented here, traditional methods of generating such detectors (e.g. reusing detectors from the literature, linear regression, model trees) were found to be inferior to those found via a PACE analysis.},
author = {Menzies, T. and Stefano, J.D. and Ammar, K. and McGill, K. and Callis, P. and Davis, J. and Chapman, R.},
booktitle = {Proceedings. 5th International Workshop on Enterprise Networking and Computing in Healthcare Industry (IEEE Cat. No.03EX717)},
doi = {10.1109/METRIC.2003.1232459},
isbn = {0-7695-1987-3},
issn = {1530-1435},
title = {{When can we test less?}},
year = {2003}
}
@inproceedings{menz91,
author = {Menzies, T J},
booktitle = {Tools Pacific 4},
editor = {Meyer, B},
title = {{\{ISA\} \{O\}bject \{PARTOF\} \{K\}nowledge \{R\}epresentation (Part Two)?}},
year = {1991}
}
@inproceedings{owen03c,
abstract = { We have been exploring LURCH, an approximate (not necessarily complete) alternative to traditional model checking based on a randomized search algorithm. Randomized algorithms like LURCH have been known to outperform their deterministic counterparts for search problems representing a wide range of applications. The cost of an approximate strategy is the potential for inaccuracy. If complete algorithms terminate, they find all the features they are searching for. On the other hand, by its very nature, randomized search can miss important features. Our experiments suggest that this inaccuracy problem is not too serious. In the case studies presented here and elsewhere, LURCHS random search usually found the correct results. Also, these case studies strongly suggest that LURCH can scale to much larger models than standard model checkers like NuSMV and SPIN. The two case studies presented in this paper are selected for their simplicity and their complexity. The simple problem of the dining philosophers has been widely studied. By making the dinner more crowded, we can compare the memory and runtimes of standard methods (SPIN) and LURCH. When hundreds of philosophers sit down to eat, both LURCH and SPIN can find the deadlock case. However, SPINS memory and runtime requirements can grow exponentially while LURCHS requirements stay quite low. Success with highly symmetric, automatically generated problems says little about the generality of a technique. Hence, our second example is far more complex: a real-world flight guidance system from Rockwell Collins. Compared to NuSMV, LURCH performed very well on this model. Our random search finds the vast majority of faults (close to 90\%); runs much faster (seconds and minutes as opposed to hours); and uses very little memory (single digits to 10s of megabytes as opposed to 10s to 100s of megabytes). The rest of this paper is structured as follows. We begin with a theoretical rationale for why random search methods like LURCH can be incomplete, yet still successful. Next, we note that for a class of problems, the complete search of standard model checkers can be overkill. LURCH is then briefly introduced and our two case studies are presented.},
author = {Owen, D. and Menzies, T. and Heimdahl, M. and Gao, Jimin Gao Jimin},
booktitle = {28th Annual NASA Goddard Software Engineering Workshop, 2003. Proceedings.},
doi = {10.1109/SEW.2003.1270728},
isbn = {0-7695-2064-2},
title = {{On the advantages of approximate vs. complete verification: bigger models, faster, less memory, usually accurate}},
year = {2003}
}
@article{me11n,
author = {Haapio, Topi and Menzies, Tim},
doi = {10.1142/S0218194011005438},
issn = {0218-1940},
journal = {International Journal of Software Engineering and Knowledge Engineering},
number = {05},
pages = {725--753},
title = {{Exploring the Effort of General Software Project Activities With Data Mining}},
volume = {21},
year = {2011}
}
@article{ma12,
abstract = {Context: Software defect prediction studies usually built models using within-company data, but very few focused on the prediction models trained with cross-company data. It is difficult to employ these models which are built on the within-company data in practice, because of the lack of these local data repositories. Recently, transfer learning has attracted more and more attention for building classifier in target domain using the data from related source domain. It is very useful in cases when distributions of training and test instances differ, but is it appropriate for cross-company software defect prediction? Objective: In this paper, we consider the cross-company defect prediction scenario where source and target data are drawn from different companies. In order to harness cross company data, we try to exploit the transfer learning method to build faster and highly effective prediction model. Method: Unlike the prior works selecting training data which are similar from the test data, we proposed a novel algorithm called Transfer Naive Bayes (TNB), by using the information of all the proper features in training data. Our solution estimates the distribution of the test data, and transfers cross-company data information into the weights of the training data. On these weighted data, the defect prediction model is built. Results: This article presents a theoretical analysis for the comparative methods, and shows the experiment results on the data sets from different organizations. It indicates that TNB is more accurate in terms of AUC (The area under the receiver operating characteristic curve), within less runtime than the state of the art methods. Conclusion: It is concluded that when there are too few local training data to train good classifiers, the useful knowledge from different-distribution training data on feature level may help. We are optimistic that our transfer learning method can guide optimal resource allocation strategies, which may reduce software testing cost and increase effectiveness of software testing process. Â© 2011 Elsevier B.V. All rights reserved.},
author = {Ma, Ying and Luo, Guangchun and Zeng, Xue and Chen, Aiguo},
doi = {10.1016/j.infsof.2011.09.007},
file = {:Users/timm/svns/doc/transfer/12ma.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Different distribution,Machine learning,Naive Bayes,Software defect prediction,Transfer learning},
month = mar,
number = {3},
pages = {248--256},
title = {{Transfer learning for cross-company software defect prediction}},
volume = {54},
year = {2012}
}
@article{Haiduc2013c,
abstract = {There are more than twenty distinct software engineering tasks addressed with text retrieval (TR) techniques, such as, traceability link recovery, feature location, refactoring, reuse, etc. A common issue with all TR applications is that the results of the retrieval depend largely on the quality of the query. When a query performs poorly, it has to be reformulated and this is a difficult task for someone who had trouble writing a good query in the first place. We propose a recommender (called Refoqus) based on machine learning, which is trained with a sample of queries and relevant results. Then, for a given query, it automatically recommends a reformulation strategy that should improve its performance, based on the properties of the query. We evaluated Refoqus empirically against four baseline approaches that are used in natural language document retrieval. The data used for the evaluation corresponds to changes from five open source systems in Java and C++ and it is used in the context of TR-based concept location in source code. Refoqus outperformed the baselines and its recommendations lead to query performance improvement or preservation in 84\% of the cases (in average).},
author = {Haiduc, Sonia and Bavota, Gabriele and Marcus, Andrian and Oliveto, Rocco and {De Lucia}, Andrea and Menzies, Tim},
doi = {10.1109/ICSE.2013.6606630},
file = {:Users/timm/svns/doc/13query.pdf:pdf},
isbn = {9781467330763},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
keywords = {Query Reformulation,Text Retrieval},
pages = {842--851},
title = {{Automatic query reformulations for text retrieval in software engineering}},
year = {2013}
}
@inproceedings{me03r,
abstract = { Model-based software has become quite popular in recent years, making its way into a broad range of areas, including the aerospace industry. The models provide an easy graphical interface to develop systems, which can generate the sometimes tedious code that follows. While there are many tools available to assess standard procedural code, there are limits to the testing of model-based systems. A major problem with the models are that their internals often contain gray areas of unknown system behavior. These possible behaviors form what is known as a data cloud, which is an overwhelming range of possibilities of a system that can overload analysts (Menzies et al., 2003). With large data clouds, it is hard to demonstrate which particular decision leads to a particular outcome. Even if definite decisions can't be made, it is possible to reduce the variance of and condense the clouds (Menzies et al., 2003). This paper presents two case studies; one with a simple illustrative model and another with a more complex application. The TAR3 treatment learning tool summarizes the particular attribute ranges that selects for particular behaviors of interest, reducing the data clouds.},
author = {Geletko, D. and Menzies, T.},
booktitle = {28th Annual NASA Goddard Software Engineering Workshop, 2003. Proceedings.},
doi = {10.1109/SEW.2003.1270729},
isbn = {0-7695-2064-2},
month = dec,
title = {{Model-based software testing via incremental treatment learning}},
year = {2003}
}
@inproceedings{me91b,
author = {Menzies, T J},
booktitle = {IJCAI '91 Knowledge Acquisition Workshop},
title = {{Concerning the User of Procedural Construct as a Knowledge Acquisition Technique}},
year = {1991}
}
@inproceedings{me08c,
abstract = {Most process models calibrate their internal settings using historical data. Collecting this data is expensive, tedious, and often an incomplete process. Is it possible to make accurate software process estimates without historical data? Suppose much of uncertainty in a model comes from a small subset of the model variables. If so, then after (a) ranking variables by their ability to constrain the output; and (b) applying a small number of the top-ranked variables; then it should be possible to (c) make stable predictions in the constrained space. To test that hypothesis, we combined a simulated annealer (to generate random solutions) with a variable ranker. The results where quite dramatic: in one of the studies in this paper, we found process options that reduced the median and variance of the effort estimates by a factor of 20. In ten case studies, we show that the estimates generated in this manner are usually similar to those produced by standard local calibration. Our conclusion is that while it is always preferable to tune models to local data, it is possible to learn process control options without that data. Â© 2008 Springer-Verlag Berlin Heidelberg.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/08icsp.pdf\}},
author = {Menzies, Tim and Elrawas, Oussama and Boehm, Barry and Madachy, Raymond and Hihn, Jairus and Baker, Daniel and Lum, Karen},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-540-79588-9\_19},
isbn = {3540795871},
issn = {03029743},
pages = {210--221},
title = {{Accurate estimates without calibration?}},
volume = {5007 LNCS},
year = {2008}
}
@article{Hea,
archivePrefix = {arXiv},
arxivId = {arXiv:1411.4228v1},
author = {He, Peng and Li, Bing and Ma, Y},
eprint = {arXiv:1411.4228v1},
file = {:Users/timm/svns/doc/transfer/ 14CPDPifs.pdf:pdf},
journal = {arXiv preprint arXiv:1411.4228},
keywords = {-cross-project defect prediction,learning technique,software metric,software quality},
title = {{Towards Cross-Project Defect Prediction with Imbalanced Feature Sets}},
url = {http://arxiv.org/abs/1411.4228},
year = {2014}
}
@inproceedings{me98e,
author = {Menzies, T J and Waugh, S},
booktitle = {Proceedings Pacific Knowledge Acquisition Workshop, Singapore, November, 1998},
title = {{More Results on the Practical Lower Limits of Test Set Size}},
year = {1998}
}
@article{Fenton99,
abstract = {The history of software metrics is almost as old as the history of software engineering. Yet, the extensive research and literature on the subject has had little impact on industrial practice. This is worrying given that the major rationale for using metrics is to improve the software engineering decision making process from a managerial and technical perspective. Industrial metrics activity is invariably based around metrics that have been around for nearly 30 years (notably Lines of Code or similar size counts, and defects counts). While such metrics can be considered as massively successful given their popularity, their limitations are well known, and mis-applications are still common. The major problem is in using such metrics in isolation. We argue that it is possible to provide genuinely improved management decision support systems based on such simplistic metrics, but only by adopting a less isolationist approach. Specifically, we feel it is important to explicitly model: (a) cause and effect relationships and (b) uncertainty and combination of evidence. Our approach uses Bayesian Belief nets, which are increasingly seen as the best means of handling decision-making under uncertainty. The approach is already having an impact in Europe.},
address = {New York, NY, USA},
author = {Fenton, Norman E. and Neil, Martin},
doi = {10.1016/S0164-1212(99)00035-7},
isbn = {0164-1212},
issn = {01641212},
journal = {Journal of Systems and Software},
month = jul,
number = {2},
pages = {149--157},
pmid = {21435355},
publisher = {Elsevier Science Inc.},
title = {{Software metrics: successes, failures and new directions}},
url = {http://dx.doi.org/10.1016/S0164-1212(99)00035-7},
volume = {47},
year = {1999}
}
@inproceedings{raffo05c,
author = {Raffo, D and Menzies, T},
booktitle = {Proceedings of the 6th International Workshop on Software Process Simulation Modeling (ProSim'05)},
title = {{Evaluating the Impact of a New Technology Using Simulation: The Case for Mining Software Repositories}},
year = {2005}
}
@inproceedings{sayyad13c,
author = {Sayyad, Abdel and Ammar, Hany},
booktitle = {RAISE'13, San Fransisco},
month = may,
title = {{Pareto-Optimal Search-Based Software Engineering (POSBSE): A Literature Survey}},
year = {2013}
}
@article{Journal2010a,
author = {Journal, C I S},
file = {:Users/timm/svns/doc/cost/11Vahid.pdf:pdf},
keywords = {- cost estimation,accuracy,cocomo,project fail},
number = {1},
pages = {21--29},
title = {{Software Cost Estimation Methods : A Review}},
volume = {2},
year = {2010}
}
@article{Paslay2010a,
abstract = {High throughput screening (HTS) has become the cornerstone of lead identification for small molecules in drug discovery during the last quarter century. The evolution of the sciences and technologies that have evolved as the foundation of modern HTS campaigns are complex and require multidisciplinary interactions. Innovations in integrated automated systems, reagent systems enabled by molecular biology, computational capabilities, and visualization tools have converged to provide sophisticated tools to HTS practitioners. The success of HTS in an organi- zation does not rest solely with those performing HTS but is critically dependent on the interactions of biology and chemistry members of the multidisciplinary teams throughout the early discovery process. Thus a basic knowledge and understanding of the components and processes of HTS is a necessary requirement for effective communication in planning, executing, and analyzing an HTS campaign. This chapter addresses the key components of HTS campaigns, common approaches, and related issues that should be understood by those engaged in small molecule drug discovery.},
author = {Paslay, Jw and Morin, Je and Harrison, Rk},
doi = {10.1007/7355},
file = {:Users/timm/svns/doc/erin/references/VirtualScreening/Bikker2009.pdf:pdf},
journal = {Topics in Medicinal Chemistry},
keywords = {assay development,automation,data management,high throughput,screening,statistics},
pages = {25--83},
title = {{High Throughput Screening in the Twenty-First Century}},
url = {http://link.springer.com/chapter/10.1007/7355\_2009\_6},
volume = {5},
year = {2010}
}
@inproceedings{ocinneide12,
author = {{\'{O} Cinn\'{e}ide}, Mel and Tratt, Laurence and Harman, Mark and Counsell, Steve and {Hemati Moghadam}, Iman},
booktitle = {Proceedings of the ACM-IEEE international symposium on Empirical software engineering and measurement - ESEM '12},
doi = {10.1145/2372251.2372260},
isbn = {9781450310567},
issn = {1938-6451},
pages = {49},
series = {ESEM '12},
title = {{Experimental assessment of software metrics using automated refactoring}},
url = {http://dl.acm.org/citation.cfm?doid=2372251.2372260},
year = {2012}
}
@inproceedings{me00f,
abstract = {Modern software is often constructed using \&amp;ldquo;spiral
specification\&amp;rdquo;; i.e. the specification is a dynamic document that
is altered by experience with the current version of the system.
Mathematically, many of the sub-tasks within spiral specification belong
to the NP-complete class of tasks. In the traditional view of computer
science, such tasks are fundamentally intractable and only solvable
using incomplete, approximate methods that can be undependable. This
traditional view suggests that we should routinely expect spiral
specification to always be performed very poorly. This paper is an
antidote to such pessimism. Contrary to the traditional view, we can
expect that spiral specification can usually be performed adequately,
providing that analysts augment their current tools with random probing
},
author = {Menzies, T.},
booktitle = {Tenth International Workshop on Software Specification and Design. IWSSD-10 2000},
doi = {10.1109/IWSSD.2000.891157},
isbn = {0-7695-0884-7},
title = {{The complexity of TRMCS-like spiral specification}},
year = {2000}
}
@article{peters12a,
abstract = {Background: Cross-company defect prediction (CCDP) is a field of study where an organization lacking enough local data can use data from other organizations for building defect predictors. To support CCDP, data must be shared. Such shared data must be privatized, but that privatization could severely damage the utility of the data. Aim: To enable effective defect prediction from shared data while preserving privacy. Method: We explore privatization algorithms that maintain class boundaries in a dataset. CLIFF is an instance pruner that deletes irrelevant examples. MORPH is a data mutator that moves the data a random distance, taking care not to cross class boundaries. CLIFF+MORPH are tested in a CCDP study among 10 defect datasets from the PROMISE data repository. Results: We find: 1) The CLIFFed+MORPHed algorithms provide more privacy than the state-of-the-art privacy algorithms; 2) in terms of utility measured by defect prediction, we find that CLIFF+MORPH performs significantly better. Conclusions: For the OO defect data studied here, data can be privatized and shared without a significant degradation in utility. To the best of our knowledge, this is the first published result where privatization does not compromise defect prediction. [ABSTRACT FROM AUTHOR]},
author = {Peters, Fayola and Menzies, Tim and Gong, Liang and Zhang, Hongyu},
doi = {10.1109/TSE.2013.6},
isbn = {0098-5589 VO  - 39},
issn = {00985589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Privacy,classification,defect prediction},
month = aug,
number = {8},
pages = {1054--1068},
title = {{Balancing privacy and utility in cross-company defect prediction}},
volume = {39},
year = {2013}
}
@article{me99q,
abstract = {Small-scale software projects usually can't afford to implement
time-consuming and expensive tests. However, the authors show that, in a
surprisingly large number of cases, a small number of randomly selected
tests will adequately probe the software},
author = {Menzies, T. and Gukic, B.},
doi = {10.1109/52.877876},
issn = {0740-7459},
journal = {IEEE Software},
number = {5},
pages = {107--112},
title = {{When to test less [software testing]}},
volume = {17},
year = {2000}
}
@inproceedings{me01e,
abstract = { Software management oracles often contain numerous subjective features. At each subjective point, a range of behaviors is possible. Stochastic simulation samples a subset of the possible behaviors. After many such stochastic simulations, the TAR2 treatment learner can find control actions that have (usually) the same impact despite the subjectivity of the oracle.},
author = {Menzies, T. and Kiper, J.D.},
booktitle = {Proceedings 16th Annual International Conference on Automated Software Engineering (ASE 2001)},
doi = {10.1109/ASE.2001.989836},
isbn = {0-7695-1426-X},
issn = {1527-1366},
title = {{Better reasoning about software engineering activities}},
year = {2001}
}
@article{Kaiser2008a,
abstract = {Over the last decade, bicluster methods have become more and more popular in different fields of two way data analysis and a wide variety of algorithms and analysis methods have been published. In this paper we introduce the R package $\backslash$verb1\{1$\backslash$tt biclust$\backslash$verb1\}1, which contains a collection of bicluster algorithms, preprocessing methods for two way data, and validation and visualization techniques for bicluster results. For the first time, such a package is provided on a platform like R, where data analysts can easily add new bicluster algorithms and adapt them to their special needs.},
author = {Kaiser, Sebastian and Leisch, Friedrich},
file = {:Users/timm/svns/doc/erin/references/SubspaceClustering/S\_Kaiser\_biclust.pdf:pdf},
isbn = {978-3-7908-2083-6},
journal = {Compstat 2008---Proceedings in Computational Statistics},
keywords = {biclustering,compstat 2008-proceedings in computational,has been accepted for,of an article which,r,software,statistics,the,this is a pre-print,two-way-clustering},
number = {028},
pages = {201--208},
title = {{A Toolbox for Bicluster Analysis in \{R\}}},
year = {2008}
}
@article{Li2008,
abstract = {Estimation by analogy (EBA) predicts effort for a new project by aggregating effort information of similar projects from a given historical data set. Existing research results have shown that a careful selection and weighting of attributes may improve the performance of the estimation methods. This paper continues along that research line and considers weighting of attributes in order to improve the estimation accuracy. More specifically, the impact of weighting (and selection) of attributes is studied as extensions to our former EBA method AQUA, which has shown promising results and also allows estimation in the case of data sets that have non-quantitative attributes and missing values. The new resulting method is called AQUA+. For attribute weighting, a qualitative analysis pre-step using rough set analysis (RSA) is performed. RSA is a proven machine learning technique for classification of objects. We exploit the RSA results in different ways and define four heuristics for attribute weighting. AQUA+ was evaluated in two ways: (1) comparison between AQUA+ and AQUA, along with the comparative analysis between the proposed four heuristics for AQUA+, (2) comparison of AQUA + with other EBA methods. The main evaluation results are: (1) better estimation accuracy was obtained by AQUA+ compared to AQUA over all six data sets; and (2) AQUA+ obtained better results than, or very close to that of other EBA methods for the three data sets applied to all the EBA methods. In conclusion, the proposed attribute weighing method using RSA can improve the estimation accuracy of EBA method AQUA+ according to the empirical studies over six data sets. Testing more data sets is necessary to get results that are more statistical significant. Â© 2007 Springer Science+Business Media, LLC.},
author = {Li, Jingzhou and Ruhe, Guenther},
doi = {10.1007/s10664-007-9054-4},
isbn = {1066400790544},
issn = {13823256},
journal = {Empirical Software Engineering},
keywords = {Attribute weighting,Effort estimation by analogy,Feature selection,Heuristics,Learning,Rough set analysis},
month = feb,
number = {1},
pages = {63--96},
title = {{Analysis of attribute weighting heuristics for analogy-based software effort estimation method AQUA+}},
volume = {13},
year = {2008}
}
@article{keung12,
abstract = {Background: Conclusion Instability in software effort estimation (SEE) refers to the inconsistent results produced by a diversity of predictors using different datasets. This is largely due to the âranking instabilityâ problem, which is highly related to the evaluation criteria and the subset of the data being used. Aim: To determine stable rankings of different predictors. Method: 90 predictors are used with 20 datasets and evaluated using 7 performance measures, whose results are subject to Wilcoxon rank test (95 \%). These results are called the âaggregate resultsâ. The aggregate results are challenged by a sanity check, which focuses on a single error measure (MRE) and uses a newly developed evaluation algorithm called CLUSTER. These results are called the âspecific results.â Results: Aggregate results show that: (1) It is now possible to draw stable conclusions about the relative performance of SEE predictors; (2) Regression trees or analogy-based methods are the best performers. The aggregate results are also confirmed by the specific results of the sanity check. Conclusion: This study offers means to address the conclusion instability issue in SEE, which is an important finding for empirical software engineering.},
author = {Keung, Jacky and Kocaguneli, Ekrem and Menzies, Tim},
doi = {10.1007/s10515-012-0108-5},
issn = {09288910},
journal = {Automated Software Engineering},
keywords = {Analogy,Data mining,Effort estimation,Evaluation criteria,Linear regression,MMRE,Neural nets,Regression trees,Stability},
month = may,
number = {4},
pages = {543--567},
title = {{Finding conclusion stability for selecting the best effort predictor in software effort estimation}},
volume = {20},
year = {2013}
}
@article{Baum2011a,
abstract = {Methods to measure the sequence diversity of polymerase chain reaction (PCR)-amplified DNA lack standards for use as assay calibrators and controls. Here we present a general and economical method for developing customizable DNA standards of known sequence diversity. Standards ranging from 1 to 25,000 sequences were generated by directional ligation of oligonucleotide "words" of standard length and GC content and then amplified by PCR. The sequence accuracy and diversity of the library were validated using AmpliCot analysis (DNA hybridization kinetics) and Illumina sequencing. The library has the following features: (i) pools containing tens of thousands of sequences can be generated from the ligation of relatively few commercially synthesized short oligonucleotides; (ii) each sequence differs from all others in the library at a minimum of three nucleotide positions, permitting discrimination between different sequences by either sequencing or hybridization; (iii) all sequences have identical length, GC content, and melting temperature; (iv) the identity of each standard can be verified by restriction digestion; and (v) once made, the ends of the library may be cleaved and replaced with sequences to match any PCR primer pair. These standards should greatly improve the accuracy and reproducibility of sequence diversity measurements. ?? 2010 Elsevier Inc. All rights reserved.},
author = {Baum, Paul D. and Young, Jennifer J. and Zhang, Qianjun and Kasakow, Zeljka and McCune, Joseph M.},
doi = {10.1016/j.ab.2010.11.035},
file = {:Users/timm/svns/doc/erin/references/SelexLiterature/Baum11.pdf:pdf},
issn = {00032697},
journal = {Analytical Biochemistry},
keywords = {AmpliCot,Diversity,Ligation,PCR,Sequence,Standards},
number = {1},
pages = {106--115},
pmid = {21111699},
publisher = {Elsevier Inc.},
title = {{Design, construction, and validation of a modular library of sequence diversity standards for polymerase chain reaction}},
url = {http://dx.doi.org/10.1016/j.ab.2010.11.035},
volume = {411},
year = {2011}
}
@inproceedings{menzies12,
abstract = {Gaming companies now routinely apply data mining to their user data in order to plan the next release of their software. We predict that such software development analytics will become commonplace, in the near future. For example, as large software systems migrate to the cloud, they are divided and sold as dozens of smaller apps; when shopping inside the cloud, users are free to mix and match their apps from multiple vendors (e.g. Google Docs' word processor with Zoho's slide manager); to extend, or even retain, market share cloud vendors must mine their user data in order to understand what features best attract their clients. This panel will address the open issues with analytics. Issues addressed will include the following. What is the potential for software development analytics? What are the strengths and weaknesses of the current generation of analytics tools? How best can we mature those tools?},
author = {Menzies, Tim and Zimmermann, Thomas},
booktitle = {Proceedings - International Conference on Software Engineering},
doi = {10.1109/ICSE.2012.6227117},
isbn = {9781467310673},
issn = {02705257},
keywords = {analytics,empirical software engineering,industry,mining software repositories},
pages = {1032--1033},
title = {{Goldfish bowl panel: Software development analytics}},
year = {2012}
}
@article{Vargha00,
abstract = {McGraw and Wong (1992) described an appealing index of effect size, called CL, which measures the difference between two populations in terms of the probability that a score sampled at random from the first population will be greater than a score sampled at random from the second. McGraw and Wong introduced this "common language effect size statistic" for normal distributions and then proposed an approximate estimation for any continuous distribution. In addition, they generalized CL to the n-group case, the correlated samples case, and the discrete values case. In the current paper a different generalization of CL, called the A measure of stochastic superiority, is proposed, which may be directly applied for any discrete or continuous variable that is at least ordinally scaled. Exact methods for point and interval estimation as well as the significance tests of the A = .5 hypothesis are provided. New generalizations ofCL are provided for the multi-group and correlated samples cases.},
author = {Vargha, a. and Delaney, H. D.},
doi = {10.3102/10769986025002101},
file = {:Users/timm/svns/doc/00varghaEffectSize.pdf:pdf},
isbn = {1076-9986},
issn = {1076-9986},
journal = {Journal of Educational and Behavioral Statistics},
number = {2},
pages = {101--132},
title = {{A Critique and Improvement of the CL Common Language Effect Size Statistics of McGraw and Wong}},
volume = {25},
year = {2000}
}
@inproceedings{me97e,
author = {M.Posterma and Wu, X and Menzies, T J},
booktitle = {First Pacific Asia Conference on Knowledge Discovery and Data Mining (PAKDD97)},
title = {{A Tuning Aid for Discretization in Rule Induction}},
year = {1997}
}
@article{webb09,
abstract = {This paper gives a survey of contrast set mining (CSM), emerging pattern mining (EPM), and subgroup
discovery (SD) in a unifying framework named supervised descriptive rule discovery. While
all these research areas aim at discovering patterns in the form of rules induced from labeled data,
they use different terminology and task definitions, claim to have different goals, claim to use different
rule learning heuristics, and use different means for selecting subsets of induced patterns.
This paper contributes a novel understanding of these subareas of data mining by presenting a unified
terminology, by explaining the apparent differences between the learning tasks as variants of
a unique supervised descriptive rule discovery task and by exploring the apparent differences between
the approaches. It also shows that various rule learning heuristics used in CSM, EPMand SD
algorithms all aim at optimizing a trade off between rule coverage and precision. The commonalities
(and differences) between the approaches are showcased on a selection of best known variants
of CSM, EPM and SD algorithms. The paper also provides a critical survey of existing supervised
descriptive rule discovery visualization methods.},
author = {Kralj, Petra and Lavrac, Nada and Webb, Geoff},
doi = {10.1145/1577069.1577083},
isbn = {1532-4435},
issn = {15324435},
journal = {J. Mach. Learn. Res.},
keywords = {Theory \& Algorithms},
month = jun,
pages = {377--403},
title = {{Supervised Descriptive Rule Discovery: A Unifying Survey of Contrast Set, Emerging Pattern and Subgroup Mining}},
url = {http://eprints.pascal-network.org/archive/00005127/},
volume = {10},
year = {2009}
}
@inproceedings{me97q,
author = {Menzies, T J},
booktitle = {Banff KA '98 workshop.},
title = {{Evaluation Issues with Critical Success Metrics}},
year = {1998}
}
@inproceedings{me01h,
author = {Menzies, T and Hu, Y},
booktitle = {Agent Technology from a Formal Perspective},
editor = {Rouff, C and Hinchey, M and Rash, J and Truszkowski, W and Gordon-Spears, D},
isbn = {1-85233-947-0},
publisher = {Springer},
title = {{Agents in a Wild World}},
year = {2006}
}
@article{Mining2009a,
abstract = {During the past decade there has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book descibes theimprtant ideas in these areas ina common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a vluable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learing (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting-the first comprehensive treatment of this topic in any book. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie wrote much of the statistical modeling software in S-PLUS and invented principal curves and surfaces. Tibshirani proposed the Lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, and projection pursuit.},
author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
doi = {10.1007/b94608},
file = {:Users/timm/svns/doc/elementsOfStatisticalLearning.pdf:pdf},
isbn = {0387952845},
issn = {00111287},
journal = {Springer 2001},
number = {4},
pages = {746},
pmid = {15512507},
title = {{The Elements of Statistical Learning}},
url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0387952845},
volume = {18},
year = {2009}
}
@inproceedings{wagner07,
author = {Wagner, T and Beume, N and Naujoks, B},
title = {{No Title}}
}
@article{Li2006c,
author = {Li, Wentian},
doi = {10.1093/bioinformatics/btl189},
file = {:Users/timm/svns/doc/erin/references/Simplicity/Li06.pdf:pdf},
issn = {13674803},
journal = {Bioinformatics},
number = {18},
pages = {2187--2188},
pmid = {16957134},
title = {{The-more-the-better and the-less-the-better}},
volume = {22},
year = {2006}
}
@misc{boehm09,
author = {Boehm, B},
title = {{Keynote address, PROMISE'09}},
year = {2009}
}
@article{Das2011a,
abstract = {Differential evolution (DE) is arguably one of the most powerful stochastic real-parameter optimization algorithms in current use. DE operates through similar computational steps as employed by a standard evolutionary algorithm (EA). However, unlike traditional EAs, the DE-variants perturb the current-generation population members with the scaled differences of randomly selected and distinct population members. Therefore, no separate probability distribution has to be used for generating the offspring. Since its inception in 1995, DE has drawn the attention of many researchers all over the world resulting in a lot of variants of the basic algorithm with improved performance. This paper presents a detailed review of the basic concepts of DE and a survey of its major variants, its application to multiobjective, constrained, large scale, and uncertain optimization problems, and the theoretical studies conducted on DE so far. Also, it provides an overview of the significant engineering applications that have benefited from the powerful nature of DE.},
author = {Das, Swagatam and Suganthan, Ponnuthurai Nagaratnam},
doi = {10.1109/TEVC.2010.2059031},
file = {:Users/timm/svns/doc/11de-state-of-the-art.pdf:pdf},
isbn = {1089-778X VO  - 15},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Derivative-free optimization,differential evolution (DE),direct search,evolutionary algorithms (EAs),genetic algorithms (GAs),metaheuristics,particle swarm optimization (PSO)},
number = {1},
pages = {4--31},
title = {{Differential evolution: A survey of the state-of-the-art}},
volume = {15},
year = {2011}
}
@article{me08a,
abstract = {Abstract  After data mining National Aeronautics and Space Administration (NASA) independent verification and validation (IV\&V) data,$\backslash$n  we offer (a) an early life cycle predictor for project issue frequency and severity; (b) an IV\&V task selector (that used$\backslash$n  the predictor to find the appropriate IV\&V tasks); and (c) pruning heuristics describing what tasks to ignore, if the budget$\backslash$n  cannot accommodate all selected tasks. In ten-way cross-validation experiments, the predictor performs very well indeed: the$\backslash$n  average f-measure for predicting four classes of issue severity was over 0.9. This predictor is built using public-domain data and$\backslash$n  software. To the best of our knowledge, this is the first reproducible report of a predictor for issue frequency and severity$\backslash$n  that can be applied early in the life cycle.},
annote = {Available from $\backslash$url\{http://menzies.us/pdf/07ivv.pdf\}},
author = {Menzies, Tim and Benson, Markland and Costello, Ken and Moats, Christina and Northey, Melissa and Richardson, Julian},
doi = {10.1007/s11334-008-0046-3},
issn = {16145046},
journal = {Innovations in Systems and Software Engineering},
keywords = {Data mining,Early life cycle defect prediction,IV\&V,NASA},
month = mar,
number = {2},
pages = {169--183},
title = {{Learning better IV\&V practices}},
volume = {4},
year = {2008}
}
@inproceedings{me97p,
author = {Menzies, T J},
booktitle = {The Second Australian Workshop on Requirements Engineering (AWRE'97)},
title = {{Qualitative Causal Diagrams for Requirements Engineering}},
year = {1997}
}
@inproceedings{meedng92,
author = {Menzies, T J and Edwards, J and Ng, K},
booktitle = {Tools Pacific 1992},
pages = {421--428},
publisher = {Prentice Hall},
title = {{The \{M\}ysterious \{C\}ase of the \{M\}issing \{R\}e-usable \{C\}lass \{L\}ibraries}},
year = {1992}
}
@inproceedings{me01h,
author = {Menzies, T and Hu, Y},
booktitle = {Agent Technology from a Formal Perspective},
editor = {Rouff, C and Hinchey, M and Rash, J and Truszkowski, W and Gordon-Spears, D},
isbn = {1-85233-947-0},
publisher = {Springer},
title = {{Agents in a Wild World}},
year = {2006}
}
@article{deb14,
abstract = {Having developed multi-objective optimization algorithms using evolutionary optimization methods and demonstrated their niche on various practical problems involving mostly two and three objectives, there is now a growing need for developing evolutionary multi-objective optimization (EMO) algorithms for handling many-objective (having four or more objectives) optimization problems. In this paper, we recognize a few recent efforts and discuss a number of viable directions for developing a potential EMO algorithm for solving many-objective optimization problems. Thereafter, we suggest a reference-point based many-objective NSGA-II (we call it NSGA-III) that emphasizes population members which are non-dominated yet close to a set of supplied reference points. The proposed NSGA-III is applied to a number of many-objective test problems having two to 15 objectives and compared with two versions of a recently suggested EMO algorithm (MOEA/D). While each of the two MOEA/D methods works well on different classes of problems, the proposed NSGA-III is found to produce satisfactory results on all problems considered in this study. This paper presents results on unconstrained problems and the sequel paper considers constrained and other specialties in handling many-objective optimization problems.},
author = {Deb, Kalyanmoy and Jain, Himanshu},
doi = {10.1109/TEVC.2013.2281534},
file = {:Users/timm/svns/doc/13nsga-III.pdf:pdf},
isbn = {1089-778X},
issn = {1089-778X},
journal = {Ieeexplore.Ieee.Org},
keywords = {genetic algorithms;sorting;EMO algorithms;MOEA/D m},
month = aug,
number = {c},
pages = {1--1},
title = {{An Evolutionary Many-Objective Optimization Algorithm Using Reference-point Based Non-dominated Sorting Approach, Part I: Solving Problems with Box Constraints}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6600851$\backslash$nhttp://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6600851},
volume = {18},
year = {2013}
}
@inproceedings{me03d,
author = {Gunnalan, Rajesh and Us, T I M Menzies and Appukutty, Kalaivani},
title = {{Feature Subset Selection with TAR2less}},
year = {2003}
}
@article{Kim2010a,
author = {Kim, Sangkyum and Kim, Hyungsul and Weninger, Tim and Han, Jiawei},
doi = {10.1145/1816112.1816121},
file = {:Users/timm/svns/doc/erin/references/AssociationRules/kim10.pdf:pdf},
isbn = {9781450302166},
journal = {Proceedings of the ACM SIGKDD Workshop on Useful Patterns - UP '10},
keywords = {authorship classification,closed pattern,discriminative pattern,pattern,text categoriza-,text categorization,text mining,tion},
pages = {65--73},
title = {{Authorship classification}},
url = {http://dl.acm.org/citation.cfm?id=1816112.1816121},
year = {2010}
}
